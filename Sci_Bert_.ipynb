{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sci_Bert_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xahram/Sci-Bert/blob/main/Sci_Bert_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First step is to load the NIPS data that is uploaded in the Google Drive"
      ],
      "metadata": {
        "id": "oPZ9rjzVQFYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive folder into the directory to access files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmrUd6BcBAKB",
        "outputId": "612301d5-e328-4971-bd6f-bbd929663035"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import time \n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YZGpDT8-BrZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a35db22-c8fb-4d58-afb6-42ee13935c83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the NIPS dataset from the drive\n",
        "\n",
        "nips_papers_df = pd.read_csv('/gdrive/My Drive/Master_dataset/papers.csv')  \n",
        "nips_papers_df.head()\n",
        "\n",
        "nips_papers = nips_papers_df.infer_objects()\n",
        "\n",
        "nips_papers.dtypes\n",
        "\n",
        "nips_papers[\"year\"] = pd.to_datetime(nips_papers[\"year\"], format=\"%Y\")\n",
        "# nips_papers['year'] = nips_papers['year'].dt.year\n",
        "nips_papers.sort_values(by='year')\n",
        "\n",
        "print(nips_papers.dtypes)\n",
        "\n",
        "max(nips_papers[\"year\"])\n",
        "min(nips_papers[\"year\"])\n",
        "\n",
        "nips_papers = nips_papers.sort_values(by = \"year\")\n"
      ],
      "metadata": {
        "id": "z0H4P5yIBexP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06df5c09-d4b7-4fe6-f46a-bc1b206a84f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                     int64\n",
            "year          datetime64[ns]\n",
            "title                 object\n",
            "event_type            object\n",
            "pdf_name              object\n",
            "abstract              object\n",
            "paper_text            object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import close\n",
        "# Slice Data Frame by 3 year interval\n",
        "\n",
        "\n",
        "# print(len(nips_papers))\n",
        "\n",
        "# Partition/Group Papers into df by the interval/freq of 3 years, closed = left to start combinbing from the 1987\n",
        "nips_papers_3y_grouped = nips_papers.groupby(pd.Grouper(key='year', freq='3Y', sort=True, closed=\"left\"))\n",
        "\n",
        "\n",
        "\n",
        "# Save partitions in the Dictionary format with 10 intervals\n",
        "nips_papers_partitions = {}\n",
        "initial_partition_id = 0\n",
        "for i, g  in nips_papers_3y_grouped:\n",
        "    nips_papers_partitions[initial_partition_id] = g\n",
        "    initial_partition_id = initial_partition_id + 1\n",
        "\n",
        "\n",
        "print(nips_papers_partitions)\n",
        "# nips_papers_three_year_partition[0].tail()\n",
        "\n",
        "\n",
        "#for i, g in nips_papers.groupby(pd.Grouper(key=nips_papers[\"year\"], freq='A')):\n",
        "#     print(g)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4A_aWwViSXFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fec302-f044-4cf9-d861-7dd2c8d516df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0:        id       year                                              title  \\\n",
            "0       1 1987-01-01  Self-Organization of Associative Database and ...   \n",
            "328    13 1987-01-01   Temporal Patterns of Activity in Neural Networks   \n",
            "6853   72 1987-01-01  Ensemble' Boltzmann Units have Collective Comp...   \n",
            "6743   71 1987-01-01  Centric Models of the Orientation Map in Prima...   \n",
            "6632   70 1987-01-01  On the Power of Neural Networks for Solving Ha...   \n",
            "...   ...        ...                                                ...   \n",
            "1650  250 1989-01-01                               Optimal Brain Damage   \n",
            "1661  251 1989-01-01  A Self-organizing Associative Memory System fo...   \n",
            "1672  252 1989-01-01  Can Simple Cells Learn Curves? A Hebbian Model...   \n",
            "1683  253 1989-01-01  Subgrouping Reduces Complexity and Speeds Up L...   \n",
            "1638  249 1989-01-01  Neural Network Analysis of Distributed Represe...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "0           NaN  1-self-organization-of-associative-database-an...   \n",
            "328         NaN  13-temporal-patterns-of-activity-in-neural-net...   \n",
            "6853        NaN  72-ensemble-boltzmann-units-have-collective-co...   \n",
            "6743        NaN  71-centric-models-of-the-orientation-map-in-pr...   \n",
            "6632        NaN  70-on-the-power-of-neural-networks-for-solving...   \n",
            "...         ...                                                ...   \n",
            "1650        NaN                       250-optimal-brain-damage.pdf   \n",
            "1661        NaN  251-a-self-organizing-associative-memory-syste...   \n",
            "1672        NaN  252-can-simple-cells-learn-curves-a-hebbian-mo...   \n",
            "1683        NaN  253-subgrouping-reduces-complexity-and-speeds-...   \n",
            "1638        NaN  249-neural-network-analysis-of-distributed-rep...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
            "328   Abstract Missing  297\\n\\nTEMPORAL PATTERNS OF ACTIVITY IN\\nNEURA...  \n",
            "6853  Abstract Missing  223\\n\\n'Ensemble' Boltzmann Units\\nhave Collec...  \n",
            "6743  Abstract Missing  62\\n\\nCentric Models of the Orientation Map in...  \n",
            "6632  Abstract Missing  137\\n\\nOn the Power of Neural Networks for\\nSo...  \n",
            "...                ...                                                ...  \n",
            "1650  Abstract Missing  598\\n\\nLe Cun, Denker and Solla\\n\\nOptimal Bra...  \n",
            "1661  Abstract Missing  332\\n\\nHormel\\n\\nA Sell-organizing Associative...  \n",
            "1672  Abstract Missing  Can Simple Cells Learn Curves? A Hebbian Model...  \n",
            "1683  Abstract Missing  638\\n\\nZipser\\n\\nSubgrouping Reduces Complexit...  \n",
            "1638  Abstract Missing  28\\n\\nLockery t Fang and Sejnowski\\n\\nNeu.?al ...  \n",
            "\n",
            "[285 rows x 7 columns], 1:        id       year                                              title  \\\n",
            "3212  391 1990-01-01  Designing Linear Threshold Based Neural Networ...   \n",
            "3401  408 1990-01-01                           Adaptive Spline Networks   \n",
            "3278  397 1990-01-01  Integrated Segmentation and Recognition of Han...   \n",
            "3390  407 1990-01-01         Convergence of a Neural Network Classifier   \n",
            "3245  394 1990-01-01  Chaitin-Kolmogorov Complexity and Generalizati...   \n",
            "...   ...        ...                                                ...   \n",
            "5946  638 1992-01-01  Network Structuring and Training Using Rule-ba...   \n",
            "5769  622 1992-01-01    Information, Prediction, and Query by Committee   \n",
            "5758  621 1992-01-01  Some Solutions to the Missing Feature Problem ...   \n",
            "5747  620 1992-01-01  Connected Letter Recognition with a Multi-Stat...   \n",
            "5802  625 1992-01-01  Visual Motion Computation in Analog VLSI Using...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3212        NaN  391-designing-linear-threshold-based-neural-ne...   \n",
            "3401        NaN                   408-adaptive-spline-networks.pdf   \n",
            "3278        NaN  397-integrated-segmentation-and-recognition-of...   \n",
            "3390        NaN  407-convergence-of-a-neural-network-classifier...   \n",
            "3245        NaN  394-chaitin-kolmogorov-complexity-and-generali...   \n",
            "...         ...                                                ...   \n",
            "5946        NaN  638-network-structuring-and-training-using-rul...   \n",
            "5769        NaN  622-information-prediction-and-query-by-commit...   \n",
            "5758        NaN  621-some-solutions-to-the-missing-feature-prob...   \n",
            "5747        NaN  620-connected-letter-recognition-with-a-multi-...   \n",
            "5802        NaN  625-visual-motion-computation-in-analog-vlsi-u...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "3212  Abstract Missing  Designing Linear Threshold Based Neural\\nNetwo...  \n",
            "3401  Abstract Missing  ADAPTIVE SPLINE NETWORKS\\n\\nJerome H. Friedman...  \n",
            "3278  Abstract Missing  Integrated Segmentation and Recognition of\\nHa...  \n",
            "3390  Abstract Missing  Convergence of a Neural Network Classifier\\n\\n...  \n",
            "3245  Abstract Missing  Chaitin-Kolmogorov Complexity\\nand Generalizat...  \n",
            "...                ...                                                ...  \n",
            "5946  Abstract Missing  Network Structuring And Training Using\\nRule-b...  \n",
            "5769  Abstract Missing  Information, prediction, and query by\\ncommitt...  \n",
            "5758  Abstract Missing  Some Solutions to the Missing Feature Problem\\...  \n",
            "5747  Abstract Missing  Connected Letter Recognition with a\\nMulti-Sta...  \n",
            "5802  Abstract Missing  Visual Motion Computation in Analog\\nVLSI usin...  \n",
            "\n",
            "[414 rows x 7 columns], 2:         id       year                                              title  \\\n",
            "7006   782 1993-01-01  Optimal Unsupervised Motor Learning Predicts t...   \n",
            "7005   781 1993-01-01  A Comparison of Dynamic Reposing and Tangent D...   \n",
            "7004   780 1993-01-01         Dynamic Modulation of Neurons and Networks   \n",
            "7002   779 1993-01-01    Address Block Location with a Neural Net System   \n",
            "7001   778 1993-01-01  A Learning Analog Neural Network Chip with Con...   \n",
            "...    ...        ...                                                ...   \n",
            "69    1060 1995-01-01  Statistical Theory of Overtraining - Is Cross-...   \n",
            "63    1055 1995-01-01  Adaptive Retina with Center-Surround Receptive...   \n",
            "150   1135 1995-01-01               Information through a Spiking Neuron   \n",
            "62    1054 1995-01-01  Implementation Issues in the Fourier Transform...   \n",
            "65    1057 1995-01-01  When is an Integrate-and-fire Neuron like a Po...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "7006        NaN  782-optimal-unsupervised-motor-learning-predic...   \n",
            "7005        NaN  781-a-comparison-of-dynamic-reposing-and-tange...   \n",
            "7004        NaN  780-dynamic-modulation-of-neurons-and-networks...   \n",
            "7002        NaN  779-address-block-location-with-a-neural-net-s...   \n",
            "7001        NaN  778-a-learning-analog-neural-network-chip-with...   \n",
            "...         ...                                                ...   \n",
            "69          NaN  1060-statistical-theory-of-overtraining-is-cro...   \n",
            "63          NaN  1055-adaptive-retina-with-center-surround-rece...   \n",
            "150         NaN      1135-information-through-a-spiking-neuron.pdf   \n",
            "62          NaN  1054-implementation-issues-in-the-fourier-tran...   \n",
            "65          NaN  1057-when-is-an-integrate-and-fire-neuron-like...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "7006  Abstract Missing  Optimal Unsupervised Motor Learning\\nPredicts ...  \n",
            "7005  Abstract Missing  A Comparison of Dynamic Reposing and\\nTangent ...  \n",
            "7004  Abstract Missing  Dynamic Modulation of Neurons and Networks\\n\\n...  \n",
            "7002  Abstract Missing  Address Block Location with a Neural Net Syste...  \n",
            "7001  Abstract Missing  A Learning Analog Neural Network Chip\\nwith Co...  \n",
            "...                ...                                                ...  \n",
            "69    Abstract Missing  Statistical Theory of Overtraining - Is\\nCross...  \n",
            "63    Abstract Missing  Adaptive Retina with Center-Surround\\nReceptiv...  \n",
            "150   Abstract Missing  Information through a Spiking Neuron\\n\\nCharle...  \n",
            "62    Abstract Missing  Implementation Issues in the Fourier\\nTransfor...  \n",
            "65    Abstract Missing  When is an Integrate-and-fire Neuron\\nlike a P...  \n",
            "\n",
            "[450 rows x 7 columns], 3:        id       year                                              title  \\\n",
            "288  1263 1996-01-01  Training Algorithms for Hidden Markov Models u...   \n",
            "290  1265 1996-01-01  A Silicon Model of Amplitude Modulation Detect...   \n",
            "291  1266 1996-01-01  Learning Temporally Persistent Hierarchical Re...   \n",
            "289  1264 1996-01-01                       Hidden Markov Decision Trees   \n",
            "279  1255 1996-01-01  A Model of Recurrent Interactions in Primary V...   \n",
            "..    ...        ...                                                ...   \n",
            "534  1489 1998-01-01            A Neuromorphic Monaural Sound Localizer   \n",
            "536  1490 1998-01-01  Very Fast EM-Based Mixture Model Clustering Us...   \n",
            "537  1491 1998-01-01        Kernel PCA and De-Noising in Feature Spaces   \n",
            "538  1492 1998-01-01  Viewing Classifier Systems as Model Free Learn...   \n",
            "532  1487 1998-01-01  A Reinforcement Learning Algorithm in Partiall...   \n",
            "\n",
            "    event_type                                           pdf_name  \\\n",
            "288        NaN  1263-training-algorithms-for-hidden-markov-mod...   \n",
            "290        NaN  1265-a-silicon-model-of-amplitude-modulation-d...   \n",
            "291        NaN  1266-learning-temporally-persistent-hierarchic...   \n",
            "289        NaN              1264-hidden-markov-decision-trees.pdf   \n",
            "279        NaN  1255-a-model-of-recurrent-interactions-in-prim...   \n",
            "..         ...                                                ...   \n",
            "534        NaN   1489-a-neuromorphic-monaural-sound-localizer.pdf   \n",
            "536        NaN  1490-very-fast-em-based-mixture-model-clusteri...   \n",
            "537        NaN  1491-kernel-pca-and-de-noising-in-feature-spac...   \n",
            "538        NaN  1492-viewing-classifier-systems-as-model-free-...   \n",
            "532        NaN  1487-a-reinforcement-learning-algorithm-in-par...   \n",
            "\n",
            "             abstract                                         paper_text  \n",
            "288  Abstract Missing  Training Algorithms for Hidden Markov Models\\n...  \n",
            "290  Abstract Missing  A Silicon Model of\\nAmplitude Modulation Detec...  \n",
            "291  Abstract Missing  Learning temporally persistent\\nhierarchical r...  \n",
            "289  Abstract Missing  Hidden Markov decision trees\\nMichael I. Jorda...  \n",
            "279  Abstract Missing  A Model of Recurrent Interactions in\\nPrimary ...  \n",
            "..                ...                                                ...  \n",
            "534  Abstract Missing  A N euromorphic Monaural Sound\\nLocalizer\\nJoh...  \n",
            "536  Abstract Missing  Very Fast EM-based Mixture Model\\nClustering u...  \n",
            "537  Abstract Missing  Kernel peA and De-Noising in Feature Spaces\\n\\...  \n",
            "538  Abstract Missing  Viewing Classifier Systems\\nas Model Free Lear...  \n",
            "532  Abstract Missing  A Reinforcement Learning Algorithm\\nin Partial...  \n",
            "\n",
            "[453 rows x 7 columns], 4:         id       year                                              title  \\\n",
            "803   1735 1999-01-01                     Uniqueness of the SVM Solution   \n",
            "807   1739 1999-01-01  Algebraic Analysis for Non-regular Learning Ma...   \n",
            "804   1736 1999-01-01  Nonlinear Discriminant Analysis Using Kernel F...   \n",
            "805   1737 1999-01-01                                Potential Boosters?   \n",
            "781   1715 1999-01-01  Invariant Feature Extraction and Classificatio...   \n",
            "...    ...        ...                                                ...   \n",
            "1125  2026 2001-01-01  Modeling Temporal Structure in Classical Condi...   \n",
            "1126  2027 2001-01-01  TAP Gibbs Free Energy, Belief Propagation and ...   \n",
            "1128  2029 2001-01-01  Hyperbolic Self-Organizing Maps for Semantic N...   \n",
            "1121  2022 2001-01-01  Learning Lateral Interactions for Feature Bind...   \n",
            "1086  1992 2001-01-01         Spectral Relaxation for K-means Clustering   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "803         NaN            1735-uniqueness-of-the-svm-solution.pdf   \n",
            "807         NaN  1739-algebraic-analysis-for-non-regular-learni...   \n",
            "804         NaN  1736-nonlinear-discriminant-analysis-using-ker...   \n",
            "805         NaN                        1737-potential-boosters.pdf   \n",
            "781         NaN  1715-invariant-feature-extraction-and-classifi...   \n",
            "...         ...                                                ...   \n",
            "1125        NaN  2026-modeling-temporal-structure-in-classical-...   \n",
            "1126        NaN  2027-tap-gibbs-free-energy-belief-propagation-...   \n",
            "1128        NaN  2029-hyperbolic-self-organizing-maps-for-seman...   \n",
            "1121        NaN  2022-learning-lateral-interactions-for-feature...   \n",
            "1086        NaN  1992-spectral-relaxation-for-k-means-clusterin...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "803   Abstract Missing  Uniqueness of the SVM Solution\\n\\nChristopher ...  \n",
            "807   Abstract Missing  Algebraic Analysis for Non-Regular\\nLearning M...  \n",
            "804   Abstract Missing  Nonlinear Discriminant Analysis using\\nKernel ...  \n",
            "805   Abstract Missing  Potential Boosters ?\\nNigel Duffy\\nDepartment ...  \n",
            "781   Abstract Missing  U nmixing Hyperspectral Data\\n\\nLucas Parra, C...  \n",
            "...                ...                                                ...  \n",
            "1125  Abstract Missing  Modeling Temporal Structure in Classical\\nCond...  \n",
            "1126  Abstract Missing  TAP Gibbs Free Energy, Belief Propagation and\\...  \n",
            "1128  Abstract Missing  Hyperbolic Self-Organizing Maps for Semantic\\n...  \n",
            "1121  Abstract Missing  Learning Lateral Interactions for\\nFeature Bin...  \n",
            "1086  Abstract Missing  Spectral Relaxation for K-means\\nClustering\\n\\...  \n",
            "\n",
            "[499 rows x 7 columns], 5:         id       year                                              title  \\\n",
            "1319  2200 2002-01-01                 A Bilinear Model for Sparse Coding   \n",
            "1392  2267 2002-01-01  Data-Dependent Bounds for Bayesian Mixture Met...   \n",
            "1393  2268 2002-01-01  Shape Recipes: Scene Representations that Refe...   \n",
            "1394  2269 2002-01-01  Ranking with Large Margin Principle: Two Appro...   \n",
            "1396  2270 2002-01-01  An Estimation-Theoretic Framework for the Pres...   \n",
            "...    ...        ...                                                ...   \n",
            "1717  2560 2004-01-01                         Adaptive Manifold Learning   \n",
            "1718  2561 2004-01-01                       Dependent Gaussian Processes   \n",
            "1704  2549 2004-01-01  The Power of Selective Memory: Self-Bounded Le...   \n",
            "1719  2562 2004-01-01  Edge of Chaos Computation in Mixed-Mode VLSI -...   \n",
            "1713  2557 2004-01-01  Conditional Models of Identity Uncertainty wit...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "1319        NaN        2200-a-bilinear-model-for-sparse-coding.pdf   \n",
            "1392        NaN  2267-data-dependent-bounds-for-bayesian-mixtur...   \n",
            "1393        NaN  2268-shape-recipes-scene-representations-that-...   \n",
            "1394        NaN  2269-ranking-with-large-margin-principle-two-a...   \n",
            "1396        NaN  2270-an-estimation-theoretic-framework-for-the...   \n",
            "...         ...                                                ...   \n",
            "1717        NaN                2560-adaptive-manifold-learning.pdf   \n",
            "1718        NaN              2561-dependent-gaussian-processes.pdf   \n",
            "1704        NaN  2549-the-power-of-selective-memory-self-bounde...   \n",
            "1719        NaN  2562-edge-of-chaos-computation-in-mixed-mode-v...   \n",
            "1713        NaN  2557-conditional-models-of-identity-uncertaint...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "1319  Abstract Missing  A Bilinear Model for Sparse Coding\\n\\nDavid B....  \n",
            "1392  Abstract Missing  Data-Dependent Bounds for Bayesian\\nMixture Me...  \n",
            "1393  Abstract Missing  Shape Recipes: Scene Representations that Refe...  \n",
            "1394  Abstract Missing  Ranking with Large Margin Principle: Two\\nAppr...  \n",
            "1396  Abstract Missing  An Estimation-Theoretic Framework for\\nthe Pre...  \n",
            "...                ...                                                ...  \n",
            "1717  Abstract Missing  Adaptive Manifold Learning\\n\\nJing Wang, Zheny...  \n",
            "1718  Abstract Missing  Dependent Gaussian Processes\\n\\nPhillip Boyle ...  \n",
            "1704  Abstract Missing  The Power of Selective Memory:\\nSelf-Bounded L...  \n",
            "1719  Abstract Missing  Edge of Chaos Computation in\\nMixed-Mode VLSI ...  \n",
            "1713  Abstract Missing  Conditional Models of Identity Uncertainty\\nwi...  \n",
            "\n",
            "[612 rows x 7 columns], 6:         id       year                                              title  \\\n",
            "2012  2828 2005-01-01  Asymptotics of Gaussian Regularized Least Squares   \n",
            "2013  2829 2005-01-01     Two view learning: SVM-2K, Theory and Practice   \n",
            "2015  2830 2005-01-01         Saliency Based on Information Maximization   \n",
            "2016  2831 2005-01-01     Faster Rates in Regression via Active Learning   \n",
            "2017  2832 2005-01-01                           Layered Dynamic Textures   \n",
            "...    ...        ...                                                ...   \n",
            "2462  3233 2007-01-01  Fitted Q-iteration in continuous action-space ...   \n",
            "2463  3234 2007-01-01      Topmoumoute Online Natural Gradient Algorithm   \n",
            "2464  3235 2007-01-01  Sparse Overcomplete Latent Variable Decomposit...   \n",
            "2465  3236 2007-01-01  Second Order Bilinear Discriminant Analysis fo...   \n",
            "2466  3237 2007-01-01  Learning Horizontal Connections in a Sparse Co...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2012        NaN  2828-asymptotics-of-gaussian-regularized-least...   \n",
            "2013        NaN  2829-two-view-learning-svm-2k-theory-and-pract...   \n",
            "2015        NaN  2830-saliency-based-on-information-maximizatio...   \n",
            "2016        NaN  2831-faster-rates-in-regression-via-active-lea...   \n",
            "2017        NaN                  2832-layered-dynamic-textures.pdf   \n",
            "...         ...                                                ...   \n",
            "2462        NaN  3233-fitted-q-iteration-in-continuous-action-s...   \n",
            "2463        NaN  3234-topmoumoute-online-natural-gradient-algor...   \n",
            "2464        NaN  3235-sparse-overcomplete-latent-variable-decom...   \n",
            "2465        NaN  3236-second-order-bilinear-discriminant-analys...   \n",
            "2466        NaN  3237-learning-horizontal-connections-in-a-spar...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2012                                   Abstract Missing   \n",
            "2013                                   Abstract Missing   \n",
            "2015                                   Abstract Missing   \n",
            "2016                                   Abstract Missing   \n",
            "2017                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "2462  We consider continuous state, continuous actio...   \n",
            "2463  Guided by the goal of obtaining an optimizatio...   \n",
            "2464  An important problem in many fields is the ana...   \n",
            "2465  Traditional analysis methods for single-trial ...   \n",
            "2466  It has been shown that adapting a dictionary o...   \n",
            "\n",
            "                                             paper_text  \n",
            "2012  Asymptotics of Gaussian Regularized\\nLeast-Squ...  \n",
            "2013  Two view learning: SVM-2K, Theory and\\nPractic...  \n",
            "2015  Saliency Based on Information Maximization\\n\\n...  \n",
            "2016  Faster Rates in Regression via Active Learning...  \n",
            "2017  Layered Dynamic Textures\\n\\nAntoni B. Chan\\nNu...  \n",
            "...                                                 ...  \n",
            "2462  Fitted Q-iteration in continuous action-space ...  \n",
            "2463  Topmoumoute online natural gradient algorithm\\...  \n",
            "2464  Sparse Overcomplete Latent Variable Decomposit...  \n",
            "2465  Second Order Bilinear Discriminant Analysis fo...  \n",
            "2466  Learning Horizontal Connections in a Sparse Co...  \n",
            "\n",
            "[628 rows x 7 columns], 7:         id       year                                              title  \\\n",
            "2810  3548 2008-01-01  Nonlinear causal discovery with additive noise...   \n",
            "2809  3547 2008-01-01  Goal-directed decision making in prefrontal co...   \n",
            "2808  3546 2008-01-01  Nonparametric Bayesian Learning of Switching L...   \n",
            "2807  3545 2008-01-01     Policy Search for Motor Primitives in Robotics   \n",
            "2806  3544 2008-01-01       Inferring rankings under constrained sensing   \n",
            "...    ...        ...                                                ...   \n",
            "3334  4019 2010-01-01  Two-Layer Generalization Analysis for Ranking ...   \n",
            "3444  4119 2010-01-01  b-Bit Minwise Hashing for Estimating Three-Way...   \n",
            "3336  4020 2010-01-01  Over-complete representations on recurrent neu...   \n",
            "3329  4014 2010-01-01       Agnostic Active Learning Without Constraints   \n",
            "3279  3970 2010-01-01  Sodium entry efficiency during action potentia...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2810        NaN  3548-nonlinear-causal-discovery-with-additive-...   \n",
            "2809        NaN  3547-goal-directed-decision-making-in-prefront...   \n",
            "2808        NaN  3546-nonparametric-bayesian-learning-of-switch...   \n",
            "2807        NaN  3545-policy-search-for-motor-primitives-in-rob...   \n",
            "2806        NaN  3544-inferring-rankings-under-constrained-sens...   \n",
            "...         ...                                                ...   \n",
            "3334        NaN  4019-two-layer-generalization-analysis-for-ran...   \n",
            "3444        NaN  4119-b-bit-minwise-hashing-for-estimating-thre...   \n",
            "3336        NaN  4020-over-complete-representations-on-recurren...   \n",
            "3329        NaN  4014-agnostic-active-learning-without-constrai...   \n",
            "3279        NaN  3970-sodium-entry-efficiency-during-action-pot...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2810  The discovery of causal relationships between ...   \n",
            "2809  Research in animal learning and behavioral neu...   \n",
            "2808  Many nonlinear dynamical phenomena can be effe...   \n",
            "2807  Many motor skills in humanoid robotics can be ...   \n",
            "2806                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "3334  This paper is concerned with the generalizatio...   \n",
            "3444  Computing two-way and multi-way set similariti...   \n",
            "3336  A striking aspect of cortical neural networks ...   \n",
            "3329  We present and analyze an agnostic active lear...   \n",
            "3279  Sodium entry during an action potential determ...   \n",
            "\n",
            "                                             paper_text  \n",
            "2810  Nonlinear causal discovery with additive noise...  \n",
            "2809  Goal-directed decision making in prefrontal\\nc...  \n",
            "2808  Nonparametric Bayesian Learning of Switching\\n...  \n",
            "2807  Policy Search for Motor Primitives in Robotics...  \n",
            "2806  Inferring rankings under constrained sensing\\n...  \n",
            "...                                                 ...  \n",
            "3334  Two-layer Generalization Analysis for Ranking ...  \n",
            "3444  b-Bit Minwise Hashing for Estimating Three-Way...  \n",
            "3336  Over-complete representations on recurrent neu...  \n",
            "3329  Agnostic Active Learning Without Constraints\\n...  \n",
            "3279  Sodium entry efficiency during action potentia...  \n",
            "\n",
            "[804 rows x 7 columns], 8:         id       year                                              title  \\\n",
            "3620  4278 2011-01-01  Learning in Hilbert vs. Banach Spaces: A Measu...   \n",
            "3798  4439 2011-01-01             Generalized Beta Mixtures of Gaussians   \n",
            "3744  4390 2011-01-01  Hogwild: A Lock-Free Approach to Parallelizing...   \n",
            "3742  4389 2011-01-01      An Exact Algorithm for F-Measure Maximization   \n",
            "3741  4388 2011-01-01                 Prediction strategies without loss   \n",
            "...    ...        ...                                                ...   \n",
            "4618  5179 2013-01-01  Learning Trajectory Preferences for  Manipulat...   \n",
            "4642  5200 2013-01-01         Non-Linear Domain Adaptation with Boosting   \n",
            "4638  5198 2013-01-01  Higher Order Priors for Joint Intrinsic Image,...   \n",
            "4643  5201 2013-01-01  Modeling Clutter Perception using Parametric P...   \n",
            "4516  5087 2013-01-01  Efficient Optimization for Sparse Gaussian Pro...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3620        NaN  4278-learning-in-hilbert-vs-banach-spaces-a-me...   \n",
            "3798        NaN    4439-generalized-beta-mixtures-of-gaussians.pdf   \n",
            "3744        NaN  4390-hogwild-a-lock-free-approach-to-paralleli...   \n",
            "3742        NaN  4389-an-exact-algorithm-for-f-measure-maximiza...   \n",
            "3741        NaN        4388-prediction-strategies-without-loss.pdf   \n",
            "...         ...                                                ...   \n",
            "4618     Poster  5179-learning-trajectory-preferences-for-manip...   \n",
            "4642     Poster  5200-non-linear-domain-adaptation-with-boostin...   \n",
            "4638     Poster  5198-higher-order-priors-for-joint-intrinsic-i...   \n",
            "4643     Poster  5201-modeling-clutter-perception-using-paramet...   \n",
            "4516     Poster  5087-efficient-optimization-for-sparse-gaussia...   \n",
            "\n",
            "                                               abstract  \\\n",
            "3620  The goal of this paper is to investigate the a...   \n",
            "3798  In recent years, a rich variety of shrinkage p...   \n",
            "3744  Stochastic Gradient Descent (SGD) is a popular...   \n",
            "3742  The F-measure, originally introduced in inform...   \n",
            "3741  Consider a sequence of bits where we are tryin...   \n",
            "...                                                 ...   \n",
            "4618  We consider the problem of learning good traje...   \n",
            "4642  A common assumption in machine vision is that ...   \n",
            "4638  Many methods have been proposed to recover the...   \n",
            "4643  Visual clutter, the perception of an image as ...   \n",
            "4516  We propose an efficient discrete optimization ...   \n",
            "\n",
            "                                             paper_text  \n",
            "3620  Learning in Hilbert vs. Banach Spaces: A Measu...  \n",
            "3798  Generalized Beta Mixtures of Gaussians\\nArtin ...  \n",
            "3744  H OGWILD !: A Lock-Free Approach to Paralleliz...  \n",
            "3742  An Exact Algorithm for F-Measure Maximization\\...  \n",
            "3741  Prediction strategies without loss\\n\\nRina Pan...  \n",
            "...                                                 ...  \n",
            "4618  Learning Trajectory Preferences for Manipulato...  \n",
            "4642  Non-Linear Domain Adaptation with Boosting\\n\\n...  \n",
            "4638  Higher Order Priors for Joint Intrinsic Image,...  \n",
            "4643  Modeling Clutter Perception using Parametric\\n...  \n",
            "4516  Efficient Optimization for\\nSparse Gaussian Pr...  \n",
            "\n",
            "[1034 rows x 7 columns], 9:         id       year                                              title  \\\n",
            "4813  5358 2014-01-01  Probabilistic low-rank matrix completion on fi...   \n",
            "4805  5350 2014-01-01  Learning to Discover Efficient Mathematical Id...   \n",
            "4806  5351 2014-01-01  Searching for Higgs Boson Decay Modes with Dee...   \n",
            "4807  5352 2014-01-01  Semi-supervised Learning with Deep Generative ...   \n",
            "4808  5353 2014-01-01  Two-Stream Convolutional Networks for Action R...   \n",
            "...    ...        ...                                                ...   \n",
            "6042  6466 2016-01-01  Bayesian optimization for automated model sele...   \n",
            "6029  6454 2016-01-01  A Non-parametric Learning Method for Confident...   \n",
            "6041  6465 2016-01-01  R-FCN: Object Detection via Region-based Fully...   \n",
            "6040  6464 2016-01-01       Learning Deep Embeddings with Histogram Loss   \n",
            "6043  6467 2016-01-01  Generalization of ERM in Stochastic Convex Opt...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "4813     Poster  5358-probabilistic-low-rank-matrix-completion-...   \n",
            "4805  Spotlight  5350-learning-to-discover-efficient-mathematic...   \n",
            "4806  Spotlight  5351-searching-for-higgs-boson-decay-modes-wit...   \n",
            "4807  Spotlight  5352-semi-supervised-learning-with-deep-genera...   \n",
            "4808  Spotlight  5353-two-stream-convolutional-networks-for-act...   \n",
            "...         ...                                                ...   \n",
            "6042     Poster  6466-bayesian-optimization-for-automated-model...   \n",
            "6029     Poster  6454-a-non-parametric-learning-method-for-conf...   \n",
            "6041     Poster  6465-r-fcn-object-detection-via-region-based-f...   \n",
            "6040     Poster  6464-learning-deep-embeddings-with-histogram-l...   \n",
            "6043     Poster  6467-generalization-of-erm-in-stochastic-conve...   \n",
            "\n",
            "                                               abstract  \\\n",
            "4813  The task of reconstructing a matrix given a sa...   \n",
            "4805  In this paper we explore how machine learning ...   \n",
            "4806  Particle colliders enable us to probe the fund...   \n",
            "4807  The ever-increasing size of modern data sets c...   \n",
            "4808  We investigate architectures of discriminative...   \n",
            "...                                                 ...   \n",
            "6042  Despite the success of kernel-based nonparamet...   \n",
            "6029  Estimating patient's clinical state from multi...   \n",
            "6041  We present region-based, fully convolutional n...   \n",
            "6040  We suggest a new loss for learning deep embedd...   \n",
            "6043  In stochastic convex optimization the goal is ...   \n",
            "\n",
            "                                             paper_text  \n",
            "4813  Probabilistic low-rank matrix completion on fi...  \n",
            "4805  Learning to Discover\\nEfficient Mathematical I...  \n",
            "4806  Searching for Higgs Boson Decay Modes\\nwith De...  \n",
            "4807  Semi-supervised Learning with\\nDeep Generative...  \n",
            "4808  Two-Stream Convolutional Networks\\nfor Action ...  \n",
            "...                                                 ...  \n",
            "6042  Bayesian optimization for automated model sele...  \n",
            "6029  A Non-parametric Learning Method for Confident...  \n",
            "6041  R-FCN: Object Detection via\\nRegion-based Full...  \n",
            "6040  Learning Deep Embeddings with Histogram Loss\\n...  \n",
            "6043  Generalization of ERM in Stochastic Convex\\nOp...  \n",
            "\n",
            "[1383 rows x 7 columns], 10:         id       year                                              title  \\\n",
            "6935  7273 2017-01-01  Houdini: Fooling Deep Structured Visual and Sp...   \n",
            "6933  7271 2017-01-01  Convergence of Gradient EM on Multi-component ...   \n",
            "6937  7275 2017-01-01  When Cyclic Coordinate Descent Outperforms Ran...   \n",
            "6936  7274 2017-01-01  Efficient and Flexible Inference for Stochasti...   \n",
            "6932  7270 2017-01-01  Kernel Feature Selection via Conditional Covar...   \n",
            "...    ...        ...                                                ...   \n",
            "6707  7067 2017-01-01             Context Selection for Embedding Models   \n",
            "6708  7068 2017-01-01  Working hard to know your neighbor's margins: ...   \n",
            "6709  7069 2017-01-01  Accelerated Stochastic Greedy Coordinate Desce...   \n",
            "6405  6794 2017-01-01  Consistent Multitask Learning with Nonlinear O...   \n",
            "6665  7029 2017-01-01                      Federated Multi-Task Learning   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "6935     Poster  7273-houdini-fooling-deep-structured-visual-an...   \n",
            "6933     Poster  7271-convergence-of-gradient-em-on-multi-compo...   \n",
            "6937     Poster  7275-when-cyclic-coordinate-descent-outperform...   \n",
            "6936     Poster  7274-efficient-and-flexible-inference-for-stoc...   \n",
            "6932     Poster  7270-kernel-feature-selection-via-conditional-...   \n",
            "...         ...                                                ...   \n",
            "6707     Poster    7067-context-selection-for-embedding-models.pdf   \n",
            "6708     Poster  7068-working-hard-to-know-your-neighbors-margi...   \n",
            "6709     Poster  7069-accelerated-stochastic-greedy-coordinate-...   \n",
            "6405     Poster  6794-consistent-multitask-learning-with-nonlin...   \n",
            "6665     Poster             7029-federated-multi-task-learning.pdf   \n",
            "\n",
            "                                               abstract  \\\n",
            "6935  Generating adversarial examples is a critical ...   \n",
            "6933  In this paper, we study convergence properties...   \n",
            "6937  The coordinate descent (CD) method is a classi...   \n",
            "6936  Many real world dynamical systems are describe...   \n",
            "6932  We propose a method for feature selection that...   \n",
            "...                                                 ...   \n",
            "6707  Word embeddings are an effective tool to analy...   \n",
            "6708  We introduce a loss for metric learning, which...   \n",
            "6709  In this paper we study the well-known greedy c...   \n",
            "6405  Key to multitask learning is exploiting the re...   \n",
            "6665  Federated learning poses new statistical and s...   \n",
            "\n",
            "                                             paper_text  \n",
            "6935  Houdini: Fooling Deep Structured Visual and Sp...  \n",
            "6933  Convergence of Gradient EM on Multi-component\\...  \n",
            "6937  When Cyclic Coordinate Descent Outperforms\\nRa...  \n",
            "6936  Efficient and Flexible Inference for Stochasti...  \n",
            "6932  Kernel Feature Selection via\\nConditional Cova...  \n",
            "...                                                 ...  \n",
            "6707  Context Selection for Embedding Models\\n\\nLi-P...  \n",
            "6708  Working hard to know your neighbor?s margins:\\...  \n",
            "6709  Accelerated Stochastic Greedy Coordinate Desce...  \n",
            "6405  Consistent Multitask Learning with\\nNonlinear ...  \n",
            "6665  Federated Multi-Task Learning\\n\\nVirginia Smit...  \n",
            "\n",
            "[679 rows x 7 columns]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT word2phrase to create bigrams and unigrams\n",
        "!git clone https://github.com/travisbrady/word2phrase.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6I115Y--CqF",
        "outputId": "ff80970e-269b-43e8-d2d7-5cdfe6d6495a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'word2phrase'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALL TIME WINDOWS SCI-BERT"
      ],
      "metadata": {
        "id": "kLi7qvOGatyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert List of Time Slice DF paper_text content to lists\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Loop through every DF and convert paper_text to list and concatenate all the papers of one time slice \n",
        "## this will be a list like  [\"All paper content string of first slice\", \"all paper content string of 2nd slice\", ...] \n",
        "\n",
        "papers_contents_list = [\" \".join(time_slice_df[\"paper_text\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n",
        "#### MEASURE THE EXECUTION TIME FOR RUNNING THE CONCATENATION CODE\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "\n",
        "# papers_contents_list\n",
        "# len(papers_contents_list[0])"
      ],
      "metadata": {
        "id": "lrwZ1HOQa9XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719ebbe9-60e6-4f58-ccf4-d836654c6cf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10576963424682617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Join Paper titles for bigram and unigram extraction\n",
        "\n",
        "\n",
        "papers_titles_list = [\" \".join(time_slice_df[\"title\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n"
      ],
      "metadata": {
        "id": "RcUQthFrPyZn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 -  Pre Processing \n",
        "\n",
        "# Remove Stopwords "
      ],
      "metadata": {
        "id": "uGQDbS_N62fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# function to rmeove digits and numbers from papers \n",
        "def regex_remove_digits(papers_contents_list):      \n",
        "    # Remove any digits for the corpus\n",
        "    all_time_window_papers_content_list = [re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", time_slice_paper) \n",
        "                                                    for time_slice_paper in papers_contents_list] \n",
        "    # Remove words with length less than 3 \n",
        "\n",
        "    # https://stackoverflow.com/questions/24332025/remove-words-of-length-less-than-4-from-string\n",
        "    all_time_window_papers_content_list = [re.sub(r'\\b\\w{1,2}\\b', '', time_slice_paper) \n",
        "                                          for time_slice_paper in all_time_window_papers_content_list]\n",
        "\n",
        "    return all_time_window_papers_content_list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4rWzW9Zl7FNs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom Stopwords List for Scientific Literature \n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "path_to_stop_words = '/gdrive/My Drive/Master_dataset/stopwords_10000_most_frequent_filtered.txt'\n",
        "\n",
        "with open(path_to_stop_words, \"r\") as file1:\n",
        "    FileasList = file1.readlines()\n",
        "\n",
        "\n",
        "stopwords = [s.strip('\\n') for s in FileasList]\n",
        "print(len(stopwords))\n",
        "\n",
        "\n",
        "scientific_literature_stopwords = text.ENGLISH_STOP_WORDS.union(stopwords)\n",
        "\n",
        "len(scientific_literature_stopwords)\n"
      ],
      "metadata": {
        "id": "EYyOHKZ1QY0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4539ce-e77f-4b0f-bfd3-e7f6b43cd655"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9958"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all paper content and titles for bigram and unigram generation\n",
        "all_time_window_papers_content_list = regex_remove_digits(papers_contents_list)\n",
        "all_time_window_papers_title_list = regex_remove_digits(papers_titles_list)\n"
      ],
      "metadata": {
        "id": "EM2Ek6JKQVJV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Bag Of Candidate Keywords For All Time Windows"
      ],
      "metadata": {
        "id": "uaAZrFV9eAu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_time_window_papers_titles = \" \".join(all_time_window_papers_title_list)"
      ],
      "metadata": {
        "id": "9vVvUZgCRXXp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#About 900 stopwords\n",
        "stop_words = list(stopwords.words('english')) #About 150 stopwords\n",
        "stop_words.extend(scientific_literature_stopwords)\n",
        "\n",
        "\n",
        "\n",
        "token = nltk.word_tokenize(all_time_window_papers_titles)\n",
        "output = [w for w in token if not w in stop_words]\n",
        "bigrams = ngrams(output,2)\n",
        "\n",
        "\n",
        "# candidate_keywords = [ for n in ngrams]\n",
        "ngrams = Counter(bigrams).most_common()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FmvaKqj7CYQT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords = [( \" \".join(n[0]) , n[1] )for n in ngrams]\n",
        "candidate_keywords = candidate_keywords[:300]\n",
        "\n",
        "\n",
        "\n",
        "###################################################"
      ],
      "metadata": {
        "id": "ZO9EFTixGRsF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords"
      ],
      "metadata": {
        "id": "Pc61_bwVLrDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93f50f3-dcb8-48c9-c23d-5d7fac89a837"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Neural Networks', 247),\n",
              " ('Reinforcement Learning', 148),\n",
              " ('Neural Network', 135),\n",
              " ('Gaussian Process', 67),\n",
              " ('Graphical Models', 59),\n",
              " ('Support Vector', 57),\n",
              " ('Gaussian Processes', 49),\n",
              " ('Active Learning', 46),\n",
              " ('Variational Inference', 45),\n",
              " ('Monte Carlo', 44),\n",
              " ('Online Learning', 43),\n",
              " ('Speech Recognition', 42),\n",
              " ('Recurrent Neural', 37),\n",
              " ('Component Analysis', 36),\n",
              " ('Gradient Descent', 34),\n",
              " ('Hidden Markov', 34),\n",
              " (': The', 32),\n",
              " ('Deep Learning', 32),\n",
              " ('Learning :', 30),\n",
              " ('Markov Models', 30),\n",
              " ('Vector Machines', 30),\n",
              " ('Analog VLSI', 29),\n",
              " ('Stochastic Gradient', 29),\n",
              " ('Markov Decision', 28),\n",
              " ('Feature Selection', 28),\n",
              " (': Learning', 27),\n",
              " ('Networks Learning', 27),\n",
              " ('Random Fields', 27),\n",
              " ('Machine Learning', 27),\n",
              " ('Networks :', 26),\n",
              " ('Belief Propagation', 26),\n",
              " ('Kernel Learning', 26),\n",
              " ('Unsupervised Learning', 25),\n",
              " ('neural networks', 25),\n",
              " ('Model Selection', 25),\n",
              " ('Matrix Completion', 25),\n",
              " ('Dynamic Programming', 24),\n",
              " ('Function Approximation', 24),\n",
              " ('Decision Processes', 24),\n",
              " ('Object Recognition', 22),\n",
              " ('Time Series', 22),\n",
              " ('Mixture Models', 21),\n",
              " ('Latent Variable', 21),\n",
              " ('Metric Learning', 21),\n",
              " ('Deep Neural', 21),\n",
              " ('Spiking Neurons', 20),\n",
              " ('Bayesian Inference', 20),\n",
              " ('Density Estimation', 20),\n",
              " ('Approximate Inference', 20),\n",
              " ('Convex Optimization', 20),\n",
              " ('Supervised Learning', 19),\n",
              " ('Dynamical Systems', 19),\n",
              " ('Convolutional Neural', 19),\n",
              " ('Generative Models', 19),\n",
              " ('Large Scale', 19),\n",
              " ('Matrix Factorization', 19),\n",
              " (': Application', 18),\n",
              " ('Stochastic Optimization', 18),\n",
              " ('Natural Images', 18),\n",
              " ('Spectral Clustering', 18),\n",
              " ('Learning The', 17),\n",
              " ('Dimensionality Reduction', 17),\n",
              " ('Principal Component', 17),\n",
              " ('Learning Sparse', 17),\n",
              " ('Object Detection', 17),\n",
              " ('MAP Inference', 17),\n",
              " ('Visual Cortex', 16),\n",
              " ('Recurrent Networks', 16),\n",
              " ('Radial Basis', 16),\n",
              " ('Risk Minimization', 16),\n",
              " ('Nearest Neighbor', 16),\n",
              " ('Independent Component', 16),\n",
              " ('High Dimensional', 16),\n",
              " ('Large Margin', 16),\n",
              " ('Structured Prediction', 16),\n",
              " ('Learning Algorithms', 15),\n",
              " ('Neural Net', 15),\n",
              " ('Learning Multiple', 15),\n",
              " ('Bayesian Model', 15),\n",
              " ('Models Learning', 15),\n",
              " ('Bayesian Networks', 15),\n",
              " ('Policy Gradient', 15),\n",
              " ('Variational Bayesian', 15),\n",
              " ('Process Regression', 15),\n",
              " ('Sparse Coding', 15),\n",
              " ('Domain Adaptation', 15),\n",
              " ('Learning Deep', 15),\n",
              " ('Recognition Using', 14),\n",
              " ('Artificial Neural', 14),\n",
              " ('Mean Field', 14),\n",
              " ('Maximum Likelihood', 14),\n",
              " ('Missing Data', 14),\n",
              " ('Sample Complexity', 14),\n",
              " ('Exponential Family', 14),\n",
              " ('Deep Networks', 14),\n",
              " ('Coordinate Descent', 14),\n",
              " ('Associative Memory', 13),\n",
              " ('Basis Function', 13),\n",
              " ('Feature Extraction', 13),\n",
              " ('Boltzmann Machines', 13),\n",
              " ('Learning Algorithm', 13),\n",
              " ('Learning Learning', 13),\n",
              " ('Learning Bayesian', 13),\n",
              " ('Vector Machine', 13),\n",
              " ('Gradient Methods', 13),\n",
              " ('Latent Dirichlet', 13),\n",
              " ('Learning Gaussian', 13),\n",
              " ('Topic Models', 13),\n",
              " ('Semi-supervised Learning', 13),\n",
              " ('Conditional Random', 13),\n",
              " ('Feature Learning', 13),\n",
              " ('Generative Adversarial', 13),\n",
              " ('Network Model', 12),\n",
              " ('Neural Nets', 12),\n",
              " ('Mutual Information', 12),\n",
              " ('Markov Random', 12),\n",
              " ('Second Order', 12),\n",
              " ('Clustering :', 12),\n",
              " ('Learning Approach', 12),\n",
              " (': Efficient', 12),\n",
              " ('Bayesian Learning', 12),\n",
              " ('Decision Trees', 12),\n",
              " ('Learning Structured', 12),\n",
              " ('Variable Models', 12),\n",
              " ('Gaussian Graphical', 12),\n",
              " ('Dirichlet Allocation', 12),\n",
              " ('Probabilistic Inference', 12),\n",
              " ('Semi-Supervised Learning', 12),\n",
              " ('Graphical Model', 12),\n",
              " ('Sparse PCA', 12),\n",
              " ('Message Passing', 12),\n",
              " ('Convolutional Networks', 12),\n",
              " ('Bayesian Optimization', 12),\n",
              " ('Learning Neural', 11),\n",
              " ('Temporal Difference', 11),\n",
              " ('Gaussian Mixtures', 11),\n",
              " (': New', 11),\n",
              " ('Least Squares', 11),\n",
              " ('Partially Observable', 11),\n",
              " ('Linear Models', 11),\n",
              " ('Belief Networks', 11),\n",
              " ('Markov Networks', 11),\n",
              " ('Policy Search', 11),\n",
              " ('Maximum Margin', 11),\n",
              " ('Restricted Boltzmann', 11),\n",
              " ('Collaborative Filtering', 11),\n",
              " ('Decision Making', 11),\n",
              " ('End --', 11),\n",
              " ('Nonparametric Bayesian', 11),\n",
              " ('Transfer Learning', 11),\n",
              " ('Tensor Decomposition', 11),\n",
              " ('Neural Model', 10),\n",
              " ('Image Segmentation', 10),\n",
              " ('Network :', 10),\n",
              " ('Information Theoretic', 10),\n",
              " (': From', 10),\n",
              " ('Parameter Estimation', 10),\n",
              " ('Efficient Learning', 10),\n",
              " ('Visual Attention', 10),\n",
              " ('Visual Recognition', 10),\n",
              " ('Value Function', 10),\n",
              " ('Learning Stochastic', 10),\n",
              " ('Linear Programming', 10),\n",
              " ('Information Bottleneck', 10),\n",
              " ('Variance Reduction', 10),\n",
              " (': Towards', 10),\n",
              " ('Sparse Gaussian', 10),\n",
              " ('Multiple Kernel', 10),\n",
              " ('Dirichlet Process', 10),\n",
              " ('Networks Neural', 9),\n",
              " ('Learning Control', 9),\n",
              " ('Distributed Representations', 9),\n",
              " ('Networks The', 9),\n",
              " ('Pattern Recognition', 9),\n",
              " ('Analog Neural', 9),\n",
              " ('VLSI Neural', 9),\n",
              " ('Ocular Dominance', 9),\n",
              " ('Learning Dynamic', 9),\n",
              " ('Natural Language', 9),\n",
              " ('Continuous Speech', 9),\n",
              " ('Learning Model', 9),\n",
              " ('Learning Curves', 9),\n",
              " ('Learning Using', 9),\n",
              " ('spiking neurons', 9),\n",
              " ('Mixtures Experts', 9),\n",
              " ('Graph Matching', 9),\n",
              " ('Learning Continuous', 9),\n",
              " ('Learning Adaptive', 9),\n",
              " ('Information Maximization', 9),\n",
              " (': Bayesian', 9),\n",
              " ('Learning Efficient', 9),\n",
              " ('Multi-Task Learning', 9),\n",
              " ('Models :', 9),\n",
              " ('Natural Scenes', 9),\n",
              " ('Learning Nonlinear', 9),\n",
              " (': Fast', 9),\n",
              " ('Process Models', 9),\n",
              " ('Sequential Data', 9),\n",
              " ('Data Learning', 9),\n",
              " ('Probabilistic Models', 9),\n",
              " ('High Dimensions', 9),\n",
              " ('Markov Chain', 9),\n",
              " ('Inference Bayesian', 9),\n",
              " ('Structure Learning', 9),\n",
              " ('Kernel Methods', 9),\n",
              " ('Logistic Regression', 9),\n",
              " ('Model Learning', 9),\n",
              " ('Hierarchical Clustering', 9),\n",
              " ('Training Deep', 9),\n",
              " ('Submodular Functions', 9),\n",
              " ('Inverse Reinforcement', 9),\n",
              " ('Empirical Risk', 9),\n",
              " (': Probabilistic', 8),\n",
              " ('Using Neural', 8),\n",
              " ('Networks Application', 8),\n",
              " ('Complexity Learning', 8),\n",
              " ('Boltzmann Machine', 8),\n",
              " ('Networks Using', 8),\n",
              " ('VLSI Implementation', 8),\n",
              " (': Theory', 8),\n",
              " ('Markov Model', 8),\n",
              " ('Selective Attention', 8),\n",
              " ('Face Recognition', 8),\n",
              " ('Anomaly Detection', 8),\n",
              " ('Finite State', 8),\n",
              " ('Population Codes', 8),\n",
              " ('Unlabeled Data', 8),\n",
              " ('Data Clustering', 8),\n",
              " ('Manifold Learning', 8),\n",
              " ('Real Time', 8),\n",
              " ('Neighbor Classification', 8),\n",
              " ('Policy Iteration', 8),\n",
              " ('Training Sets', 8),\n",
              " ('Source Separation', 8),\n",
              " ('Learning Probabilistic', 8),\n",
              " ('Discriminant Analysis', 8),\n",
              " ('The Infinite', 8),\n",
              " ('Importance Sampling', 8),\n",
              " ('Lower Bounds', 8),\n",
              " ('Probabilistic Model', 8),\n",
              " ('Kernel Machines', 8),\n",
              " ('Causal Inference', 8),\n",
              " ('Data :', 8),\n",
              " ('Side Information', 8),\n",
              " ('Distance Metric', 8),\n",
              " ('Loss Functions', 8),\n",
              " ('Expectation Propagation', 8),\n",
              " ('Fast Rates', 8),\n",
              " ('Spectral Methods', 8),\n",
              " ('-- End', 8),\n",
              " ('Random Projections', 8),\n",
              " ('graphical models', 8),\n",
              " ('Subspace Clustering', 8),\n",
              " ('Generalized Linear', 8),\n",
              " (': Deep', 8),\n",
              " ('Sparse Inverse', 8),\n",
              " ('Inverse Covariance', 8),\n",
              " ('Robust PCA', 8),\n",
              " ('Adversarial Networks', 8),\n",
              " ('Stochastic Learning', 7),\n",
              " ('Its Application', 7),\n",
              " ('Basis Functions', 7),\n",
              " ('Signal Processing', 7),\n",
              " ('Nets :', 7),\n",
              " ('Function Networks', 7),\n",
              " ('Learning Rate', 7),\n",
              " ('Receptive Field', 7),\n",
              " ('Data Analysis', 7),\n",
              " ('Eye Movements', 7),\n",
              " ('Difference Learning', 7),\n",
              " ('Vector Quantization', 7),\n",
              " ('Receptive Fields', 7),\n",
              " ('Algorithm Learning', 7),\n",
              " ('Training Neural', 7),\n",
              " ('Learning Rules', 7),\n",
              " ('The Power', 7),\n",
              " ('Generalization Error', 7),\n",
              " ('Dimension Reduction', 7),\n",
              " ('Value Iteration', 7),\n",
              " ('-line Learning', 7),\n",
              " ('Blind Separation', 7),\n",
              " ('Pose Estimation', 7),\n",
              " ('Mixture Model', 7),\n",
              " ('Statistical Models', 7),\n",
              " ('Factor Analysis', 7),\n",
              " ('Inference Learning', 7),\n",
              " ('Likelihood Estimation', 7),\n",
              " ('Components Analysis', 7),\n",
              " ('Generative Model', 7),\n",
              " ('Learning Linear', 7),\n",
              " ('Analysis :', 7),\n",
              " ('Approach Learning', 7),\n",
              " ('Bayesian Models', 7),\n",
              " (': Unified', 7),\n",
              " ('Markov Chains', 7),\n",
              " ('Semidefinite Programming', 7),\n",
              " ('Learning Optimal', 7),\n",
              " ('Spectral Learning', 7),\n",
              " ('Imitation Learning', 7),\n",
              " ('Regret Bounds', 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - BERT EMBEDDING GENERATE"
      ],
      "metadata": {
        "id": "kTigylDrZ2xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_ngram_candidate_keywords_time_slices_sorted_ = [ngram[0] for ngram in candidate_keywords]\n",
        "t = \"\\n\".join(title_ngram_candidate_keywords_time_slices_sorted_)\n",
        "t"
      ],
      "metadata": {
        "id": "4fcx51Krc-lh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e439d2dc-fb35-46c2-aaad-e6c93f36ca29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neural Networks\\nReinforcement Learning\\nNeural Network\\nGaussian Process\\nGraphical Models\\nSupport Vector\\nGaussian Processes\\nActive Learning\\nVariational Inference\\nMonte Carlo\\nOnline Learning\\nSpeech Recognition\\nRecurrent Neural\\nComponent Analysis\\nGradient Descent\\nHidden Markov\\n: The\\nDeep Learning\\nLearning :\\nMarkov Models\\nVector Machines\\nAnalog VLSI\\nStochastic Gradient\\nMarkov Decision\\nFeature Selection\\n: Learning\\nNetworks Learning\\nRandom Fields\\nMachine Learning\\nNetworks :\\nBelief Propagation\\nKernel Learning\\nUnsupervised Learning\\nneural networks\\nModel Selection\\nMatrix Completion\\nDynamic Programming\\nFunction Approximation\\nDecision Processes\\nObject Recognition\\nTime Series\\nMixture Models\\nLatent Variable\\nMetric Learning\\nDeep Neural\\nSpiking Neurons\\nBayesian Inference\\nDensity Estimation\\nApproximate Inference\\nConvex Optimization\\nSupervised Learning\\nDynamical Systems\\nConvolutional Neural\\nGenerative Models\\nLarge Scale\\nMatrix Factorization\\n: Application\\nStochastic Optimization\\nNatural Images\\nSpectral Clustering\\nLearning The\\nDimensionality Reduction\\nPrincipal Component\\nLearning Sparse\\nObject Detection\\nMAP Inference\\nVisual Cortex\\nRecurrent Networks\\nRadial Basis\\nRisk Minimization\\nNearest Neighbor\\nIndependent Component\\nHigh Dimensional\\nLarge Margin\\nStructured Prediction\\nLearning Algorithms\\nNeural Net\\nLearning Multiple\\nBayesian Model\\nModels Learning\\nBayesian Networks\\nPolicy Gradient\\nVariational Bayesian\\nProcess Regression\\nSparse Coding\\nDomain Adaptation\\nLearning Deep\\nRecognition Using\\nArtificial Neural\\nMean Field\\nMaximum Likelihood\\nMissing Data\\nSample Complexity\\nExponential Family\\nDeep Networks\\nCoordinate Descent\\nAssociative Memory\\nBasis Function\\nFeature Extraction\\nBoltzmann Machines\\nLearning Algorithm\\nLearning Learning\\nLearning Bayesian\\nVector Machine\\nGradient Methods\\nLatent Dirichlet\\nLearning Gaussian\\nTopic Models\\nSemi-supervised Learning\\nConditional Random\\nFeature Learning\\nGenerative Adversarial\\nNetwork Model\\nNeural Nets\\nMutual Information\\nMarkov Random\\nSecond Order\\nClustering :\\nLearning Approach\\n: Efficient\\nBayesian Learning\\nDecision Trees\\nLearning Structured\\nVariable Models\\nGaussian Graphical\\nDirichlet Allocation\\nProbabilistic Inference\\nSemi-Supervised Learning\\nGraphical Model\\nSparse PCA\\nMessage Passing\\nConvolutional Networks\\nBayesian Optimization\\nLearning Neural\\nTemporal Difference\\nGaussian Mixtures\\n: New\\nLeast Squares\\nPartially Observable\\nLinear Models\\nBelief Networks\\nMarkov Networks\\nPolicy Search\\nMaximum Margin\\nRestricted Boltzmann\\nCollaborative Filtering\\nDecision Making\\nEnd --\\nNonparametric Bayesian\\nTransfer Learning\\nTensor Decomposition\\nNeural Model\\nImage Segmentation\\nNetwork :\\nInformation Theoretic\\n: From\\nParameter Estimation\\nEfficient Learning\\nVisual Attention\\nVisual Recognition\\nValue Function\\nLearning Stochastic\\nLinear Programming\\nInformation Bottleneck\\nVariance Reduction\\n: Towards\\nSparse Gaussian\\nMultiple Kernel\\nDirichlet Process\\nNetworks Neural\\nLearning Control\\nDistributed Representations\\nNetworks The\\nPattern Recognition\\nAnalog Neural\\nVLSI Neural\\nOcular Dominance\\nLearning Dynamic\\nNatural Language\\nContinuous Speech\\nLearning Model\\nLearning Curves\\nLearning Using\\nspiking neurons\\nMixtures Experts\\nGraph Matching\\nLearning Continuous\\nLearning Adaptive\\nInformation Maximization\\n: Bayesian\\nLearning Efficient\\nMulti-Task Learning\\nModels :\\nNatural Scenes\\nLearning Nonlinear\\n: Fast\\nProcess Models\\nSequential Data\\nData Learning\\nProbabilistic Models\\nHigh Dimensions\\nMarkov Chain\\nInference Bayesian\\nStructure Learning\\nKernel Methods\\nLogistic Regression\\nModel Learning\\nHierarchical Clustering\\nTraining Deep\\nSubmodular Functions\\nInverse Reinforcement\\nEmpirical Risk\\n: Probabilistic\\nUsing Neural\\nNetworks Application\\nComplexity Learning\\nBoltzmann Machine\\nNetworks Using\\nVLSI Implementation\\n: Theory\\nMarkov Model\\nSelective Attention\\nFace Recognition\\nAnomaly Detection\\nFinite State\\nPopulation Codes\\nUnlabeled Data\\nData Clustering\\nManifold Learning\\nReal Time\\nNeighbor Classification\\nPolicy Iteration\\nTraining Sets\\nSource Separation\\nLearning Probabilistic\\nDiscriminant Analysis\\nThe Infinite\\nImportance Sampling\\nLower Bounds\\nProbabilistic Model\\nKernel Machines\\nCausal Inference\\nData :\\nSide Information\\nDistance Metric\\nLoss Functions\\nExpectation Propagation\\nFast Rates\\nSpectral Methods\\n-- End\\nRandom Projections\\ngraphical models\\nSubspace Clustering\\nGeneralized Linear\\n: Deep\\nSparse Inverse\\nInverse Covariance\\nRobust PCA\\nAdversarial Networks\\nStochastic Learning\\nIts Application\\nBasis Functions\\nSignal Processing\\nNets :\\nFunction Networks\\nLearning Rate\\nReceptive Field\\nData Analysis\\nEye Movements\\nDifference Learning\\nVector Quantization\\nReceptive Fields\\nAlgorithm Learning\\nTraining Neural\\nLearning Rules\\nThe Power\\nGeneralization Error\\nDimension Reduction\\nValue Iteration\\n-line Learning\\nBlind Separation\\nPose Estimation\\nMixture Model\\nStatistical Models\\nFactor Analysis\\nInference Learning\\nLikelihood Estimation\\nComponents Analysis\\nGenerative Model\\nLearning Linear\\nAnalysis :\\nApproach Learning\\nBayesian Models\\n: Unified\\nMarkov Chains\\nSemidefinite Programming\\nLearning Optimal\\nSpectral Learning\\nImitation Learning\\nRegret Bounds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install Unidecode"
      ],
      "metadata": {
        "id": "j6BqKd5ZheKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec8dace-4f7b-4fb5-8386-ee9fbe4ef88b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 28.3 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.51-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 24.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n",
            "Collecting botocore<1.28.0,>=1.27.51\n",
            "  Downloading botocore-1.27.51-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 59.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.51->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.51->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.51 botocore-1.27.51 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 31.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "from collections import OrderedDict\n",
        "import unidecode\n",
        "import numpy as np\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline"
      ],
      "metadata": {
        "id": "x6P0dfVehoGZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "import torch\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "mTl8ffpftcpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "59b00836-e4ba-4d47-ed79-9bbea8edf7f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Use the pre-trained Base BERT model \n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.cuda()\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "FKo54yLjzQut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de28983-8e3e-462c-b573-d5d6a98321b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:03<00:00, 66385.06B/s] \n",
            "100%|██████████| 407873900/407873900 [00:33<00:00, 12171191.62B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class Data():\n",
        "\n",
        "    def __getitem__(self, content=None):\n",
        "         if content!=None:\n",
        "             self.doc = \"\".join(content)\n",
        "         return self.doc\n",
        "     \n",
        "    def _preprocess(self,targets,corpus):\n",
        "        self.index=[]\n",
        "        self.t_index=OrderedDict()\n",
        "        for target in targets:\n",
        "            \n",
        "            for _,item in enumerate(corpus):\n",
        "                # if target in item:\n",
        "                  if item.lower().find(target) != -1:\n",
        "                # if bool(re.search(target, item)):\n",
        "\n",
        "                      count_target=item.count(target)\n",
        "                  #   Avoiding the sentences with multiple occurrences of the target term for the time being###\n",
        "                      if count_target==1:\n",
        "                        if target not in self.t_index.keys():\n",
        "                            self.t_index[target]=[_]\n",
        "                        else:\n",
        "                            self.t_index[target].append(_)\n",
        "                        self.index.append(_)\n",
        "        return self.index,self.t_index"
      ],
      "metadata": {
        "id": "7FhI9iflZ-2_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "LOAD & EXTRACT DATA\n",
        "'''\n",
        "import os\n",
        "\n",
        "\n",
        "# OUTPUT_DIR = root_dir+'Colab Notebooks/Challenge_Semeval/CLUSTERING/English_test/' # the path thatcontains the (Corpus1_text, Corpus2_text, Targets)\n",
        "# p1 = os.path.join(OUTPUT_DIR, 'ccoha1.txt')\n",
        "# p2 = os.path.join(OUTPUT_DIR, 'ccoha2.txt')\n",
        "# t = os.path.join(OUTPUT_DIR, 'targets.txt')\n",
        "\n",
        "# INPUT_DIR = '.\\\\evaluation\\\\semeval2020_ulscd_eng\\\\'\n",
        "# p1 = os.path.join(INPUT_DIR, 'corpus1\\\\ccoha1.txt')\n",
        "# p2 = os.path.join(INPUT_DIR, 'corpus2\\\\ccoha2.txt')\n",
        "# #TARGET_DIR = '.\\\\targets\\\\'\n",
        "# t = os.path.join(INPUT_DIR, 'targets.txt')\n",
        "# p1='ccoha1.txt'\n",
        "# p2='ccoha2.txt'\n",
        "# t='targets.txt'\n",
        "\n",
        "p1 = nips_papers_partitions[0][\"paper_text\"].tolist()\n",
        "p2 = nips_papers_partitions[1][\"paper_text\"].tolist()\n",
        "p3 = nips_papers_partitions[2][\"paper_text\"].tolist()\n",
        "p4 = nips_papers_partitions[3][\"paper_text\"].tolist()\n",
        "p5 = nips_papers_partitions[4][\"paper_text\"].tolist()\n",
        "p6 = nips_papers_partitions[5][\"paper_text\"].tolist()\n",
        "p7 = nips_papers_partitions[6][\"paper_text\"].tolist()\n",
        "p8 = nips_papers_partitions[7][\"paper_text\"].tolist()\n",
        "p9 = nips_papers_partitions[8][\"paper_text\"].tolist()\n",
        "p10 = nips_papers_partitions[9][\"paper_text\"].tolist()\n",
        "\n",
        "\n",
        "t = t\n",
        "datasets = Data() \n",
        "\n",
        "# doc1 =  [\"Sentence1\", \"Sentence2\".....]\n",
        "doc1=datasets.__getitem__(p1).split('\\n')   \n",
        "doc2=datasets.__getitem__(p2).split('\\n')\n",
        "doc3=datasets.__getitem__(p3).split('\\n')\n",
        "doc4=datasets.__getitem__(p4).split('\\n')\n",
        "doc5=datasets.__getitem__(p5).split('\\n')\n",
        "doc6=datasets.__getitem__(p6).split('\\n')\n",
        "doc7=datasets.__getitem__(p7).split('\\n')\n",
        "doc8=datasets.__getitem__(p8).split('\\n')\n",
        "doc9=datasets.__getitem__(p9).split('\\n')\n",
        "doc10=datasets.__getitem__(p10).split('\\n')\n",
        "\n",
        "\n",
        "t1=datasets.__getitem__(t).split('\\n')\n",
        "target_act=[x for x in t1 if len(x)>1]\n",
        "t1=[x.lower() for x in t1 if len(x)>1]\n",
        "\n",
        "index1=datasets._preprocess(t1,doc1)\n",
        "index2=datasets._preprocess(t1,doc2)\n",
        "index3=datasets._preprocess(t1,doc3)\n",
        "index4=datasets._preprocess(t1,doc4)\n",
        "index5=datasets._preprocess(t1,doc5)\n",
        "index6=datasets._preprocess(t1,doc6)\n",
        "index7=datasets._preprocess(t1,doc7)\n",
        "index8=datasets._preprocess(t1,doc8)\n",
        "index9=datasets._preprocess(t1,doc9)\n",
        "index10=datasets._preprocess(t1,doc10)\n",
        "\n",
        "\n",
        "index_t1=index1[1]\n",
        "index_t2=index2[1]\n",
        "index_t3=index3[1]\n",
        "index_t4=index4[1]\n",
        "index_t5=index5[1]\n",
        "index_t6=index6[1]\n",
        "index_t7=index7[1]\n",
        "index_t8=index8[1]\n",
        "index_t9=index9[1]\n",
        "index_t10=index10[1]\n",
        "\n",
        "print('The target words are:',t1)\n",
        "target_words=t1\n",
        "\n",
        "print('The index_t1 are ', index_t1)\n",
        "print('The index_t2 are ', index_t2)\n",
        "\n",
        "\n",
        "#conversions\n",
        "target_uni=[unidecode.unidecode(m) for m in t1]\n",
        "target_toks=[]\n",
        "# print(target_uni)\n",
        "for k in t1:\n",
        "  target_toks.append(tokenizer.tokenize(k))\n",
        "print('converted target toks',target_toks)"
      ],
      "metadata": {
        "id": "WBbu-VZwaN3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078e2ef8-357b-4e20-9cc1-f7dd1026dd01"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target words are: ['neural networks', 'reinforcement learning', 'neural network', 'gaussian process', 'graphical models', 'support vector', 'gaussian processes', 'active learning', 'variational inference', 'monte carlo', 'online learning', 'speech recognition', 'recurrent neural', 'component analysis', 'gradient descent', 'hidden markov', ': the', 'deep learning', 'learning :', 'markov models', 'vector machines', 'analog vlsi', 'stochastic gradient', 'markov decision', 'feature selection', ': learning', 'networks learning', 'random fields', 'machine learning', 'networks :', 'belief propagation', 'kernel learning', 'unsupervised learning', 'neural networks', 'model selection', 'matrix completion', 'dynamic programming', 'function approximation', 'decision processes', 'object recognition', 'time series', 'mixture models', 'latent variable', 'metric learning', 'deep neural', 'spiking neurons', 'bayesian inference', 'density estimation', 'approximate inference', 'convex optimization', 'supervised learning', 'dynamical systems', 'convolutional neural', 'generative models', 'large scale', 'matrix factorization', ': application', 'stochastic optimization', 'natural images', 'spectral clustering', 'learning the', 'dimensionality reduction', 'principal component', 'learning sparse', 'object detection', 'map inference', 'visual cortex', 'recurrent networks', 'radial basis', 'risk minimization', 'nearest neighbor', 'independent component', 'high dimensional', 'large margin', 'structured prediction', 'learning algorithms', 'neural net', 'learning multiple', 'bayesian model', 'models learning', 'bayesian networks', 'policy gradient', 'variational bayesian', 'process regression', 'sparse coding', 'domain adaptation', 'learning deep', 'recognition using', 'artificial neural', 'mean field', 'maximum likelihood', 'missing data', 'sample complexity', 'exponential family', 'deep networks', 'coordinate descent', 'associative memory', 'basis function', 'feature extraction', 'boltzmann machines', 'learning algorithm', 'learning learning', 'learning bayesian', 'vector machine', 'gradient methods', 'latent dirichlet', 'learning gaussian', 'topic models', 'semi-supervised learning', 'conditional random', 'feature learning', 'generative adversarial', 'network model', 'neural nets', 'mutual information', 'markov random', 'second order', 'clustering :', 'learning approach', ': efficient', 'bayesian learning', 'decision trees', 'learning structured', 'variable models', 'gaussian graphical', 'dirichlet allocation', 'probabilistic inference', 'semi-supervised learning', 'graphical model', 'sparse pca', 'message passing', 'convolutional networks', 'bayesian optimization', 'learning neural', 'temporal difference', 'gaussian mixtures', ': new', 'least squares', 'partially observable', 'linear models', 'belief networks', 'markov networks', 'policy search', 'maximum margin', 'restricted boltzmann', 'collaborative filtering', 'decision making', 'end --', 'nonparametric bayesian', 'transfer learning', 'tensor decomposition', 'neural model', 'image segmentation', 'network :', 'information theoretic', ': from', 'parameter estimation', 'efficient learning', 'visual attention', 'visual recognition', 'value function', 'learning stochastic', 'linear programming', 'information bottleneck', 'variance reduction', ': towards', 'sparse gaussian', 'multiple kernel', 'dirichlet process', 'networks neural', 'learning control', 'distributed representations', 'networks the', 'pattern recognition', 'analog neural', 'vlsi neural', 'ocular dominance', 'learning dynamic', 'natural language', 'continuous speech', 'learning model', 'learning curves', 'learning using', 'spiking neurons', 'mixtures experts', 'graph matching', 'learning continuous', 'learning adaptive', 'information maximization', ': bayesian', 'learning efficient', 'multi-task learning', 'models :', 'natural scenes', 'learning nonlinear', ': fast', 'process models', 'sequential data', 'data learning', 'probabilistic models', 'high dimensions', 'markov chain', 'inference bayesian', 'structure learning', 'kernel methods', 'logistic regression', 'model learning', 'hierarchical clustering', 'training deep', 'submodular functions', 'inverse reinforcement', 'empirical risk', ': probabilistic', 'using neural', 'networks application', 'complexity learning', 'boltzmann machine', 'networks using', 'vlsi implementation', ': theory', 'markov model', 'selective attention', 'face recognition', 'anomaly detection', 'finite state', 'population codes', 'unlabeled data', 'data clustering', 'manifold learning', 'real time', 'neighbor classification', 'policy iteration', 'training sets', 'source separation', 'learning probabilistic', 'discriminant analysis', 'the infinite', 'importance sampling', 'lower bounds', 'probabilistic model', 'kernel machines', 'causal inference', 'data :', 'side information', 'distance metric', 'loss functions', 'expectation propagation', 'fast rates', 'spectral methods', '-- end', 'random projections', 'graphical models', 'subspace clustering', 'generalized linear', ': deep', 'sparse inverse', 'inverse covariance', 'robust pca', 'adversarial networks', 'stochastic learning', 'its application', 'basis functions', 'signal processing', 'nets :', 'function networks', 'learning rate', 'receptive field', 'data analysis', 'eye movements', 'difference learning', 'vector quantization', 'receptive fields', 'algorithm learning', 'training neural', 'learning rules', 'the power', 'generalization error', 'dimension reduction', 'value iteration', '-line learning', 'blind separation', 'pose estimation', 'mixture model', 'statistical models', 'factor analysis', 'inference learning', 'likelihood estimation', 'components analysis', 'generative model', 'learning linear', 'analysis :', 'approach learning', 'bayesian models', ': unified', 'markov chains', 'semidefinite programming', 'learning optimal', 'spectral learning', 'imitation learning', 'regret bounds']\n",
            "The index_t1 are  OrderedDict([('neural networks', [55, 59, 67, 93, 527, 609, 611, 644, 645, 1192, 1665, 1689, 1773, 2651, 2700, 3665, 4854, 4868, 5136, 5181, 5328, 5340, 5398, 5428, 6241, 6357, 6667, 6701, 6721, 6801, 7262, 7267, 7275, 7647, 7825, 8280, 8669, 8671, 8680, 8789, 8794, 9999, 10001, 10002, 10005, 10018, 10072, 11879, 12834, 14032, 14697, 14699, 15068, 15364, 15372, 15376, 15892, 15895, 15950, 15957, 16257, 16270, 17420, 18681, 18733, 19662, 20650, 21159, 22283, 22323, 22347, 22354, 22356, 22365, 22796, 26348, 26914, 27244, 28050, 28902, 29367, 30442, 30483, 30486, 30546, 30558, 30561, 30915, 30936, 30938, 32606, 32657, 32661, 32681, 33233, 33258, 33329, 33360, 33431, 33441, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34268, 34971, 35531, 35548, 35858, 35896, 36337, 36395, 36413, 36892, 36897, 36899, 36910, 36938, 37320, 37504, 37509, 37511, 38128, 38897, 38912, 42588, 44434, 44446, 46317, 47396, 48398, 48538, 48987, 49005, 49061, 49076, 49772, 49774, 49798, 49840, 50496, 50576, 50611, 50637, 52209, 52289, 52370, 53161, 53374, 56521, 56720, 56724, 56840, 56884, 56998, 57005, 57781, 57801, 58481, 59008, 59042, 59053, 59055, 59651, 59856, 61183, 61192, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 64670, 65360, 66391, 66400, 66452, 66854, 66859, 66863, 66868, 67653, 69142, 69149, 69446, 69483, 69960, 69962, 69980, 71940, 72476, 72483, 72486, 73170, 73175, 73279, 73369, 75827, 75833, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76351, 76397, 77195, 77207, 77593, 77599, 77611, 77625, 79379, 79409, 79510, 79825, 81758, 82044, 82566, 82594, 82599, 83219, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86635, 87042, 87086, 87462, 87473, 88956, 89195, 89219, 89266, 90718, 92327, 92357, 92359, 92366, 92372, 92373, 92376, 92379, 92380, 92631, 92665, 92676, 92819, 92824, 92873, 92967, 93699, 93701, 93708, 93714, 93728, 94100, 94154, 94158, 94170, 94235, 94238, 94240, 94577, 95681, 95718, 95746, 95967, 96006, 96093, 97183, 97187, 97908, 97974, 97987, 97996, 99036, 99090, 99125, 99258, 101124, 101890, 101893, 103041, 103076, 103114, 103327, 103481, 106635, 108079, 108440, 108459, 108461, 108503, 108510, 108516, 108727, 108927, 108956, 109826, 109966, 110133, 111659, 111660, 112455, 113161, 117952, 118424, 119251, 121389, 121392, 121393, 121402, 121403, 121430, 121438, 121439, 121441, 121442, 121443, 121501, 121502, 121507, 121509, 121602, 121609, 121610, 121640, 121651, 121672, 121689, 121698, 121699, 121700, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122255, 122264, 122267, 122279, 122815, 122820, 122829, 123360, 123391, 123416, 123454, 123914, 124793, 124802, 125275, 125333, 125385, 125754, 125755, 125757, 125828, 129598, 129995, 129999, 130107, 130186, 130192, 130211, 130217, 130282, 130424, 130435, 130445, 130471, 130480, 130490, 130493, 131234, 131455, 131469, 131472, 131932, 132120, 132153, 133540, 135026, 135029, 135072, 135243, 135306, 135647, 135686, 135787, 135788, 135885, 136727, 136739, 136786, 137044, 137055, 137058, 137063, 137068, 137095, 139207, 140011, 140012, 140425, 140430, 140475, 140476, 140493, 140499, 140540, 140954, 140956, 141072, 141098, 141295, 143950, 144992, 145013, 146825, 55, 59, 67, 93, 527, 609, 611, 644, 645, 1192, 1665, 1689, 1773, 2651, 2700, 3665, 4854, 4868, 5136, 5181, 5328, 5340, 5398, 5428, 6241, 6357, 6667, 6701, 6721, 6801, 7262, 7267, 7275, 7647, 7825, 8280, 8669, 8671, 8680, 8789, 8794, 9999, 10001, 10002, 10005, 10018, 10072, 11879, 12834, 14032, 14697, 14699, 15068, 15364, 15372, 15376, 15892, 15895, 15950, 15957, 16257, 16270, 17420, 18681, 18733, 19662, 20650, 21159, 22283, 22323, 22347, 22354, 22356, 22365, 22796, 26348, 26914, 27244, 28050, 28902, 29367, 30442, 30483, 30486, 30546, 30558, 30561, 30915, 30936, 30938, 32606, 32657, 32661, 32681, 33233, 33258, 33329, 33360, 33431, 33441, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34268, 34971, 35531, 35548, 35858, 35896, 36337, 36395, 36413, 36892, 36897, 36899, 36910, 36938, 37320, 37504, 37509, 37511, 38128, 38897, 38912, 42588, 44434, 44446, 46317, 47396, 48398, 48538, 48987, 49005, 49061, 49076, 49772, 49774, 49798, 49840, 50496, 50576, 50611, 50637, 52209, 52289, 52370, 53161, 53374, 56521, 56720, 56724, 56840, 56884, 56998, 57005, 57781, 57801, 58481, 59008, 59042, 59053, 59055, 59651, 59856, 61183, 61192, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 64670, 65360, 66391, 66400, 66452, 66854, 66859, 66863, 66868, 67653, 69142, 69149, 69446, 69483, 69960, 69962, 69980, 71940, 72476, 72483, 72486, 73170, 73175, 73279, 73369, 75827, 75833, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76351, 76397, 77195, 77207, 77593, 77599, 77611, 77625, 79379, 79409, 79510, 79825, 81758, 82044, 82566, 82594, 82599, 83219, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86635, 87042, 87086, 87462, 87473, 88956, 89195, 89219, 89266, 90718, 92327, 92357, 92359, 92366, 92372, 92373, 92376, 92379, 92380, 92631, 92665, 92676, 92819, 92824, 92873, 92967, 93699, 93701, 93708, 93714, 93728, 94100, 94154, 94158, 94170, 94235, 94238, 94240, 94577, 95681, 95718, 95746, 95967, 96006, 96093, 97183, 97187, 97908, 97974, 97987, 97996, 99036, 99090, 99125, 99258, 101124, 101890, 101893, 103041, 103076, 103114, 103327, 103481, 106635, 108079, 108440, 108459, 108461, 108503, 108510, 108516, 108727, 108927, 108956, 109826, 109966, 110133, 111659, 111660, 112455, 113161, 117952, 118424, 119251, 121389, 121392, 121393, 121402, 121403, 121430, 121438, 121439, 121441, 121442, 121443, 121501, 121502, 121507, 121509, 121602, 121609, 121610, 121640, 121651, 121672, 121689, 121698, 121699, 121700, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122255, 122264, 122267, 122279, 122815, 122820, 122829, 123360, 123391, 123416, 123454, 123914, 124793, 124802, 125275, 125333, 125385, 125754, 125755, 125757, 125828, 129598, 129995, 129999, 130107, 130186, 130192, 130211, 130217, 130282, 130424, 130435, 130445, 130471, 130480, 130490, 130493, 131234, 131455, 131469, 131472, 131932, 132120, 132153, 133540, 135026, 135029, 135072, 135243, 135306, 135647, 135686, 135787, 135788, 135885, 136727, 136739, 136786, 137044, 137055, 137058, 137063, 137068, 137095, 139207, 140011, 140012, 140425, 140430, 140475, 140476, 140493, 140499, 140540, 140954, 140956, 141072, 141098, 141295, 143950, 144992, 145013, 146825]), ('reinforcement learning', [19716, 19802, 20214, 20240, 20343, 20345, 20605, 20655, 51729, 51737, 60828, 60830, 109822, 109838, 109844, 109968, 109972, 109974, 109976, 110133, 119714, 119732, 119742, 120170, 120344, 120345, 120372]), ('neural network', [10, 55, 59, 67, 93, 178, 527, 609, 611, 622, 644, 645, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1934, 1950, 1952, 1957, 1972, 2583, 2651, 2653, 2654, 2700, 2706, 2796, 2814, 2817, 2824, 2933, 3086, 3128, 3607, 3665, 3672, 3705, 3855, 3876, 4854, 4855, 4868, 4870, 4891, 5136, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 6241, 6323, 6357, 6667, 6701, 6721, 6792, 6801, 6802, 6851, 7262, 7267, 7273, 7275, 7290, 7454, 7456, 7641, 7647, 7825, 8280, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9383, 9534, 9749, 9969, 9974, 9975, 9999, 10001, 10002, 10005, 10013, 10016, 10018, 10045, 10072, 11879, 12245, 12834, 12908, 13276, 13351, 14032, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15892, 15895, 15950, 15957, 15979, 16062, 16257, 16270, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17529, 18681, 18733, 19659, 19662, 20650, 20674, 21159, 21240, 22283, 22323, 22347, 22354, 22356, 22365, 22387, 22779, 22796, 23038, 23159, 23168, 23175, 26348, 26844, 26864, 26914, 27188, 27244, 28050, 28667, 28793, 28902, 29003, 29038, 29058, 29060, 29285, 29367, 29833, 30442, 30445, 30483, 30484, 30486, 30496, 30546, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30854, 30915, 30936, 30938, 30943, 30963, 32144, 32166, 32606, 32657, 32661, 32681, 33225, 33233, 33247, 33251, 33258, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34253, 34258, 34268, 34301, 34417, 34891, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35896, 36322, 36325, 36331, 36337, 36382, 36395, 36413, 36416, 36493, 36548, 36747, 36750, 36784, 36802, 36892, 36897, 36899, 36910, 36913, 36919, 36929, 36938, 37053, 37121, 37157, 37320, 37369, 37385, 37420, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 38128, 38897, 38898, 38904, 38908, 38912, 38919, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43706, 43761, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45657, 46258, 46317, 47396, 48398, 48405, 48408, 48538, 48592, 48594, 48640, 48647, 48706, 48770, 48876, 48879, 48891, 48900, 48901, 48987, 49002, 49005, 49016, 49021, 49025, 49061, 49063, 49076, 49094, 49294, 49542, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50611, 50637, 51186, 51201, 51214, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55952, 56521, 56720, 56724, 56840, 56857, 56865, 56884, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57781, 57801, 58223, 58275, 58465, 58481, 59008, 59042, 59053, 59055, 59639, 59651, 59856, 59926, 60715, 61176, 61183, 61192, 61504, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 62891, 62906, 64670, 65360, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69142, 69149, 69446, 69483, 69673, 69960, 69962, 69980, 70832, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72473, 72476, 72483, 72486, 72487, 72550, 72588, 73156, 73167, 73170, 73171, 73175, 73279, 73369, 74215, 74797, 74832, 75041, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76332, 76351, 76397, 76413, 76528, 76617, 76719, 77195, 77207, 77218, 77228, 77593, 77599, 77610, 77611, 77625, 78264, 78279, 78522, 78545, 79379, 79409, 79510, 79825, 81267, 81758, 82044, 82566, 82594, 82599, 83219, 83259, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87086, 87462, 87473, 87918, 87932, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 90486, 90598, 90622, 90638, 90718, 90725, 92322, 92327, 92357, 92359, 92361, 92366, 92372, 92373, 92376, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92676, 92819, 92824, 92873, 92967, 93655, 93699, 93701, 93708, 93714, 93717, 93728, 93731, 94080, 94100, 94142, 94151, 94154, 94158, 94170, 94221, 94235, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95672, 95681, 95746, 95854, 95967, 96006, 96014, 96024, 96093, 96213, 96661, 96685, 97183, 97187, 97199, 97225, 97908, 97974, 97987, 97996, 98367, 99036, 99090, 99123, 99125, 99258, 99266, 100805, 101124, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103492, 103493, 103590, 103684, 103728, 103734, 103742, 106635, 106645, 108061, 108072, 108079, 108103, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108727, 108927, 108937, 108956, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 111656, 111659, 111660, 112074, 112438, 112455, 113161, 113753, 115874, 115878, 117952, 118424, 119251, 119722, 120918, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122247, 122254, 122264, 122267, 122279, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123416, 123454, 123914, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125375, 125385, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125828, 125829, 125831, 126020, 126025, 126027, 126087, 126100, 126126, 127242, 127457, 128631, 129031, 129598, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130445, 130471, 130480, 130490, 130493, 130627, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134433, 134473, 135026, 135029, 135072, 135239, 135243, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136727, 136739, 136760, 136762, 136772, 136786, 136820, 137044, 137055, 137058, 137063, 137068, 137095, 138161, 138378, 138424, 138744, 138759, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139448, 139994, 140011, 140012, 140016, 140385, 140425, 140430, 140475, 140476, 140484, 140493, 140495, 140499, 140540, 140954, 140956, 141004, 141011, 141072, 141098, 141295, 142457, 142465, 143092, 143149, 143183, 143265, 143303, 143313, 143398, 143410, 143411, 143492, 143924, 143950, 144992, 145013, 145324, 145362, 145733, 146825]), ('active learning', [43726, 43898, 130427]), ('monte carlo', [76705]), ('online learning', [96036]), ('speech recognition', [12291, 12353, 12894, 15377, 15396, 15459, 18676, 31446, 32154, 32157, 34962, 35897, 44444, 47157, 47360, 50332, 50392, 50393, 54326, 54419, 54967, 56823, 60706, 60749, 61529, 61548, 61821, 61849, 61861, 61865, 61883, 74274, 74289, 75156, 75175, 76868, 76908, 77147, 77593, 77609, 77610, 77618, 77739, 78175, 83221, 83232, 88958, 89938, 90529, 90530, 90622, 90660, 90662, 90664, 90668, 90674, 90680, 91795, 91800, 91807, 91817, 91827, 92265, 92306, 103036, 103038, 103052, 103062, 103064, 103301, 108064, 108084, 108440, 108442, 109410, 109426, 109788, 110109, 111647, 111651, 111655, 111659, 118086, 124675, 124803, 125272, 128008, 128319, 128418, 128633, 129013, 129600, 136728, 136741, 136873, 136879, 136969, 137044, 137052, 137068, 144416, 144539, 144999]), ('recurrent neural', [4245, 14699, 15950, 66391, 69483, 78264, 82566, 90718, 108416, 122815, 122829, 129999, 137063, 143150, 143183, 146825]), ('component analysis', [41496, 48534, 90930, 90955, 91252, 91277, 143476]), ('gradient descent', [703, 704, 788, 3675, 3799, 3903, 3986, 4133, 4179, 10703, 10741, 11803, 12018, 13158, 15391, 16733, 16943, 16994, 17013, 17019, 17025, 17084, 17250, 21878, 21927, 22212, 22252, 22257, 23162, 23219, 23285, 23330, 23334, 23339, 32497, 35169, 37875, 37880, 37981, 42088, 46692, 46756, 49237, 49238, 49270, 49273, 54331, 54332, 54377, 58752, 58754, 59077, 59169, 59608, 66268, 67641, 67686, 67818, 67944, 68021, 68595, 71212, 71614, 71658, 73838, 73980, 79384, 79867, 79889, 79917, 83150, 90932, 90960, 91254, 91282, 96002, 97429, 97453, 97754, 102883, 112081, 112083, 114207, 114278, 114365, 117660, 117879, 118058, 122251, 122692, 123485, 123820, 123924, 129778, 134373, 137962, 139284, 139306, 140541, 142595, 142624, 142635, 143143, 143214, 143319, 143787]), (': the', [19, 1015, 1630, 2848, 4066, 4103, 11362, 11367, 11604, 11659, 11729, 16076, 16604, 17525, 20840, 21117, 21119, 23977, 26744, 28256, 28596, 29303, 36275, 37558, 38035, 38763, 41230, 41233, 43933, 45388, 45766, 45869, 45871, 45887, 45938, 46300, 46667, 49163, 49272, 51255, 51455, 55943, 55950, 58960, 59673, 61583, 61794, 62155, 63000, 63004, 63100, 64181, 64182, 64297, 65689, 65979, 66076, 66185, 66860, 71900, 73905, 77622, 78626, 78634, 82431, 85780, 87564, 87890, 90526, 91426, 91555, 99255, 101728, 102500, 102880, 103836, 104064, 107114, 108349, 108674, 108732, 108781, 108910, 109104, 111920, 117119, 117399, 117513, 117822, 120971, 121788, 123373, 123568, 123663, 123676, 124452, 124477, 124613, 127103, 127110, 128009, 131477, 133173, 134995, 135606, 135681, 136909, 137096, 138401, 138402, 138403, 139382, 139404, 139435, 140557, 142341, 145347, 145635, 146452]), ('analog vlsi', [140488]), ('stochastic gradient', [704, 12018, 23339, 61009]), ('feature selection', [73282, 134033, 139945]), (': learning', [117793, 130296]), ('networks learning', [23559, 23653, 84028, 84030, 101903, 101972, 101974, 140648, 140692, 140848]), ('random fields', [2816]), ('machine learning', [19826, 23149, 23237, 28594, 47156, 51755, 92320, 92323, 92337, 92363, 92405, 110156, 129634, 134371]), ('unsupervised learning', [20353, 20629, 26312, 26333, 28058, 51734, 51768, 60546, 61502, 61504, 64785, 70013, 91774, 101851, 104005, 112057, 112503, 114965, 120918, 120925, 123397, 128954, 132141, 142357, 142444, 143457, 143492]), ('dynamic programming', [15369, 15459, 15460, 92015, 92016, 92296, 109868, 137730]), ('function approximation', [71123, 97259, 99114, 102877, 109836, 131612, 131618, 133844]), ('object recognition', [19212, 19228, 19667, 19668, 19671, 66112, 90477, 114997, 115208, 120424, 120787, 139209, 141563, 142137, 142145, 142432, 142478]), ('time series', [10006, 10022, 10036, 10037, 10213, 10231, 10233, 10238, 10250, 10310, 10605, 16413, 16456, 54240, 58392, 58412, 58442, 58445, 58448, 58451, 58457, 58473, 71920, 101222, 101231, 102649, 112133, 138067, 138769, 138887, 138889, 138893, 138906]), ('mixture models', [111273]), ('spiking neurons', [106618, 136127, 136165, 106618, 136127, 136165]), ('convex optimization', [90917, 91239]), ('supervised learning', [628, 19713, 19814, 19819, 20208, 20218, 20220, 20353, 20629, 26312, 26333, 28033, 28058, 28533, 28627, 28633, 28643, 28654, 32147, 51732, 51734, 51768, 54422, 58202, 59027, 59042, 59043, 59076, 59605, 60545, 60546, 60553, 61502, 61504, 64783, 64785, 65294, 70013, 71120, 71146, 77067, 84022, 91774, 99540, 101851, 104005, 109819, 109843, 112057, 112503, 113650, 114031, 114965, 117450, 119251, 119730, 120343, 120918, 120925, 123137, 123299, 123397, 128954, 130471, 130719, 132141, 137912, 139659, 141110, 142357, 142366, 142444, 142500, 143457, 143492]), ('dynamical systems', [3666, 3680, 4181, 4384, 10028, 10312, 16167, 26425, 36891, 36900, 36904, 36909, 37504, 52210, 52221, 52353, 52355, 52376, 52399, 52540, 52603, 53164, 53167, 56811, 56865, 56869, 56874, 56882, 56887, 85067, 85068, 109956, 131100, 131197, 131252, 134992, 138179, 146711, 146712]), ('large scale', [11887, 34244, 37504, 53731, 55320, 69467, 77617, 78175, 86570, 105360, 105667, 106118, 112059, 143996, 144394]), (': application', [61883, 83232]), ('natural images', [32401]), ('learning the', [11234, 11651, 20269, 21930, 28036, 29980, 34543, 42298, 42468, 52126, 59542, 60324, 60690, 72010, 78155, 99164, 101764, 102066, 112537, 120348, 122877, 122980, 123220, 130062, 130084, 130103, 131216, 133541, 134988, 140648, 140848, 141764]), ('dimensionality reduction', [56790, 89935, 112412, 112413, 128327, 128330, 143459, 143485, 143493]), ('principal component', [41496, 48534, 48743, 61381, 90930, 90955, 91252, 91277, 143476, 143489]), ('visual cortex', [1202, 1211, 1229, 1244, 1679, 46250, 53368, 53370, 53594, 53795, 61378, 64679, 65327, 75119, 82051, 82053, 82065, 82077, 83693, 83759, 83855, 83984, 89334, 89809, 91389, 91400, 91430, 91435, 91740, 104755, 105243, 110691, 111089, 120397, 120429, 120898, 124255, 134018, 134245, 134419, 143918, 143923, 143945, 143975, 143976, 144000, 144010, 144058, 144061, 144063, 144064, 144071, 144076, 144082, 144092, 144143, 144154, 144187, 144365, 144377, 144381, 144384, 146310, 146334, 146340, 146343]), ('recurrent networks', [15959, 16174, 34560, 38459, 42322, 68745, 69056, 76900, 77171, 82562, 90693, 114832, 118057, 122239, 122577, 136939, 137047]), ('radial basis', [71561, 71563, 100826, 112049, 112488, 133843, 142500]), ('nearest neighbor', [6202, 6211, 6215, 7585, 15373, 31441, 31448, 31458, 31935, 31938, 32016, 32127, 32138, 32139, 38370, 39125, 39392, 41003, 64521, 66551, 72583, 72587, 73082, 73166, 73942, 74880, 74885, 75024, 82608, 82903, 91508, 91517, 100182, 100546, 100739, 102607, 102608, 102609, 102639, 102642, 102643, 102645, 102647, 102648, 102651, 102653, 102654, 102663, 102685, 102757, 103326, 104809, 104968, 111137, 119578, 129011, 129038, 129201, 129222, 129318, 129373, 129483, 129550, 142502, 142568, 142593, 142774]), ('independent component', [7614]), ('high dimensional', [10650, 29034, 29200, 36919, 36930, 37515, 102053, 112103, 112107, 112120, 112402, 113092, 120727, 131482, 143465, 143466, 143885]), ('learning algorithms', [3677, 3715, 5055, 5060, 7606, 7653, 10587, 11909, 17446, 19709, 19737, 20196, 23147, 23329, 26796, 28067, 28079, 28596, 28704, 37448, 41982, 41986, 42486, 44531, 44812, 47405, 49076, 51728, 51764, 60243, 68519, 70000, 71120, 71146, 72006, 72040, 72219, 72421, 73176, 77761, 82099, 84519, 84912, 85751, 88254, 89611, 89786, 94277, 96004, 98367, 100835, 101792, 109836, 109844, 112418, 119264, 119335, 119583, 120358, 122267, 122285, 122786, 123137, 123299, 127496, 127503, 127510, 127528, 127615, 127945, 130484, 130543, 131933, 135061, 140373]), ('neural net', [10, 55, 59, 67, 93, 178, 527, 609, 611, 622, 644, 645, 649, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1934, 1950, 1952, 1957, 1972, 2583, 2653, 2654, 2662, 2669, 2688, 2700, 2706, 2796, 2814, 2817, 2824, 2833, 2933, 2990, 3009, 3086, 3128, 3607, 3665, 3672, 3705, 3855, 3876, 4256, 4854, 4855, 4868, 4870, 4891, 5136, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 6241, 6323, 6357, 6667, 6701, 6721, 6792, 6801, 6802, 6851, 7262, 7267, 7273, 7275, 7290, 7454, 7456, 7641, 7647, 7825, 8280, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9383, 9534, 9749, 9966, 9969, 9974, 9975, 9999, 10001, 10002, 10003, 10005, 10007, 10009, 10013, 10016, 10018, 10045, 10048, 10050, 10051, 10052, 10055, 10057, 10072, 10077, 10259, 10261, 10288, 10299, 10308, 10314, 10321, 10554, 10586, 10589, 10595, 10596, 10610, 10615, 10617, 10636, 10660, 10669, 11879, 12245, 12834, 12908, 13276, 13351, 14032, 14036, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15403, 15404, 15456, 15892, 15895, 15950, 15957, 15979, 16062, 16257, 16270, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17529, 18086, 18129, 18681, 18733, 19659, 19662, 20650, 20674, 20707, 21139, 21159, 21240, 22283, 22323, 22347, 22354, 22356, 22365, 22387, 22779, 22796, 23038, 23159, 23168, 23175, 25506, 26348, 26844, 26864, 26914, 27102, 27188, 27244, 28050, 28667, 28747, 28793, 28902, 29003, 29038, 29058, 29060, 29285, 29367, 29833, 30442, 30445, 30483, 30484, 30486, 30496, 30502, 30546, 30556, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30839, 30843, 30854, 30915, 30936, 30938, 30943, 30963, 31448, 31459, 31772, 32144, 32151, 32155, 32166, 32606, 32657, 32661, 32681, 33225, 33233, 33247, 33251, 33258, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34253, 34258, 34268, 34301, 34417, 34891, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35882, 35887, 35896, 36059, 36310, 36322, 36325, 36331, 36337, 36382, 36395, 36413, 36416, 36493, 36548, 36747, 36750, 36784, 36802, 36812, 36892, 36897, 36899, 36910, 36913, 36919, 36929, 36938, 37053, 37121, 37157, 37320, 37369, 37385, 37420, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 38128, 38897, 38898, 38904, 38908, 38912, 38919, 39995, 41958, 41970, 41981, 42149, 42170, 42173, 42176, 42179, 42188, 42224, 42247, 42256, 42303, 42310, 42323, 42441, 42442, 42445, 42446, 42453, 42475, 42480, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43706, 43761, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45640, 45645, 45657, 46258, 46317, 47396, 47403, 48398, 48405, 48408, 48538, 48592, 48594, 48640, 48647, 48706, 48770, 48876, 48879, 48891, 48900, 48901, 48987, 49002, 49005, 49016, 49021, 49025, 49061, 49063, 49076, 49094, 49294, 49542, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50611, 50637, 51186, 51201, 51214, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55387, 55918, 55952, 56521, 56720, 56724, 56804, 56811, 56840, 56857, 56865, 56884, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57781, 57801, 58223, 58275, 58465, 58481, 59008, 59042, 59053, 59055, 59639, 59651, 59751, 59856, 59926, 60715, 61176, 61183, 61192, 61496, 61504, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 62891, 62906, 64670, 65360, 65744, 65770, 66023, 66024, 66030, 66031, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69141, 69142, 69149, 69446, 69483, 69673, 69960, 69962, 69980, 70832, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72362, 72438, 72473, 72476, 72483, 72486, 72487, 72550, 72555, 72567, 72588, 73156, 73161, 73163, 73165, 73167, 73170, 73171, 73175, 73279, 73369, 73804, 74215, 74270, 74284, 74793, 74797, 74832, 75041, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76332, 76351, 76397, 76413, 76528, 76617, 76681, 76719, 77195, 77207, 77218, 77228, 77593, 77599, 77610, 77611, 77625, 77782, 78264, 78279, 78522, 78545, 79379, 79409, 79510, 79825, 80243, 80684, 81267, 81758, 82044, 82566, 82594, 82599, 83219, 83259, 84022, 84039, 84059, 84406, 84462, 84463, 84513, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87086, 87462, 87473, 87918, 87932, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 89294, 90486, 90598, 90622, 90638, 90718, 90725, 92322, 92327, 92328, 92357, 92359, 92361, 92366, 92372, 92373, 92376, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92674, 92676, 92677, 92680, 92700, 92773, 92819, 92823, 92824, 92863, 92865, 92873, 92881, 92884, 92922, 92923, 92928, 92930, 92935, 92939, 92948, 92952, 92967, 92968, 93655, 93699, 93701, 93708, 93714, 93717, 93728, 93731, 94080, 94100, 94142, 94151, 94154, 94158, 94170, 94221, 94235, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95632, 95672, 95681, 95746, 95854, 95967, 96006, 96014, 96024, 96093, 96097, 96213, 96661, 96685, 97183, 97187, 97199, 97225, 97908, 97974, 97987, 97996, 98367, 99036, 99090, 99123, 99125, 99258, 99266, 100178, 100184, 100191, 100194, 100210, 100734, 100738, 100805, 101124, 101134, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103491, 103492, 103493, 103590, 103684, 103728, 103734, 103742, 106159, 106174, 106178, 106179, 106191, 106591, 106635, 106645, 108061, 108072, 108079, 108103, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108727, 108927, 108937, 108956, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 111130, 111132, 111134, 111136, 111139, 111165, 111273, 111653, 111656, 111659, 111660, 112074, 112438, 112455, 113161, 113753, 115260, 115874, 115878, 117558, 117952, 118424, 118881, 119251, 119722, 120417, 120918, 120958, 120975, 120977, 120978, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122247, 122254, 122264, 122267, 122279, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123416, 123454, 123914, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125375, 125385, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125828, 125829, 125831, 125988, 126020, 126025, 126027, 126087, 126100, 126126, 127242, 127457, 127507, 128631, 129011, 129031, 129036, 129559, 129569, 129591, 129598, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130443, 130445, 130471, 130480, 130490, 130493, 130627, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134005, 134021, 134116, 134249, 134433, 134473, 135026, 135029, 135072, 135239, 135243, 135303, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136727, 136739, 136760, 136762, 136772, 136786, 136812, 136820, 137044, 137055, 137058, 137063, 137068, 137095, 138161, 138378, 138424, 138744, 138756, 138759, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139448, 139994, 140011, 140012, 140016, 140385, 140425, 140430, 140475, 140476, 140484, 140493, 140495, 140499, 140540, 140954, 140956, 141004, 141011, 141072, 141098, 141295, 141315, 141321, 141416, 142457, 142465, 143092, 143138, 143140, 143141, 143149, 143150, 143172, 143183, 143223, 143232, 143262, 143268, 143269, 143271, 143285, 143288, 143303, 143313, 143357, 143360, 143398, 143410, 143411, 143492, 143924, 143950, 144992, 145013, 145324, 145362, 145733, 146825]), ('learning multiple', [3888, 3927, 4167]), ('recognition using', [19221, 76945, 90674, 108442, 118424, 137058, 142469]), ('artificial neural', [15376, 15388, 15895, 18681, 20674, 21139, 23175, 26844, 26914, 33248, 33251, 33258, 33260, 33277, 33329, 33431, 33457, 33462, 33468, 33472, 34021, 34253, 34258, 34948, 34959, 35532, 35704, 39555, 39568, 52209, 52211, 52218, 52257, 52289, 52370, 52391, 52414, 53161, 53374, 59028, 65768, 67647, 69960, 74270, 74284, 75827, 75833, 75863, 75873, 75889, 76351, 76397, 82594, 82599, 83219, 83227, 87086, 88961, 92819, 93701, 95531, 100191, 110131, 119251, 119263, 120926, 127242, 134249, 135243, 138378, 140484, 143148, 145013]), ('mean field', [986, 987, 992, 999, 1000, 1191, 53371, 53464, 53504, 53508, 53532, 53562, 53565, 53585, 53638, 53689, 53709, 53787, 53792, 53805, 79373, 79375, 79377, 79401, 79416, 79418, 79419, 79469, 79485, 79510, 79567, 79713, 79716, 79720, 79782, 79823, 79828, 127495, 127510, 129613, 129623, 129626, 129635, 129849, 129946, 129980, 129994, 129996, 132234, 135646, 135684, 135765, 135789, 135819, 135886, 143608]), ('maximum likelihood', [5436, 5543, 5545, 5571, 10883, 10913, 17430, 17432, 31833, 31841, 31930, 32024, 32746, 58320, 73166, 92774, 108372, 111186, 112046, 112207, 112211, 112227, 112258, 112381, 112423, 115554, 138046, 139700, 139764, 139768, 139905]), ('deep networks', [119329]), ('associative memory', [1759, 2137, 3684, 4070, 4150, 5086, 5176, 5178, 5345, 5376, 6233, 8649, 11777, 11778, 11835, 11843, 13017, 13018, 13354, 13618, 15952, 15973, 15974, 15979, 15991, 16076, 16166, 16241, 19212, 19221, 19223, 19246, 19421, 19433, 19436, 19548, 19551, 19646, 19652, 19653, 19657, 19659, 19665, 19671, 19686, 19734, 29008, 29024, 29052, 29859, 29867, 30926, 30977, 31372, 35931, 35938, 35941, 35942, 35944, 35951, 35955, 35959, 35963, 35982, 35986, 35987, 35990, 35995, 35997, 35998, 36002, 36037, 36054, 36058, 36064, 36071, 36088, 36185, 36188, 36201, 36281, 36283, 36286, 36291, 36299, 36301, 36805, 43709, 43739, 43756, 44501, 45528, 47395, 47413, 47526, 47542, 47661, 47681, 47732, 47880, 49079, 50281, 50506, 50554, 50586, 56543, 56771, 56898, 56916, 57033, 69477, 70457, 81183, 82088, 85418, 85429, 85453, 85456, 85458, 85462, 85466, 85793, 97994, 103702, 104173, 104705, 106780, 106978, 116659, 116850, 116853, 116863, 116889, 116891, 119228, 120392, 120453, 120479, 120482, 120804, 120900, 123396, 133190, 133191, 135561, 135583, 137098, 137099, 137118, 145828, 145958, 145980, 145993, 146265]), ('basis function', [71561, 71563, 90709, 100826, 111337, 111545, 111547, 111552, 111615, 112049, 112488, 142500]), ('feature extraction', [12918, 13020, 13027, 13032, 13154, 39489, 66394, 75067, 103998, 104107, 139640, 139643, 139644, 139648, 139660, 143459, 143485, 143493, 143497, 143511, 143574, 143826, 143876]), ('learning algorithm', [1191, 2046, 2450, 2567, 3673, 3677, 3715, 3854, 5049, 5055, 5060, 5063, 6319, 7606, 7653, 10072, 10587, 11803, 11909, 14104, 14106, 14119, 14129, 17277, 17446, 19709, 19713, 19737, 20175, 20196, 20208, 20619, 23147, 23152, 23284, 23329, 23386, 26434, 26443, 26446, 26508, 26575, 26758, 26792, 26796, 28067, 28079, 28278, 28596, 28634, 28663, 28704, 28792, 28893, 32701, 34679, 36585, 36624, 37448, 41982, 41986, 42486, 44515, 44519, 44531, 44685, 44812, 46888, 47156, 47405, 49076, 50467, 50469, 51728, 51749, 51764, 55235, 56966, 57072, 57080, 57089, 57094, 57095, 57202, 58202, 58645, 59641, 59683, 60243, 60781, 61915, 61919, 62149, 62365, 66901, 67114, 68519, 68646, 69444, 69626, 69632, 69985, 69993, 70000, 71120, 71146, 71928, 71968, 72006, 72028, 72040, 72219, 72253, 72362, 72364, 72370, 72421, 73176, 73279, 77064, 77067, 77761, 78230, 78251, 78282, 82099, 82565, 84519, 84707, 84912, 85751, 86675, 88254, 89536, 89611, 89650, 89786, 92368, 94277, 95104, 95329, 95532, 96004, 97453, 98367, 100178, 100194, 100793, 100835, 101792, 103813, 108283, 108455, 109823, 109836, 109844, 112418, 112526, 112534, 112547, 112548, 112549, 112557, 112568, 112570, 112579, 112610, 112844, 112854, 112900, 112927, 115996, 115997, 117272, 117364, 117449, 118442, 118876, 119251, 119264, 119269, 119301, 119332, 119335, 119583, 119720, 120358, 122095, 122267, 122285, 122711, 122786, 122828, 122880, 123110, 123137, 123299, 123485, 123916, 123963, 125830, 125835, 127496, 127503, 127510, 127528, 127615, 127945, 127997, 128468, 129994, 130484, 130543, 130719, 131539, 131933, 135061, 136733, 136902, 137062, 140373, 140528, 140540, 146824]), ('learning learning', [130040]), ('network model', [1755, 1780, 1921, 2004, 2653, 2814, 2817, 2820, 2833, 2848, 2933, 2992, 3086, 3128, 3131, 3137, 3387, 3607, 4870, 5164, 6821, 9259, 9383, 13351, 14084, 14092, 14094, 14720, 14740, 15313, 17302, 17308, 17314, 17340, 17391, 17423, 17497, 19657, 19659, 21240, 23159, 26864, 27248, 34129, 34132, 34301, 34964, 34965, 35532, 38579, 38898, 38908, 38918, 43706, 43759, 43761, 44434, 44435, 44467, 44476, 44478, 44492, 45068, 45080, 45084, 45086, 45435, 45442, 45657, 45758, 45774, 49875, 55944, 55952, 55953, 55980, 57051, 57072, 57089, 62891, 62906, 64655, 66535, 67647, 71139, 72493, 72588, 77219, 77250, 77610, 81789, 83259, 86815, 87918, 87932, 88137, 88163, 89302, 89815, 89817, 93710, 96794, 98416, 100805, 103395, 105420, 105431, 105443, 105581, 108500, 118874, 120889, 121424, 122247, 125288, 126100, 126126, 131537, 132140, 139954, 142465, 142530, 143092, 143149, 143184, 146873, 147145, 147281]), ('neural nets', [649, 2651, 2662, 2688, 2990, 3009, 10299, 10308, 10615, 10660, 14036, 15403, 15404, 15456, 18129, 20707, 21139, 25506, 30502, 30839, 30843, 32155, 35882, 35887, 36812, 41958, 41981, 42149, 42303, 42310, 42446, 42453, 42480, 47403, 55918, 61496, 66024, 66030, 72438, 72567, 73163, 74270, 77782, 80684, 84513, 92680, 92881, 92928, 92968, 100184, 100191, 100210, 100738, 101134, 103491, 106159, 106591, 111132, 111134, 117558, 118881, 130443, 134021]), ('mutual information', [53881, 78317, 102565, 108332, 108420, 128627, 129626, 129841, 129844, 129950, 129951, 142444]), ('second order', [3801, 6495, 6607, 6652, 24329, 25554, 61159, 67739, 67766, 67777, 96111, 96244, 96363, 96368, 96530, 96608, 96662, 97387, 99943, 106775, 110542, 129669, 138006, 138803, 138827, 141476]), ('learning approach', [28533, 51768]), ('message passing', [30590, 30766]), ('temporal difference', [26470, 26473, 28599, 77175, 89497, 89533, 89845, 110160, 123122, 123362]), ('least squares', [10704, 10740, 10748, 17375, 19514, 37616, 52521, 54399, 54414, 61214, 90836, 91158, 102652, 112274, 112315, 119856, 133845]), ('linear models', [105760]), ('decision making', [39078, 39575, 39650, 39896, 39947, 66892, 69985, 77645, 110147, 120597]), ('neural model', [5441, 14816, 19693, 30491, 34922, 39318, 49065, 75911, 75958, 75997, 95715, 122310, 129604]), ('image segmentation', [38515, 74231, 115830, 136056, 139585, 139586, 139590, 139601, 139604, 139624, 139638, 139639, 139661, 139680, 139685, 139692, 139775, 139786, 139937]), ('network :', [59673]), ('information theoretic', [46068, 78622, 112496]), (': from', [79326, 80715, 87901]), ('parameter estimation', [54387, 58218, 108426, 123969, 143457, 143491]), ('efficient learning', [59047, 82609, 101636, 131933]), ('visual recognition', [19217, 87085, 87092, 87095, 87108, 87273, 133951]), ('linear programming', [1186, 49079, 94359, 94993, 95179, 112523, 112811, 113038, 115880, 116182, 116203]), ('variance reduction', [92888]), ('learning control', [36626, 43698, 43840, 99262, 99269, 101144, 110144, 122851, 122855, 122862, 123299, 123352, 145816, 145956, 146031]), ('distributed representations', [11228, 11233, 11241, 11244, 11276, 11356, 11375, 39465, 56517, 56544, 56714, 56722, 129982, 146891]), ('networks the', [14100, 44441, 44989, 109966, 114485, 128479]), ('pattern recognition', [614, 636, 652, 4257, 6289, 11194, 12908, 12944, 14091, 14445, 14515, 14524, 15372, 24168, 28652, 32159, 34532, 39566, 42623, 43712, 45407, 55014, 57788, 60097, 60682, 64282, 69141, 69459, 69469, 72010, 72411, 72413, 72480, 75091, 76398, 76402, 76410, 78288, 82591, 87255, 88953, 89202, 89972, 94655, 95206, 95623, 99539, 108073, 108085, 108453, 111167, 112077, 112433, 113610, 118886, 120410, 120438, 120979, 123386, 125836, 129595, 134012, 134023, 134101, 134240, 134258, 134389, 137465, 137481, 139955, 142418, 142466, 143165]), ('analog neural', [29003, 35896, 69446, 84510, 87076, 87462, 93717, 96014, 97974, 121389, 121424, 121430, 121501, 121642, 121687, 121706, 121713, 141004, 141416]), ('ocular dominance', [1260, 1277, 1281, 1682, 1685, 53368, 53605, 53607, 83776, 83777, 83841, 83860, 83898, 83903, 83980, 91388, 91403, 91407, 91414, 91430, 91505, 91517, 91541, 91542, 91554, 91584, 91625, 91642, 91656, 91728, 91732, 91758, 91770, 91775, 105367, 105373]), ('learning dynamic', [2132, 34969, 123478, 123687, 131197]), ('natural language', [11239, 42319, 56729, 80274, 80676, 80680, 82542, 96795, 96798, 96816, 97150]), ('continuous speech', [577, 11750, 12383, 61858, 82614, 83230, 90597, 109418, 109426, 109438, 109457, 111640, 111647, 111651, 111655, 137019, 137022, 137025, 145190, 145203]), ('learning model', [10703, 60083, 89496, 89532, 89569, 109870, 113118, 130542, 134014, 134103, 134240, 134513]), ('learning curves', [23393, 23397, 57356, 57449, 57507, 60328, 68734, 68864, 102754, 123252]), ('learning using', [20214, 28594, 36596, 110156, 112827, 128954, 130490]), ('graph matching', [87075]), ('learning nonlinear', [99112, 131205]), ('high dimensions', [143467]), ('model learning', [115319, 115323, 115454]), ('hierarchical clustering', [95016, 95089]), ('using neural', [10001, 42588, 55348, 58481, 72438, 73279, 103395, 111660, 125288, 129598, 140430]), ('networks using', [36608, 39645, 68233, 86169, 95969, 112329, 137044, 140493]), (': theory', [78634]), ('face recognition', [125299]), ('finite state', [5501, 42441, 42443, 42444, 42448, 56865, 91828, 101517, 123448, 143137, 143141, 143156, 143244]), ('data clustering', [32717]), ('real time', [2278, 13264, 30140, 32556, 34234, 39854, 48404, 48985, 48995, 49013, 49028, 51837, 53127, 60706, 60749, 67649, 71124, 71157, 71211, 71578, 71585, 71870, 71887, 84924, 86528, 90482, 95287, 102739, 103074, 122645, 136106, 136129, 139585, 139600, 139624, 139680, 139691, 139889, 141000, 141428, 143092]), ('neighbor classification', [39029, 39125]), ('training sets', [21471, 21473, 56545, 59045, 61148, 67717, 68323, 68329, 71652, 76671, 97775, 109480, 134040, 134054, 134108, 134379, 143415, 145004]), ('discriminant analysis', [90699, 90715, 113518, 143477]), ('the infinite', [49, 2850, 10229, 10235, 19670, 27707, 47002, 56550, 56960, 93885, 93928, 126325]), ('importance sampling', [92678, 92890, 92904, 92907, 92915, 92922]), ('lower bounds', [4911, 5360, 5390, 70446, 72016, 72276, 137470]), ('probabilistic model', [2990]), ('distance metric', [82902, 83045, 83053, 87255, 87256, 102642, 102686, 102900, 133153]), ('loss functions', [143513]), ('stochastic learning', [61157, 88330, 120369]), ('its application', [13345, 30900, 39857, 43768, 77552, 118396, 141868]), ('basis functions', [71561, 71563, 90709, 111337, 111545, 111615, 112488, 142500]), ('signal processing', [3085, 3714, 10011, 10023, 10026, 10036, 10069, 10289, 10311, 10650, 18891, 20708, 34187, 34963, 41584, 44489, 45081, 47392, 47411, 47878, 55013, 55390, 55408, 55458, 55901, 58395, 58481, 61794, 71137, 71170, 73310, 73313, 73731, 89434, 89823, 95265, 99259, 101225, 104111, 125506, 131216, 136106, 136170, 136175, 136177, 136180, 136206, 136664, 138167]), ('function networks', [112466]), ('learning rate', [10936, 12030, 23376, 26609, 42083, 46811, 47265, 54535, 54696, 59183, 59308, 59407, 59409, 59533, 61019, 61046, 61048, 61560, 68600, 68659, 68864, 68878, 68879, 68963, 68964, 69027, 69052, 80088, 87926, 88302, 89632, 89709, 90950, 91012, 91019, 91272, 91334, 91341, 97415, 97791, 98456, 98698, 100446, 106108, 113368, 114455, 117227, 117808, 117831, 117904, 119771, 123197, 123248, 123249, 123250, 127499, 127524, 127574, 127825, 127849, 127884, 127894, 127925, 129593, 131098, 131500, 131546, 134061, 134062, 140962, 142498, 142623, 142626, 142631, 142643, 142651, 142654, 142657, 142690, 142703, 142770, 143094, 143218, 144620, 144889]), ('receptive field', [1213, 1248, 1661, 6374, 8114, 8304, 8488, 8489, 24122, 24130, 24132, 24286, 24288, 24322, 24324, 24326, 24327, 24331, 24332, 24333, 24338, 24339, 24345, 24349, 24366, 24372, 28105, 37550, 37771, 37821, 38975, 39027, 39056, 39061, 39072, 39076, 39080, 39084, 39141, 39252, 39255, 39257, 39260, 39299, 39301, 39303, 39304, 39310, 39311, 39312, 39314, 39317, 39362, 39373, 39392, 39393, 39436, 39440, 39476, 51225, 51232, 51258, 51297, 51636, 51642, 51839, 51849, 51850, 51860, 51914, 51918, 51929, 51978, 51979, 54109, 54110, 54194, 54262, 57646, 57648, 57691, 57713, 57728, 57770, 57801, 60994, 60995, 60998, 61378, 61382, 61388, 61399, 61432, 61485, 61486, 62447, 62449, 62455, 62458, 62475, 62477, 62493, 62502, 62503, 62504, 62505, 62507, 62554, 62605, 62633, 62702, 62704, 62882, 62885, 62903, 62989, 62991, 64781, 65270, 65272, 65337, 65479, 65487, 66760, 71934, 77032, 77035, 77044, 77074, 82051, 82077, 89414, 91509, 91593, 91596, 91629, 91731, 91750, 99053, 100793, 100816, 100823, 100881, 100885, 100886, 100907, 100908, 101072, 101146, 102169, 102172, 102397, 102411, 102416, 102424, 102447, 102450, 102454, 102455, 102457, 102469, 102501, 102502, 102527, 102528, 102531, 102537, 102582, 103903, 103914, 104029, 106151, 106153, 106172, 106205, 106232, 106469, 106472, 106474, 106576, 110197, 110693, 112316, 112485, 119513, 119623, 124175, 124201, 128359, 128605, 131562, 132345, 134016, 134256, 134260, 134271, 134272, 134275, 134279, 134280, 134352, 134404, 134405, 134410, 134412, 134446, 140382, 141869, 142321, 142322, 142325, 142501, 142503, 142506, 142531, 142558, 142563, 142567, 142592, 142593, 142594, 142662, 143025, 143096, 145984, 145985, 145988, 146019, 146313, 146315, 146317, 146362, 146552, 146978]), ('data analysis', [54776, 71141, 71555, 129579]), ('eye movements', [84962, 84982, 84984, 85249, 85262, 85277, 85329, 102586, 128674, 128709, 128715, 128751, 133794]), ('vector quantization', [60690, 73279, 116877, 116894, 144431]), ('receptive fields', [1248, 1661, 8114, 8304, 8488, 8489, 24122, 24326, 24327, 24345, 24349, 28105, 37771, 39255, 39304, 39310, 39312, 39314, 51225, 51636, 51642, 51850, 51860, 51929, 54109, 54194, 57646, 57648, 57691, 57713, 57728, 57770, 57801, 60995, 61378, 61382, 61388, 61399, 61486, 62633, 62903, 62989, 62991, 64781, 65487, 71934, 77044, 89414, 91509, 91731, 100793, 100816, 100881, 100885, 101146, 102397, 102450, 102493, 102537, 106151, 106172, 106232, 110197, 110693, 112316, 112485, 119623, 124201, 128605, 131545, 132345, 134016, 134256, 134260, 134271, 134272, 134275, 134279, 134280, 134352, 134404, 134405, 134410, 134446, 140382, 141869, 142325, 142592, 142662, 145984, 145985, 146313, 146315, 146552]), ('training neural', [94234, 94238, 94240, 130186, 130424, 133540]), ('learning rules', [638, 6281, 6707, 6838, 15950, 15971, 16016, 16240, 16250, 17448, 34970, 35067, 35122, 35150, 35702, 44681, 45744, 45749, 45753, 59047, 62009, 70455, 100895, 109860, 113601, 131444, 143270]), ('the power', [1765, 10746, 11287, 11288, 11329, 11918, 20827, 20830, 32432, 34245, 34257, 39935, 42434, 46704, 71543, 82591, 87550, 98263, 109679, 143414, 145021, 145115, 145150, 145152, 145249]), ('generalization error', [123636, 123645, 130330]), ('-line learning', [61556]), ('mixture model', [111273]), ('statistical models', [72485, 95183, 134372, 139900]), ('factor analysis', [143476]), ('likelihood estimation', [77, 10883, 17430]), ('components analysis', [22156]), ('generative model', [90623]), ('learning linear', [84028])])\n",
            "The index_t2 are  OrderedDict([('neural networks', [10, 30, 59, 78, 191, 1373, 2402, 2870, 3433, 3824, 4189, 4361, 4369, 6398, 6413, 6457, 8675, 9042, 9337, 9388, 9495, 9511, 9567, 9570, 9967, 11498, 11657, 11661, 11943, 11949, 11950, 12801, 12825, 15539, 15854, 15888, 16318, 16345, 16843, 16878, 16887, 16894, 16913, 17079, 17179, 17525, 18031, 18060, 18489, 20401, 20422, 20454, 20467, 20469, 20561, 20983, 21035, 21552, 21560, 21834, 22798, 24025, 25091, 25124, 26169, 27051, 27065, 27067, 27440, 27465, 27850, 27867, 27868, 28313, 28773, 29543, 29551, 29991, 30005, 30814, 30826, 30827, 31020, 31028, 31261, 32437, 32546, 35341, 37523, 37824, 37838, 37839, 37840, 37841, 38167, 40479, 40962, 42728, 42744, 43307, 43325, 43328, 43744, 43795, 44547, 44995, 45722, 45753, 47411, 48067, 48186, 48194, 48198, 48528, 48533, 48554, 48650, 48675, 48801, 48818, 49012, 49046, 49056, 49078, 49559, 50848, 51206, 51658, 51713, 52506, 52511, 53149, 53182, 53361, 53680, 53753, 53849, 54096, 54252, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55964, 57356, 57792, 58136, 59090, 60364, 60406, 60857, 61286, 61669, 63078, 63091, 63133, 63147, 63168, 63170, 63442, 63449, 63451, 64446, 64461, 64489, 64923, 64935, 68319, 68793, 68809, 70255, 71891, 72421, 73650, 73677, 75905, 75929, 78377, 79276, 79538, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 83185, 84715, 85380, 86554, 86960, 86988, 87950, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89565, 89603, 89613, 89662, 89706, 91170, 91748, 96275, 96278, 96295, 96758, 96759, 96842, 96848, 97129, 97235, 97239, 97307, 97415, 97440, 98408, 98455, 98878, 98883, 99302, 99933, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101074, 101085, 101091, 101166, 101641, 101657, 102171, 103310, 105836, 105838, 105848, 106017, 106327, 106328, 106340, 106834, 106840, 107592, 107595, 107596, 107632, 107749, 111130, 111175, 111178, 112264, 112278, 112790, 113934, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117857, 119500, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 123277, 123312, 123327, 123331, 123340, 123440, 123578, 123657, 123849, 124249, 124252, 124275, 124705, 124739, 125008, 125009, 125011, 125435, 125775, 125844, 126356, 126387, 126402, 126426, 126427, 126428, 126557, 126790, 126791, 126834, 126838, 126851, 126866, 127283, 127420, 127430, 127432, 127436, 127476, 127488, 128182, 128395, 128852, 130274, 130336, 130726, 131362, 131936, 132954, 133394, 135411, 135599, 135646, 135658, 135669, 136307, 136711, 137026, 137076, 137127, 137133, 137165, 138108, 139777, 139869, 140047, 140090, 140576, 141667, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144975, 145067, 145365, 145368, 145370, 145379, 145568, 145575, 145580, 146492, 146553, 146582, 146595, 146599, 150809, 150812, 150847, 150869, 152225, 152249, 152703, 153245, 153275, 153294, 153698, 156354, 156912, 157514, 157537, 158652, 158664, 158681, 158684, 159215, 161493, 161651, 161652, 161658, 161660, 161726, 161731, 161733, 161737, 161745, 161784, 161823, 161869, 162891, 162908, 163677, 163687, 164152, 164890, 165043, 166669, 167039, 167265, 167490, 167573, 168033, 168094, 168108, 168109, 168122, 168125, 168325, 168416, 168419, 172384, 177424, 177849, 177883, 178220, 178258, 178441, 178457, 179092, 179558, 179577, 179583, 180681, 181215, 182196, 182583, 182763, 183064, 183623, 183827, 183866, 184797, 184799, 184802, 185306, 185324, 185348, 185750, 185787, 186223, 189130, 189581, 190036, 190694, 190726, 190730, 191205, 191219, 191699, 191713, 191729, 192193, 192762, 192874, 192877, 193199, 193568, 193665, 194048, 194711, 195171, 195823, 195829, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197618, 198752, 198765, 199310, 199316, 199330, 199334, 199343, 200871, 200873, 201113, 202459, 202492, 202621, 202624, 203011, 204978, 206966, 207233, 207827, 208522, 209049, 209055, 209517, 209595, 10, 30, 59, 78, 191, 1373, 2402, 2870, 3433, 3824, 4189, 4361, 4369, 6398, 6413, 6457, 8675, 9042, 9337, 9388, 9495, 9511, 9567, 9570, 9967, 11498, 11657, 11661, 11943, 11949, 11950, 12801, 12825, 15539, 15854, 15888, 16318, 16345, 16843, 16878, 16887, 16894, 16913, 17079, 17179, 17525, 18031, 18060, 18489, 20401, 20422, 20454, 20467, 20469, 20561, 20983, 21035, 21552, 21560, 21834, 22798, 24025, 25091, 25124, 26169, 27051, 27065, 27067, 27440, 27465, 27850, 27867, 27868, 28313, 28773, 29543, 29551, 29991, 30005, 30814, 30826, 30827, 31020, 31028, 31261, 32437, 32546, 35341, 37523, 37824, 37838, 37839, 37840, 37841, 38167, 40479, 40962, 42728, 42744, 43307, 43325, 43328, 43744, 43795, 44547, 44995, 45722, 45753, 47411, 48067, 48186, 48194, 48198, 48528, 48533, 48554, 48650, 48675, 48801, 48818, 49012, 49046, 49056, 49078, 49559, 50848, 51206, 51658, 51713, 52506, 52511, 53149, 53182, 53361, 53680, 53753, 53849, 54096, 54252, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55964, 57356, 57792, 58136, 59090, 60364, 60406, 60857, 61286, 61669, 63078, 63091, 63133, 63147, 63168, 63170, 63442, 63449, 63451, 64446, 64461, 64489, 64923, 64935, 68319, 68793, 68809, 70255, 71891, 72421, 73650, 73677, 75905, 75929, 78377, 79276, 79538, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 83185, 84715, 85380, 86554, 86960, 86988, 87950, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89565, 89603, 89613, 89662, 89706, 91170, 91748, 96275, 96278, 96295, 96758, 96759, 96842, 96848, 97129, 97235, 97239, 97307, 97415, 97440, 98408, 98455, 98878, 98883, 99302, 99933, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101074, 101085, 101091, 101166, 101641, 101657, 102171, 103310, 105836, 105838, 105848, 106017, 106327, 106328, 106340, 106834, 106840, 107592, 107595, 107596, 107632, 107749, 111130, 111175, 111178, 112264, 112278, 112790, 113934, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117857, 119500, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 123277, 123312, 123327, 123331, 123340, 123440, 123578, 123657, 123849, 124249, 124252, 124275, 124705, 124739, 125008, 125009, 125011, 125435, 125775, 125844, 126356, 126387, 126402, 126426, 126427, 126428, 126557, 126790, 126791, 126834, 126838, 126851, 126866, 127283, 127420, 127430, 127432, 127436, 127476, 127488, 128182, 128395, 128852, 130274, 130336, 130726, 131362, 131936, 132954, 133394, 135411, 135599, 135646, 135658, 135669, 136307, 136711, 137026, 137076, 137127, 137133, 137165, 138108, 139777, 139869, 140047, 140090, 140576, 141667, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144975, 145067, 145365, 145368, 145370, 145379, 145568, 145575, 145580, 146492, 146553, 146582, 146595, 146599, 150809, 150812, 150847, 150869, 152225, 152249, 152703, 153245, 153275, 153294, 153698, 156354, 156912, 157514, 157537, 158652, 158664, 158681, 158684, 159215, 161493, 161651, 161652, 161658, 161660, 161726, 161731, 161733, 161737, 161745, 161784, 161823, 161869, 162891, 162908, 163677, 163687, 164152, 164890, 165043, 166669, 167039, 167265, 167490, 167573, 168033, 168094, 168108, 168109, 168122, 168125, 168325, 168416, 168419, 172384, 177424, 177849, 177883, 178220, 178258, 178441, 178457, 179092, 179558, 179577, 179583, 180681, 181215, 182196, 182583, 182763, 183064, 183623, 183827, 183866, 184797, 184799, 184802, 185306, 185324, 185348, 185750, 185787, 186223, 189130, 189581, 190036, 190694, 190726, 190730, 191205, 191219, 191699, 191713, 191729, 192193, 192762, 192874, 192877, 193199, 193568, 193665, 194048, 194711, 195171, 195823, 195829, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197618, 198752, 198765, 199310, 199316, 199330, 199334, 199343, 200871, 200873, 201113, 202459, 202492, 202621, 202624, 203011, 204978, 206966, 207233, 207827, 208522, 209049, 209055, 209517, 209595]), ('reinforcement learning', [3494, 3749, 3765, 3824, 23254, 23259, 23383, 23476, 23509, 23513, 23516, 31790, 31807, 31816, 31837, 31843, 31962, 32203, 32217, 32226, 54732, 78331, 78384, 87974, 87994, 88103, 107815, 121190, 121201, 121203, 121208, 121234, 121239, 121584, 121640, 141883, 142175, 162363, 162373, 166996, 168148, 169045, 169051, 169064, 169065, 169073, 169087, 169090, 169571, 169577, 169591, 169613, 170189, 170202, 170476, 170551, 170561, 174241, 174247, 174263, 174272, 174276, 174277, 174283, 174285, 174510, 174511, 174662, 174732, 174770, 182099, 185314, 185747, 189674, 189677, 194138, 194193, 194627]), ('neural network', [10, 30, 45, 59, 78, 115, 191, 290, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2870, 3429, 3433, 3456, 3824, 4189, 4200, 4217, 4361, 4369, 4444, 6398, 6413, 6457, 7563, 7577, 7590, 7836, 8231, 8245, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9368, 9388, 9434, 9444, 9495, 9511, 9567, 9570, 9967, 10287, 11498, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12801, 12825, 13163, 13832, 13858, 15539, 15579, 15854, 15888, 16016, 16318, 16345, 16352, 16395, 16581, 16584, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17254, 17324, 17414, 17447, 17525, 18031, 18060, 18489, 18554, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20653, 20718, 20983, 21026, 21035, 21457, 21552, 21560, 21604, 21834, 22153, 22161, 22164, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24025, 25091, 25124, 26169, 26179, 27051, 27065, 27067, 27119, 27297, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28313, 28634, 28773, 29016, 29039, 29442, 29488, 29543, 29551, 29556, 29991, 30005, 30028, 30345, 30378, 30382, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30891, 30895, 30981, 31020, 31024, 31028, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 34034, 34040, 34602, 34633, 34634, 34653, 34676, 35319, 35320, 35341, 37098, 37112, 37188, 37469, 37485, 37523, 37790, 37803, 37824, 37825, 37838, 37840, 37841, 38138, 38144, 38149, 38150, 38162, 38167, 38655, 39238, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43744, 43775, 43795, 44125, 44547, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45722, 45753, 47250, 47411, 47661, 48067, 48172, 48183, 48186, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49046, 49056, 49078, 49091, 49559, 50392, 50395, 50399, 50415, 50432, 50539, 50691, 50694, 50696, 50706, 50767, 50775, 50777, 50848, 50931, 51206, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53149, 53173, 53182, 53361, 53680, 53741, 53743, 53753, 53798, 53849, 54067, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54362, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55103, 55108, 55122, 55964, 56080, 57356, 57364, 57380, 57391, 57438, 57768, 57792, 58127, 58129, 58131, 58136, 58144, 58148, 58149, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58577, 58581, 58589, 58633, 58852, 59088, 59090, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63091, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63283, 63315, 63373, 63392, 63416, 63423, 63442, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64866, 64876, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 67789, 67803, 67867, 68319, 68793, 68809, 69930, 70021, 70200, 70255, 70386, 70398, 70405, 70707, 70994, 71891, 72405, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73248, 73301, 73303, 73305, 73332, 73335, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 75069, 75853, 75905, 75929, 77962, 77966, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80450, 80466, 80488, 81117, 81123, 81132, 81859, 81870, 82303, 82309, 82747, 82749, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87704, 87774, 87950, 88015, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89662, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91170, 91358, 91748, 91777, 91781, 92363, 92395, 92397, 92421, 96250, 96275, 96278, 96284, 96295, 96497, 96528, 96541, 96758, 96759, 96834, 96842, 96848, 96852, 96904, 96913, 96926, 97120, 97129, 97224, 97235, 97236, 97239, 97241, 97307, 97310, 97415, 97416, 97440, 97493, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98850, 98866, 98878, 98883, 99302, 99330, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101084, 101085, 101091, 101166, 101641, 101657, 101839, 102171, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103529, 103616, 103862, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 106017, 106327, 106328, 106337, 106340, 106455, 106489, 106546, 106797, 106834, 106840, 106899, 107588, 107592, 107595, 107596, 107629, 107632, 107669, 107671, 107720, 107723, 107744, 107749, 107769, 108237, 109776, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111720, 112221, 112250, 112264, 112278, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117857, 119375, 119379, 119473, 119500, 119503, 119505, 119927, 119981, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124739, 124741, 124909, 124913, 125008, 125009, 125011, 125435, 125467, 125775, 125844, 125847, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126831, 126834, 126838, 126851, 126866, 127283, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128188, 128378, 128395, 128420, 128436, 128852, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131936, 131953, 132020, 132297, 132872, 132888, 132903, 132954, 133394, 133480, 133878, 133896, 134543, 135398, 135411, 135599, 135624, 135646, 135658, 135669, 136149, 136300, 136314, 136400, 136644, 136711, 137026, 137076, 137108, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140613, 140614, 140669, 141667, 141683, 142241, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144951, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 146129, 146130, 146155, 146244, 146439, 146492, 146553, 146573, 146582, 146595, 146597, 146599, 147072, 147816, 147899, 150129, 150809, 150812, 150847, 150869, 151108, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152703, 152707, 152746, 152946, 153078, 153083, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156258, 156354, 156491, 156497, 156506, 156912, 157511, 157512, 157514, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159286, 159850, 160065, 160069, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161724, 161726, 161731, 161733, 161737, 161745, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161993, 162276, 162306, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165043, 166217, 166256, 166283, 166669, 167039, 167067, 167089, 167106, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167622, 167628, 167744, 167749, 167750, 168033, 168040, 168094, 168108, 168109, 168122, 168125, 168140, 168325, 168380, 168384, 168397, 168411, 168416, 168419, 168423, 172384, 172415, 173746, 176754, 176774, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178427, 178437, 178441, 178452, 178457, 179092, 179558, 179559, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180675, 180681, 180711, 181215, 181245, 181279, 181942, 182196, 182583, 182763, 182870, 183064, 183184, 183329, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185638, 185706, 185750, 185787, 186223, 187223, 187620, 187671, 188243, 188435, 189130, 189151, 189376, 189436, 189499, 189562, 189578, 189581, 189594, 190015, 190036, 190694, 190726, 190730, 190741, 191205, 191219, 191699, 191713, 191729, 192147, 192193, 192230, 192236, 192243, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193209, 193240, 193259, 193568, 193665, 193685, 193728, 194048, 194180, 194199, 194711, 195160, 195168, 195171, 195419, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197404, 197618, 197629, 197921, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199343, 199362, 199418, 200441, 200456, 200861, 200871, 200873, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202827, 203011, 204044, 204049, 204523, 204978, 205021, 205555, 205558, 205982, 205995, 206611, 206666, 206966, 207056, 207233, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('active learning', [111109]), ('monte carlo', [207829]), ('online learning', [110685, 203165]), ('speech recognition', [3857, 3867, 3888, 3903, 3908, 3954, 4090, 4131, 7214, 9080, 9366, 9510, 12820, 13134, 13833, 18519, 27920, 27943, 28282, 30888, 32510, 37836, 44996, 45000, 45247, 48473, 48525, 48529, 52006, 57784, 57805, 59091, 60363, 60366, 60381, 60393, 60394, 60395, 60776, 62289, 62295, 62305, 62477, 62585, 62638, 62641, 62644, 62653, 62672, 62675, 62677, 62682, 62722, 62727, 62874, 63032, 63033, 70758, 71178, 73756, 73978, 74064, 75489, 77659, 77975, 79199, 79272, 79278, 83865, 87298, 87315, 89590, 89599, 89606, 91841, 91846, 92340, 115393, 116863, 116900, 116914, 116938, 116995, 117172, 117225, 117230, 117240, 117245, 117260, 117263, 119998, 120002, 120048, 120226, 120415, 120447, 123932, 124134, 124222, 124249, 129306, 129308, 129316, 135336, 135337, 135391, 135392, 135415, 135480, 135599, 135609, 135612, 135615, 137126, 146192, 148278, 148666, 156260, 156919, 164791, 165028, 165038, 165041, 165046, 165048, 167750, 167775, 168597, 168633, 168697, 168991, 169017, 190032, 193673, 193759, 194749, 196726, 206076, 206160, 207868, 207876, 207878, 207892, 207904, 208048, 208056, 208246, 208382, 208385, 210153, 210210, 210565]), ('recurrent neural', [9967, 28773, 29016, 34653, 35341, 43346, 48194, 48198, 50765, 50848, 53149, 55075, 78377, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 88066, 88254, 88277, 88325, 89594, 96842, 96848, 96904, 96926, 97129, 120017, 122703, 123277, 123312, 123440, 126851, 126866, 127420, 127430, 127432, 136785, 137133, 150847, 150869, 158652, 158681, 166283, 167039, 167592, 177883, 182763, 183188, 184802, 198752, 198765, 199330, 199334, 199343]), ('component analysis', [33520, 33529, 63391, 86967, 86969, 87054, 87104, 111782, 112216, 177358, 178535, 202443, 202456]), ('gradient descent', [3546, 3676, 3793, 3818, 7150, 7157, 7226, 7236, 7342, 8182, 8186, 8258, 10412, 17187, 19740, 20488, 21346, 22187, 23749, 25814, 26445, 26595, 26605, 26607, 26617, 26620, 26622, 26653, 26770, 26791, 26798, 26823, 28256, 32364, 32395, 33176, 33182, 33680, 34109, 34168, 34283, 38264, 38586, 38609, 39252, 39310, 39324, 39680, 42300, 42353, 42505, 44658, 45782, 48753, 52496, 52524, 52772, 53114, 54691, 54692, 54727, 54733, 54746, 54752, 54759, 54809, 55032, 55046, 60844, 60878, 60928, 61105, 61213, 63869, 65024, 65548, 65550, 65563, 69102, 73843, 73846, 74919, 74991, 75024, 75265, 75299, 76729, 76731, 76744, 78037, 78066, 78075, 78091, 78139, 80169, 80324, 80583, 81373, 82618, 83523, 83535, 86752, 87024, 87087, 87965, 90877, 92858, 96978, 99019, 99091, 102482, 102565, 111979, 111982, 112002, 113916, 113923, 113937, 113939, 113950, 114103, 119159, 120298, 123485, 124470, 126953, 129363, 129372, 129390, 129391, 129420, 129663, 131701, 131770, 131783, 131784, 131787, 131808, 131830, 132391, 132444, 132473, 132510, 132517, 132839, 140805, 144339, 148145, 156464, 156468, 156844, 158241, 158696, 164035, 164123, 164129, 164231, 165247, 167863, 168830, 171109, 171746, 176828, 177006, 177210, 177417, 177432, 177569, 177865, 177872, 182027, 182109, 182113, 182139, 182160, 182162, 182164, 182199, 182220, 182250, 182251, 182374, 182407, 182414, 182433, 182455, 182457, 182458, 186564, 186621, 187625, 187653, 188404, 188413, 188435, 189119, 190868, 191305, 193574, 194633, 195127, 197700, 197711, 197737, 197851, 197955, 198096, 201509, 201541, 201542, 201578, 201587, 201666, 201768, 201927, 201935, 201943, 201959, 204507, 204519, 204888, 207323, 207573, 207592, 207630, 207666, 208579, 208869, 208943, 209972, 210414]), ('hidden markov', [165025, 165028]), (': the', [1363, 2530, 2532, 2548, 3000, 3535, 6112, 6418, 6451, 6470, 7855, 9262, 9424, 9428, 9431, 9680, 10741, 11650, 14536, 18973, 19742, 19930, 23572, 23759, 23760, 23764, 25790, 26146, 26872, 27913, 28108, 29498, 31209, 31972, 39469, 39761, 40386, 41946, 42094, 42261, 44115, 44577, 44656, 44787, 44816, 44832, 48041, 53447, 53472, 53507, 56027, 56217, 60910, 61889, 63771, 63869, 65461, 65750, 66539, 68560, 71152, 73780, 73788, 73936, 73969, 74137, 74194, 74369, 74392, 74714, 75486, 76642, 76931, 77621, 78193, 78577, 79255, 79430, 79712, 81182, 86266, 92417, 92418, 92420, 92425, 92746, 98409, 100217, 102777, 107635, 107913, 107971, 108374, 110537, 111007, 111828, 111980, 112143, 114240, 114955, 115266, 116188, 117181, 118761, 119216, 119313, 119384, 119982, 120231, 120312, 120983, 121101, 121548, 124965, 127914, 127962, 128167, 128233, 131918, 139621, 139707, 140745, 140804, 140909, 140914, 140916, 141778, 141896, 147849, 148800, 148808, 150705, 150763, 150909, 151351, 152016, 152033, 152057, 155646, 155786, 160074, 160544, 160771, 161946, 161979, 162019, 162423, 163979, 165697, 166001, 167635, 169875, 171353, 175213, 177579, 177593, 178295, 180988, 183521, 184169, 188847, 189346, 189376, 189428, 189513, 190718, 190823, 190830, 191309, 191987, 192800, 192810, 192866, 193856, 194746, 195464, 195816, 197367, 197399, 197458, 197868, 198586, 198637, 198667, 201688, 201689, 201696, 202524, 202810, 202832, 203115, 203871, 204858, 205083, 205128, 208500, 208815, 209643]), ('markov models', [87298, 165028]), ('analog vlsi', [189128]), ('stochastic gradient', [7138, 7150, 7226, 7236, 7338, 34109, 34168, 34283, 62389, 65548, 65550, 65563, 76729, 76731, 76744, 114010, 129372, 150169, 164231, 168830, 198096, 204507, 207573]), ('feature selection', [23716, 52212, 52213, 52437, 115004, 144974, 145546]), (': learning', [7868, 63508, 107904, 157501, 165062, 169840]), ('networks learning', [7822]), ('random fields', [68801, 93188, 107119, 132011, 132285]), ('machine learning', [7213, 15567, 54649, 60859, 83838, 83851, 84651, 99312, 101053, 101405, 104453, 105333, 108046, 108230, 117857, 131953, 132885, 140090, 150646, 156353, 156848, 204701]), ('unsupervised learning', [24070, 28296, 28639, 34057, 38655, 45577, 53694, 56410, 64407, 70405, 70504, 84376, 84772, 85399, 91093, 101839, 102268, 102647, 112123, 112249, 125776, 134315, 137443, 137444, 146611, 190849, 194666, 194844, 194898, 206754, 207328, 207353]), ('model selection', [665, 11723, 11938, 87938, 116082, 132000, 139706, 153296, 153683, 159208, 162891, 162895, 162898, 162908, 162937, 163106, 171059, 172398, 172400, 172401, 172403, 172404, 172406, 172416, 172434, 172439, 172441, 172443, 172517, 172559, 172611, 172703, 172842, 172952, 172954, 172955, 192257, 192707, 192708, 192743]), ('dynamic programming', [9122, 23222, 23237, 23257, 23364, 23512, 23965, 23972, 48482, 62330, 68838, 69342, 69934, 70353, 78363, 78382, 91850, 92019, 103576, 103577, 121205, 135289, 135624, 141845, 148285, 156999, 157143, 157208, 160560, 160562, 160564, 160572, 162363, 164906, 167764, 170203, 170554, 170556, 185740, 185763, 189242, 189244, 194152, 194154, 194160, 194193, 194614, 203099, 206182]), ('function approximation', [456, 739, 13900, 20023, 20226, 37522, 40985, 41124, 41141, 47650, 65019, 65477, 65482, 65483, 71440, 76658, 76663, 76664, 83805, 83808, 118998, 127936, 128236, 132932, 132967, 133249, 133264, 133267, 133393, 133400, 137570, 157498, 178204, 185474, 191068, 191315]), ('decision processes', [11976, 167113]), ('object recognition', [10020, 14113, 28336, 41930, 50776, 64937, 67470, 77607, 77636, 77918, 77943, 77949, 77970, 77983, 81897, 91189, 91193, 91205, 103122, 103135, 103136, 103160, 103171, 103527, 104394, 111811, 118453, 149588, 152704, 152729, 153230, 156251, 161949, 162162, 162183, 194711, 194744, 195180]), ('time series', [25065, 25541, 25889, 26112, 26126, 26157, 26596, 26829, 26830, 26832, 44255, 44285, 57439, 57443, 57444, 57447, 61323, 64966, 65289, 65409, 75104, 75822, 87407, 123309, 123322, 123324, 123328, 123331, 123341, 123432, 123465, 123644, 123849, 123864, 124389, 124601, 124655, 125900, 125907, 125923, 127285, 136151, 136327, 136333, 136676, 136720, 136915, 136918, 136946, 136948, 137065, 141592, 145603, 145629, 145777, 145817, 145832, 157024, 165072, 165203, 165345, 167766, 168035, 178396, 190820, 190961, 191055, 191163, 191296, 191308, 191309, 191575, 194102, 200274]), ('mixture models', [13967, 14030, 42709, 84381, 91784, 164104]), ('metric learning', [37521, 37754, 37808, 74911, 132007, 132301, 167084]), ('spiking neurons', [17606, 17803, 144110, 144257, 144261, 196896, 17606, 17803, 144110, 144257, 144261, 196896]), ('density estimation', [11944, 37515, 37755, 84363, 84513, 84720, 84731, 85358, 91818, 91856, 91858, 92030, 92331, 105561, 105824, 116940, 117223, 126360, 132277, 139623, 139972]), ('convex optimization', [26524]), ('supervised learning', [405, 449, 1003, 3765, 6428, 14305, 24070, 28296, 28639, 28670, 34027, 34057, 37118, 38646, 38655, 42197, 45577, 45741, 45753, 53583, 53694, 56410, 63222, 63300, 64407, 69037, 69090, 70387, 70399, 70405, 70504, 70551, 78377, 84339, 84376, 84388, 84534, 84739, 84772, 85265, 85355, 85399, 87407, 88245, 90834, 91015, 91093, 98408, 101839, 102171, 102224, 102229, 102268, 102278, 102288, 102290, 102292, 102294, 102301, 102324, 102338, 102436, 102444, 102471, 102483, 102572, 102650, 102655, 102657, 102659, 102660, 102672, 102676, 107842, 107888, 107907, 110693, 112123, 112249, 115092, 120969, 125776, 129453, 134315, 137444, 137519, 141762, 146130, 146184, 146552, 146611, 174260, 182009, 189630, 190848, 190849, 190860, 191157, 192205, 194086, 194096, 194666, 194844, 194898, 195204, 195418, 195829, 198289, 203634, 206667, 206677, 206751, 206754, 206785, 207328, 207353, 207371, 207572, 208870, 209092]), ('dynamical systems', [8260, 14788, 15361, 21953, 31482, 33519, 43348, 43359, 43649, 43744, 49547, 49568, 57362, 80487, 101672, 143457, 143499, 143526, 151113, 165439, 166637, 166672, 169046, 181215, 181290, 181878, 193630]), ('large scale', [130275, 139503, 166610, 170437]), (': application', [180681]), ('stochastic optimization', [7215, 129774, 137167, 207832]), ('natural images', [49612, 49620, 49646, 49815, 49853, 49893, 49961, 49962, 49964, 50147, 106917, 147070]), ('learning the', [2131, 5692, 5703, 5720, 6416, 6453, 8033, 11118, 14337, 14455, 19570, 19897, 19946, 29993, 29997, 33265, 33445, 43489, 48751, 53090, 60329, 60859, 64403, 69001, 71362, 71386, 75976, 82596, 83881, 83882, 83884, 84378, 84775, 93140, 99331, 100470, 100476, 102559, 102656, 107798, 113838, 113867, 122185, 127417, 127902, 129963, 131418, 137527, 140047, 148282, 150642, 156711, 157501, 161591, 165062, 165071, 165214, 165282, 165283, 165295, 165296, 165311, 165352, 167819, 167825, 169051, 185313, 185368, 185506, 185517, 187082, 198969]), ('dimensionality reduction', [32254, 32258, 32268, 32426, 32427, 32457, 64330, 77638, 77639, 77669, 77670, 77925, 192144, 200113]), ('principal component', [32286, 32432, 33520, 33527, 33529, 33531, 33532, 33535, 33541, 33592, 33822, 33824, 34041, 34045, 34047, 38294, 60901, 60943, 63391, 64224, 86967, 86969, 87054, 87068, 87070, 87076, 87104, 87262, 87263, 87266, 87288, 87296, 91935, 91940, 92335, 98281, 98282, 98286, 111772, 111782, 111784, 111786, 112216, 112230, 112242, 115007, 115098, 118618, 137517, 146637, 155937, 176746, 176781, 176782, 176790, 176808, 177129, 177173, 177207, 177266, 177358, 177378, 177381, 178535, 200050, 200101, 200297, 200340, 202388, 202392, 202393, 202395, 202443, 202456, 203765, 203772, 203811, 203873, 207825]), ('visual cortex', [17576, 17614, 17949, 25114, 25117, 25165, 25167, 25193, 25247, 25463, 25473, 25481, 25484, 25492, 25498, 30028, 30040, 30041, 32527, 38931, 38935, 38950, 38953, 41476, 41483, 45424, 49619, 49643, 49647, 49790, 49914, 57827, 58043, 58091, 66744, 66753, 66759, 67184, 67186, 71893, 71914, 72365, 72391, 72394, 72402, 77942, 80139, 82301, 82305, 86515, 90349, 98075, 98285, 98286, 98303, 98414, 103874, 104028, 104265, 104386, 104387, 104415, 104422, 104424, 110649, 118453, 120922, 143880, 143884, 143905, 143923, 144009, 144038, 144289, 149545, 151141, 151784, 156211, 159232, 159244, 162302, 162305, 162309, 162332, 163709, 163745, 163877, 164089, 164096, 167041, 171911, 187280, 199379, 199516, 204047, 204947]), ('recurrent networks', [31512, 31532, 43735, 50931, 52532, 54800, 54919, 75106, 81215, 81258, 81850, 81856, 81862, 82367, 82742, 87975, 87996, 88118, 88305, 91825, 96915, 97084, 109741, 109758, 109768, 109832, 109957, 110075, 110140, 123311, 123315, 123329, 123549, 123596, 123647, 123666, 126867, 126869, 126871, 126977, 158125, 158131, 158135, 158633, 158677, 164239, 164725, 166968, 167033, 167034, 177415, 177418, 177429, 177577, 177729, 177879, 177880, 178540, 179033, 179057, 182003, 183330, 195761, 205997]), ('radial basis', [801, 827, 836, 13135, 13163, 13197, 13198, 19749, 19977, 20020, 20241, 20258, 24469, 26588, 26857, 28422, 28509, 28512, 32588, 32605, 33491, 37514, 37522, 37524, 37638, 37651, 37673, 37693, 37717, 37720, 37791, 37792, 47403, 48553, 48570, 48675, 52275, 53575, 57310, 64971, 69154, 74731, 84001, 86978, 87373, 87439, 89613, 102219, 102225, 102230, 102484, 103185, 103187, 113872, 116853, 116915, 116968, 120934, 131931, 132051, 132052, 132063, 133247, 133305, 137158, 137192, 139737, 150133, 150134, 150156, 153403, 161074, 161088, 161587, 161600, 170574, 179225, 180660, 191190, 192732, 192977, 197357, 197605, 198309, 198310, 198311, 198391, 198401, 198562, 198620, 198669, 198685, 198689, 209517]), ('risk minimization', [127883, 127884, 127915, 127981, 128167, 128401, 131418, 140044]), ('nearest neighbor', [1744, 1755, 1764, 1776, 1782, 13137, 13164, 13165, 13181, 17622, 17779, 17799, 17904, 20227, 26606, 26628, 29715, 30010, 37572, 37601, 38146, 38794, 38865, 52012, 52437, 57971, 61929, 63285, 70120, 76589, 102378, 102429, 102466, 114501, 115024, 128985, 128986, 129006, 129007, 129008, 142642, 142648, 155939, 161074, 161419, 161476, 161491, 161493, 161507, 161531, 161585, 161593, 161595, 171726, 185619, 191716, 191973, 191979, 191982, 192023, 209978]), ('high dimensional', [526, 13473, 13475, 13835, 13846, 32267, 32269, 32289, 55984, 74898, 77626, 77669, 77671, 77697, 83809, 91111, 126855, 126859, 132898, 155902, 156043, 156082, 156154, 156192, 156196, 159904, 160437, 161548, 167013, 171024, 177558, 178205, 178514, 200279, 200381, 208456]), ('learning algorithms', [5758, 6041, 6042, 6984, 8351, 19166, 21543, 21575, 21595, 23237, 23372, 26872, 31417, 31575, 31739, 32226, 34080, 34326, 34521, 37808, 39250, 39323, 54337, 54649, 54656, 56457, 68850, 68874, 82417, 83878, 84357, 84773, 84779, 88332, 100154, 100447, 101023, 101027, 101652, 102268, 102308, 102684, 109772, 111782, 111827, 126851, 129380, 129839, 132007, 132301, 140777, 141762, 148512, 156979, 166965, 167011, 169073, 169591, 170561, 176773, 178183, 185755, 190762, 190779, 190845, 190905, 192885, 194152, 202489, 203634, 204073, 204076, 204087, 204111, 204313, 205728, 207361, 207807]), ('neural net', [10, 30, 45, 59, 78, 115, 191, 290, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2817, 2830, 2832, 2870, 3123, 3311, 3320, 3429, 3433, 3456, 3824, 3925, 4189, 4200, 4217, 4361, 4369, 4444, 6398, 6413, 6457, 7108, 7563, 7577, 7590, 7836, 8231, 8245, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9365, 9368, 9388, 9434, 9444, 9495, 9511, 9567, 9570, 9967, 10287, 11219, 11223, 11240, 11249, 11498, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12801, 12825, 13163, 13832, 13858, 15539, 15579, 15854, 15870, 15882, 15888, 16011, 16016, 16318, 16345, 16352, 16395, 16581, 16584, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17254, 17324, 17414, 17447, 17525, 18031, 18060, 18489, 18554, 18818, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20653, 20718, 20983, 21026, 21035, 21457, 21552, 21560, 21604, 21834, 22153, 22161, 22164, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24010, 24025, 25091, 25124, 26169, 26179, 27051, 27065, 27067, 27119, 27297, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28279, 28313, 28634, 28773, 29016, 29039, 29442, 29488, 29543, 29551, 29556, 29991, 30005, 30028, 30345, 30378, 30382, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30891, 30895, 30981, 31020, 31024, 31028, 31089, 31139, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 34034, 34040, 34563, 34602, 34633, 34634, 34653, 34676, 35319, 35320, 35341, 36204, 36216, 36231, 36238, 36290, 36321, 36384, 36388, 36397, 36399, 36431, 37098, 37112, 37188, 37469, 37485, 37523, 37790, 37803, 37824, 37825, 37838, 37840, 37841, 38063, 38138, 38144, 38149, 38150, 38162, 38214, 38222, 38226, 38465, 38503, 38504, 38655, 39238, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43744, 43775, 43795, 44125, 44547, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45722, 45753, 47250, 47411, 47661, 48067, 48172, 48183, 48186, 48189, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49046, 49056, 49062, 49078, 49091, 49559, 50392, 50395, 50399, 50415, 50432, 50539, 50691, 50694, 50696, 50706, 50767, 50775, 50777, 50848, 50931, 51206, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53131, 53149, 53173, 53182, 53361, 53680, 53741, 53743, 53753, 53798, 53849, 53865, 54013, 54063, 54067, 54073, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54362, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55103, 55108, 55122, 55964, 56080, 57356, 57364, 57380, 57391, 57438, 57768, 57792, 58127, 58129, 58131, 58136, 58144, 58148, 58149, 58223, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58577, 58581, 58589, 58633, 58645, 58652, 58852, 59049, 59070, 59083, 59088, 59090, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63091, 63114, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63283, 63315, 63373, 63392, 63416, 63423, 63442, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64866, 64876, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 67431, 67459, 67585, 67606, 67608, 67610, 67674, 67675, 67676, 67678, 67679, 67738, 67739, 67745, 67748, 67789, 67803, 67867, 68319, 68793, 68809, 69930, 70021, 70200, 70209, 70255, 70386, 70398, 70405, 70707, 70994, 71379, 71891, 72399, 72405, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73248, 73301, 73303, 73305, 73332, 73335, 73379, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 73718, 75069, 75105, 75838, 75853, 75905, 75929, 75930, 76588, 76590, 77962, 77966, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80450, 80466, 80488, 81117, 81123, 81132, 81859, 81870, 82303, 82309, 82351, 82413, 82747, 82749, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87704, 87774, 87950, 87965, 88015, 88066, 88200, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89662, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91170, 91358, 91748, 91777, 91781, 92363, 92395, 92397, 92421, 96250, 96275, 96278, 96284, 96293, 96295, 96497, 96528, 96541, 96758, 96759, 96834, 96836, 96840, 96842, 96848, 96852, 96904, 96913, 96926, 97119, 97120, 97129, 97132, 97224, 97235, 97236, 97238, 97239, 97241, 97257, 97307, 97310, 97415, 97416, 97440, 97493, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98850, 98866, 98870, 98878, 98883, 99302, 99330, 99360, 99891, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101084, 101085, 101091, 101166, 101641, 101652, 101657, 101839, 102156, 102171, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103529, 103616, 103862, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 106017, 106327, 106328, 106337, 106340, 106455, 106489, 106546, 106777, 106794, 106797, 106834, 106840, 106899, 107588, 107592, 107595, 107596, 107629, 107632, 107669, 107671, 107720, 107723, 107744, 107749, 107769, 108237, 109776, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111720, 112221, 112250, 112264, 112278, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117856, 117857, 117873, 117877, 118122, 118135, 118150, 118158, 119375, 119379, 119473, 119500, 119503, 119505, 119927, 119981, 119983, 120002, 120019, 120225, 120416, 120967, 120971, 120980, 121014, 121135, 121664, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124730, 124739, 124741, 124909, 124913, 124922, 125008, 125009, 125011, 125072, 125074, 125435, 125467, 125775, 125844, 125847, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126819, 126831, 126834, 126838, 126851, 126866, 127283, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128187, 128188, 128206, 128378, 128395, 128420, 128436, 128852, 129418, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131936, 131953, 132020, 132297, 132872, 132888, 132903, 132954, 133394, 133480, 133878, 133896, 134543, 135398, 135411, 135599, 135624, 135646, 135658, 135669, 136149, 136300, 136314, 136400, 136644, 136683, 136711, 137026, 137076, 137101, 137108, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140613, 140614, 140669, 141667, 141683, 142241, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144951, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 146129, 146130, 146155, 146157, 146244, 146439, 146492, 146553, 146573, 146582, 146595, 146597, 146599, 147072, 147810, 147816, 147899, 150129, 150809, 150812, 150847, 150869, 151108, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152703, 152707, 152746, 152946, 153078, 153083, 153217, 153220, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156248, 156254, 156258, 156304, 156354, 156491, 156497, 156506, 156912, 157511, 157512, 157514, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159286, 159850, 160065, 160069, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161724, 161726, 161731, 161733, 161737, 161745, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161993, 162276, 162306, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165043, 165076, 166217, 166256, 166283, 166669, 167039, 167067, 167089, 167106, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167610, 167622, 167628, 167744, 167749, 167750, 168033, 168036, 168040, 168094, 168108, 168109, 168122, 168125, 168140, 168325, 168329, 168380, 168384, 168397, 168411, 168416, 168419, 168423, 171083, 171086, 171091, 171131, 171148, 171176, 171295, 171428, 171455, 172384, 172415, 173746, 174745, 176754, 176774, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178427, 178437, 178441, 178452, 179092, 179553, 179558, 179559, 179565, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180675, 180681, 180711, 181215, 181245, 181279, 181942, 182196, 182583, 182763, 182870, 183064, 183184, 183329, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 185302, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185638, 185706, 185750, 185787, 186223, 187065, 187223, 187620, 187671, 188243, 188435, 189130, 189151, 189376, 189436, 189499, 189562, 189578, 189581, 189594, 190015, 190036, 190694, 190726, 190730, 190741, 191205, 191219, 191699, 191713, 191729, 191868, 192147, 192157, 192163, 192193, 192230, 192236, 192243, 192245, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193209, 193240, 193259, 193568, 193665, 193684, 193685, 193688, 193694, 193728, 193750, 193854, 193881, 193991, 194048, 194180, 194199, 194711, 195160, 195168, 195171, 195304, 195419, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197404, 197618, 197629, 197921, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199343, 199362, 199418, 200441, 200456, 200861, 200871, 200873, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202827, 203011, 204044, 204049, 204523, 204978, 205021, 205555, 205558, 205577, 205588, 205708, 205727, 205958, 205982, 205995, 206611, 206666, 206966, 207056, 207233, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('sparse coding', [45961, 56342, 146822]), ('recognition using', [2402, 9504, 9505, 9506, 13088, 28647, 48529, 48533, 57797, 57810, 62305, 64312, 64937, 79185, 92340, 92349, 97640, 103509, 117260, 120442, 124249, 124252, 146597, 147361, 156254, 156257, 156319, 189587, 195180]), ('artificial neural', [3925, 11943, 12801, 12825, 15579, 16878, 16894, 16922, 17175, 17179, 18031, 18060, 20454, 21560, 32579, 37098, 38668, 42193, 42219, 42728, 42744, 43325, 53361, 54263, 60351, 63087, 70994, 72421, 79657, 92340, 99360, 100361, 100380, 102722, 105848, 136297, 136300, 136400, 138108, 145568, 146130, 146149, 155907, 156981, 159215, 161631, 161651, 167267, 167577, 168402, 180711, 185302, 186921, 191729, 192768, 193201, 193202, 194048, 197273, 200873, 202042, 202459, 207827]), ('mean field', [32400, 50768, 50933, 50942, 68350, 68367, 68389, 68541, 68591, 68779, 68801, 84660, 85380, 92803, 93056, 93105, 93140, 93188, 113332, 150811, 182452, 182456]), ('maximum likelihood', [4221, 37104, 37443, 37460, 37462, 37472, 57650, 57655, 57656, 57657, 57774, 84359, 84586, 86833, 87931, 100138, 110321, 115388, 116898, 116914, 117167, 117171, 117177, 117179, 120229, 126363, 127984, 134693, 139565, 139706, 148284, 148369, 148466, 160594, 162396, 171214, 172478, 172974, 185789]), ('sample complexity', [5697, 5756, 113377, 113638, 113836, 113870, 135665, 135700, 136087, 140564, 209544, 209549]), ('associative memory', [7565, 7591, 7625, 9596, 9636, 9987, 9988, 9991, 12081, 12106, 27865, 27872, 31411, 32909, 35658, 35671, 35677, 35726, 35781, 36177, 36187, 47676, 47681, 47712, 48048, 52815, 64938, 90358, 99897, 103513, 121584, 128851, 150675, 166649, 166669, 166689, 166716, 167030, 177416, 177432, 177455, 177544, 177862, 177874, 202477, 202624, 202651, 202693, 204948]), ('basis function', [482, 493, 494, 501, 527, 531, 535, 566, 567, 581, 588, 591, 599, 811, 816, 817, 821, 822, 827, 836, 13135, 13163, 13180, 13197, 13201, 13663, 13835, 19589, 19749, 19977, 20020, 20241, 20258, 23092, 23109, 24469, 24484, 24687, 25073, 25076, 26588, 26636, 26857, 32588, 32605, 33491, 37524, 37638, 37643, 37647, 37649, 37650, 37651, 37673, 37693, 37719, 37720, 37791, 40996, 41000, 47331, 47340, 47342, 47343, 47348, 47391, 47395, 47403, 47406, 47421, 47430, 47438, 47451, 47653, 48553, 48570, 48675, 48678, 48683, 48686, 52275, 57310, 64971, 65018, 65021, 74731, 78399, 78409, 78445, 78454, 78475, 78509, 78513, 78516, 78517, 78518, 78536, 78537, 78538, 78591, 78593, 78595, 78599, 78667, 78668, 78732, 78805, 78860, 79049, 79052, 79136, 79144, 79148, 84001, 86978, 87373, 87439, 89230, 89613, 92891, 102225, 102230, 102236, 102264, 102484, 102646, 103185, 103187, 105557, 106881, 113872, 116853, 116915, 116968, 116970, 117258, 120934, 131931, 132051, 132052, 132058, 132063, 132064, 132142, 137158, 137192, 139737, 150133, 150156, 153403, 161074, 161088, 161587, 161600, 170574, 170591, 171034, 178174, 178210, 179225, 180660, 191156, 191190, 192977, 193911, 195490, 198309, 198310, 198311, 198318, 198322, 198323, 198379, 198384, 198387, 198388, 198390, 198391, 198512, 198519, 198542, 198543, 198544, 198549, 198551, 198552, 198553, 198560, 198561, 198564, 198565, 198571, 198572, 198618, 198620, 198667, 198669, 198685, 198687, 198689, 208446, 208496, 208497, 208505, 208518, 208524, 208536, 208574, 208628, 208629, 208639, 208645, 208677, 208890, 208893, 208929, 208942, 208947, 209517, 209587, 209730]), ('feature extraction', [2405, 8714, 9043, 9336, 17119, 23804, 32260, 32268, 32418, 32432, 32498, 34036, 34208, 36433, 64015, 64908, 67635, 67722, 67746, 70426, 70441, 77600, 77603, 77631, 77638, 77652, 77697, 77926, 77975, 96847, 97415, 106467, 111177, 111178, 112225, 125497, 125612, 125613, 130977, 156259, 176754, 206668, 206735, 206742, 206748]), ('learning algorithm', [1003, 1018, 1030, 1432, 1433, 1437, 1733, 3838, 5758, 5765, 6041, 6042, 6984, 8351, 8478, 15576, 15582, 15588, 17254, 19166, 19171, 19188, 21543, 21575, 21595, 21635, 23237, 23372, 26872, 28758, 29016, 31186, 31417, 31483, 31558, 31562, 31575, 31739, 31805, 31807, 32226, 32572, 32823, 34040, 34080, 34326, 34521, 35341, 37808, 38230, 39250, 39323, 40483, 40559, 44003, 47421, 49558, 54244, 54249, 54337, 54649, 54656, 55075, 55130, 55191, 55265, 55269, 56457, 56552, 56648, 56650, 64981, 68837, 68850, 68874, 69851, 69854, 70925, 70928, 75265, 79449, 80454, 80490, 80498, 80536, 81131, 81869, 82417, 82757, 83878, 83974, 83975, 84357, 84358, 84361, 84399, 84588, 84651, 84734, 84773, 84779, 85350, 87966, 88229, 88254, 88304, 88311, 88331, 88332, 96542, 98883, 98886, 99907, 100079, 100154, 100434, 100447, 100469, 101023, 101027, 101652, 102268, 102308, 102684, 104501, 109772, 111782, 111827, 112123, 113332, 115021, 121234, 121345, 123276, 125778, 126851, 126857, 126994, 127272, 127420, 127435, 129380, 129839, 130795, 130890, 131065, 131132, 131356, 132007, 132301, 132472, 137132, 137150, 137307, 137328, 137569, 140100, 140237, 140244, 140777, 141006, 141762, 143388, 144339, 146187, 146594, 148512, 150355, 150646, 150667, 150703, 150795, 150811, 156979, 157537, 158415, 158680, 164360, 165178, 165193, 166669, 166674, 166965, 167011, 168093, 169073, 169577, 169591, 169770, 170042, 170561, 174511, 174770, 176773, 178028, 178031, 178183, 182213, 183944, 184631, 184638, 184640, 184658, 184781, 184786, 185357, 185367, 185755, 190762, 190779, 190798, 190804, 190845, 190905, 190957, 190960, 192885, 193165, 194103, 194152, 199342, 200854, 202489, 203065, 203392, 203621, 203634, 203677, 203695, 203814, 203890, 203912, 204073, 204076, 204081, 204087, 204111, 204313, 204701, 205728, 207361, 207375, 207807]), ('gradient methods', [5666, 132343, 132364, 132384, 132390, 132392, 132395, 132470, 182214]), ('network model', [1399, 8236, 10287, 11732, 11815, 17254, 17324, 17447, 18874, 19704, 19719, 19740, 19746, 19913, 19916, 19917, 19999, 26179, 27878, 29090, 29488, 30028, 30345, 31744, 32942, 33015, 33163, 33470, 34056, 34602, 34653, 34676, 34908, 35319, 35328, 36511, 37056, 39238, 40353, 40363, 40368, 40480, 41477, 48472, 49022, 56080, 57318, 58633, 58852, 61694, 61817, 62232, 64350, 64375, 71879, 77639, 81271, 81727, 82303, 83431, 86069, 87704, 91775, 91777, 91781, 96528, 98069, 103862, 106337, 107629, 107669, 107671, 107744, 107767, 111192, 115522, 115596, 115648, 115870, 115989, 117587, 117599, 117783, 119505, 122690, 122980, 123264, 123342, 123572, 123656, 125478, 125481, 125932, 128420, 128436, 132020, 133896, 136644, 141143, 142669, 142701, 151357, 152675, 159214, 159850, 161943, 162276, 162306, 164138, 165657, 166217, 167019, 168403, 172178, 172209, 172211, 172221, 172268, 172316, 175258, 178479, 179621, 179658, 179674, 179683, 180174, 180175, 180177, 180181, 180225, 180227, 180276, 187623, 192768, 197361, 199362, 202706, 205021, 205558, 206950, 206963, 207056]), ('neural nets', [2832, 3123, 3925, 9365, 11240, 18818, 34563, 36216, 38167, 48189, 53865, 54063, 58645, 63114, 67739, 71379, 72399, 75930, 76588, 76590, 88200, 96293, 97238, 99360, 102156, 118150, 118158, 120019, 120971, 124730, 124922, 125072, 126819, 127380, 129418, 147810, 153217, 153220, 165076, 168329, 171083, 171086, 171091, 171176, 171295, 171455, 174745, 178457, 179553, 179565, 185302, 192157, 192163, 193688, 193694]), ('mutual information', [11947, 28275, 28299, 28474, 28517, 28547, 85483, 92346, 102143, 102381, 111809, 115047, 115161, 115163, 117249, 141037, 146611, 146644, 146987, 147076, 149480, 171883, 171916, 171928, 194666, 194764, 194765, 194811, 194816, 194821, 195131, 195165, 200830, 205993]), ('markov random', [68801]), ('second order', [7198, 15050, 15119, 15244, 15246, 20017, 32296, 39240, 39253, 42714, 45666, 74312, 87374, 87673, 87706, 87721, 92942, 98149, 131344, 134690, 134917, 135128, 135137, 135140, 135221, 156335, 156386, 156454, 158918, 158933, 158947, 160022, 160036, 167038, 172471, 172583, 172739, 173154, 173605, 174029, 187672, 187673, 187796, 193377, 193398, 204209, 204217, 204520, 207423, 207555]), ('learning approach', [18453, 70551, 99312, 124123, 194138]), (': efficient', [170551]), ('decision trees', [11660, 15556, 23370, 47647, 54339, 72557, 76589, 101636, 102708, 117966, 117972, 117973, 117984, 117987, 138101, 186914]), ('graphical model', [183622]), ('convolutional networks', [75108]), ('learning neural', [99900, 107723]), ('temporal difference', [3831, 14304, 14563, 50090, 53586, 53696, 69352, 107795, 108232, 108239, 155530, 169617, 169619, 170562, 185518, 185760, 189694, 190000, 194638]), ('gaussian mixtures', [86978, 87297, 92033, 124578]), (': new', [111144, 169815, 202813]), ('least squares', [24890, 37651, 37691, 47431, 65545, 74888, 74910, 74930, 74932, 75044, 75045, 76726, 99080, 134904, 136504, 138414, 138418, 145064, 161198, 161283, 172981]), ('linear models', [87534, 87672, 87673, 87692, 87706, 87849, 115561, 123311, 123338, 123343, 123353, 123439, 123613, 123850, 136293, 146158, 153699]), ('maximum margin', [159906, 159956, 159968, 160005, 160021, 160078, 160258, 160275, 160442, 160449]), ('decision making', [12368, 29498, 127493, 127803, 167132, 170269]), ('neural model', [8234, 12291, 14774, 14855, 17393, 17708, 21001, 30356, 30357, 30360, 30911, 32903, 36171, 43367, 58634, 59070, 65478, 76659, 120182, 126054, 126071, 133488, 136674, 136683, 136712, 136785, 137025, 157351, 162319, 174802, 193574, 196730]), ('image segmentation', [81925, 92984, 93190, 150748]), ('information theoretic', [13190, 13860, 25535, 25564, 70408, 70544, 70552, 101839, 101840, 102153, 171881, 171884, 171913, 171917, 171997, 172178, 172192, 200174, 206679, 206783, 206786]), (': from', [42253, 67408, 125439, 143860, 202462, 206158, 206366, 206533]), ('parameter estimation', [43315, 84380, 120019, 148197]), ('efficient learning', [99834, 99891, 141791, 199202]), ('visual attention', [71898, 82303, 98069, 98072, 104394, 161944, 161982, 162323]), ('visual recognition', [77613, 107240, 107250, 107267, 107285, 107545]), ('value function', [55358, 121327, 125176, 125261, 125262, 141035, 156997, 157000, 157028, 157099, 157116, 157117, 157191, 157214, 157455, 169078, 169091, 170205, 170525, 189699, 189763, 194160]), ('linear programming', [3239, 22838, 43918, 70365, 200871]), (': towards', [42250]), ('learning control', [7582, 24432, 24436, 40404, 53385, 53400, 53682, 69338, 71210, 71336, 71438, 71524, 71542, 78010, 91761, 121626, 141772, 174242, 174257, 174274, 174659, 177979, 178130, 178211, 185364, 194126, 194618]), ('distributed representations', [2765, 8352, 12064, 14481, 17252, 19541, 31725, 38214, 38228, 38279, 46587, 177426, 177888, 207293]), ('networks the', [47306, 123584, 208522]), ('pattern recognition', [1013, 1029, 1400, 3476, 3924, 7571, 7588, 8641, 8664, 8708, 9042, 13094, 13879, 14262, 18032, 18040, 18064, 18110, 18458, 20423, 20560, 28270, 29554, 31701, 32958, 33466, 34118, 34126, 34524, 35857, 36231, 37484, 42700, 64015, 64497, 64843, 64918, 67747, 70387, 70398, 70415, 70617, 70707, 77639, 79192, 79271, 79274, 82303, 83966, 97618, 98878, 111164, 111177, 113362, 113378, 113398, 113407, 113411, 113842, 113866, 118459, 125848, 125903, 128013, 128303, 135847, 137612, 156353, 160472, 161219, 162307, 162320, 166612, 168148, 176754, 181174, 190585, 192153, 194625, 195169, 202452, 203907, 206967]), ('analog neural', [4361, 59090, 67437, 67676, 70200, 97627, 137125, 152703, 166669, 173551, 183040, 183520]), ('ocular dominance', [25100, 25105, 25106, 25111, 25113, 25127, 25129, 25341, 25352, 25353, 25357, 25482, 25493, 25503, 41477, 41504, 41507, 41509, 41521, 41569, 41600, 41606, 41749, 41755, 41761, 41764, 41768, 41776, 41778, 41782, 41817, 41840, 41841, 41854, 57826, 57830, 66791, 66932, 66934, 66936, 66973, 66975, 67046, 67184, 67364, 67382, 77252, 77485, 77541, 133916, 133919, 133921, 133927, 133963, 133967, 133968, 134018, 134019, 134046, 134171, 134177, 134278, 134280, 134283, 134300, 134336, 134341, 134345, 134347, 134365, 134369, 134370, 134372, 134373, 134376, 134377, 134378, 134386, 134396, 134405, 204719, 204720, 204722, 204737, 204743, 204744, 204746, 204747, 204749, 204753, 204756, 204842, 204878, 204885, 204886, 204889, 204891, 204907, 204938, 204943, 204959]), ('learning dynamic', [24061, 33550, 33845, 39511, 170203, 182145, 182316]), ('natural language', [2781, 3888, 3894, 3904, 3937, 3955, 3958, 4018, 19373, 19464, 19513, 19549, 97658, 97669, 98032, 98041, 98874, 123904, 187219, 191713, 191723, 191773, 192181, 193286, 193360, 193404, 205585, 205947]), ('continuous speech', [3867, 24014, 44998, 45350, 48334, 48517, 60363, 60395, 60433, 60503, 60776, 62295, 62305, 62477, 62674, 62722, 62727, 71178, 79199, 89590, 89599, 91841, 91848, 91886, 92340, 92451, 116863, 116914, 116995, 117137, 117240, 117260, 120222, 165028, 165041, 168614, 168633, 193662, 193673, 193688, 207868, 207892, 207904, 208048, 208056, 208385, 210510]), ('learning model', [32942, 34027, 38275, 38525, 43868, 69387, 69470, 88265, 100161, 140085, 164158, 166225, 184433, 184590, 184779, 198281]), ('learning curves', [14246, 14420, 14482, 26094, 33439, 45959, 84287, 84304, 136932, 136992, 140102, 140110, 140535, 164392, 164480, 166171, 177377, 177383, 177384, 177399, 184167, 192233, 192691, 192757, 209536]), ('learning using', [32588, 84772, 105310, 108230, 121806, 140564, 164155, 186318, 186461, 209549]), ('models :', [148242]), ('natural scenes', [6190, 49816, 120644, 146977, 183519]), (': fast', [28666, 28956, 143579, 150141]), ('sequential data', [28959, 177849]), ('probabilistic models', [185787]), ('high dimensions', [450]), ('structure learning', [148302, 205985]), ('kernel methods', [75065, 145472]), ('logistic regression', [137159]), ('hierarchical clustering', [38638, 178537]), ('empirical risk', [127883, 127914, 127963, 127991, 128007, 128016, 128076, 128147, 128168, 128170, 128171, 128190, 128285, 128300, 128317, 128358, 128361, 128379, 128401, 130809, 130868, 130904]), ('using neural', [4369, 17525, 22798, 24025, 29488, 38162, 49015, 51658, 55059, 57792, 89603, 91170, 96774, 101074, 103128, 103138, 103310, 105961, 107596, 117260, 119500, 126426, 126834, 146095, 157003, 174745, 178220, 185348, 185638, 192193]), ('complexity learning', [88311]), ('networks using', [8692, 19588, 53575, 61887, 65441, 76622, 121664, 126615, 145365, 166696, 167265, 189133, 191699, 195829, 195959]), (': theory', [202524]), ('markov model', [87298, 165025, 165028, 206019]), ('selective attention', [78058, 78206, 78296, 78305, 161979, 162286, 162306]), ('face recognition', [5704, 12820, 64040, 64350, 161579]), ('finite state', [43364, 43366, 43382, 43685, 43696, 57481, 57548, 57662, 81215, 81217, 81224, 81249, 81728, 81850, 88257, 97224, 110093, 166704, 166968, 166972, 167038, 168610, 168624, 169295, 178509, 178539, 178543, 178548, 178759, 196484, 199330]), ('population codes', [162184]), ('real time', [7583, 7729, 12390, 12801, 12863, 12865, 20414, 20425, 20428, 20451, 20538, 31423, 50013, 50041, 64960, 71523, 103310, 130727, 132191, 136683, 136789, 140663, 162361, 162365, 162427, 162589, 162777, 162778, 162783, 183580, 183684, 210684, 210701]), ('neighbor classification', [29725, 76589, 142651]), ('policy iteration', [23267, 23374, 23379, 169290, 169294, 169300, 169302, 169334, 169336, 169339, 169359, 169360, 169470, 169573, 169575, 169588, 169604]), ('training sets', [2290, 28497, 28823, 28943, 42672, 43852, 45643, 45653, 46568, 46664, 46672, 59264, 62913, 65795, 70931, 76976, 78736, 78869, 79041, 79403, 81258, 81350, 81363, 81378, 81707, 82388, 84193, 87384, 87529, 87570, 87571, 87585, 87588, 87683, 87883, 87886, 99084, 101345, 109826, 113369, 114988, 118658, 142535, 146065, 167557, 184168, 184196, 184361, 195664, 197961, 198088, 198289, 205580, 205873, 205967]), ('discriminant analysis', [15857, 58580, 58583, 105824, 109764, 110084, 130339, 130384, 178561]), ('the infinite', [29532, 29553, 29688, 29693, 48625, 140166, 166591, 166705, 181628, 209801]), ('lower bounds', [11144, 23116, 23173, 69892, 135712, 135904, 136022, 140106, 140261, 140286, 140346, 140347, 179424, 197247, 197349, 197496, 209179]), ('probabilistic model', [124740, 140401, 185787]), ('side information', [100540, 100544, 100568, 100643, 100800, 184420]), ('distance metric', [19979, 24473, 24489, 24493, 25034, 25035, 25037, 25044, 45157, 99081, 102223, 102289, 142362, 187043]), ('loss functions', [32319, 32334, 140534]), ('generalized linear', [87534]), ('stochastic learning', [31854, 174753, 184259, 204073, 204076, 204110, 204111, 204684, 204687, 207318, 207323, 207334, 207361, 207556, 207640, 207815, 207835]), ('its application', [21517, 47632, 61613, 62640, 62677, 63031, 70636, 83801, 165038, 171885, 174771, 179583, 203892, 204966, 206615, 207892, 209051]), ('basis functions', [501, 527, 531, 535, 567, 581, 591, 599, 811, 816, 817, 821, 822, 827, 836, 13198, 13663, 19589, 20258, 23109, 24469, 24484, 24687, 25073, 25076, 26636, 26857, 32588, 33491, 37524, 37643, 37647, 37649, 37650, 37651, 37673, 37717, 37719, 37720, 37791, 40996, 41000, 47331, 47342, 47343, 47348, 47391, 47395, 47406, 47421, 47430, 47438, 47451, 47653, 48678, 48686, 57310, 64971, 65021, 74731, 78399, 78409, 78454, 78475, 78509, 78513, 78516, 78517, 78518, 78536, 78538, 78591, 78595, 78599, 78667, 78668, 78732, 78805, 78860, 79049, 79052, 79136, 79144, 84001, 86978, 87373, 89230, 92891, 102484, 103185, 103187, 116853, 116968, 116970, 117258, 120934, 131931, 132064, 139737, 150133, 153403, 161074, 161088, 161587, 161600, 171034, 178174, 178210, 179225, 191156, 193911, 195490, 198309, 198310, 198311, 198318, 198323, 198379, 198384, 198390, 198391, 198560, 198561, 198571, 198618, 198667, 198669, 198685, 198687, 208446, 208536, 208574, 208629, 208630, 208645, 208677, 208890, 208929, 208942, 208947, 209730]), ('signal processing', [4093, 5708, 7571, 7589, 12332, 12334, 12337, 12360, 12371, 12376, 12385, 12439, 12730, 20423, 34119, 34174, 34208, 34622, 38168, 48565, 49015, 49633, 50478, 57792, 61307, 61335, 61412, 64958, 74203, 87407, 107585, 122648, 125488, 125521, 125847, 133473, 135341, 141667, 146095, 146144, 152318, 161032, 168125, 173013, 173222, 183578]), ('function networks', [19977, 20020, 20241, 87439, 102264, 102646, 132051, 137192, 191190, 209517, 209587, 209982]), ('learning rate', [1435, 3533, 3612, 6501, 7138, 7177, 7248, 7285, 7318, 7332, 7862, 7868, 8197, 8587, 15745, 17051, 19744, 20163, 24390, 24397, 26098, 27155, 31780, 34004, 34012, 34161, 39746, 41114, 42892, 42894, 43673, 45551, 45873, 46737, 53115, 56942, 58948, 60929, 60975, 62392, 64117, 64120, 64142, 64143, 64967, 66875, 68947, 69119, 70949, 71202, 71448, 75270, 75271, 75437, 75460, 75463, 75466, 78118, 82108, 84024, 84322, 88174, 89348, 91357, 91726, 92316, 96996, 97101, 99839, 99840, 99964, 99997, 100391, 100903, 100921, 101850, 102380, 103676, 104505, 109029, 110742, 111837, 111854, 112140, 114445, 114446, 114459, 114630, 114966, 114972, 115014, 119305, 121251, 127365, 127368, 129368, 129378, 129428, 129451, 129549, 129554, 129635, 129651, 129774, 129785, 130419, 137425, 137794, 144612, 144778, 144781, 144879, 144888, 150172, 158254, 158711, 158723, 158725, 158728, 158730, 158734, 158788, 158815, 158991, 159204, 159211, 164230, 164389, 165987, 166197, 168748, 168749, 168831, 170888, 171021, 176801, 177099, 177107, 178101, 178120, 178133, 182113, 182140, 182153, 182178, 182224, 182375, 182451, 182456, 184713, 185057, 185078, 185104, 187083, 189686, 189872, 190597, 193136, 194483, 197711, 197749, 197769, 197771, 197805, 197836, 197850, 197861, 197865, 197883, 198078, 198081, 198087, 198091, 198092, 198094, 198102, 198195, 198197, 198265, 203187, 204097, 204335, 204677, 207346, 207370, 207478, 207591, 207677, 207815, 207817, 207831]), ('receptive field', [1040, 1065, 1162, 1163, 1166, 7604, 7628, 7686, 7700, 7724, 7727, 7763, 8679, 8682, 8684, 8712, 8720, 8724, 8740, 8778, 8779, 12733, 13916, 20025, 20182, 20204, 20227, 20241, 20332, 20337, 24061, 25304, 25407, 25488, 30056, 30071, 30090, 30130, 30197, 30203, 30205, 32571, 32572, 32580, 32585, 32591, 32603, 32630, 32631, 32638, 32655, 32732, 32736, 32741, 32742, 32751, 32753, 32754, 32774, 32777, 32780, 32790, 32793, 32796, 32798, 32824, 32827, 32828, 32829, 32833, 32835, 32842, 32843, 32871, 32876, 32881, 32891, 32893, 32896, 32945, 33081, 33168, 33451, 36233, 36234, 36518, 36714, 36756, 36763, 36764, 37037, 37043, 37068, 40989, 41006, 41052, 41075, 41094, 41115, 41118, 41120, 41160, 41181, 41185, 41535, 41565, 41567, 41572, 41750, 41765, 41770, 45389, 45390, 45395, 45482, 45528, 45598, 45599, 45602, 45605, 45613, 45616, 45643, 45696, 45707, 46190, 46202, 46260, 46261, 46426, 49637, 49639, 49643, 49645, 49647, 49659, 49662, 49695, 49752, 49806, 49811, 49813, 49854, 49885, 49898, 49899, 49910, 49912, 49913, 49933, 49953, 49955, 49957, 49963, 49965, 51250, 51277, 51286, 51311, 51420, 56806, 64221, 64334, 64986, 65017, 65059, 65074, 65237, 66732, 67624, 77231, 79250, 79251, 79252, 79293, 79294, 79300, 79467, 79469, 79470, 80158, 80192, 80195, 80197, 80206, 80247, 80248, 82161, 85617, 85619, 85621, 85954, 86486, 86977, 87239, 87262, 87269, 87293, 98176, 98389, 101677, 101690, 103622, 103939, 104027, 104028, 104029, 104148, 104266, 105840, 106562, 108261, 108301, 108329, 108526, 108527, 108528, 108530, 108713, 112012, 112013, 112121, 112125, 112131, 112133, 112424, 114493, 114720, 115010, 128379, 134024, 134298, 134299, 134321, 134322, 146617, 146781, 151807, 151822, 151833, 152000, 152002, 152017, 152028, 152029, 152086, 152089, 159388, 159486, 159487, 159675, 163712, 163731, 163841, 163875, 163876, 163880, 163889, 163890, 163891, 163892, 163894, 163896, 163915, 163921, 163927, 163928, 163931, 163949, 183849, 183878, 183893, 183901, 187023, 187235, 189932, 189996, 199374, 199375, 199516, 199518, 199538, 199568, 199585, 199639, 199897, 199899, 200927, 200943, 200944, 200946, 200947, 200955, 200956, 200963, 200973, 201222, 201224, 201450, 201452, 201455, 201464, 204757, 204823, 204828, 204854, 204858, 210133]), ('data analysis', [74897, 115045, 115097, 138105, 140041, 156225, 171464, 176754, 193201]), ('eye movements', [34680, 80424, 90739, 98151, 99355, 99366, 99910, 99916, 103878, 104267, 104270, 104414, 106743, 107584, 107617, 107641, 107680, 107779, 122761, 159229, 159233, 159478, 159541, 159545, 159590, 159601, 159779, 159781, 159857, 166433, 166534, 166552, 186934, 186952, 189657, 189944]), ('difference learning', [23255, 23351, 108239, 155530, 169619, 170562, 189694]), ('vector quantization', [122, 123, 1652, 31739, 38222, 38404, 38470, 38503, 38531, 55290, 56402, 56410, 62358, 128909, 144323, 144335, 144339, 145724, 180261, 180343, 180596]), ('receptive fields', [1040, 1162, 1166, 7600, 7628, 7700, 7724, 7727, 7763, 8679, 8682, 8684, 8712, 8740, 8778, 8779, 13916, 20241, 20337, 24061, 25407, 30056, 30071, 30130, 30197, 32591, 32603, 32630, 32732, 32741, 32742, 32753, 32754, 32774, 32777, 32780, 32793, 32796, 32798, 32824, 32827, 32828, 32829, 32876, 32893, 32945, 33081, 33168, 36233, 40989, 41006, 41115, 41160, 45389, 45395, 45482, 45528, 45602, 45643, 45696, 45707, 46260, 49637, 49639, 49643, 49645, 49806, 49811, 49813, 49854, 49885, 49899, 49910, 49912, 49933, 49953, 49955, 49957, 49963, 49965, 51420, 56806, 64221, 64986, 65059, 65074, 79467, 79469, 79470, 80248, 85617, 86977, 87239, 87293, 98389, 101690, 103622, 103939, 104028, 104029, 104148, 104266, 105840, 106562, 112121, 112131, 112133, 114720, 115010, 128379, 146617, 151807, 151833, 152000, 152017, 152086, 163712, 163731, 163875, 163876, 183849, 183878, 183893, 183901, 187023, 187235, 189932, 189996, 199516, 199518, 199538, 199568, 199585, 199639, 201464, 204823, 204828, 204854, 210133]), ('training neural', [23737, 171091, 184799, 189584, 194711, 199316]), ('learning rules', [13914, 16908, 16910, 16929, 16995, 16999, 17045, 17052, 17059, 17177, 17178, 20100, 20337, 49564, 58939, 58941, 69102, 77522, 87257, 111771, 140596, 141045, 147076, 165499, 165528, 165529, 165531, 165701, 165714, 165853, 166065, 166201, 166203, 176755, 177036, 203766]), ('the power', [2438, 2504, 8246, 11482, 15620, 19239, 20007, 22836, 22872, 23182, 28111, 28121, 29964, 31587, 32944, 33025, 44826, 49682, 49816, 59395, 64961, 73758, 74223, 74507, 81656, 103566, 107336, 110259, 121102, 123665, 125219, 130720, 133845, 140906, 140934, 141092, 141244, 141591, 141603, 143497, 143629, 143660, 143670, 143816, 146945, 161898, 164665, 164671, 167623, 167747, 168000, 177523, 179311, 183170, 183171, 183225, 197541, 197907, 204921, 209095, 209123, 209514]), ('generalization error', [6435, 6527, 44078, 59215, 59376, 59472, 59530, 59555, 59632, 59666, 60878, 67973, 67982, 68067, 68084, 68117, 68124, 68272, 68280, 97115, 130811, 130834, 135745, 135746, 135853, 159912, 159931, 159966, 160442, 160447, 183849, 183851, 183856, 183859, 183890, 183996, 184010, 184011, 184046, 184079, 184193, 184199, 184257, 184263, 184275, 184281, 184357, 185607, 192548, 208943, 208945, 208948, 208949]), ('dimension reduction', [134410, 144943, 144947, 145386, 145576]), ('-line learning', [3494, 3507, 3568, 5765, 5877, 6041, 26855, 26856, 64960, 64967, 70928, 90891, 97018, 100469, 101023, 126345, 126979, 126994, 127420, 185093, 204321]), ('blind separation', [140610, 140659, 140660, 140661, 140671, 141036]), ('mixture model', [13967, 14029, 14030, 42709, 84381, 84537, 84541, 84567, 84569, 84574, 84577, 84706, 84708, 85258, 85259, 85262, 85342, 85343, 85541, 87239, 91784, 115114, 116940, 124281, 126228, 126229, 126230, 126301, 164104, 208666, 209785]), ('statistical models', [67, 123668, 192211]), ('likelihood estimation', [57774, 84586, 148298, 168700]), ('components analysis', [37784, 38294, 64192, 64322, 92335, 115098, 202445]), ('generative model', [86604, 124806, 126134, 126345])])\n",
            "converted target toks [['neural', 'networks'], ['reinforcement', 'learning'], ['neural', 'network'], ['ga', '##uss', '##ian', 'process'], ['graphical', 'models'], ['support', 'vector'], ['ga', '##uss', '##ian', 'processes'], ['active', 'learning'], ['variation', '##al', 'inference'], ['monte', 'carlo'], ['online', 'learning'], ['speech', 'recognition'], ['rec', '##urrent', 'neural'], ['component', 'analysis'], ['gradient', 'descent'], ['hidden', 'marko', '##v'], [':', 'the'], ['deep', 'learning'], ['learning', ':'], ['marko', '##v', 'models'], ['vector', 'machines'], ['analog', 'v', '##ls', '##i'], ['st', '##och', '##astic', 'gradient'], ['marko', '##v', 'decision'], ['feature', 'selection'], [':', 'learning'], ['networks', 'learning'], ['random', 'fields'], ['machine', 'learning'], ['networks', ':'], ['belief', 'propagation'], ['kernel', 'learning'], ['un', '##su', '##per', '##vis', '##ed', 'learning'], ['neural', 'networks'], ['model', 'selection'], ['matrix', 'completion'], ['dynamic', 'programming'], ['function', 'approximation'], ['decision', 'processes'], ['object', 'recognition'], ['time', 'series'], ['mixture', 'models'], ['late', '##nt', 'variable'], ['metric', 'learning'], ['deep', 'neural'], ['sp', '##iki', '##ng', 'neurons'], ['bay', '##esian', 'inference'], ['density', 'estimation'], ['approximate', 'inference'], ['convex', 'optimization'], ['supervised', 'learning'], ['dynamic', '##al', 'systems'], ['con', '##vo', '##lu', '##tion', '##al', 'neural'], ['genera', '##tive', 'models'], ['large', 'scale'], ['matrix', 'factor', '##ization'], [':', 'application'], ['st', '##och', '##astic', 'optimization'], ['natural', 'images'], ['spectral', 'cluster', '##ing'], ['learning', 'the'], ['dimensional', '##ity', 'reduction'], ['principal', 'component'], ['learning', 'sparse'], ['object', 'detection'], ['map', 'inference'], ['visual', 'cortex'], ['rec', '##urrent', 'networks'], ['radial', 'basis'], ['risk', 'mini', '##mi', '##zation'], ['nearest', 'neighbor'], ['independent', 'component'], ['high', 'dimensional'], ['large', 'margin'], ['structured', 'prediction'], ['learning', 'algorithms'], ['neural', 'net'], ['learning', 'multiple'], ['bay', '##esian', 'model'], ['models', 'learning'], ['bay', '##esian', 'networks'], ['policy', 'gradient'], ['variation', '##al', 'bay', '##esian'], ['process', 'regression'], ['sparse', 'coding'], ['domain', 'adaptation'], ['learning', 'deep'], ['recognition', 'using'], ['artificial', 'neural'], ['mean', 'field'], ['maximum', 'likelihood'], ['missing', 'data'], ['sample', 'complexity'], ['exponential', 'family'], ['deep', 'networks'], ['coordinate', 'descent'], ['ass', '##oc', '##ia', '##tive', 'memory'], ['basis', 'function'], ['feature', 'extraction'], ['bolt', '##zman', '##n', 'machines'], ['learning', 'algorithm'], ['learning', 'learning'], ['learning', 'bay', '##esian'], ['vector', 'machine'], ['gradient', 'methods'], ['late', '##nt', 'dir', '##ich', '##let'], ['learning', 'ga', '##uss', '##ian'], ['topic', 'models'], ['semi', '-', 'supervised', 'learning'], ['conditional', 'random'], ['feature', 'learning'], ['genera', '##tive', 'ad', '##vers', '##aria', '##l'], ['network', 'model'], ['neural', 'nets'], ['mutual', 'information'], ['marko', '##v', 'random'], ['second', 'order'], ['cluster', '##ing', ':'], ['learning', 'approach'], [':', 'efficient'], ['bay', '##esian', 'learning'], ['decision', 'trees'], ['learning', 'structured'], ['variable', 'models'], ['ga', '##uss', '##ian', 'graphical'], ['dir', '##ich', '##let', 'allocation'], ['pro', '##ba', '##bilis', '##tic', 'inference'], ['semi', '-', 'supervised', 'learning'], ['graphical', 'model'], ['sparse', 'pc', '##a'], ['message', 'passing'], ['con', '##vo', '##lu', '##tion', '##al', 'networks'], ['bay', '##esian', 'optimization'], ['learning', 'neural'], ['temporal', 'difference'], ['ga', '##uss', '##ian', 'mixture', '##s'], [':', 'new'], ['least', 'squares'], ['partially', 'ob', '##ser', '##vable'], ['linear', 'models'], ['belief', 'networks'], ['marko', '##v', 'networks'], ['policy', 'search'], ['maximum', 'margin'], ['restricted', 'bolt', '##zman', '##n'], ['collaborative', 'filtering'], ['decision', 'making'], ['end', '-', '-'], ['non', '##para', '##metric', 'bay', '##esian'], ['transfer', 'learning'], ['tensor', 'decomposition'], ['neural', 'model'], ['image', 'segment', '##ation'], ['network', ':'], ['information', 'theo', '##ret', '##ic'], [':', 'from'], ['parameter', 'estimation'], ['efficient', 'learning'], ['visual', 'attention'], ['visual', 'recognition'], ['value', 'function'], ['learning', 'st', '##och', '##astic'], ['linear', 'programming'], ['information', 'bottle', '##neck'], ['variance', 'reduction'], [':', 'towards'], ['sparse', 'ga', '##uss', '##ian'], ['multiple', 'kernel'], ['dir', '##ich', '##let', 'process'], ['networks', 'neural'], ['learning', 'control'], ['distributed', 'representations'], ['networks', 'the'], ['pattern', 'recognition'], ['analog', 'neural'], ['v', '##ls', '##i', 'neural'], ['o', '##cular', 'dominance'], ['learning', 'dynamic'], ['natural', 'language'], ['continuous', 'speech'], ['learning', 'model'], ['learning', 'curves'], ['learning', 'using'], ['sp', '##iki', '##ng', 'neurons'], ['mixture', '##s', 'experts'], ['graph', 'matching'], ['learning', 'continuous'], ['learning', 'adaptive'], ['information', 'maxim', '##ization'], [':', 'bay', '##esian'], ['learning', 'efficient'], ['multi', '-', 'task', 'learning'], ['models', ':'], ['natural', 'scenes'], ['learning', 'nonlinear'], [':', 'fast'], ['process', 'models'], ['sequential', 'data'], ['data', 'learning'], ['pro', '##ba', '##bilis', '##tic', 'models'], ['high', 'dimensions'], ['marko', '##v', 'chain'], ['inference', 'bay', '##esian'], ['structure', 'learning'], ['kernel', 'methods'], ['log', '##istic', 'regression'], ['model', 'learning'], ['hierarchical', 'cluster', '##ing'], ['training', 'deep'], ['sub', '##mo', '##du', '##lar', 'functions'], ['inverse', 'reinforcement'], ['empirical', 'risk'], [':', 'pro', '##ba', '##bilis', '##tic'], ['using', 'neural'], ['networks', 'application'], ['complexity', 'learning'], ['bolt', '##zman', '##n', 'machine'], ['networks', 'using'], ['v', '##ls', '##i', 'implementation'], [':', 'theory'], ['marko', '##v', 'model'], ['selective', 'attention'], ['face', 'recognition'], ['anomaly', 'detection'], ['finite', 'state'], ['population', 'codes'], ['un', '##lab', '##ele', '##d', 'data'], ['data', 'cluster', '##ing'], ['manifold', 'learning'], ['real', 'time'], ['neighbor', 'classification'], ['policy', 'iteration'], ['training', 'sets'], ['source', 'separation'], ['learning', 'pro', '##ba', '##bilis', '##tic'], ['disc', '##rim', '##ina', '##nt', 'analysis'], ['the', 'infinite'], ['importance', 'sampling'], ['lower', 'bounds'], ['pro', '##ba', '##bilis', '##tic', 'model'], ['kernel', 'machines'], ['causal', 'inference'], ['data', ':'], ['side', 'information'], ['distance', 'metric'], ['loss', 'functions'], ['expectation', 'propagation'], ['fast', 'rates'], ['spectral', 'methods'], ['-', '-', 'end'], ['random', 'projections'], ['graphical', 'models'], ['subsp', '##ace', 'cluster', '##ing'], ['generalized', 'linear'], [':', 'deep'], ['sparse', 'inverse'], ['inverse', 'co', '##var', '##iance'], ['robust', 'pc', '##a'], ['ad', '##vers', '##aria', '##l', 'networks'], ['st', '##och', '##astic', 'learning'], ['its', 'application'], ['basis', 'functions'], ['signal', 'processing'], ['nets', ':'], ['function', 'networks'], ['learning', 'rate'], ['rec', '##eptive', 'field'], ['data', 'analysis'], ['eye', 'movements'], ['difference', 'learning'], ['vector', 'quan', '##ti', '##zation'], ['rec', '##eptive', 'fields'], ['algorithm', 'learning'], ['training', 'neural'], ['learning', 'rules'], ['the', 'power'], ['general', '##ization', 'error'], ['dimension', 'reduction'], ['value', 'iteration'], ['-', 'line', 'learning'], ['blind', 'separation'], ['pose', 'estimation'], ['mixture', 'model'], ['statistical', 'models'], ['factor', 'analysis'], ['inference', 'learning'], ['likelihood', 'estimation'], ['components', 'analysis'], ['genera', '##tive', 'model'], ['learning', 'linear'], ['analysis', ':'], ['approach', 'learning'], ['bay', '##esian', 'models'], [':', 'unified'], ['marko', '##v', 'chains'], ['semi', '##de', '##fin', '##ite', 'programming'], ['learning', 'optimal'], ['spectral', 'learning'], ['imitation', 'learning'], ['regret', 'bounds']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(t1)\n",
        "print(len(index_t1))\n",
        "print(len(index_t2))\n",
        "# target_toks\n",
        "\n",
        "len(list(index_t1.values())[1])\n"
      ],
      "metadata": {
        "id": "dkhf0E9Zoo1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cdd3d4-8079-4ada-cd78-e6ad7273c96f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129\n",
            "157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _pre_bert(doc,index,t):\n",
        "  \n",
        "  # index =  index_t1 -> { target_w1: index, target_w2: index2, target_w1 : index5 } -  index = Sentence index in which target word appears\n",
        "  s=[\"Not Found\"]  \n",
        "  \n",
        "  if t in index.keys():\n",
        "      s=[doc[ind] for ind in index[t]]\n",
        "\n",
        "  print('len of sentences',len(s))\n",
        "  l=len(s)\n",
        "  marked_text = [\"[CLS] \" + text + \" [SEP]\" for text in s]\n",
        "  tokenized_text = [tokenizer.tokenize(m) for m in marked_text]\n",
        "  \n",
        "  tokenized_text=[x[:512] if len(x)>512 else x for x in tokenized_text]\n",
        "  indexed_tokens = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n",
        "  segments_ids = [[1] * len(x) for x in tokenized_text]\n",
        "  return s,marked_text,tokenized_text,indexed_tokens,segments_ids,l\n",
        "\n",
        "\n",
        "def _bert_features(tokens_tensor, segments_tensors,tokenized_text):\n",
        "  # print(len(tokens_tensor[0]))\n",
        "  with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
        "  # print (\"Number of layers:\", len(encoded_layers))\n",
        "  layer_i = 0\n",
        "\n",
        "  # # print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "  batch_i = 0\n",
        "\n",
        "  # print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "  token_i = 0\n",
        "\n",
        "  # print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
        "  # Convert the hidden state embeddings into single token vectors\n",
        "\n",
        "  # Holds the list of 12 layer embeddings for each token\n",
        "  # Will have the shape: [# tokens, # layers, # features]\n",
        "  token_embeddings = [] \n",
        "\n",
        "  # For each token in the sentence...\n",
        "  # tokenized_text=[x for x in tokenized_text if x not in ['_', 'n', '##n','v', '##b']]\n",
        "  for token_i in range(len(tokenized_text)):\n",
        "    \n",
        "    # Holds 12 layers of hidden states for each token \n",
        "    hidden_layers = [] \n",
        "    \n",
        "    # For each of the 12 layers...\n",
        "    for layer_i in range(len(encoded_layers)):\n",
        "      \n",
        "      # Lookup the vector for `token_i` in `layer_i`\n",
        "      vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "      \n",
        "      hidden_layers.append(vec)\n",
        "      \n",
        "    token_embeddings.append(hidden_layers)\n",
        "\n",
        "  # Sanity check the dimensions:\n",
        "  # print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
        "  # print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
        "  return token_embeddings\n",
        "# s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "def _get_embeddings(pre,tg):\n",
        "  m_embed_full=[]\n",
        "  # print('len(pre[0])',len(pre[0]))\n",
        "  # print(tg)\n",
        "  for _,item in enumerate(pre[0]):\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    # print(item)\n",
        "    token_list=pre[2][_]\n",
        "    \n",
        "    tokens_tensor = torch.tensor([pre[3][_]])\n",
        "    segments_tensors = torch.tensor([pre[4][_]])\n",
        "    # Predict hidden states features for each layer\n",
        "    token_embeddings=_bert_features(tokens_tensor, segments_tensors,pre[2][_])\n",
        "    concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
        "\n",
        "    summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]\n",
        "    \n",
        "    #consider the tokenized target\n",
        "  \n",
        "    indxs=[]\n",
        "    # print(token_list)\n",
        "    for tok in tg:\n",
        "      '''\n",
        "      remove -1,-2,-3\n",
        "      '''\n",
        "      if tok in token_list:\n",
        "        if tok not in ['_', 'n', '##n','v', '##b']:\n",
        "          indxs.append(token_list.index(tok))\n",
        "\n",
        "    # print('indxs',indxs)\n",
        "    if len(indxs)==1:\n",
        "      #bert_embed=concatenated_last_4_layers [indxs[0]]\n",
        "      bert_embed=summed_last_4_layers [indxs[0]]\n",
        "\n",
        "      m_embed_full.append(bert_embed)\n",
        "    elif len(indxs)>1:\n",
        "      b_emb=[]\n",
        "      for ind in indxs:\n",
        "        #b_emb.append(concatenated_last_4_layers[ind])\n",
        "        b_emb.append(summed_last_4_layers[ind])\n",
        "        \n",
        "      bert_embed= torch.sum(torch.stack(b_emb), 0)\n",
        "      m_embed_full.append(bert_embed)\n",
        "    # indx=token_list.index(tg.lower())\n",
        "    # indx = [i for (i, elem) in enumerate(pre[2][_]) if t in elem]\n",
        "    # print('indx',indx)\n",
        "    # print(pre[1][_],indx)\n",
        "\n",
        "    # if len(indx)>0:\n",
        "    # bert_embed=concatenated_last_4_layers[indx[0]]\n",
        "    \n",
        "    # cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
        "    \n",
        "    \n",
        "  return  m_embed_full, summed_last_4_layers\n",
        "# For a particular target word,do clustering and find if there is a sense change\n"
      ],
      "metadata": {
        "id": "ec5y4w-gqamr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding for all time windows\n",
        "\n",
        "sents_all=[]\n",
        "\n",
        "# Holds all bert embeddings \n",
        "# [] -> [[embedding1], [embedding2],...]\n",
        "X=[]\n",
        "\n",
        "def embeddings_extract(target_words,target_toks,doc1,index_t1):\n",
        "  t=target_words\n",
        "  X_C1=[]\n",
        "  lens1=[]\n",
        "  for k,t in enumerate(target_words) :\n",
        "    berts=[]\n",
        "    sents=[]\n",
        "    print('The target word is',t)    \n",
        "    \n",
        "    #get the sentences from corpus c1 and c2 for the specific target word 't'\n",
        "    \n",
        "    # This will generate tokenized sentences, tokens for the specific word. Or sentences containing specific word\n",
        "    pre1=_pre_bert(doc1,index_t1,t)\n",
        "\n",
        "    # lens1.append(pre1[-1])\n",
        "    # lens2.append(pre2[-1])\n",
        "    # print(pre1)\n",
        "    \n",
        "    sents.extend(pre1[0])\n",
        "    #aggregate all the embeddings\n",
        "    # s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "\n",
        "    '''\n",
        "    Get the embeddings of the targets from corpus 1 and 2\n",
        "    '''\n",
        "    _ , b1=_get_embeddings(pre1,target_toks[k])\n",
        "    print('len of t1',len(b1))\n",
        "    \n",
        "    '''\n",
        "    store the lenghts of no. of sentences extracted for each target word for each corpus\n",
        "    '''\n",
        "    lens1.append(len(b1))\n",
        "    \n",
        "    berts.extend(b1)\n",
        "    print('len of each target word extractions is',len(berts))\n",
        "    X.append(berts)\n",
        "\n",
        "    # ______________ Placeholder to flatten the tensors into 1-D tensor for the \n",
        "    #           respective sentence tensors of specific keyword _______________ (b1)\n",
        "\n",
        "    X_C1.append(b1)# the embeddings for C1\n",
        "    sents_all.append(sents)\n",
        "  return X,X_C1,lens1,sents_all\n",
        "\n"
      ],
      "metadata": {
        "id": "encxlY89yzVe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "# embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "\n",
        "# lens=[len_c1]\n",
        "# # lens.append(len_c2)\n",
        "# print('saved')\n",
        "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "LLgkz2ZztHOa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sWzlJE8F5UGV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT Embeddings\n",
        "\n",
        "embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "embed_full,embed_C2,len_c2,sents=embeddings_extract(target_words,target_toks,doc2,index_t2)\n",
        "embed_full,embed_C3,len_c3,sents=embeddings_extract(target_words,target_toks,doc3,index_t3)\n",
        "embed_full,embed_C4,len_c4,sents=embeddings_extract(target_words,target_toks,doc4,index_t4)\n",
        "embed_full,embed_C5,len_c5,sents=embeddings_extract(target_words,target_toks,doc5,index_t5)\n",
        "embed_full,embed_C6,len_c6,sents=embeddings_extract(target_words,target_toks,doc6,index_t6)\n",
        "embed_full,embed_C7,len_c7,sents=embeddings_extract(target_words,target_toks,doc7,index_t7)\n",
        "embed_full,embed_C8,len_c8,sents=embeddings_extract(target_words,target_toks,doc8,index_t8)\n",
        "embed_full,embed_C9,len_c9,sents=embeddings_extract(target_words,target_toks,doc9,index_t9)\n",
        "embed_full,embed_C10,len_c10,sents=embeddings_extract(target_words,target_toks,doc10,index_t10)\n"
      ],
      "metadata": {
        "id": "KPcYgXrINfhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9768e934-babd-4e77-c7b7-3fe5bb34656a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The target word is random projections\n",
            "len of sentences 2\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is graphical models\n",
            "len of sentences 330\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is subspace clustering\n",
            "len of sentences 4\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is generalized linear\n",
            "len of sentences 25\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is : deep\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is sparse inverse\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is inverse covariance\n",
            "len of sentences 13\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is robust pca\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is adversarial networks\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic learning\n",
            "len of sentences 2\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is its application\n",
            "len of sentences 32\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is basis functions\n",
            "len of sentences 217\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is signal processing\n",
            "len of sentences 47\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is nets :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is function networks\n",
            "len of sentences 3\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is learning rate\n",
            "len of sentences 149\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is receptive field\n",
            "len of sentences 160\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is data analysis\n",
            "len of sentences 34\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is eye movements\n",
            "len of sentences 43\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is difference learning\n",
            "len of sentences 15\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is vector quantization\n",
            "len of sentences 10\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is receptive fields\n",
            "len of sentences 73\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is algorithm learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is training neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning rules\n",
            "len of sentences 73\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is the power\n",
            "len of sentences 104\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is generalization error\n",
            "len of sentences 152\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is dimension reduction\n",
            "len of sentences 32\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is value iteration\n",
            "len of sentences 39\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is -line learning\n",
            "len of sentences 31\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is blind separation\n",
            "len of sentences 16\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is pose estimation\n",
            "len of sentences 19\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is mixture model\n",
            "len of sentences 294\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is statistical models\n",
            "len of sentences 29\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is factor analysis\n",
            "len of sentences 74\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is inference learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is likelihood estimation\n",
            "len of sentences 32\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is components analysis\n",
            "len of sentences 29\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is generative model\n",
            "len of sentences 269\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is learning linear\n",
            "len of sentences 4\n",
            "len of t1 63\n",
            "len of each target word extractions is 63\n",
            "The target word is analysis :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is approach learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian models\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is : unified\n",
            "len of sentences 1\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is markov chains\n",
            "len of sentences 2\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is semidefinite programming\n",
            "len of sentences 38\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is learning optimal\n",
            "len of sentences 1\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is spectral learning\n",
            "len of sentences 2\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is imitation learning\n",
            "len of sentences 2\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is regret bounds\n",
            "len of sentences 2\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is neural networks\n",
            "len of sentences 228\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is reinforcement learning\n",
            "len of sentences 201\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is neural network\n",
            "len of sentences 220\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is gaussian process\n",
            "len of sentences 17\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is graphical models\n",
            "len of sentences 314\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is support vector\n",
            "len of sentences 269\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is gaussian processes\n",
            "len of sentences 8\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is active learning\n",
            "len of sentences 255\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is variational inference\n",
            "len of sentences 51\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is monte carlo\n",
            "len of sentences 3\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is online learning\n",
            "len of sentences 71\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is speech recognition\n",
            "len of sentences 41\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is recurrent neural\n",
            "len of sentences 19\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is component analysis\n",
            "len of sentences 118\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is gradient descent\n",
            "len of sentences 193\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is hidden markov\n",
            "len of sentences 15\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is : the\n",
            "len of sentences 504\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is deep learning\n",
            "len of sentences 3\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is learning :\n",
            "len of sentences 1\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is markov models\n",
            "len of sentences 12\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is vector machines\n",
            "len of sentences 159\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is analog vlsi\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic gradient\n",
            "len of sentences 66\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is markov decision\n",
            "len of sentences 3\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is feature selection\n",
            "len of sentences 185\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is : learning\n",
            "len of sentences 8\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is networks learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random fields\n",
            "len of sentences 125\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is machine learning\n",
            "len of sentences 306\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is networks :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is belief propagation\n",
            "len of sentences 206\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is kernel learning\n",
            "len of sentences 58\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is unsupervised learning\n",
            "len of sentences 80\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is neural networks\n",
            "len of sentences 228\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is model selection\n",
            "len of sentences 181\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is matrix completion\n",
            "len of sentences 5\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is dynamic programming\n",
            "len of sentences 147\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is function approximation\n",
            "len of sentences 90\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is decision processes\n",
            "len of sentences 40\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is object recognition\n",
            "len of sentences 78\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is time series\n",
            "len of sentences 147\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is mixture models\n",
            "len of sentences 114\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is latent variable\n",
            "len of sentences 250\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is metric learning\n",
            "len of sentences 37\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is deep neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is spiking neurons\n",
            "len of sentences 116\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is bayesian inference\n",
            "len of sentences 8\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is density estimation\n",
            "len of sentences 108\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is approximate inference\n",
            "len of sentences 96\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is convex optimization\n",
            "len of sentences 136\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is supervised learning\n",
            "len of sentences 475\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is dynamical systems\n",
            "len of sentences 62\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is convolutional neural\n",
            "len of sentences 16\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is generative models\n",
            "len of sentences 78\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is large scale\n",
            "len of sentences 77\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is matrix factorization\n",
            "len of sentences 83\n",
            "len of t1 56\n",
            "len of each target word extractions is 56\n",
            "The target word is : application\n",
            "len of sentences 1\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is stochastic optimization\n",
            "len of sentences 5\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is natural images\n",
            "len of sentences 160\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is spectral clustering\n",
            "len of sentences 198\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is learning the\n",
            "len of sentences 202\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 175\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is principal component\n",
            "len of sentences 143\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning sparse\n",
            "len of sentences 8\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is object detection\n",
            "len of sentences 64\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is map inference\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is visual cortex\n",
            "len of sentences 100\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is recurrent networks\n",
            "len of sentences 10\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is radial basis\n",
            "len of sentences 33\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is risk minimization\n",
            "len of sentences 66\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is nearest neighbor\n",
            "len of sentences 213\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is independent component\n",
            "len of sentences 89\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is high dimensional\n",
            "len of sentences 121\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is large margin\n",
            "len of sentences 73\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is structured prediction\n",
            "len of sentences 37\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is learning algorithms\n",
            "len of sentences 293\n",
            "len of t1 7\n",
            "len of each target word extractions is 7\n",
            "The target word is neural net\n",
            "len of sentences 244\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is learning multiple\n",
            "len of sentences 10\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is bayesian model\n",
            "len of sentences 9\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is models learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian networks\n",
            "len of sentences 3\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is policy gradient\n",
            "len of sentences 46\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is variational bayesian\n",
            "len of sentences 3\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is process regression\n",
            "len of sentences 25\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is sparse coding\n",
            "len of sentences 73\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is domain adaptation\n",
            "len of sentences 32\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is learning deep\n",
            "len of sentences 3\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is recognition using\n",
            "len of sentences 34\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is artificial neural\n",
            "len of sentences 8\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is mean field\n",
            "len of sentences 79\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is maximum likelihood\n",
            "len of sentences 210\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is missing data\n",
            "len of sentences 49\n",
            "len of t1 73\n",
            "len of each target word extractions is 73\n",
            "The target word is sample complexity\n",
            "len of sentences 64\n",
            "len of t1 48\n",
            "len of each target word extractions is 48\n",
            "The target word is exponential family\n",
            "len of sentences 78\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is deep networks\n",
            "len of sentences 14\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is coordinate descent\n",
            "len of sentences 36\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is associative memory\n",
            "len of sentences 8\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is basis function\n",
            "len of sentences 199\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is feature extraction\n",
            "len of sentences 52\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is boltzmann machines\n",
            "len of sentences 6\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is learning algorithm\n",
            "len of sentences 618\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is learning learning\n",
            "len of sentences 1\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vector machine\n",
            "len of sentences 250\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is gradient methods\n",
            "len of sentences 35\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is latent dirichlet\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning gaussian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is topic models\n",
            "len of sentences 31\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 352\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is conditional random\n",
            "len of sentences 58\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is feature learning\n",
            "len of sentences 8\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is generative adversarial\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is network model\n",
            "len of sentences 33\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is neural nets\n",
            "len of sentences 10\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is mutual information\n",
            "len of sentences 229\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is markov random\n",
            "len of sentences 5\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is second order\n",
            "len of sentences 88\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is clustering :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning approach\n",
            "len of sentences 39\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is : efficient\n",
            "len of sentences 2\n",
            "len of t1 62\n",
            "len of each target word extractions is 62\n",
            "The target word is bayesian learning\n",
            "len of sentences 5\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is decision trees\n",
            "len of sentences 38\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is learning structured\n",
            "len of sentences 1\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is variable models\n",
            "len of sentences 25\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is gaussian graphical\n",
            "len of sentences 1\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is dirichlet allocation\n",
            "len of sentences 7\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is probabilistic inference\n",
            "len of sentences 44\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 352\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is graphical model\n",
            "len of sentences 365\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is sparse pca\n",
            "len of sentences 1\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is message passing\n",
            "len of sentences 60\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is convolutional networks\n",
            "len of sentences 3\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is bayesian optimization\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is temporal difference\n",
            "len of sentences 46\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is gaussian mixtures\n",
            "len of sentences 4\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is : new\n",
            "len of sentences 6\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is least squares\n",
            "len of sentences 130\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is partially observable\n",
            "len of sentences 53\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is linear models\n",
            "len of sentences 99\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is belief networks\n",
            "len of sentences 23\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is markov networks\n",
            "len of sentences 7\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is policy search\n",
            "len of sentences 23\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is maximum margin\n",
            "len of sentences 79\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is restricted boltzmann\n",
            "len of sentences 1\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is collaborative filtering\n",
            "len of sentences 37\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is decision making\n",
            "len of sentences 28\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is end --\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is nonparametric bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is transfer learning\n",
            "len of sentences 40\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is tensor decomposition\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is neural model\n",
            "len of sentences 11\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is image segmentation\n",
            "len of sentences 75\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is network :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information theoretic\n",
            "len of sentences 24\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is : from\n",
            "len of sentences 12\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is parameter estimation\n",
            "len of sentences 99\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is efficient learning\n",
            "len of sentences 26\n",
            "len of t1 7\n",
            "len of each target word extractions is 7\n",
            "The target word is visual attention\n",
            "len of sentences 37\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is visual recognition\n",
            "len of sentences 7\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is value function\n",
            "len of sentences 248\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is learning stochastic\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is linear programming\n",
            "len of sentences 74\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is information bottleneck\n",
            "len of sentences 32\n",
            "len of t1 63\n",
            "len of each target word extractions is 63\n",
            "The target word is variance reduction\n",
            "len of sentences 14\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is : towards\n",
            "len of sentences 4\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is sparse gaussian\n",
            "len of sentences 1\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is multiple kernel\n",
            "len of sentences 15\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is dirichlet process\n",
            "len of sentences 3\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is networks neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning control\n",
            "len of sentences 2\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is distributed representations\n",
            "len of sentences 8\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is networks the\n",
            "len of sentences 1\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is pattern recognition\n",
            "len of sentences 48\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is analog neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vlsi neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is ocular dominance\n",
            "len of sentences 1\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning dynamic\n",
            "len of sentences 18\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is natural language\n",
            "len of sentences 87\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is continuous speech\n",
            "len of sentences 6\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is learning model\n",
            "len of sentences 39\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning curves\n",
            "len of sentences 19\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning using\n",
            "len of sentences 44\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is spiking neurons\n",
            "len of sentences 116\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is mixtures experts\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is graph matching\n",
            "len of sentences 30\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is learning continuous\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning adaptive\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information maximization\n",
            "len of sentences 18\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is : bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning efficient\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is multi-task learning\n",
            "len of sentences 33\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is models :\n",
            "len of sentences 1\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is natural scenes\n",
            "len of sentences 56\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is learning nonlinear\n",
            "len of sentences 7\n",
            "len of t1 55\n",
            "len of each target word extractions is 55\n",
            "The target word is : fast\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is process models\n",
            "len of sentences 12\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is sequential data\n",
            "len of sentences 22\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is data learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is probabilistic models\n",
            "len of sentences 62\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is high dimensions\n",
            "len of sentences 31\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is markov chain\n",
            "len of sentences 2\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is inference bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is structure learning\n",
            "len of sentences 40\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is kernel methods\n",
            "len of sentences 63\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is logistic regression\n",
            "len of sentences 142\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is model learning\n",
            "len of sentences 21\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is hierarchical clustering\n",
            "len of sentences 40\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is training deep\n",
            "len of sentences 3\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is submodular functions\n",
            "len of sentences 9\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is inverse reinforcement\n",
            "len of sentences 9\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is empirical risk\n",
            "len of sentences 102\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is : probabilistic\n",
            "len of sentences 7\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is using neural\n",
            "len of sentences 5\n",
            "len of t1 56\n",
            "len of each target word extractions is 56\n",
            "The target word is networks application\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is complexity learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is boltzmann machine\n",
            "len of sentences 7\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is networks using\n",
            "len of sentences 7\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is vlsi implementation\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is : theory\n",
            "len of sentences 7\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is markov model\n",
            "len of sentences 17\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is selective attention\n",
            "len of sentences 13\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is face recognition\n",
            "len of sentences 33\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is anomaly detection\n",
            "len of sentences 38\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is finite state\n",
            "len of sentences 28\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is population codes\n",
            "len of sentences 8\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is unlabeled data\n",
            "len of sentences 257\n",
            "len of t1 58\n",
            "len of each target word extractions is 58\n",
            "The target word is data clustering\n",
            "len of sentences 21\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is manifold learning\n",
            "len of sentences 89\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is real time\n",
            "len of sentences 28\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neighbor classification\n",
            "len of sentences 6\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is policy iteration\n",
            "len of sentences 27\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is training sets\n",
            "len of sentences 48\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is source separation\n",
            "len of sentences 29\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is learning probabilistic\n",
            "len of sentences 2\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is discriminant analysis\n",
            "len of sentences 31\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is the infinite\n",
            "len of sentences 66\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is importance sampling\n",
            "len of sentences 63\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is lower bounds\n",
            "len of sentences 84\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is probabilistic model\n",
            "len of sentences 175\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is kernel machines\n",
            "len of sentences 31\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is causal inference\n",
            "len of sentences 25\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is data :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is side information\n",
            "len of sentences 30\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is distance metric\n",
            "len of sentences 51\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is loss functions\n",
            "len of sentences 98\n",
            "len of t1 10\n",
            "len of each target word extractions is 10\n",
            "The target word is expectation propagation\n",
            "len of sentences 24\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is fast rates\n",
            "len of sentences 1\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is spectral methods\n",
            "len of sentences 14\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is -- end\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random projections\n",
            "len of sentences 93\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is graphical models\n",
            "len of sentences 314\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is subspace clustering\n",
            "len of sentences 3\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is generalized linear\n",
            "len of sentences 31\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is : deep\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is sparse inverse\n",
            "len of sentences 3\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is inverse covariance\n",
            "len of sentences 17\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is robust pca\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is adversarial networks\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic learning\n",
            "len of sentences 2\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is its application\n",
            "len of sentences 38\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is basis functions\n",
            "len of sentences 168\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is signal processing\n",
            "len of sentences 33\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is nets :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is function networks\n",
            "len of sentences 1\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is learning rate\n",
            "len of sentences 124\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is receptive field\n",
            "len of sentences 194\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is data analysis\n",
            "len of sentences 65\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is eye movements\n",
            "len of sentences 52\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is difference learning\n",
            "len of sentences 42\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is vector quantization\n",
            "len of sentences 27\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is receptive fields\n",
            "len of sentences 101\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is algorithm learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is training neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning rules\n",
            "len of sentences 28\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is the power\n",
            "len of sentences 141\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is generalization error\n",
            "len of sentences 127\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is dimension reduction\n",
            "len of sentences 55\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is value iteration\n",
            "len of sentences 67\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is -line learning\n",
            "len of sentences 36\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is blind separation\n",
            "len of sentences 6\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is pose estimation\n",
            "len of sentences 25\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is mixture model\n",
            "len of sentences 279\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is statistical models\n",
            "len of sentences 46\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is factor analysis\n",
            "len of sentences 13\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is inference learning\n",
            "len of sentences 1\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is likelihood estimation\n",
            "len of sentences 52\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is components analysis\n",
            "len of sentences 22\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is generative model\n",
            "len of sentences 309\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is learning linear\n",
            "len of sentences 6\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is analysis :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is approach learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian models\n",
            "len of sentences 1\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is : unified\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is markov chains\n",
            "len of sentences 1\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is semidefinite programming\n",
            "len of sentences 50\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is learning optimal\n",
            "len of sentences 4\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is spectral learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is imitation learning\n",
            "len of sentences 11\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is regret bounds\n",
            "len of sentences 28\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is neural networks\n",
            "len of sentences 384\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is reinforcement learning\n",
            "len of sentences 371\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neural network\n",
            "len of sentences 323\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is gaussian process\n",
            "len of sentences 22\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is graphical models\n",
            "len of sentences 488\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is support vector\n",
            "len of sentences 303\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is gaussian processes\n",
            "len of sentences 8\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is active learning\n",
            "len of sentences 378\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is variational inference\n",
            "len of sentences 116\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is monte carlo\n",
            "len of sentences 19\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is online learning\n",
            "len of sentences 249\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is speech recognition\n",
            "len of sentences 72\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is recurrent neural\n",
            "len of sentences 28\n",
            "len of t1 10\n",
            "len of each target word extractions is 10\n",
            "The target word is component analysis\n",
            "len of sentences 182\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is gradient descent\n",
            "len of sentences 338\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is hidden markov\n",
            "len of sentences 26\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is : the\n",
            "len of sentences 632\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is deep learning\n",
            "len of sentences 31\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is learning :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is markov models\n",
            "len of sentences 26\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is vector machines\n",
            "len of sentences 185\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is analog vlsi\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic gradient\n",
            "len of sentences 139\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is markov decision\n",
            "len of sentences 8\n",
            "len of t1 58\n",
            "len of each target word extractions is 58\n",
            "The target word is feature selection\n",
            "len of sentences 238\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is : learning\n",
            "len of sentences 18\n",
            "len of t1 62\n",
            "len of each target word extractions is 62\n",
            "The target word is networks learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random fields\n",
            "len of sentences 196\n",
            "len of t1 64\n",
            "len of each target word extractions is 64\n",
            "The target word is machine learning\n",
            "len of sentences 584\n",
            "len of t1 57\n",
            "len of each target word extractions is 57\n",
            "The target word is networks :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is belief propagation\n",
            "len of sentences 199\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is kernel learning\n",
            "len of sentences 233\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is unsupervised learning\n",
            "len of sentences 108\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is neural networks\n",
            "len of sentences 384\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is model selection\n",
            "len of sentences 239\n",
            "len of t1 8\n",
            "len of each target word extractions is 8\n",
            "The target word is matrix completion\n",
            "len of sentences 131\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is dynamic programming\n",
            "len of sentences 120\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is function approximation\n",
            "len of sentences 150\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is decision processes\n",
            "len of sentences 71\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is object recognition\n",
            "len of sentences 250\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is time series\n",
            "len of sentences 263\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is mixture models\n",
            "len of sentences 102\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is latent variable\n",
            "len of sentences 462\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is metric learning\n",
            "len of sentences 223\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is deep neural\n",
            "len of sentences 7\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is spiking neurons\n",
            "len of sentences 132\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is bayesian inference\n",
            "len of sentences 10\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is density estimation\n",
            "len of sentences 120\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is approximate inference\n",
            "len of sentences 141\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is convex optimization\n",
            "len of sentences 269\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is supervised learning\n",
            "len of sentences 554\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is dynamical systems\n",
            "len of sentences 55\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is convolutional neural\n",
            "len of sentences 20\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is generative models\n",
            "len of sentences 107\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is large scale\n",
            "len of sentences 108\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is matrix factorization\n",
            "len of sentences 146\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is : application\n",
            "len of sentences 7\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is stochastic optimization\n",
            "len of sentences 32\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is natural images\n",
            "len of sentences 283\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is spectral clustering\n",
            "len of sentences 142\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning the\n",
            "len of sentences 229\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 290\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is principal component\n",
            "len of sentences 198\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is learning sparse\n",
            "len of sentences 17\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is object detection\n",
            "len of sentences 128\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is map inference\n",
            "len of sentences 1\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is visual cortex\n",
            "len of sentences 151\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is recurrent networks\n",
            "len of sentences 17\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is radial basis\n",
            "len of sentences 31\n",
            "len of t1 69\n",
            "len of each target word extractions is 69\n",
            "The target word is risk minimization\n",
            "len of sentences 108\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is nearest neighbor\n",
            "len of sentences 337\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is independent component\n",
            "len of sentences 87\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is high dimensional\n",
            "len of sentences 212\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is large margin\n",
            "len of sentences 107\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is structured prediction\n",
            "len of sentences 114\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is learning algorithms\n",
            "len of sentences 324\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neural net\n",
            "len of sentences 356\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is learning multiple\n",
            "len of sentences 16\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is bayesian model\n",
            "len of sentences 17\n",
            "len of t1 62\n",
            "len of each target word extractions is 62\n",
            "The target word is models learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian networks\n",
            "len of sentences 11\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is policy gradient\n",
            "len of sentences 156\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is variational bayesian\n",
            "len of sentences 4\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is process regression\n",
            "len of sentences 51\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is sparse coding\n",
            "len of sentences 270\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is domain adaptation\n",
            "len of sentences 64\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is learning deep\n",
            "len of sentences 1\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is recognition using\n",
            "len of sentences 35\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is artificial neural\n",
            "len of sentences 15\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is mean field\n",
            "len of sentences 80\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is maximum likelihood\n",
            "len of sentences 233\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is missing data\n",
            "len of sentences 106\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is sample complexity\n",
            "len of sentences 180\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is exponential family\n",
            "len of sentences 139\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is deep networks\n",
            "len of sentences 41\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is coordinate descent\n",
            "len of sentences 85\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is associative memory\n",
            "len of sentences 4\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is basis function\n",
            "len of sentences 283\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is feature extraction\n",
            "len of sentences 92\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is boltzmann machines\n",
            "len of sentences 19\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is learning algorithm\n",
            "len of sentences 743\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vector machine\n",
            "len of sentences 267\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is gradient methods\n",
            "len of sentences 106\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is latent dirichlet\n",
            "len of sentences 8\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is learning gaussian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is topic models\n",
            "len of sentences 153\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 348\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is conditional random\n",
            "len of sentences 107\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is feature learning\n",
            "len of sentences 62\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is generative adversarial\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is network model\n",
            "len of sentences 66\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is neural nets\n",
            "len of sentences 13\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is mutual information\n",
            "len of sentences 300\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is markov random\n",
            "len of sentences 20\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is second order\n",
            "len of sentences 109\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is clustering :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning approach\n",
            "len of sentences 113\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is : efficient\n",
            "len of sentences 2\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is bayesian learning\n",
            "len of sentences 4\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is decision trees\n",
            "len of sentences 53\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning structured\n",
            "len of sentences 7\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is variable models\n",
            "len of sentences 53\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is gaussian graphical\n",
            "len of sentences 2\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is dirichlet allocation\n",
            "len of sentences 18\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is probabilistic inference\n",
            "len of sentences 90\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 348\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is graphical model\n",
            "len of sentences 547\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is sparse pca\n",
            "len of sentences 1\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is message passing\n",
            "len of sentences 106\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is convolutional networks\n",
            "len of sentences 19\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is bayesian optimization\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is temporal difference\n",
            "len of sentences 83\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is gaussian mixtures\n",
            "len of sentences 1\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is : new\n",
            "len of sentences 6\n",
            "len of t1 5\n",
            "len of each target word extractions is 5\n",
            "The target word is least squares\n",
            "len of sentences 180\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is partially observable\n",
            "len of sentences 77\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is linear models\n",
            "len of sentences 158\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is belief networks\n",
            "len of sentences 65\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is markov networks\n",
            "len of sentences 16\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is policy search\n",
            "len of sentences 33\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is maximum margin\n",
            "len of sentences 41\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is restricted boltzmann\n",
            "len of sentences 13\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is collaborative filtering\n",
            "len of sentences 69\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is decision making\n",
            "len of sentences 67\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is end --\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is nonparametric bayesian\n",
            "len of sentences 1\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is transfer learning\n",
            "len of sentences 29\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is tensor decomposition\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is neural model\n",
            "len of sentences 18\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is image segmentation\n",
            "len of sentences 107\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is network :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information theoretic\n",
            "len of sentences 35\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is : from\n",
            "len of sentences 25\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is parameter estimation\n",
            "len of sentences 99\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is efficient learning\n",
            "len of sentences 27\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is visual attention\n",
            "len of sentences 30\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is visual recognition\n",
            "len of sentences 36\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is value function\n",
            "len of sentences 410\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is learning stochastic\n",
            "len of sentences 2\n",
            "len of t1 63\n",
            "len of each target word extractions is 63\n",
            "The target word is linear programming\n",
            "len of sentences 107\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is information bottleneck\n",
            "len of sentences 11\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is variance reduction\n",
            "len of sentences 14\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is : towards\n",
            "len of sentences 4\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is sparse gaussian\n",
            "len of sentences 3\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is multiple kernel\n",
            "len of sentences 148\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is dirichlet process\n",
            "len of sentences 14\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is networks neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning control\n",
            "len of sentences 9\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is distributed representations\n",
            "len of sentences 23\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is networks the\n",
            "len of sentences 2\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is pattern recognition\n",
            "len of sentences 33\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is analog neural\n",
            "len of sentences 1\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is vlsi neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is ocular dominance\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning dynamic\n",
            "len of sentences 3\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is natural language\n",
            "len of sentences 88\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is continuous speech\n",
            "len of sentences 8\n",
            "len of t1 64\n",
            "len of each target word extractions is 64\n",
            "The target word is learning model\n",
            "len of sentences 83\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning curves\n",
            "len of sentences 69\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning using\n",
            "len of sentences 64\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is spiking neurons\n",
            "len of sentences 132\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is mixtures experts\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is graph matching\n",
            "len of sentences 40\n",
            "len of t1 57\n",
            "len of each target word extractions is 57\n",
            "The target word is learning continuous\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning adaptive\n",
            "len of sentences 1\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is information maximization\n",
            "len of sentences 7\n",
            "len of t1 48\n",
            "len of each target word extractions is 48\n",
            "The target word is : bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning efficient\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is multi-task learning\n",
            "len of sentences 112\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is models :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is natural scenes\n",
            "len of sentences 73\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is learning nonlinear\n",
            "len of sentences 6\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is : fast\n",
            "len of sentences 1\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is process models\n",
            "len of sentences 37\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is sequential data\n",
            "len of sentences 9\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is data learning\n",
            "len of sentences 2\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is probabilistic models\n",
            "len of sentences 90\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is high dimensions\n",
            "len of sentences 45\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is markov chain\n",
            "len of sentences 9\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is inference bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is structure learning\n",
            "len of sentences 103\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is kernel methods\n",
            "len of sentences 68\n",
            "len of t1 55\n",
            "len of each target word extractions is 55\n",
            "The target word is logistic regression\n",
            "len of sentences 313\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is model learning\n",
            "len of sentences 27\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is hierarchical clustering\n",
            "len of sentences 38\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is training deep\n",
            "len of sentences 6\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is submodular functions\n",
            "len of sentences 75\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is inverse reinforcement\n",
            "len of sentences 9\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is empirical risk\n",
            "len of sentences 156\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is : probabilistic\n",
            "len of sentences 3\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is using neural\n",
            "len of sentences 4\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is networks application\n",
            "len of sentences 1\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is complexity learning\n",
            "len of sentences 1\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is boltzmann machine\n",
            "len of sentences 20\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is networks using\n",
            "len of sentences 15\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is vlsi implementation\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is : theory\n",
            "len of sentences 18\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is markov model\n",
            "len of sentences 31\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is selective attention\n",
            "len of sentences 11\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is face recognition\n",
            "len of sentences 52\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is anomaly detection\n",
            "len of sentences 35\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is finite state\n",
            "len of sentences 20\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is population codes\n",
            "len of sentences 41\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is unlabeled data\n",
            "len of sentences 396\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is data clustering\n",
            "len of sentences 14\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is manifold learning\n",
            "len of sentences 71\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is real time\n",
            "len of sentences 27\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neighbor classification\n",
            "len of sentences 32\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is policy iteration\n",
            "len of sentences 86\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is training sets\n",
            "len of sentences 86\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is source separation\n",
            "len of sentences 27\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is learning probabilistic\n",
            "len of sentences 3\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is discriminant analysis\n",
            "len of sentences 57\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is the infinite\n",
            "len of sentences 111\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is importance sampling\n",
            "len of sentences 104\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is lower bounds\n",
            "len of sentences 128\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is probabilistic model\n",
            "len of sentences 264\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is kernel machines\n",
            "len of sentences 44\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is causal inference\n",
            "len of sentences 21\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is data :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is side information\n",
            "len of sentences 36\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is distance metric\n",
            "len of sentences 125\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is loss functions\n",
            "len of sentences 271\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is expectation propagation\n",
            "len of sentences 17\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is fast rates\n",
            "len of sentences 13\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is spectral methods\n",
            "len of sentences 4\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is -- end\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random projections\n",
            "len of sentences 55\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is graphical models\n",
            "len of sentences 488\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is subspace clustering\n",
            "len of sentences 5\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is generalized linear\n",
            "len of sentences 64\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is : deep\n",
            "len of sentences 1\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is sparse inverse\n",
            "len of sentences 16\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is inverse covariance\n",
            "len of sentences 77\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is robust pca\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is adversarial networks\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic learning\n",
            "len of sentences 12\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is its application\n",
            "len of sentences 65\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is basis functions\n",
            "len of sentences 225\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is signal processing\n",
            "len of sentences 56\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is nets :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is function networks\n",
            "len of sentences 3\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is learning rate\n",
            "len of sentences 212\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is receptive field\n",
            "len of sentences 185\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is data analysis\n",
            "len of sentences 76\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is eye movements\n",
            "len of sentences 7\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is difference learning\n",
            "len of sentences 57\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is vector quantization\n",
            "len of sentences 15\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is receptive fields\n",
            "len of sentences 99\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is algorithm learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is training neural\n",
            "len of sentences 1\n",
            "len of t1 7\n",
            "len of each target word extractions is 7\n",
            "The target word is learning rules\n",
            "len of sentences 40\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is the power\n",
            "len of sentences 135\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is generalization error\n",
            "len of sentences 121\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is dimension reduction\n",
            "len of sentences 99\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is value iteration\n",
            "len of sentences 51\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is -line learning\n",
            "len of sentences 36\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is blind separation\n",
            "len of sentences 6\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is pose estimation\n",
            "len of sentences 45\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is mixture model\n",
            "len of sentences 274\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is statistical models\n",
            "len of sentences 49\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is factor analysis\n",
            "len of sentences 68\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is inference learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is likelihood estimation\n",
            "len of sentences 60\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is components analysis\n",
            "len of sentences 32\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is generative model\n",
            "len of sentences 417\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is learning linear\n",
            "len of sentences 14\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is analysis :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is approach learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian models\n",
            "len of sentences 3\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is : unified\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is markov chains\n",
            "len of sentences 3\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is semidefinite programming\n",
            "len of sentences 51\n",
            "len of t1 57\n",
            "len of each target word extractions is 57\n",
            "The target word is learning optimal\n",
            "len of sentences 3\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is spectral learning\n",
            "len of sentences 2\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is imitation learning\n",
            "len of sentences 18\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is regret bounds\n",
            "len of sentences 69\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neural networks\n",
            "len of sentences 838\n",
            "len of t1 60\n",
            "len of each target word extractions is 60\n",
            "The target word is reinforcement learning\n",
            "len of sentences 535\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is neural network\n",
            "len of sentences 710\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is gaussian process\n",
            "len of sentences 67\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is graphical models\n",
            "len of sentences 1058\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is support vector\n",
            "len of sentences 253\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is gaussian processes\n",
            "len of sentences 29\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is active learning\n",
            "len of sentences 487\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is variational inference\n",
            "len of sentences 292\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is monte carlo\n",
            "len of sentences 35\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is online learning\n",
            "len of sentences 331\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is speech recognition\n",
            "len of sentences 63\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is recurrent neural\n",
            "len of sentences 45\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is component analysis\n",
            "len of sentences 288\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is gradient descent\n",
            "len of sentences 553\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is hidden markov\n",
            "len of sentences 30\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is : the\n",
            "len of sentences 856\n",
            "len of t1 56\n",
            "len of each target word extractions is 56\n",
            "The target word is deep learning\n",
            "len of sentences 95\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is learning :\n",
            "len of sentences 1\n",
            "len of t1 58\n",
            "len of each target word extractions is 58\n",
            "The target word is markov models\n",
            "len of sentences 30\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is vector machines\n",
            "len of sentences 166\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is analog vlsi\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic gradient\n",
            "len of sentences 381\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is markov decision\n",
            "len of sentences 24\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is feature selection\n",
            "len of sentences 279\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is : learning\n",
            "len of sentences 25\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is networks learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random fields\n",
            "len of sentences 176\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is machine learning\n",
            "len of sentences 807\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is networks :\n",
            "len of sentences 2\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is belief propagation\n",
            "len of sentences 240\n",
            "len of t1 56\n",
            "len of each target word extractions is 56\n",
            "The target word is kernel learning\n",
            "len of sentences 186\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is unsupervised learning\n",
            "len of sentences 178\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neural networks\n",
            "len of sentences 838\n",
            "len of t1 60\n",
            "len of each target word extractions is 60\n",
            "The target word is model selection\n",
            "len of sentences 329\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is matrix completion\n",
            "len of sentences 361\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is dynamic programming\n",
            "len of sentences 213\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is function approximation\n",
            "len of sentences 142\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is decision processes\n",
            "len of sentences 125\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is object recognition\n",
            "len of sentences 241\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is time series\n",
            "len of sentences 379\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is mixture models\n",
            "len of sentences 233\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is latent variable\n",
            "len of sentences 764\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is metric learning\n",
            "len of sentences 285\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is deep neural\n",
            "len of sentences 57\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is spiking neurons\n",
            "len of sentences 100\n",
            "len of t1 48\n",
            "len of each target word extractions is 48\n",
            "The target word is bayesian inference\n",
            "len of sentences 13\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is density estimation\n",
            "len of sentences 166\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is approximate inference\n",
            "len of sentences 194\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is convex optimization\n",
            "len of sentences 489\n",
            "len of t1 51\n",
            "len of each target word extractions is 51\n",
            "The target word is supervised learning\n",
            "len of sentences 565\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is dynamical systems\n",
            "len of sentences 104\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is convolutional neural\n",
            "len of sentences 77\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is generative models\n",
            "len of sentences 77\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is large scale\n",
            "len of sentences 174\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is matrix factorization\n",
            "len of sentences 356\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is : application\n",
            "len of sentences 5\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is stochastic optimization\n",
            "len of sentences 162\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is natural images\n",
            "len of sentences 197\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is spectral clustering\n",
            "len of sentences 197\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is learning the\n",
            "len of sentences 324\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 221\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is principal component\n",
            "len of sentences 397\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning sparse\n",
            "len of sentences 18\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is object detection\n",
            "len of sentences 206\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is map inference\n",
            "len of sentences 3\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is visual cortex\n",
            "len of sentences 129\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is recurrent networks\n",
            "len of sentences 12\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is radial basis\n",
            "len of sentences 24\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is risk minimization\n",
            "len of sentences 150\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is nearest neighbor\n",
            "len of sentences 462\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is independent component\n",
            "len of sentences 65\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is high dimensional\n",
            "len of sentences 310\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is large margin\n",
            "len of sentences 131\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is structured prediction\n",
            "len of sentences 118\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is learning algorithms\n",
            "len of sentences 433\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is neural net\n",
            "len of sentences 751\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is learning multiple\n",
            "len of sentences 13\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is bayesian model\n",
            "len of sentences 14\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is models learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian networks\n",
            "len of sentences 11\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is policy gradient\n",
            "len of sentences 128\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is variational bayesian\n",
            "len of sentences 2\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is process regression\n",
            "len of sentences 49\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is sparse coding\n",
            "len of sentences 301\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is domain adaptation\n",
            "len of sentences 151\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is learning deep\n",
            "len of sentences 5\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is recognition using\n",
            "len of sentences 22\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is artificial neural\n",
            "len of sentences 28\n",
            "len of t1 66\n",
            "len of each target word extractions is 66\n",
            "The target word is mean field\n",
            "len of sentences 106\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is maximum likelihood\n",
            "len of sentences 309\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is missing data\n",
            "len of sentences 142\n",
            "len of t1 51\n",
            "len of each target word extractions is 51\n",
            "The target word is sample complexity\n",
            "len of sentences 282\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is exponential family\n",
            "len of sentences 251\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is deep networks\n",
            "len of sentences 65\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is coordinate descent\n",
            "len of sentences 261\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is associative memory\n",
            "len of sentences 27\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is basis function\n",
            "len of sentences 234\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is feature extraction\n",
            "len of sentences 100\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is boltzmann machines\n",
            "len of sentences 25\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is learning algorithm\n",
            "len of sentences 987\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is learning learning\n",
            "len of sentences 1\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is learning bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vector machine\n",
            "len of sentences 247\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is gradient methods\n",
            "len of sentences 198\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is latent dirichlet\n",
            "len of sentences 15\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning gaussian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is topic models\n",
            "len of sentences 248\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 260\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is conditional random\n",
            "len of sentences 83\n",
            "len of t1 90\n",
            "len of each target word extractions is 90\n",
            "The target word is feature learning\n",
            "len of sentences 258\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is generative adversarial\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is network model\n",
            "len of sentences 103\n",
            "len of t1 55\n",
            "len of each target word extractions is 55\n",
            "The target word is neural nets\n",
            "len of sentences 28\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is mutual information\n",
            "len of sentences 275\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is markov random\n",
            "len of sentences 12\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is second order\n",
            "len of sentences 89\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is clustering :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning approach\n",
            "len of sentences 142\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is : efficient\n",
            "len of sentences 10\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is bayesian learning\n",
            "len of sentences 10\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is decision trees\n",
            "len of sentences 68\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is learning structured\n",
            "len of sentences 2\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is variable models\n",
            "len of sentences 136\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is gaussian graphical\n",
            "len of sentences 21\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is dirichlet allocation\n",
            "len of sentences 28\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is probabilistic inference\n",
            "len of sentences 100\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 260\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is graphical model\n",
            "len of sentences 1009\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is sparse pca\n",
            "len of sentences 7\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is message passing\n",
            "len of sentences 187\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is convolutional networks\n",
            "len of sentences 32\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is bayesian optimization\n",
            "len of sentences 9\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is learning neural\n",
            "len of sentences 1\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is temporal difference\n",
            "len of sentences 60\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is gaussian mixtures\n",
            "len of sentences 7\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is : new\n",
            "len of sentences 3\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is least squares\n",
            "len of sentences 233\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is partially observable\n",
            "len of sentences 49\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is linear models\n",
            "len of sentences 203\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is belief networks\n",
            "len of sentences 75\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is markov networks\n",
            "len of sentences 16\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is policy search\n",
            "len of sentences 66\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is maximum margin\n",
            "len of sentences 54\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is restricted boltzmann\n",
            "len of sentences 17\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is collaborative filtering\n",
            "len of sentences 137\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is decision making\n",
            "len of sentences 103\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is end --\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is nonparametric bayesian\n",
            "len of sentences 4\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is transfer learning\n",
            "len of sentences 91\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is tensor decomposition\n",
            "len of sentences 73\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is neural model\n",
            "len of sentences 27\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is image segmentation\n",
            "len of sentences 130\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is network :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information theoretic\n",
            "len of sentences 34\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is : from\n",
            "len of sentences 22\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is parameter estimation\n",
            "len of sentences 166\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is efficient learning\n",
            "len of sentences 42\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is visual attention\n",
            "len of sentences 19\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is visual recognition\n",
            "len of sentences 63\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is value function\n",
            "len of sentences 618\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is learning stochastic\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is linear programming\n",
            "len of sentences 151\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is information bottleneck\n",
            "len of sentences 14\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is variance reduction\n",
            "len of sentences 69\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is : towards\n",
            "len of sentences 6\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is sparse gaussian\n",
            "len of sentences 7\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is multiple kernel\n",
            "len of sentences 122\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is dirichlet process\n",
            "len of sentences 30\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is networks neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning control\n",
            "len of sentences 6\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is distributed representations\n",
            "len of sentences 9\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is networks the\n",
            "len of sentences 2\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is pattern recognition\n",
            "len of sentences 59\n",
            "len of t1 55\n",
            "len of each target word extractions is 55\n",
            "The target word is analog neural\n",
            "len of sentences 3\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is vlsi neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is ocular dominance\n",
            "len of sentences 1\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning dynamic\n",
            "len of sentences 14\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is natural language\n",
            "len of sentences 122\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is continuous speech\n",
            "len of sentences 3\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning model\n",
            "len of sentences 122\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning curves\n",
            "len of sentences 32\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is learning using\n",
            "len of sentences 84\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is spiking neurons\n",
            "len of sentences 100\n",
            "len of t1 48\n",
            "len of each target word extractions is 48\n",
            "The target word is mixtures experts\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is graph matching\n",
            "len of sentences 48\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning continuous\n",
            "len of sentences 1\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is learning adaptive\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information maximization\n",
            "len of sentences 3\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is : bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning efficient\n",
            "len of sentences 2\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is multi-task learning\n",
            "len of sentences 158\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is models :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is natural scenes\n",
            "len of sentences 43\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is learning nonlinear\n",
            "len of sentences 3\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is : fast\n",
            "len of sentences 2\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is process models\n",
            "len of sentences 22\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is sequential data\n",
            "len of sentences 20\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is data learning\n",
            "len of sentences 1\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is probabilistic models\n",
            "len of sentences 103\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is high dimensions\n",
            "len of sentences 113\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is markov chain\n",
            "len of sentences 14\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is inference bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is structure learning\n",
            "len of sentences 118\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is kernel methods\n",
            "len of sentences 71\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is logistic regression\n",
            "len of sentences 394\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is model learning\n",
            "len of sentences 40\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is hierarchical clustering\n",
            "len of sentences 53\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is training deep\n",
            "len of sentences 20\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is submodular functions\n",
            "len of sentences 140\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is inverse reinforcement\n",
            "len of sentences 59\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is empirical risk\n",
            "len of sentences 183\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is : probabilistic\n",
            "len of sentences 8\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is using neural\n",
            "len of sentences 10\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is networks application\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is complexity learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is boltzmann machine\n",
            "len of sentences 29\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is networks using\n",
            "len of sentences 19\n",
            "len of t1 57\n",
            "len of each target word extractions is 57\n",
            "The target word is vlsi implementation\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is : theory\n",
            "len of sentences 22\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is markov model\n",
            "len of sentences 36\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is selective attention\n",
            "len of sentences 3\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is face recognition\n",
            "len of sentences 34\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is anomaly detection\n",
            "len of sentences 87\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is finite state\n",
            "len of sentences 69\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is population codes\n",
            "len of sentences 29\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is unlabeled data\n",
            "len of sentences 154\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is data clustering\n",
            "len of sentences 13\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is manifold learning\n",
            "len of sentences 20\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is real time\n",
            "len of sentences 21\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neighbor classification\n",
            "len of sentences 45\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is policy iteration\n",
            "len of sentences 124\n",
            "len of t1 55\n",
            "len of each target word extractions is 55\n",
            "The target word is training sets\n",
            "len of sentences 71\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is source separation\n",
            "len of sentences 14\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is learning probabilistic\n",
            "len of sentences 3\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is discriminant analysis\n",
            "len of sentences 23\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is the infinite\n",
            "len of sentences 92\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is importance sampling\n",
            "len of sentences 103\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is lower bounds\n",
            "len of sentences 311\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is probabilistic model\n",
            "len of sentences 269\n",
            "len of t1 59\n",
            "len of each target word extractions is 59\n",
            "The target word is kernel machines\n",
            "len of sentences 22\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is causal inference\n",
            "len of sentences 19\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is data :\n",
            "len of sentences 1\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is side information\n",
            "len of sentences 95\n",
            "len of t1 44\n",
            "len of each target word extractions is 44\n",
            "The target word is distance metric\n",
            "len of sentences 175\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is loss functions\n",
            "len of sentences 287\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is expectation propagation\n",
            "len of sentences 47\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is fast rates\n",
            "len of sentences 25\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is spectral methods\n",
            "len of sentences 34\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is -- end\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random projections\n",
            "len of sentences 133\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is graphical models\n",
            "len of sentences 1058\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is subspace clustering\n",
            "len of sentences 45\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is generalized linear\n",
            "len of sentences 84\n",
            "len of t1 49\n",
            "len of each target word extractions is 49\n",
            "The target word is : deep\n",
            "len of sentences 6\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is sparse inverse\n",
            "len of sentences 46\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is inverse covariance\n",
            "len of sentences 199\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is robust pca\n",
            "len of sentences 4\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is adversarial networks\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic learning\n",
            "len of sentences 15\n",
            "len of t1 51\n",
            "len of each target word extractions is 51\n",
            "The target word is its application\n",
            "len of sentences 84\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is basis functions\n",
            "len of sentences 185\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is signal processing\n",
            "len of sentences 84\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is nets :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is function networks\n",
            "len of sentences 1\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is learning rate\n",
            "len of sentences 359\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is receptive field\n",
            "len of sentences 340\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is data analysis\n",
            "len of sentences 152\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is eye movements\n",
            "len of sentences 29\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is difference learning\n",
            "len of sentences 35\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is vector quantization\n",
            "len of sentences 28\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is receptive fields\n",
            "len of sentences 195\n",
            "len of t1 50\n",
            "len of each target word extractions is 50\n",
            "The target word is algorithm learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is training neural\n",
            "len of sentences 7\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is learning rules\n",
            "len of sentences 48\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is the power\n",
            "len of sentences 139\n",
            "len of t1 56\n",
            "len of each target word extractions is 56\n",
            "The target word is generalization error\n",
            "len of sentences 97\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is dimension reduction\n",
            "len of sentences 78\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is value iteration\n",
            "len of sentences 105\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is -line learning\n",
            "len of sentences 42\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is blind separation\n",
            "len of sentences 4\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is pose estimation\n",
            "len of sentences 55\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is mixture model\n",
            "len of sentences 475\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is statistical models\n",
            "len of sentences 89\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is factor analysis\n",
            "len of sentences 83\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is inference learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is likelihood estimation\n",
            "len of sentences 99\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is components analysis\n",
            "len of sentences 45\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is generative model\n",
            "len of sentences 333\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is learning linear\n",
            "len of sentences 13\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is analysis :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is approach learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian models\n",
            "len of sentences 8\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is : unified\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is markov chains\n",
            "len of sentences 8\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is semidefinite programming\n",
            "len of sentences 51\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is learning optimal\n",
            "len of sentences 4\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is spectral learning\n",
            "len of sentences 22\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is imitation learning\n",
            "len of sentences 26\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is regret bounds\n",
            "len of sentences 166\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neural networks\n",
            "len of sentences 3748\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is reinforcement learning\n",
            "len of sentences 615\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neural network\n",
            "len of sentences 3042\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is gaussian process\n",
            "len of sentences 71\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is graphical models\n",
            "len of sentences 1092\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is support vector\n",
            "len of sentences 285\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is gaussian processes\n",
            "len of sentences 35\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is active learning\n",
            "len of sentences 500\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is variational inference\n",
            "len of sentences 675\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is monte carlo\n",
            "len of sentences 71\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is online learning\n",
            "len of sentences 418\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is speech recognition\n",
            "len of sentences 163\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is recurrent neural\n",
            "len of sentences 410\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is component analysis\n",
            "len of sentences 259\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is gradient descent\n",
            "len of sentences 1108\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is hidden markov\n",
            "len of sentences 45\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is : the\n",
            "len of sentences 1085\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is deep learning\n",
            "len of sentences 507\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is learning :\n",
            "len of sentences 1\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is markov models\n",
            "len of sentences 43\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is vector machines\n",
            "len of sentences 178\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is analog vlsi\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is stochastic gradient\n",
            "len of sentences 1040\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is markov decision\n",
            "len of sentences 15\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is feature selection\n",
            "len of sentences 261\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is : learning\n",
            "len of sentences 29\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is networks learning\n",
            "len of sentences 1\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is random fields\n",
            "len of sentences 183\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is machine learning\n",
            "len of sentences 1459\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is networks :\n",
            "len of sentences 1\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is belief propagation\n",
            "len of sentences 220\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is kernel learning\n",
            "len of sentences 110\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is unsupervised learning\n",
            "len of sentences 223\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is neural networks\n",
            "len of sentences 3748\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is model selection\n",
            "len of sentences 274\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is matrix completion\n",
            "len of sentences 658\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is dynamic programming\n",
            "len of sentences 175\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is function approximation\n",
            "len of sentences 144\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is decision processes\n",
            "len of sentences 83\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is object recognition\n",
            "len of sentences 215\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is time series\n",
            "len of sentences 444\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is mixture models\n",
            "len of sentences 215\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is latent variable\n",
            "len of sentences 945\n",
            "len of t1 60\n",
            "len of each target word extractions is 60\n",
            "The target word is metric learning\n",
            "len of sentences 268\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is deep neural\n",
            "len of sentences 404\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is spiking neurons\n",
            "len of sentences 82\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is bayesian inference\n",
            "len of sentences 25\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is density estimation\n",
            "len of sentences 208\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is approximate inference\n",
            "len of sentences 242\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is convex optimization\n",
            "len of sentences 824\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is supervised learning\n",
            "len of sentences 888\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is dynamical systems\n",
            "len of sentences 124\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is convolutional neural\n",
            "len of sentences 523\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is generative models\n",
            "len of sentences 387\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is large scale\n",
            "len of sentences 277\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is matrix factorization\n",
            "len of sentences 393\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is : application\n",
            "len of sentences 8\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is stochastic optimization\n",
            "len of sentences 383\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is natural images\n",
            "len of sentences 162\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is spectral clustering\n",
            "len of sentences 196\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning the\n",
            "len of sentences 499\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 204\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is principal component\n",
            "len of sentences 366\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning sparse\n",
            "len of sentences 17\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is object detection\n",
            "len of sentences 251\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is map inference\n",
            "len of sentences 3\n",
            "len of t1 10\n",
            "len of each target word extractions is 10\n",
            "The target word is visual cortex\n",
            "len of sentences 103\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is recurrent networks\n",
            "len of sentences 85\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is radial basis\n",
            "len of sentences 38\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is risk minimization\n",
            "len of sentences 190\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is nearest neighbor\n",
            "len of sentences 471\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is independent component\n",
            "len of sentences 65\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is high dimensional\n",
            "len of sentences 394\n",
            "len of t1 10\n",
            "len of each target word extractions is 10\n",
            "The target word is large margin\n",
            "len of sentences 141\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is structured prediction\n",
            "len of sentences 259\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is learning algorithms\n",
            "len of sentences 514\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is neural net\n",
            "len of sentences 3234\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is learning multiple\n",
            "len of sentences 5\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is bayesian model\n",
            "len of sentences 6\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is models learning\n",
            "len of sentences 2\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is bayesian networks\n",
            "len of sentences 16\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is policy gradient\n",
            "len of sentences 91\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is variational bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is process regression\n",
            "len of sentences 92\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is sparse coding\n",
            "len of sentences 204\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is domain adaptation\n",
            "len of sentences 184\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is learning deep\n",
            "len of sentences 16\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is recognition using\n",
            "len of sentences 33\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is artificial neural\n",
            "len of sentences 26\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is mean field\n",
            "len of sentences 73\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is maximum likelihood\n",
            "len of sentences 389\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is missing data\n",
            "len of sentences 170\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is sample complexity\n",
            "len of sentences 767\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is exponential family\n",
            "len of sentences 267\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is deep networks\n",
            "len of sentences 246\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is coordinate descent\n",
            "len of sentences 394\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is associative memory\n",
            "len of sentences 66\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is basis function\n",
            "len of sentences 165\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is feature extraction\n",
            "len of sentences 103\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is boltzmann machines\n",
            "len of sentences 55\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is learning algorithm\n",
            "len of sentences 1167\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is learning learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vector machine\n",
            "len of sentences 254\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is gradient methods\n",
            "len of sentences 264\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is latent dirichlet\n",
            "len of sentences 20\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning gaussian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is topic models\n",
            "len of sentences 240\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 380\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is conditional random\n",
            "len of sentences 61\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is feature learning\n",
            "len of sentences 154\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is generative adversarial\n",
            "len of sentences 63\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is network model\n",
            "len of sentences 160\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neural nets\n",
            "len of sentences 83\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is mutual information\n",
            "len of sentences 307\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is markov random\n",
            "len of sentences 24\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is second order\n",
            "len of sentences 189\n",
            "len of t1 6\n",
            "len of each target word extractions is 6\n",
            "The target word is clustering :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning approach\n",
            "len of sentences 177\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is : efficient\n",
            "len of sentences 6\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is bayesian learning\n",
            "len of sentences 6\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is decision trees\n",
            "len of sentences 113\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is learning structured\n",
            "len of sentences 3\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is variable models\n",
            "len of sentences 204\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is gaussian graphical\n",
            "len of sentences 15\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is dirichlet allocation\n",
            "len of sentences 40\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is probabilistic inference\n",
            "len of sentences 123\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is semi-supervised learning\n",
            "len of sentences 380\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is graphical model\n",
            "len of sentences 910\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is sparse pca\n",
            "len of sentences 28\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is message passing\n",
            "len of sentences 248\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is convolutional networks\n",
            "len of sentences 345\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is bayesian optimization\n",
            "len of sentences 19\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning neural\n",
            "len of sentences 8\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is temporal difference\n",
            "len of sentences 35\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is gaussian mixtures\n",
            "len of sentences 14\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is : new\n",
            "len of sentences 33\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is least squares\n",
            "len of sentences 323\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is partially observable\n",
            "len of sentences 31\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is linear models\n",
            "len of sentences 273\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is belief networks\n",
            "len of sentences 132\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is markov networks\n",
            "len of sentences 9\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is policy search\n",
            "len of sentences 153\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is maximum margin\n",
            "len of sentences 42\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is restricted boltzmann\n",
            "len of sentences 36\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is collaborative filtering\n",
            "len of sentences 174\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is decision making\n",
            "len of sentences 216\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is end --\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is nonparametric bayesian\n",
            "len of sentences 4\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is transfer learning\n",
            "len of sentences 99\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is tensor decomposition\n",
            "len of sentences 201\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is neural model\n",
            "len of sentences 28\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is image segmentation\n",
            "len of sentences 148\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is network :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is information theoretic\n",
            "len of sentences 104\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is : from\n",
            "len of sentences 30\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is parameter estimation\n",
            "len of sentences 153\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is efficient learning\n",
            "len of sentences 43\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is visual attention\n",
            "len of sentences 84\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is visual recognition\n",
            "len of sentences 97\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is value function\n",
            "len of sentences 367\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is learning stochastic\n",
            "len of sentences 3\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is linear programming\n",
            "len of sentences 206\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is information bottleneck\n",
            "len of sentences 16\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is variance reduction\n",
            "len of sentences 142\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is : towards\n",
            "len of sentences 8\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is sparse gaussian\n",
            "len of sentences 9\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is multiple kernel\n",
            "len of sentences 38\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is dirichlet process\n",
            "len of sentences 21\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is networks neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning control\n",
            "len of sentences 11\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is distributed representations\n",
            "len of sentences 22\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is networks the\n",
            "len of sentences 5\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is pattern recognition\n",
            "len of sentences 58\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is analog neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is vlsi neural\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is ocular dominance\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning dynamic\n",
            "len of sentences 16\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is natural language\n",
            "len of sentences 264\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is continuous speech\n",
            "len of sentences 11\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is learning model\n",
            "len of sentences 169\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is learning curves\n",
            "len of sentences 26\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is learning using\n",
            "len of sentences 83\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is spiking neurons\n",
            "len of sentences 82\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is mixtures experts\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is graph matching\n",
            "len of sentences 12\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is learning continuous\n",
            "len of sentences 2\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is learning adaptive\n",
            "len of sentences 1\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is information maximization\n",
            "len of sentences 20\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is : bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is learning efficient\n",
            "len of sentences 3\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is multi-task learning\n",
            "len of sentences 88\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is models :\n",
            "len of sentences 1\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is natural scenes\n",
            "len of sentences 51\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is learning nonlinear\n",
            "len of sentences 1\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is : fast\n",
            "len of sentences 5\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is process models\n",
            "len of sentences 35\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is sequential data\n",
            "len of sentences 42\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is data learning\n",
            "len of sentences 1\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is probabilistic models\n",
            "len of sentences 129\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is high dimensions\n",
            "len of sentences 146\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is markov chain\n",
            "len of sentences 34\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is inference bayesian\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is structure learning\n",
            "len of sentences 119\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is kernel methods\n",
            "len of sentences 132\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is logistic regression\n",
            "len of sentences 529\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is model learning\n",
            "len of sentences 27\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is hierarchical clustering\n",
            "len of sentences 103\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is training deep\n",
            "len of sentences 74\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is submodular functions\n",
            "len of sentences 301\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is inverse reinforcement\n",
            "len of sentences 45\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is empirical risk\n",
            "len of sentences 287\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is : probabilistic\n",
            "len of sentences 4\n",
            "len of t1 51\n",
            "len of each target word extractions is 51\n",
            "The target word is using neural\n",
            "len of sentences 16\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is networks application\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is complexity learning\n",
            "len of sentences 1\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is boltzmann machine\n",
            "len of sentences 64\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is networks using\n",
            "len of sentences 70\n",
            "len of t1 65\n",
            "len of each target word extractions is 65\n",
            "The target word is vlsi implementation\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is : theory\n",
            "len of sentences 19\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is markov model\n",
            "len of sentences 52\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is selective attention\n",
            "len of sentences 8\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is face recognition\n",
            "len of sentences 90\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is anomaly detection\n",
            "len of sentences 60\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is finite state\n",
            "len of sentences 22\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is population codes\n",
            "len of sentences 28\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is unlabeled data\n",
            "len of sentences 300\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is data clustering\n",
            "len of sentences 6\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is manifold learning\n",
            "len of sentences 49\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is real time\n",
            "len of sentences 22\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is neighbor classification\n",
            "len of sentences 42\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is policy iteration\n",
            "len of sentences 21\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is training sets\n",
            "len of sentences 144\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is source separation\n",
            "len of sentences 44\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is learning probabilistic\n",
            "len of sentences 3\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is discriminant analysis\n",
            "len of sentences 38\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is the infinite\n",
            "len of sentences 119\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is importance sampling\n",
            "len of sentences 215\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is lower bounds\n",
            "len of sentences 607\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is probabilistic model\n",
            "len of sentences 350\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is kernel machines\n",
            "len of sentences 79\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is causal inference\n",
            "len of sentences 54\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is data :\n",
            "len of sentences 1\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is side information\n",
            "len of sentences 102\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is distance metric\n",
            "len of sentences 87\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is loss functions\n",
            "len of sentences 477\n",
            "len of t1 9\n",
            "len of each target word extractions is 9\n",
            "The target word is expectation propagation\n",
            "len of sentences 39\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is fast rates\n",
            "len of sentences 68\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is spectral methods\n",
            "len of sentences 79\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is -- end\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is random projections\n",
            "len of sentences 91\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is graphical models\n",
            "len of sentences 1092\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is subspace clustering\n",
            "len of sentences 164\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is generalized linear\n",
            "len of sentences 121\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is : deep\n",
            "len of sentences 4\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is sparse inverse\n",
            "len of sentences 17\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is inverse covariance\n",
            "len of sentences 100\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is robust pca\n",
            "len of sentences 7\n",
            "len of t1 48\n",
            "len of each target word extractions is 48\n",
            "The target word is adversarial networks\n",
            "len of sentences 61\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is stochastic learning\n",
            "len of sentences 17\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is its application\n",
            "len of sentences 138\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is basis functions\n",
            "len of sentences 114\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is signal processing\n",
            "len of sentences 106\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is nets :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is function networks\n",
            "len of sentences 3\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is learning rate\n",
            "len of sentences 821\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is receptive field\n",
            "len of sentences 213\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is data analysis\n",
            "len of sentences 201\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is eye movements\n",
            "len of sentences 18\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is difference learning\n",
            "len of sentences 21\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is vector quantization\n",
            "len of sentences 21\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is receptive fields\n",
            "len of sentences 66\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is algorithm learning\n",
            "len of sentences 1\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is training neural\n",
            "len of sentences 32\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is learning rules\n",
            "len of sentences 65\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is the power\n",
            "len of sentences 263\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is generalization error\n",
            "len of sentences 212\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is dimension reduction\n",
            "len of sentences 73\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is value iteration\n",
            "len of sentences 50\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is -line learning\n",
            "len of sentences 47\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is blind separation\n",
            "len of sentences 3\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is pose estimation\n",
            "len of sentences 133\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is mixture model\n",
            "len of sentences 427\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is statistical models\n",
            "len of sentences 96\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is factor analysis\n",
            "len of sentences 87\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is inference learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is likelihood estimation\n",
            "len of sentences 128\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is components analysis\n",
            "len of sentences 39\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is generative model\n",
            "len of sentences 902\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is learning linear\n",
            "len of sentences 16\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is analysis :\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is approach learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is bayesian models\n",
            "len of sentences 1\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is : unified\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is markov chains\n",
            "len of sentences 16\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is semidefinite programming\n",
            "len of sentences 72\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is learning optimal\n",
            "len of sentences 5\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is spectral learning\n",
            "len of sentences 39\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is imitation learning\n",
            "len of sentences 39\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is regret bounds\n",
            "len of sentences 266\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_map3 = {\n",
        "\n",
        "    \"embed_C1\":embed_C1,\n",
        "    \"embed_C2\":embed_C2,\n",
        "    \"embed_C3\":embed_C3,\n",
        "    \"embed_C4\":embed_C4,\n",
        "    \"embed_C5\":embed_C5,\n",
        "    \"embed_C6\":embed_C6,\n",
        "    \"embed_C7\":embed_C7,\n",
        "    \"embed_C8\":embed_C8,\n",
        "    \"embed_C9\":embed_C9,\n",
        "    \"embed_C10\":embed_C10,\n",
        "    \"sents\":sents,\n",
        "    \"embed_full\":embed_full\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_2.pickle', 'wb+') as f:\n",
        "     pickle.dump(saved_map3, f)"
      ],
      "metadata": {
        "id": "90ABnsNnpfoD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply K-NN with Cosine Similarity "
      ],
      "metadata": {
        "id": "0Pd6JvLB5k9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "UmdHFHk3ytYu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_2.pickle', 'rb+') as f:\n",
        "  saved_map = pickle.load(f)"
      ],
      "metadata": {
        "id": "2FS2lzDHwl5g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(saved_map[\"embed_C7\"][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tER4rF1JhoJr",
        "outputId": "7cb31bae-2ff6-40c5-f50d-46a3242f3c18"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_C1 = saved_map[\"embed_C1\"]\n",
        "embed_C2 = saved_map[\"embed_C2\"]\n",
        "embed_C3 = saved_map[\"embed_C3\"]\n",
        "embed_C4 = saved_map[\"embed_C4\"]\n",
        "embed_C5 = saved_map[\"embed_C5\"]\n",
        "embed_C6 = saved_map[\"embed_C6\"]\n",
        "embed_C7 = saved_map[\"embed_C7\"]\n",
        "embed_C8 = saved_map[\"embed_C8\"]\n",
        "embed_C9 = saved_map[\"embed_C9\"]\n",
        "embed_C10 = saved_map[\"embed_C10\"]"
      ],
      "metadata": {
        "id": "CPaPK6goyQUb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-NN to calculate the Nearest neighbor of keywords\n",
        "\n",
        "def convert_tensors_tolist(mapping):\n",
        "  for i, word_sentences in enumerate(mapping):\n",
        "        # Use below line whe converting tensors to numpy array\n",
        "        X1=np.array([np.array(x.to('cpu')) for x in word_sentences])\n",
        "\n",
        "        # X1=np.array([np.array(x) for x in word_sentences])\n",
        "        X1=X1.sum(axis=0).tolist()\n",
        "        mapping[i] = X1\n",
        "  return mapping"
      ],
      "metadata": {
        "id": "5bVz7KBItoEt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### FLATTEN tensors of sentences of respective words to 1-D\n",
        "\n",
        "# embed_C1_ = convert_tensors_tolist(embed_C1)\n",
        "embed_C2_ = convert_tensors_tolist(embed_C2)\n",
        "embed_C3_ = convert_tensors_tolist(embed_C3)\n",
        "embed_C4_ = convert_tensors_tolist(embed_C4)\n",
        "embed_C5_ = convert_tensors_tolist(embed_C5)\n",
        "embed_C6_ = convert_tensors_tolist(embed_C6)\n",
        "embed_C7_ = convert_tensors_tolist(embed_C7)\n",
        "embed_C8_ = convert_tensors_tolist(embed_C8)\n",
        "embed_C9_ = convert_tensors_tolist(embed_C9)\n",
        "embed_C10_ = convert_tensors_tolist(embed_C10)\n",
        "\n"
      ],
      "metadata": {
        "id": "PEb6gAo3BTJl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed_C2_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQZIuXhYIl-T",
        "outputId": "0fa97a10-6a2e-41cf-d382-c5854de01f89"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def nn_(X):\n",
        "  model = NearestNeighbors(n_neighbors=10,\n",
        "                          metric='cosine',\n",
        "                          algorithm='brute',\n",
        "                          n_jobs=-1)\n",
        "\n",
        "  n_n = model.fit(X)  \n",
        "  distance, indeces = model.kneighbors(X)\n",
        "\n",
        "\n",
        "  return indeces\n"
      ],
      "metadata": {
        "id": "VZVMkWUeRBJr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indeces_1 = nn_(embed_C1_)\n",
        "indeces_2 = nn_(embed_C2_)\n",
        "indeces_3 = nn_(embed_C3_)\n",
        "indeces_4 = nn_(embed_C4_)\n",
        "indeces_5 = nn_(embed_C5_)\n",
        "indeces_6 = nn_(embed_C6_)\n",
        "indeces_7 = nn_(embed_C7_)\n",
        "indeces_8 = nn_(embed_C8_)\n",
        "indeces_9 = nn_(embed_C9_)\n",
        "indeces_10 = nn_(embed_C10_)\n",
        "\n"
      ],
      "metadata": {
        "id": "rGjvILCoRe6D"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec2dynamics_keywords = ['Neural Network', 'Reinforcement Learning', 'Active Learning', 'Monte Carlo', 'Learning Deep',\n",
        "                          'Machine Learning', 'Supervised Learning', 'Time Series', 'Artificial Neural',\n",
        "                         'Gaussian Process', 'Active Learning', 'Gradient Descent', 'Hidden Markov',\n",
        "                         'Nearest Neighbor', 'Dynamical Systems', 'Dimensionality Reduction',\n",
        "                         'Unsupervised Learning', 'Graphical Models', 'Dynamic Programming', 'Component Analysis']"
      ],
      "metadata": {
        "id": "hqzzfXfjQ4RY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keywords_np = np.array(candidate_keywords)\n",
        "\n",
        "candidate_keywords_ = np.array([keyword[0] for keyword in candidate_keywords])\n",
        "\n",
        "candidate_keywords_"
      ],
      "metadata": {
        "id": "Aco3xvQpSRV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69a2c94-9441-46ae-e3a9-7c17c2bcc03e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Neural Networks', 'Reinforcement Learning', 'Neural Network',\n",
              "       'Gaussian Process', 'Graphical Models', 'Support Vector',\n",
              "       'Gaussian Processes', 'Active Learning', 'Variational Inference',\n",
              "       'Monte Carlo', 'Online Learning', 'Speech Recognition',\n",
              "       'Recurrent Neural', 'Component Analysis', 'Gradient Descent',\n",
              "       'Hidden Markov', ': The', 'Deep Learning', 'Learning :',\n",
              "       'Markov Models', 'Vector Machines', 'Analog VLSI',\n",
              "       'Stochastic Gradient', 'Markov Decision', 'Feature Selection',\n",
              "       ': Learning', 'Networks Learning', 'Random Fields',\n",
              "       'Machine Learning', 'Networks :', 'Belief Propagation',\n",
              "       'Kernel Learning', 'Unsupervised Learning', 'neural networks',\n",
              "       'Model Selection', 'Matrix Completion', 'Dynamic Programming',\n",
              "       'Function Approximation', 'Decision Processes',\n",
              "       'Object Recognition', 'Time Series', 'Mixture Models',\n",
              "       'Latent Variable', 'Metric Learning', 'Deep Neural',\n",
              "       'Spiking Neurons', 'Bayesian Inference', 'Density Estimation',\n",
              "       'Approximate Inference', 'Convex Optimization',\n",
              "       'Supervised Learning', 'Dynamical Systems', 'Convolutional Neural',\n",
              "       'Generative Models', 'Large Scale', 'Matrix Factorization',\n",
              "       ': Application', 'Stochastic Optimization', 'Natural Images',\n",
              "       'Spectral Clustering', 'Learning The', 'Dimensionality Reduction',\n",
              "       'Principal Component', 'Learning Sparse', 'Object Detection',\n",
              "       'MAP Inference', 'Visual Cortex', 'Recurrent Networks',\n",
              "       'Radial Basis', 'Risk Minimization', 'Nearest Neighbor',\n",
              "       'Independent Component', 'High Dimensional', 'Large Margin',\n",
              "       'Structured Prediction', 'Learning Algorithms', 'Neural Net',\n",
              "       'Learning Multiple', 'Bayesian Model', 'Models Learning',\n",
              "       'Bayesian Networks', 'Policy Gradient', 'Variational Bayesian',\n",
              "       'Process Regression', 'Sparse Coding', 'Domain Adaptation',\n",
              "       'Learning Deep', 'Recognition Using', 'Artificial Neural',\n",
              "       'Mean Field', 'Maximum Likelihood', 'Missing Data',\n",
              "       'Sample Complexity', 'Exponential Family', 'Deep Networks',\n",
              "       'Coordinate Descent', 'Associative Memory', 'Basis Function',\n",
              "       'Feature Extraction', 'Boltzmann Machines', 'Learning Algorithm',\n",
              "       'Learning Learning', 'Learning Bayesian', 'Vector Machine',\n",
              "       'Gradient Methods', 'Latent Dirichlet', 'Learning Gaussian',\n",
              "       'Topic Models', 'Semi-supervised Learning', 'Conditional Random',\n",
              "       'Feature Learning', 'Generative Adversarial', 'Network Model',\n",
              "       'Neural Nets', 'Mutual Information', 'Markov Random',\n",
              "       'Second Order', 'Clustering :', 'Learning Approach', ': Efficient',\n",
              "       'Bayesian Learning', 'Decision Trees', 'Learning Structured',\n",
              "       'Variable Models', 'Gaussian Graphical', 'Dirichlet Allocation',\n",
              "       'Probabilistic Inference', 'Semi-Supervised Learning',\n",
              "       'Graphical Model', 'Sparse PCA', 'Message Passing',\n",
              "       'Convolutional Networks', 'Bayesian Optimization',\n",
              "       'Learning Neural', 'Temporal Difference', 'Gaussian Mixtures',\n",
              "       ': New', 'Least Squares', 'Partially Observable', 'Linear Models',\n",
              "       'Belief Networks', 'Markov Networks', 'Policy Search',\n",
              "       'Maximum Margin', 'Restricted Boltzmann',\n",
              "       'Collaborative Filtering', 'Decision Making', 'End --',\n",
              "       'Nonparametric Bayesian', 'Transfer Learning',\n",
              "       'Tensor Decomposition', 'Neural Model', 'Image Segmentation',\n",
              "       'Network :', 'Information Theoretic', ': From',\n",
              "       'Parameter Estimation', 'Efficient Learning', 'Visual Attention',\n",
              "       'Visual Recognition', 'Value Function', 'Learning Stochastic',\n",
              "       'Linear Programming', 'Information Bottleneck',\n",
              "       'Variance Reduction', ': Towards', 'Sparse Gaussian',\n",
              "       'Multiple Kernel', 'Dirichlet Process', 'Networks Neural',\n",
              "       'Learning Control', 'Distributed Representations', 'Networks The',\n",
              "       'Pattern Recognition', 'Analog Neural', 'VLSI Neural',\n",
              "       'Ocular Dominance', 'Learning Dynamic', 'Natural Language',\n",
              "       'Continuous Speech', 'Learning Model', 'Learning Curves',\n",
              "       'Learning Using', 'spiking neurons', 'Mixtures Experts',\n",
              "       'Graph Matching', 'Learning Continuous', 'Learning Adaptive',\n",
              "       'Information Maximization', ': Bayesian', 'Learning Efficient',\n",
              "       'Multi-Task Learning', 'Models :', 'Natural Scenes',\n",
              "       'Learning Nonlinear', ': Fast', 'Process Models',\n",
              "       'Sequential Data', 'Data Learning', 'Probabilistic Models',\n",
              "       'High Dimensions', 'Markov Chain', 'Inference Bayesian',\n",
              "       'Structure Learning', 'Kernel Methods', 'Logistic Regression',\n",
              "       'Model Learning', 'Hierarchical Clustering', 'Training Deep',\n",
              "       'Submodular Functions', 'Inverse Reinforcement', 'Empirical Risk',\n",
              "       ': Probabilistic', 'Using Neural', 'Networks Application',\n",
              "       'Complexity Learning', 'Boltzmann Machine', 'Networks Using',\n",
              "       'VLSI Implementation', ': Theory', 'Markov Model',\n",
              "       'Selective Attention', 'Face Recognition', 'Anomaly Detection',\n",
              "       'Finite State', 'Population Codes', 'Unlabeled Data',\n",
              "       'Data Clustering', 'Manifold Learning', 'Real Time',\n",
              "       'Neighbor Classification', 'Policy Iteration', 'Training Sets',\n",
              "       'Source Separation', 'Learning Probabilistic',\n",
              "       'Discriminant Analysis', 'The Infinite', 'Importance Sampling',\n",
              "       'Lower Bounds', 'Probabilistic Model', 'Kernel Machines',\n",
              "       'Causal Inference', 'Data :', 'Side Information',\n",
              "       'Distance Metric', 'Loss Functions', 'Expectation Propagation',\n",
              "       'Fast Rates', 'Spectral Methods', '-- End', 'Random Projections',\n",
              "       'graphical models', 'Subspace Clustering', 'Generalized Linear',\n",
              "       ': Deep', 'Sparse Inverse', 'Inverse Covariance', 'Robust PCA',\n",
              "       'Adversarial Networks', 'Stochastic Learning', 'Its Application',\n",
              "       'Basis Functions', 'Signal Processing', 'Nets :',\n",
              "       'Function Networks', 'Learning Rate', 'Receptive Field',\n",
              "       'Data Analysis', 'Eye Movements', 'Difference Learning',\n",
              "       'Vector Quantization', 'Receptive Fields', 'Algorithm Learning',\n",
              "       'Training Neural', 'Learning Rules', 'The Power',\n",
              "       'Generalization Error', 'Dimension Reduction', 'Value Iteration',\n",
              "       '-line Learning', 'Blind Separation', 'Pose Estimation',\n",
              "       'Mixture Model', 'Statistical Models', 'Factor Analysis',\n",
              "       'Inference Learning', 'Likelihood Estimation',\n",
              "       'Components Analysis', 'Generative Model', 'Learning Linear',\n",
              "       'Analysis :', 'Approach Learning', 'Bayesian Models', ': Unified',\n",
              "       'Markov Chains', 'Semidefinite Programming', 'Learning Optimal',\n",
              "       'Spectral Learning', 'Imitation Learning', 'Regret Bounds'],\n",
              "      dtype='<U27')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(vec2dynamics_keywords) - set(candidate_keywords_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZG38qs5TmkQ",
        "outputId": "78d2991f-d01d-4262-a348-62d6c3c8d79f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monitering_keywords = list(set(vec2dynamics_keywords).intersection(set(candidate_keywords_)))"
      ],
      "metadata": {
        "id": "Kn3otZ9NSfwy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(monitering_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45O_nIsPU6S0",
        "outputId": "2b41ecf3-c21d-48d3-c026-f3179fe1ca7d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_nearest_keywords(indeces, keywords_np=candidate_keywords_):\n",
        "  tup_nearest_neighbor = []\n",
        "  for index, candidate_keyword in enumerate(keywords_np):\n",
        "      # Take the current index of the keyword and get the list of 10 nearest index from KNN algorithm\n",
        "      nearest_neighbors_indeces_of_current_keyword = indeces[index]\n",
        "\n",
        "      # Filter the keyword list using the list of indeces obtained in previous step\n",
        "      nearest_keywords = keywords_np[nearest_neighbors_indeces_of_current_keyword]\n",
        "\n",
        "      # Create tuple with first element as the keyword for current iteration and 2nd element as list of its nearest neighbors\n",
        "      tup_nearest_neighbor.append({candidate_keyword : set(nearest_keywords)})\n",
        "\n",
        "\n",
        "  return tup_nearest_neighbor"
      ],
      "metadata": {
        "id": "LbPZ_ZUoQ7E7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn_1 = get_nearest_keywords(indeces_1)\n",
        "nn_2 = get_nearest_keywords(indeces_2)\n",
        "nn_3 = get_nearest_keywords(indeces_3)\n",
        "nn_4 = get_nearest_keywords(indeces_4)\n",
        "nn_5 = get_nearest_keywords(indeces_5)\n",
        "nn_6 = get_nearest_keywords(indeces_6)\n",
        "nn_7 = get_nearest_keywords(indeces_7)\n",
        "nn_8 = get_nearest_keywords(indeces_8)\n",
        "nn_9 = get_nearest_keywords(indeces_9)\n",
        "nn_10 = get_nearest_keywords(indeces_10)\n"
      ],
      "metadata": {
        "id": "EqQF0JRVxUDZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_target_nn(nn, monitering_keywords = monitering_keywords):\n",
        "    return [n for n in nn for key in list(n.keys()) if key in monitering_keywords]\n",
        "    "
      ],
      "metadata": {
        "id": "BnWxBHdAg6xQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2_ = get_target_nn(nn_2)\n",
        "nn_3_ = get_target_nn(nn_3)\n",
        "nn_4_ = get_target_nn(nn_4)\n",
        "nn_5_ = get_target_nn(nn_5)\n",
        "nn_6_ = get_target_nn(nn_6)\n",
        "nn_7_ = get_target_nn(nn_7)\n",
        "nn_8_ = get_target_nn(nn_8)\n",
        "nn_9_ = get_target_nn(nn_9)\n",
        "nn_10_ = get_target_nn(nn_10)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QBae2ny_XDFe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_10_"
      ],
      "metadata": {
        "id": "rNv_LeWZYx_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac628ed-f92d-497a-e579-67849c863766"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Reinforcement Learning': {'Conditional Random',\n",
              "   'Decision Trees',\n",
              "   'Learning Approach',\n",
              "   'Learning Efficient',\n",
              "   'Model Selection',\n",
              "   'Natural Language',\n",
              "   'Random Fields',\n",
              "   'Reinforcement Learning',\n",
              "   'Structure Learning',\n",
              "   'Support Vector'}},\n",
              " {'Neural Network': {'Active Learning',\n",
              "   'Convolutional Networks',\n",
              "   'Convolutional Neural',\n",
              "   'Data Learning',\n",
              "   'Distance Metric',\n",
              "   'Gaussian Graphical',\n",
              "   'Neural Net',\n",
              "   'Neural Network',\n",
              "   'Stochastic Gradient',\n",
              "   'Stochastic Learning'}},\n",
              " {'Gaussian Process': {': Probabilistic',\n",
              "   'Distance Metric',\n",
              "   'Gaussian Process',\n",
              "   'Large Margin',\n",
              "   'Least Squares',\n",
              "   'Nearest Neighbor',\n",
              "   'Neighbor Classification',\n",
              "   'Regret Bounds',\n",
              "   'Stochastic Gradient',\n",
              "   'The Infinite'}},\n",
              " {'Graphical Models': {'Belief Networks',\n",
              "   'Density Estimation',\n",
              "   'Generative Model',\n",
              "   'Graphical Models',\n",
              "   'Importance Sampling',\n",
              "   'Large Scale',\n",
              "   'Mutual Information',\n",
              "   'Neural Model',\n",
              "   'Spectral Methods',\n",
              "   'graphical models'}},\n",
              " {'Active Learning': {': Learning',\n",
              "   'Active Learning',\n",
              "   'Convolutional Neural',\n",
              "   'Neural Net',\n",
              "   'Neural Network',\n",
              "   'Pattern Recognition',\n",
              "   'Support Vector',\n",
              "   'Vector Machine',\n",
              "   'Vector Machines',\n",
              "   'Visual Recognition'}},\n",
              " {'Monte Carlo': {'Active Learning',\n",
              "   'Conditional Random',\n",
              "   'Markov Chain',\n",
              "   'Monte Carlo',\n",
              "   'Network Model',\n",
              "   'Principal Component',\n",
              "   'Random Fields',\n",
              "   'Recurrent Neural',\n",
              "   'Support Vector',\n",
              "   'Variable Models'}},\n",
              " {'Component Analysis': {': From',\n",
              "   'Bayesian Inference',\n",
              "   'Component Analysis',\n",
              "   'Coordinate Descent',\n",
              "   'Gradient Descent',\n",
              "   'Latent Dirichlet',\n",
              "   'Least Squares',\n",
              "   'Radial Basis',\n",
              "   'Random Projections',\n",
              "   'Variance Reduction'}},\n",
              " {'Gradient Descent': {'Component Analysis',\n",
              "   'Coordinate Descent',\n",
              "   'Gradient Descent',\n",
              "   'Large Margin',\n",
              "   'Least Squares',\n",
              "   'Nearest Neighbor',\n",
              "   'Random Projections',\n",
              "   'Regret Bounds',\n",
              "   'Semidefinite Programming',\n",
              "   'Variance Reduction'}},\n",
              " {'Hidden Markov': {': Probabilistic',\n",
              "   'Dynamical Systems',\n",
              "   'Hidden Markov',\n",
              "   'Kernel Learning',\n",
              "   'Markov Model',\n",
              "   'Markov Models',\n",
              "   'Nonparametric Bayesian',\n",
              "   'Regret Bounds',\n",
              "   'Stochastic Gradient',\n",
              "   'Variational Inference'}},\n",
              " {'Machine Learning': {'Learning Approach',\n",
              "   'Learning Efficient',\n",
              "   'Learning Optimal',\n",
              "   'Learning Sparse',\n",
              "   'Learning The',\n",
              "   'Machine Learning',\n",
              "   'Model Selection',\n",
              "   'Natural Language',\n",
              "   'Reinforcement Learning',\n",
              "   'Stochastic Optimization'}},\n",
              " {'Unsupervised Learning': {'Decision Processes',\n",
              "   'Dimensionality Reduction',\n",
              "   'Generative Adversarial',\n",
              "   'Learning Model',\n",
              "   'Learning Structured',\n",
              "   'Markov Decision',\n",
              "   'Semi-Supervised Learning',\n",
              "   'Semi-supervised Learning',\n",
              "   'Structure Learning',\n",
              "   'Unsupervised Learning'}},\n",
              " {'Dynamic Programming': {'Decision Trees',\n",
              "   'Dynamic Programming',\n",
              "   'Generative Model',\n",
              "   'Learning Model',\n",
              "   'Learning Probabilistic',\n",
              "   'Learning Sparse',\n",
              "   'Learning Structured',\n",
              "   'Mixture Model',\n",
              "   'Process Models',\n",
              "   'The Power'}},\n",
              " {'Time Series': {': Fast',\n",
              "   'Active Learning',\n",
              "   'Bayesian Networks',\n",
              "   'Conditional Random',\n",
              "   'Data Analysis',\n",
              "   'Dirichlet Allocation',\n",
              "   'Function Approximation',\n",
              "   'Random Fields',\n",
              "   'Support Vector',\n",
              "   'Time Series'}},\n",
              " {'Supervised Learning': {'Basis Function',\n",
              "   'Basis Functions',\n",
              "   'Generalization Error',\n",
              "   'Generative Models',\n",
              "   'Learning Model',\n",
              "   'Probabilistic Model',\n",
              "   'Probabilistic Models',\n",
              "   'Semi-Supervised Learning',\n",
              "   'Semi-supervised Learning',\n",
              "   'Supervised Learning'}},\n",
              " {'Dynamical Systems': {': Probabilistic',\n",
              "   'Components Analysis',\n",
              "   'Dynamical Systems',\n",
              "   'Eye Movements',\n",
              "   'Feature Learning',\n",
              "   'Inverse Reinforcement',\n",
              "   'Kernel Learning',\n",
              "   'Markov Networks',\n",
              "   'Online Learning',\n",
              "   'Variational Inference'}},\n",
              " {'Dimensionality Reduction': {': Efficient',\n",
              "   'Basis Function',\n",
              "   'Basis Functions',\n",
              "   'Dimensionality Reduction',\n",
              "   'Exponential Family',\n",
              "   'Learning Model',\n",
              "   'Learning Structured',\n",
              "   'Likelihood Estimation',\n",
              "   'Mixture Model',\n",
              "   'Side Information'}},\n",
              " {'Nearest Neighbor': {': Application',\n",
              "   'Distance Metric',\n",
              "   'Gaussian Graphical',\n",
              "   'Large Margin',\n",
              "   'Least Squares',\n",
              "   'Markov Networks',\n",
              "   'Nearest Neighbor',\n",
              "   'Neighbor Classification',\n",
              "   'Radial Basis',\n",
              "   'Regret Bounds'}},\n",
              " {'Learning Deep': {'Deep Networks',\n",
              "   'Generative Model',\n",
              "   'Learning Deep',\n",
              "   'Learning Probabilistic',\n",
              "   'Learning Stochastic',\n",
              "   'Learning Structured',\n",
              "   'Neural Model',\n",
              "   'Parameter Estimation',\n",
              "   'Structure Learning',\n",
              "   'The Power'}},\n",
              " {'Artificial Neural': {'Artificial Neural',\n",
              "   'Generative Model',\n",
              "   'Learning Multiple',\n",
              "   'Learning Probabilistic',\n",
              "   'Model Learning',\n",
              "   'Neural Model',\n",
              "   'Partially Observable',\n",
              "   'Probabilistic Inference',\n",
              "   'Process Models',\n",
              "   'The Power'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(nn_10_[0][\"Reinforcement Learning\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86ZMV8dhYoPa",
        "outputId": "3e66d9f4-7c1f-4087-8f89-c8813feb960c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_slice_nn = [nn_2_, nn_3_, nn_4_ , nn_5_ , nn_6_, nn_7_ , nn_8_ , nn_9_ , nn_10_]"
      ],
      "metadata": {
        "id": "Igv6VTt1qIWZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def log_stability(A, B):\n",
        "    a = len(A.intersection(B))\n",
        "    b = len(A-B)\n",
        "\n",
        "    if a != 0 and b!=0:\n",
        "      return ( math.log( len(A.intersection(B)) , 10) / math.log ( 0.5 * len((A - B) ) , 10)  )\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "def calc_stability(nn):\n",
        "    i = 0\n",
        "    # print(nn)\n",
        "    stability = []\n",
        "    for _,n in enumerate(nn):\n",
        "       i = _ + 1\n",
        "      #  print(len(nn))\n",
        "       if i < len(nn):\n",
        "          # print(i)\n",
        "          stability.append( log_stability(nn[_], nn[i]) )\n",
        "\n",
        "    # print(stability)\n",
        "    return stability\n",
        "\n",
        "def extract_keyword_nns(target_nn_10tw, keyword):\n",
        "    keyword_neighbors_all_windows = []\n",
        "    for _ , target_nn in enumerate(target_nn_10tw):\n",
        "      # print(list(target_nn[_].keys()))\n",
        "\n",
        "      keyword_neighbors_all_windows.extend([target[keyword] for index, target in enumerate(target_nn) if list(target.keys())[0] == keyword ])\n",
        "    \n",
        "\n",
        "    # print(keyword_neighbors_all_windows)\n",
        "    s = calc_stability(keyword_neighbors_all_windows)\n",
        "    \n",
        "    return s\n",
        "\n",
        "def extract_stability(target_nn_10tw):\n",
        "    s_n = []\n",
        "    for _ , keyword in enumerate(monitering_keywords):\n",
        "      #  print(extract_keyword_nns(target_nn_10tw, keyword) )\n",
        "       s_n.append( { keyword: extract_keyword_nns(target_nn_10tw, keyword) } )\n",
        "        # s_n.extend( { keyword : extract_keyword_nns(target_nn_10tw, keyword) } )\n",
        "\n",
        "    return s_n"
      ],
      "metadata": {
        "id": "yqLHw5F5XbA-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_stab = extract_stability(all_slice_nn)\n",
        "keyword_stab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5EfLzPzzbFh",
        "outputId": "d0f4ecf6-12cb-4aad-9861-7cd2bac3313e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Neural Network': [0.5,\n",
              "   0.5,\n",
              "   0.8769514395748774,\n",
              "   1.7564707973660298,\n",
              "   1.2618595071429146,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Dynamical Systems': [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0]},\n",
              " {'Reinforcement Learning': [0.5,\n",
              "   0.0,\n",
              "   1.2618595071429146,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0]},\n",
              " {'Active Learning': [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0]},\n",
              " {'Nearest Neighbor': [0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.8769514395748774,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Gaussian Process': [2.584962500721156,\n",
              "   2.584962500721156,\n",
              "   0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0]},\n",
              " {'Gradient Descent': [0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]},\n",
              " {'Time Series': [0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]},\n",
              " {'Supervised Learning': [0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774]},\n",
              " {'Unsupervised Learning': [0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146,\n",
              "   1.2618595071429146]},\n",
              " {'Artificial Neural': [0.0,\n",
              "   0.8769514395748774,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5]},\n",
              " {'Monte Carlo': [0, 0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0]},\n",
              " {'Component Analysis': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0]},\n",
              " {'Hidden Markov': [0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146,\n",
              "   0.8769514395748774,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Machine Learning': [0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5]},\n",
              " {'Learning Deep': [2.584962500721156,\n",
              "   2.584962500721156,\n",
              "   2.584962500721156,\n",
              "   1.7564707973660298,\n",
              "   0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Graphical Models': [0,\n",
              "   0.5,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146,\n",
              "   0.8769514395748774,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5]},\n",
              " {'Dynamic Programming': [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0]},\n",
              " {'Dimensionality Reduction': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_stability(nn_8_[0][\"Reinforcement Learning\"], nn_7_[0][\"Reinforcement Learning\"])\n"
      ],
      "metadata": {
        "id": "ROcoZZiyzZaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba23dfce-7fc5-49dd-ed71-2edc0ed0f8df"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = [n for n in nn_2_] \n",
        "\n",
        "\n",
        "\n",
        "list(nn_2_[0].keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O0LyJM3F04gM",
        "outputId": "f9d86f58-90c3-41e0-c9a7-c91385114e20"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reinforcement Learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}