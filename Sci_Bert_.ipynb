{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sci_Bert_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xahram/Sci-Bert/blob/main/Sci_Bert_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First step is to load the NIPS data that is uploaded in the Google Drive"
      ],
      "metadata": {
        "id": "oPZ9rjzVQFYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive folder into the directory to access files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmrUd6BcBAKB",
        "outputId": "81e948f7-594c-49be-ba4a-a6d2df14fbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import time \n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YZGpDT8-BrZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68f6e99-2b4b-4194-dd1a-9a55390c3305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the NIPS dataset from the drive\n",
        "\n",
        "nips_papers_df = pd.read_csv('/gdrive/My Drive/Master_dataset/papers.csv')  \n",
        "nips_papers_df.head()\n",
        "\n",
        "nips_papers = nips_papers_df.infer_objects()\n",
        "\n",
        "nips_papers.dtypes\n",
        "\n",
        "nips_papers[\"year\"] = pd.to_datetime(nips_papers[\"year\"], format=\"%Y\")\n",
        "# nips_papers['year'] = nips_papers['year'].dt.year\n",
        "nips_papers.sort_values(by='year')\n",
        "\n",
        "print(nips_papers.dtypes)\n",
        "\n",
        "max(nips_papers[\"year\"])\n",
        "min(nips_papers[\"year\"])\n",
        "\n",
        "nips_papers = nips_papers.sort_values(by = \"year\")\n"
      ],
      "metadata": {
        "id": "z0H4P5yIBexP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9bd9bd-7096-4d4d-f9d6-0be88e5a3783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                     int64\n",
            "year          datetime64[ns]\n",
            "title                 object\n",
            "event_type            object\n",
            "pdf_name              object\n",
            "abstract              object\n",
            "paper_text            object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import close\n",
        "# Slice Data Frame by 3 year interval\n",
        "\n",
        "\n",
        "# print(len(nips_papers))\n",
        "\n",
        "# Partition/Group Papers into df by the interval/freq of 3 years, closed = left to start combinbing from the 1987\n",
        "nips_papers_3y_grouped = nips_papers.groupby(pd.Grouper(key='year', freq='3Y', sort=True, closed=\"left\"))\n",
        "\n",
        "\n",
        "\n",
        "# Save partitions in the Dictionary format with 10 intervals\n",
        "nips_papers_partitions = {}\n",
        "initial_partition_id = 0\n",
        "for i, g  in nips_papers_3y_grouped:\n",
        "    nips_papers_partitions[initial_partition_id] = g\n",
        "    initial_partition_id = initial_partition_id + 1\n",
        "\n",
        "\n",
        "print(nips_papers_partitions)\n",
        "# nips_papers_three_year_partition[0].tail()\n",
        "\n",
        "\n",
        "#for i, g in nips_papers.groupby(pd.Grouper(key=nips_papers[\"year\"], freq='A')):\n",
        "#     print(g)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4A_aWwViSXFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929375c4-4d96-4287-afb7-10698895e95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0:        id       year                                              title  \\\n",
            "0       1 1987-01-01  Self-Organization of Associative Database and ...   \n",
            "328    13 1987-01-01   Temporal Patterns of Activity in Neural Networks   \n",
            "6853   72 1987-01-01  Ensemble' Boltzmann Units have Collective Comp...   \n",
            "6743   71 1987-01-01  Centric Models of the Orientation Map in Prima...   \n",
            "6632   70 1987-01-01  On the Power of Neural Networks for Solving Ha...   \n",
            "...   ...        ...                                                ...   \n",
            "1650  250 1989-01-01                               Optimal Brain Damage   \n",
            "1661  251 1989-01-01  A Self-organizing Associative Memory System fo...   \n",
            "1672  252 1989-01-01  Can Simple Cells Learn Curves? A Hebbian Model...   \n",
            "1683  253 1989-01-01  Subgrouping Reduces Complexity and Speeds Up L...   \n",
            "1638  249 1989-01-01  Neural Network Analysis of Distributed Represe...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "0           NaN  1-self-organization-of-associative-database-an...   \n",
            "328         NaN  13-temporal-patterns-of-activity-in-neural-net...   \n",
            "6853        NaN  72-ensemble-boltzmann-units-have-collective-co...   \n",
            "6743        NaN  71-centric-models-of-the-orientation-map-in-pr...   \n",
            "6632        NaN  70-on-the-power-of-neural-networks-for-solving...   \n",
            "...         ...                                                ...   \n",
            "1650        NaN                       250-optimal-brain-damage.pdf   \n",
            "1661        NaN  251-a-self-organizing-associative-memory-syste...   \n",
            "1672        NaN  252-can-simple-cells-learn-curves-a-hebbian-mo...   \n",
            "1683        NaN  253-subgrouping-reduces-complexity-and-speeds-...   \n",
            "1638        NaN  249-neural-network-analysis-of-distributed-rep...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
            "328   Abstract Missing  297\\n\\nTEMPORAL PATTERNS OF ACTIVITY IN\\nNEURA...  \n",
            "6853  Abstract Missing  223\\n\\n'Ensemble' Boltzmann Units\\nhave Collec...  \n",
            "6743  Abstract Missing  62\\n\\nCentric Models of the Orientation Map in...  \n",
            "6632  Abstract Missing  137\\n\\nOn the Power of Neural Networks for\\nSo...  \n",
            "...                ...                                                ...  \n",
            "1650  Abstract Missing  598\\n\\nLe Cun, Denker and Solla\\n\\nOptimal Bra...  \n",
            "1661  Abstract Missing  332\\n\\nHormel\\n\\nA Sell-organizing Associative...  \n",
            "1672  Abstract Missing  Can Simple Cells Learn Curves? A Hebbian Model...  \n",
            "1683  Abstract Missing  638\\n\\nZipser\\n\\nSubgrouping Reduces Complexit...  \n",
            "1638  Abstract Missing  28\\n\\nLockery t Fang and Sejnowski\\n\\nNeu.?al ...  \n",
            "\n",
            "[285 rows x 7 columns], 1:        id       year                                              title  \\\n",
            "3212  391 1990-01-01  Designing Linear Threshold Based Neural Networ...   \n",
            "3401  408 1990-01-01                           Adaptive Spline Networks   \n",
            "3278  397 1990-01-01  Integrated Segmentation and Recognition of Han...   \n",
            "3390  407 1990-01-01         Convergence of a Neural Network Classifier   \n",
            "3245  394 1990-01-01  Chaitin-Kolmogorov Complexity and Generalizati...   \n",
            "...   ...        ...                                                ...   \n",
            "5946  638 1992-01-01  Network Structuring and Training Using Rule-ba...   \n",
            "5769  622 1992-01-01    Information, Prediction, and Query by Committee   \n",
            "5758  621 1992-01-01  Some Solutions to the Missing Feature Problem ...   \n",
            "5747  620 1992-01-01  Connected Letter Recognition with a Multi-Stat...   \n",
            "5802  625 1992-01-01  Visual Motion Computation in Analog VLSI Using...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3212        NaN  391-designing-linear-threshold-based-neural-ne...   \n",
            "3401        NaN                   408-adaptive-spline-networks.pdf   \n",
            "3278        NaN  397-integrated-segmentation-and-recognition-of...   \n",
            "3390        NaN  407-convergence-of-a-neural-network-classifier...   \n",
            "3245        NaN  394-chaitin-kolmogorov-complexity-and-generali...   \n",
            "...         ...                                                ...   \n",
            "5946        NaN  638-network-structuring-and-training-using-rul...   \n",
            "5769        NaN  622-information-prediction-and-query-by-commit...   \n",
            "5758        NaN  621-some-solutions-to-the-missing-feature-prob...   \n",
            "5747        NaN  620-connected-letter-recognition-with-a-multi-...   \n",
            "5802        NaN  625-visual-motion-computation-in-analog-vlsi-u...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "3212  Abstract Missing  Designing Linear Threshold Based Neural\\nNetwo...  \n",
            "3401  Abstract Missing  ADAPTIVE SPLINE NETWORKS\\n\\nJerome H. Friedman...  \n",
            "3278  Abstract Missing  Integrated Segmentation and Recognition of\\nHa...  \n",
            "3390  Abstract Missing  Convergence of a Neural Network Classifier\\n\\n...  \n",
            "3245  Abstract Missing  Chaitin-Kolmogorov Complexity\\nand Generalizat...  \n",
            "...                ...                                                ...  \n",
            "5946  Abstract Missing  Network Structuring And Training Using\\nRule-b...  \n",
            "5769  Abstract Missing  Information, prediction, and query by\\ncommitt...  \n",
            "5758  Abstract Missing  Some Solutions to the Missing Feature Problem\\...  \n",
            "5747  Abstract Missing  Connected Letter Recognition with a\\nMulti-Sta...  \n",
            "5802  Abstract Missing  Visual Motion Computation in Analog\\nVLSI usin...  \n",
            "\n",
            "[414 rows x 7 columns], 2:         id       year                                              title  \\\n",
            "7006   782 1993-01-01  Optimal Unsupervised Motor Learning Predicts t...   \n",
            "7005   781 1993-01-01  A Comparison of Dynamic Reposing and Tangent D...   \n",
            "7004   780 1993-01-01         Dynamic Modulation of Neurons and Networks   \n",
            "7002   779 1993-01-01    Address Block Location with a Neural Net System   \n",
            "7001   778 1993-01-01  A Learning Analog Neural Network Chip with Con...   \n",
            "...    ...        ...                                                ...   \n",
            "69    1060 1995-01-01  Statistical Theory of Overtraining - Is Cross-...   \n",
            "63    1055 1995-01-01  Adaptive Retina with Center-Surround Receptive...   \n",
            "150   1135 1995-01-01               Information through a Spiking Neuron   \n",
            "62    1054 1995-01-01  Implementation Issues in the Fourier Transform...   \n",
            "65    1057 1995-01-01  When is an Integrate-and-fire Neuron like a Po...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "7006        NaN  782-optimal-unsupervised-motor-learning-predic...   \n",
            "7005        NaN  781-a-comparison-of-dynamic-reposing-and-tange...   \n",
            "7004        NaN  780-dynamic-modulation-of-neurons-and-networks...   \n",
            "7002        NaN  779-address-block-location-with-a-neural-net-s...   \n",
            "7001        NaN  778-a-learning-analog-neural-network-chip-with...   \n",
            "...         ...                                                ...   \n",
            "69          NaN  1060-statistical-theory-of-overtraining-is-cro...   \n",
            "63          NaN  1055-adaptive-retina-with-center-surround-rece...   \n",
            "150         NaN      1135-information-through-a-spiking-neuron.pdf   \n",
            "62          NaN  1054-implementation-issues-in-the-fourier-tran...   \n",
            "65          NaN  1057-when-is-an-integrate-and-fire-neuron-like...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "7006  Abstract Missing  Optimal Unsupervised Motor Learning\\nPredicts ...  \n",
            "7005  Abstract Missing  A Comparison of Dynamic Reposing and\\nTangent ...  \n",
            "7004  Abstract Missing  Dynamic Modulation of Neurons and Networks\\n\\n...  \n",
            "7002  Abstract Missing  Address Block Location with a Neural Net Syste...  \n",
            "7001  Abstract Missing  A Learning Analog Neural Network Chip\\nwith Co...  \n",
            "...                ...                                                ...  \n",
            "69    Abstract Missing  Statistical Theory of Overtraining - Is\\nCross...  \n",
            "63    Abstract Missing  Adaptive Retina with Center-Surround\\nReceptiv...  \n",
            "150   Abstract Missing  Information through a Spiking Neuron\\n\\nCharle...  \n",
            "62    Abstract Missing  Implementation Issues in the Fourier\\nTransfor...  \n",
            "65    Abstract Missing  When is an Integrate-and-fire Neuron\\nlike a P...  \n",
            "\n",
            "[450 rows x 7 columns], 3:        id       year                                              title  \\\n",
            "288  1263 1996-01-01  Training Algorithms for Hidden Markov Models u...   \n",
            "290  1265 1996-01-01  A Silicon Model of Amplitude Modulation Detect...   \n",
            "291  1266 1996-01-01  Learning Temporally Persistent Hierarchical Re...   \n",
            "289  1264 1996-01-01                       Hidden Markov Decision Trees   \n",
            "279  1255 1996-01-01  A Model of Recurrent Interactions in Primary V...   \n",
            "..    ...        ...                                                ...   \n",
            "534  1489 1998-01-01            A Neuromorphic Monaural Sound Localizer   \n",
            "536  1490 1998-01-01  Very Fast EM-Based Mixture Model Clustering Us...   \n",
            "537  1491 1998-01-01        Kernel PCA and De-Noising in Feature Spaces   \n",
            "538  1492 1998-01-01  Viewing Classifier Systems as Model Free Learn...   \n",
            "532  1487 1998-01-01  A Reinforcement Learning Algorithm in Partiall...   \n",
            "\n",
            "    event_type                                           pdf_name  \\\n",
            "288        NaN  1263-training-algorithms-for-hidden-markov-mod...   \n",
            "290        NaN  1265-a-silicon-model-of-amplitude-modulation-d...   \n",
            "291        NaN  1266-learning-temporally-persistent-hierarchic...   \n",
            "289        NaN              1264-hidden-markov-decision-trees.pdf   \n",
            "279        NaN  1255-a-model-of-recurrent-interactions-in-prim...   \n",
            "..         ...                                                ...   \n",
            "534        NaN   1489-a-neuromorphic-monaural-sound-localizer.pdf   \n",
            "536        NaN  1490-very-fast-em-based-mixture-model-clusteri...   \n",
            "537        NaN  1491-kernel-pca-and-de-noising-in-feature-spac...   \n",
            "538        NaN  1492-viewing-classifier-systems-as-model-free-...   \n",
            "532        NaN  1487-a-reinforcement-learning-algorithm-in-par...   \n",
            "\n",
            "             abstract                                         paper_text  \n",
            "288  Abstract Missing  Training Algorithms for Hidden Markov Models\\n...  \n",
            "290  Abstract Missing  A Silicon Model of\\nAmplitude Modulation Detec...  \n",
            "291  Abstract Missing  Learning temporally persistent\\nhierarchical r...  \n",
            "289  Abstract Missing  Hidden Markov decision trees\\nMichael I. Jorda...  \n",
            "279  Abstract Missing  A Model of Recurrent Interactions in\\nPrimary ...  \n",
            "..                ...                                                ...  \n",
            "534  Abstract Missing  A N euromorphic Monaural Sound\\nLocalizer\\nJoh...  \n",
            "536  Abstract Missing  Very Fast EM-based Mixture Model\\nClustering u...  \n",
            "537  Abstract Missing  Kernel peA and De-Noising in Feature Spaces\\n\\...  \n",
            "538  Abstract Missing  Viewing Classifier Systems\\nas Model Free Lear...  \n",
            "532  Abstract Missing  A Reinforcement Learning Algorithm\\nin Partial...  \n",
            "\n",
            "[453 rows x 7 columns], 4:         id       year                                              title  \\\n",
            "803   1735 1999-01-01                     Uniqueness of the SVM Solution   \n",
            "807   1739 1999-01-01  Algebraic Analysis for Non-regular Learning Ma...   \n",
            "804   1736 1999-01-01  Nonlinear Discriminant Analysis Using Kernel F...   \n",
            "805   1737 1999-01-01                                Potential Boosters?   \n",
            "781   1715 1999-01-01  Invariant Feature Extraction and Classificatio...   \n",
            "...    ...        ...                                                ...   \n",
            "1125  2026 2001-01-01  Modeling Temporal Structure in Classical Condi...   \n",
            "1126  2027 2001-01-01  TAP Gibbs Free Energy, Belief Propagation and ...   \n",
            "1128  2029 2001-01-01  Hyperbolic Self-Organizing Maps for Semantic N...   \n",
            "1121  2022 2001-01-01  Learning Lateral Interactions for Feature Bind...   \n",
            "1086  1992 2001-01-01         Spectral Relaxation for K-means Clustering   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "803         NaN            1735-uniqueness-of-the-svm-solution.pdf   \n",
            "807         NaN  1739-algebraic-analysis-for-non-regular-learni...   \n",
            "804         NaN  1736-nonlinear-discriminant-analysis-using-ker...   \n",
            "805         NaN                        1737-potential-boosters.pdf   \n",
            "781         NaN  1715-invariant-feature-extraction-and-classifi...   \n",
            "...         ...                                                ...   \n",
            "1125        NaN  2026-modeling-temporal-structure-in-classical-...   \n",
            "1126        NaN  2027-tap-gibbs-free-energy-belief-propagation-...   \n",
            "1128        NaN  2029-hyperbolic-self-organizing-maps-for-seman...   \n",
            "1121        NaN  2022-learning-lateral-interactions-for-feature...   \n",
            "1086        NaN  1992-spectral-relaxation-for-k-means-clusterin...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "803   Abstract Missing  Uniqueness of the SVM Solution\\n\\nChristopher ...  \n",
            "807   Abstract Missing  Algebraic Analysis for Non-Regular\\nLearning M...  \n",
            "804   Abstract Missing  Nonlinear Discriminant Analysis using\\nKernel ...  \n",
            "805   Abstract Missing  Potential Boosters ?\\nNigel Duffy\\nDepartment ...  \n",
            "781   Abstract Missing  U nmixing Hyperspectral Data\\n\\nLucas Parra, C...  \n",
            "...                ...                                                ...  \n",
            "1125  Abstract Missing  Modeling Temporal Structure in Classical\\nCond...  \n",
            "1126  Abstract Missing  TAP Gibbs Free Energy, Belief Propagation and\\...  \n",
            "1128  Abstract Missing  Hyperbolic Self-Organizing Maps for Semantic\\n...  \n",
            "1121  Abstract Missing  Learning Lateral Interactions for\\nFeature Bin...  \n",
            "1086  Abstract Missing  Spectral Relaxation for K-means\\nClustering\\n\\...  \n",
            "\n",
            "[499 rows x 7 columns], 5:         id       year                                              title  \\\n",
            "1319  2200 2002-01-01                 A Bilinear Model for Sparse Coding   \n",
            "1392  2267 2002-01-01  Data-Dependent Bounds for Bayesian Mixture Met...   \n",
            "1393  2268 2002-01-01  Shape Recipes: Scene Representations that Refe...   \n",
            "1394  2269 2002-01-01  Ranking with Large Margin Principle: Two Appro...   \n",
            "1396  2270 2002-01-01  An Estimation-Theoretic Framework for the Pres...   \n",
            "...    ...        ...                                                ...   \n",
            "1717  2560 2004-01-01                         Adaptive Manifold Learning   \n",
            "1718  2561 2004-01-01                       Dependent Gaussian Processes   \n",
            "1704  2549 2004-01-01  The Power of Selective Memory: Self-Bounded Le...   \n",
            "1719  2562 2004-01-01  Edge of Chaos Computation in Mixed-Mode VLSI -...   \n",
            "1713  2557 2004-01-01  Conditional Models of Identity Uncertainty wit...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "1319        NaN        2200-a-bilinear-model-for-sparse-coding.pdf   \n",
            "1392        NaN  2267-data-dependent-bounds-for-bayesian-mixtur...   \n",
            "1393        NaN  2268-shape-recipes-scene-representations-that-...   \n",
            "1394        NaN  2269-ranking-with-large-margin-principle-two-a...   \n",
            "1396        NaN  2270-an-estimation-theoretic-framework-for-the...   \n",
            "...         ...                                                ...   \n",
            "1717        NaN                2560-adaptive-manifold-learning.pdf   \n",
            "1718        NaN              2561-dependent-gaussian-processes.pdf   \n",
            "1704        NaN  2549-the-power-of-selective-memory-self-bounde...   \n",
            "1719        NaN  2562-edge-of-chaos-computation-in-mixed-mode-v...   \n",
            "1713        NaN  2557-conditional-models-of-identity-uncertaint...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "1319  Abstract Missing  A Bilinear Model for Sparse Coding\\n\\nDavid B....  \n",
            "1392  Abstract Missing  Data-Dependent Bounds for Bayesian\\nMixture Me...  \n",
            "1393  Abstract Missing  Shape Recipes: Scene Representations that Refe...  \n",
            "1394  Abstract Missing  Ranking with Large Margin Principle: Two\\nAppr...  \n",
            "1396  Abstract Missing  An Estimation-Theoretic Framework for\\nthe Pre...  \n",
            "...                ...                                                ...  \n",
            "1717  Abstract Missing  Adaptive Manifold Learning\\n\\nJing Wang, Zheny...  \n",
            "1718  Abstract Missing  Dependent Gaussian Processes\\n\\nPhillip Boyle ...  \n",
            "1704  Abstract Missing  The Power of Selective Memory:\\nSelf-Bounded L...  \n",
            "1719  Abstract Missing  Edge of Chaos Computation in\\nMixed-Mode VLSI ...  \n",
            "1713  Abstract Missing  Conditional Models of Identity Uncertainty\\nwi...  \n",
            "\n",
            "[612 rows x 7 columns], 6:         id       year                                              title  \\\n",
            "2012  2828 2005-01-01  Asymptotics of Gaussian Regularized Least Squares   \n",
            "2013  2829 2005-01-01     Two view learning: SVM-2K, Theory and Practice   \n",
            "2015  2830 2005-01-01         Saliency Based on Information Maximization   \n",
            "2016  2831 2005-01-01     Faster Rates in Regression via Active Learning   \n",
            "2017  2832 2005-01-01                           Layered Dynamic Textures   \n",
            "...    ...        ...                                                ...   \n",
            "2462  3233 2007-01-01  Fitted Q-iteration in continuous action-space ...   \n",
            "2463  3234 2007-01-01      Topmoumoute Online Natural Gradient Algorithm   \n",
            "2464  3235 2007-01-01  Sparse Overcomplete Latent Variable Decomposit...   \n",
            "2465  3236 2007-01-01  Second Order Bilinear Discriminant Analysis fo...   \n",
            "2466  3237 2007-01-01  Learning Horizontal Connections in a Sparse Co...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2012        NaN  2828-asymptotics-of-gaussian-regularized-least...   \n",
            "2013        NaN  2829-two-view-learning-svm-2k-theory-and-pract...   \n",
            "2015        NaN  2830-saliency-based-on-information-maximizatio...   \n",
            "2016        NaN  2831-faster-rates-in-regression-via-active-lea...   \n",
            "2017        NaN                  2832-layered-dynamic-textures.pdf   \n",
            "...         ...                                                ...   \n",
            "2462        NaN  3233-fitted-q-iteration-in-continuous-action-s...   \n",
            "2463        NaN  3234-topmoumoute-online-natural-gradient-algor...   \n",
            "2464        NaN  3235-sparse-overcomplete-latent-variable-decom...   \n",
            "2465        NaN  3236-second-order-bilinear-discriminant-analys...   \n",
            "2466        NaN  3237-learning-horizontal-connections-in-a-spar...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2012                                   Abstract Missing   \n",
            "2013                                   Abstract Missing   \n",
            "2015                                   Abstract Missing   \n",
            "2016                                   Abstract Missing   \n",
            "2017                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "2462  We consider continuous state, continuous actio...   \n",
            "2463  Guided by the goal of obtaining an optimizatio...   \n",
            "2464  An important problem in many fields is the ana...   \n",
            "2465  Traditional analysis methods for single-trial ...   \n",
            "2466  It has been shown that adapting a dictionary o...   \n",
            "\n",
            "                                             paper_text  \n",
            "2012  Asymptotics of Gaussian Regularized\\nLeast-Squ...  \n",
            "2013  Two view learning: SVM-2K, Theory and\\nPractic...  \n",
            "2015  Saliency Based on Information Maximization\\n\\n...  \n",
            "2016  Faster Rates in Regression via Active Learning...  \n",
            "2017  Layered Dynamic Textures\\n\\nAntoni B. Chan\\nNu...  \n",
            "...                                                 ...  \n",
            "2462  Fitted Q-iteration in continuous action-space ...  \n",
            "2463  Topmoumoute online natural gradient algorithm\\...  \n",
            "2464  Sparse Overcomplete Latent Variable Decomposit...  \n",
            "2465  Second Order Bilinear Discriminant Analysis fo...  \n",
            "2466  Learning Horizontal Connections in a Sparse Co...  \n",
            "\n",
            "[628 rows x 7 columns], 7:         id       year                                              title  \\\n",
            "2810  3548 2008-01-01  Nonlinear causal discovery with additive noise...   \n",
            "2809  3547 2008-01-01  Goal-directed decision making in prefrontal co...   \n",
            "2808  3546 2008-01-01  Nonparametric Bayesian Learning of Switching L...   \n",
            "2807  3545 2008-01-01     Policy Search for Motor Primitives in Robotics   \n",
            "2806  3544 2008-01-01       Inferring rankings under constrained sensing   \n",
            "...    ...        ...                                                ...   \n",
            "3334  4019 2010-01-01  Two-Layer Generalization Analysis for Ranking ...   \n",
            "3444  4119 2010-01-01  b-Bit Minwise Hashing for Estimating Three-Way...   \n",
            "3336  4020 2010-01-01  Over-complete representations on recurrent neu...   \n",
            "3329  4014 2010-01-01       Agnostic Active Learning Without Constraints   \n",
            "3279  3970 2010-01-01  Sodium entry efficiency during action potentia...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2810        NaN  3548-nonlinear-causal-discovery-with-additive-...   \n",
            "2809        NaN  3547-goal-directed-decision-making-in-prefront...   \n",
            "2808        NaN  3546-nonparametric-bayesian-learning-of-switch...   \n",
            "2807        NaN  3545-policy-search-for-motor-primitives-in-rob...   \n",
            "2806        NaN  3544-inferring-rankings-under-constrained-sens...   \n",
            "...         ...                                                ...   \n",
            "3334        NaN  4019-two-layer-generalization-analysis-for-ran...   \n",
            "3444        NaN  4119-b-bit-minwise-hashing-for-estimating-thre...   \n",
            "3336        NaN  4020-over-complete-representations-on-recurren...   \n",
            "3329        NaN  4014-agnostic-active-learning-without-constrai...   \n",
            "3279        NaN  3970-sodium-entry-efficiency-during-action-pot...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2810  The discovery of causal relationships between ...   \n",
            "2809  Research in animal learning and behavioral neu...   \n",
            "2808  Many nonlinear dynamical phenomena can be effe...   \n",
            "2807  Many motor skills in humanoid robotics can be ...   \n",
            "2806                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "3334  This paper is concerned with the generalizatio...   \n",
            "3444  Computing two-way and multi-way set similariti...   \n",
            "3336  A striking aspect of cortical neural networks ...   \n",
            "3329  We present and analyze an agnostic active lear...   \n",
            "3279  Sodium entry during an action potential determ...   \n",
            "\n",
            "                                             paper_text  \n",
            "2810  Nonlinear causal discovery with additive noise...  \n",
            "2809  Goal-directed decision making in prefrontal\\nc...  \n",
            "2808  Nonparametric Bayesian Learning of Switching\\n...  \n",
            "2807  Policy Search for Motor Primitives in Robotics...  \n",
            "2806  Inferring rankings under constrained sensing\\n...  \n",
            "...                                                 ...  \n",
            "3334  Two-layer Generalization Analysis for Ranking ...  \n",
            "3444  b-Bit Minwise Hashing for Estimating Three-Way...  \n",
            "3336  Over-complete representations on recurrent neu...  \n",
            "3329  Agnostic Active Learning Without Constraints\\n...  \n",
            "3279  Sodium entry efficiency during action potentia...  \n",
            "\n",
            "[804 rows x 7 columns], 8:         id       year                                              title  \\\n",
            "3620  4278 2011-01-01  Learning in Hilbert vs. Banach Spaces: A Measu...   \n",
            "3798  4439 2011-01-01             Generalized Beta Mixtures of Gaussians   \n",
            "3744  4390 2011-01-01  Hogwild: A Lock-Free Approach to Parallelizing...   \n",
            "3742  4389 2011-01-01      An Exact Algorithm for F-Measure Maximization   \n",
            "3741  4388 2011-01-01                 Prediction strategies without loss   \n",
            "...    ...        ...                                                ...   \n",
            "4618  5179 2013-01-01  Learning Trajectory Preferences for  Manipulat...   \n",
            "4642  5200 2013-01-01         Non-Linear Domain Adaptation with Boosting   \n",
            "4638  5198 2013-01-01  Higher Order Priors for Joint Intrinsic Image,...   \n",
            "4643  5201 2013-01-01  Modeling Clutter Perception using Parametric P...   \n",
            "4516  5087 2013-01-01  Efficient Optimization for Sparse Gaussian Pro...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3620        NaN  4278-learning-in-hilbert-vs-banach-spaces-a-me...   \n",
            "3798        NaN    4439-generalized-beta-mixtures-of-gaussians.pdf   \n",
            "3744        NaN  4390-hogwild-a-lock-free-approach-to-paralleli...   \n",
            "3742        NaN  4389-an-exact-algorithm-for-f-measure-maximiza...   \n",
            "3741        NaN        4388-prediction-strategies-without-loss.pdf   \n",
            "...         ...                                                ...   \n",
            "4618     Poster  5179-learning-trajectory-preferences-for-manip...   \n",
            "4642     Poster  5200-non-linear-domain-adaptation-with-boostin...   \n",
            "4638     Poster  5198-higher-order-priors-for-joint-intrinsic-i...   \n",
            "4643     Poster  5201-modeling-clutter-perception-using-paramet...   \n",
            "4516     Poster  5087-efficient-optimization-for-sparse-gaussia...   \n",
            "\n",
            "                                               abstract  \\\n",
            "3620  The goal of this paper is to investigate the a...   \n",
            "3798  In recent years, a rich variety of shrinkage p...   \n",
            "3744  Stochastic Gradient Descent (SGD) is a popular...   \n",
            "3742  The F-measure, originally introduced in inform...   \n",
            "3741  Consider a sequence of bits where we are tryin...   \n",
            "...                                                 ...   \n",
            "4618  We consider the problem of learning good traje...   \n",
            "4642  A common assumption in machine vision is that ...   \n",
            "4638  Many methods have been proposed to recover the...   \n",
            "4643  Visual clutter, the perception of an image as ...   \n",
            "4516  We propose an efficient discrete optimization ...   \n",
            "\n",
            "                                             paper_text  \n",
            "3620  Learning in Hilbert vs. Banach Spaces: A Measu...  \n",
            "3798  Generalized Beta Mixtures of Gaussians\\nArtin ...  \n",
            "3744  H OGWILD !: A Lock-Free Approach to Paralleliz...  \n",
            "3742  An Exact Algorithm for F-Measure Maximization\\...  \n",
            "3741  Prediction strategies without loss\\n\\nRina Pan...  \n",
            "...                                                 ...  \n",
            "4618  Learning Trajectory Preferences for Manipulato...  \n",
            "4642  Non-Linear Domain Adaptation with Boosting\\n\\n...  \n",
            "4638  Higher Order Priors for Joint Intrinsic Image,...  \n",
            "4643  Modeling Clutter Perception using Parametric\\n...  \n",
            "4516  Efficient Optimization for\\nSparse Gaussian Pr...  \n",
            "\n",
            "[1034 rows x 7 columns], 9:         id       year                                              title  \\\n",
            "4813  5358 2014-01-01  Probabilistic low-rank matrix completion on fi...   \n",
            "4805  5350 2014-01-01  Learning to Discover Efficient Mathematical Id...   \n",
            "4806  5351 2014-01-01  Searching for Higgs Boson Decay Modes with Dee...   \n",
            "4807  5352 2014-01-01  Semi-supervised Learning with Deep Generative ...   \n",
            "4808  5353 2014-01-01  Two-Stream Convolutional Networks for Action R...   \n",
            "...    ...        ...                                                ...   \n",
            "6042  6466 2016-01-01  Bayesian optimization for automated model sele...   \n",
            "6029  6454 2016-01-01  A Non-parametric Learning Method for Confident...   \n",
            "6041  6465 2016-01-01  R-FCN: Object Detection via Region-based Fully...   \n",
            "6040  6464 2016-01-01       Learning Deep Embeddings with Histogram Loss   \n",
            "6043  6467 2016-01-01  Generalization of ERM in Stochastic Convex Opt...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "4813     Poster  5358-probabilistic-low-rank-matrix-completion-...   \n",
            "4805  Spotlight  5350-learning-to-discover-efficient-mathematic...   \n",
            "4806  Spotlight  5351-searching-for-higgs-boson-decay-modes-wit...   \n",
            "4807  Spotlight  5352-semi-supervised-learning-with-deep-genera...   \n",
            "4808  Spotlight  5353-two-stream-convolutional-networks-for-act...   \n",
            "...         ...                                                ...   \n",
            "6042     Poster  6466-bayesian-optimization-for-automated-model...   \n",
            "6029     Poster  6454-a-non-parametric-learning-method-for-conf...   \n",
            "6041     Poster  6465-r-fcn-object-detection-via-region-based-f...   \n",
            "6040     Poster  6464-learning-deep-embeddings-with-histogram-l...   \n",
            "6043     Poster  6467-generalization-of-erm-in-stochastic-conve...   \n",
            "\n",
            "                                               abstract  \\\n",
            "4813  The task of reconstructing a matrix given a sa...   \n",
            "4805  In this paper we explore how machine learning ...   \n",
            "4806  Particle colliders enable us to probe the fund...   \n",
            "4807  The ever-increasing size of modern data sets c...   \n",
            "4808  We investigate architectures of discriminative...   \n",
            "...                                                 ...   \n",
            "6042  Despite the success of kernel-based nonparamet...   \n",
            "6029  Estimating patient's clinical state from multi...   \n",
            "6041  We present region-based, fully convolutional n...   \n",
            "6040  We suggest a new loss for learning deep embedd...   \n",
            "6043  In stochastic convex optimization the goal is ...   \n",
            "\n",
            "                                             paper_text  \n",
            "4813  Probabilistic low-rank matrix completion on fi...  \n",
            "4805  Learning to Discover\\nEfficient Mathematical I...  \n",
            "4806  Searching for Higgs Boson Decay Modes\\nwith De...  \n",
            "4807  Semi-supervised Learning with\\nDeep Generative...  \n",
            "4808  Two-Stream Convolutional Networks\\nfor Action ...  \n",
            "...                                                 ...  \n",
            "6042  Bayesian optimization for automated model sele...  \n",
            "6029  A Non-parametric Learning Method for Confident...  \n",
            "6041  R-FCN: Object Detection via\\nRegion-based Full...  \n",
            "6040  Learning Deep Embeddings with Histogram Loss\\n...  \n",
            "6043  Generalization of ERM in Stochastic Convex\\nOp...  \n",
            "\n",
            "[1383 rows x 7 columns], 10:         id       year                                              title  \\\n",
            "6935  7273 2017-01-01  Houdini: Fooling Deep Structured Visual and Sp...   \n",
            "6933  7271 2017-01-01  Convergence of Gradient EM on Multi-component ...   \n",
            "6937  7275 2017-01-01  When Cyclic Coordinate Descent Outperforms Ran...   \n",
            "6936  7274 2017-01-01  Efficient and Flexible Inference for Stochasti...   \n",
            "6932  7270 2017-01-01  Kernel Feature Selection via Conditional Covar...   \n",
            "...    ...        ...                                                ...   \n",
            "6707  7067 2017-01-01             Context Selection for Embedding Models   \n",
            "6708  7068 2017-01-01  Working hard to know your neighbor's margins: ...   \n",
            "6709  7069 2017-01-01  Accelerated Stochastic Greedy Coordinate Desce...   \n",
            "6405  6794 2017-01-01  Consistent Multitask Learning with Nonlinear O...   \n",
            "6665  7029 2017-01-01                      Federated Multi-Task Learning   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "6935     Poster  7273-houdini-fooling-deep-structured-visual-an...   \n",
            "6933     Poster  7271-convergence-of-gradient-em-on-multi-compo...   \n",
            "6937     Poster  7275-when-cyclic-coordinate-descent-outperform...   \n",
            "6936     Poster  7274-efficient-and-flexible-inference-for-stoc...   \n",
            "6932     Poster  7270-kernel-feature-selection-via-conditional-...   \n",
            "...         ...                                                ...   \n",
            "6707     Poster    7067-context-selection-for-embedding-models.pdf   \n",
            "6708     Poster  7068-working-hard-to-know-your-neighbors-margi...   \n",
            "6709     Poster  7069-accelerated-stochastic-greedy-coordinate-...   \n",
            "6405     Poster  6794-consistent-multitask-learning-with-nonlin...   \n",
            "6665     Poster             7029-federated-multi-task-learning.pdf   \n",
            "\n",
            "                                               abstract  \\\n",
            "6935  Generating adversarial examples is a critical ...   \n",
            "6933  In this paper, we study convergence properties...   \n",
            "6937  The coordinate descent (CD) method is a classi...   \n",
            "6936  Many real world dynamical systems are describe...   \n",
            "6932  We propose a method for feature selection that...   \n",
            "...                                                 ...   \n",
            "6707  Word embeddings are an effective tool to analy...   \n",
            "6708  We introduce a loss for metric learning, which...   \n",
            "6709  In this paper we study the well-known greedy c...   \n",
            "6405  Key to multitask learning is exploiting the re...   \n",
            "6665  Federated learning poses new statistical and s...   \n",
            "\n",
            "                                             paper_text  \n",
            "6935  Houdini: Fooling Deep Structured Visual and Sp...  \n",
            "6933  Convergence of Gradient EM on Multi-component\\...  \n",
            "6937  When Cyclic Coordinate Descent Outperforms\\nRa...  \n",
            "6936  Efficient and Flexible Inference for Stochasti...  \n",
            "6932  Kernel Feature Selection via\\nConditional Cova...  \n",
            "...                                                 ...  \n",
            "6707  Context Selection for Embedding Models\\n\\nLi-P...  \n",
            "6708  Working hard to know your neighbor?s margins:\\...  \n",
            "6709  Accelerated Stochastic Greedy Coordinate Desce...  \n",
            "6405  Consistent Multitask Learning with\\nNonlinear ...  \n",
            "6665  Federated Multi-Task Learning\\n\\nVirginia Smit...  \n",
            "\n",
            "[679 rows x 7 columns]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT word2phrase to create bigrams and unigrams\n",
        "!git clone https://github.com/travisbrady/word2phrase.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6I115Y--CqF",
        "outputId": "80fdbc5c-dc92-4813-81b5-fac20b517c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'word2phrase' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALL TIME WINDOWS SCI-BERT"
      ],
      "metadata": {
        "id": "kLi7qvOGatyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert List of Time Slice DF paper_text content to lists\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Loop through every DF and convert paper_text to list and concatenate all the papers of one time slice \n",
        "## this will be a list like  [\"All paper content string of first slice\", \"all paper content string of 2nd slice\", ...] \n",
        "\n",
        "papers_contents_list = [\" \".join(time_slice_df[\"paper_text\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n",
        "#### MEASURE THE EXECUTION TIME FOR RUNNING THE CONCATENATION CODE\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "\n",
        "# papers_contents_list\n",
        "# len(papers_contents_list[0])"
      ],
      "metadata": {
        "id": "lrwZ1HOQa9XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc291740-964a-44d5-96f9-f83231e9d734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18548321723937988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Join Paper titles for bigram and unigram extraction\n",
        "\n",
        "\n",
        "papers_titles_list = [\" \".join(time_slice_df[\"title\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n"
      ],
      "metadata": {
        "id": "RcUQthFrPyZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 -  Pre Processing \n",
        "\n",
        "# Remove Stopwords "
      ],
      "metadata": {
        "id": "uGQDbS_N62fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# function to rmeove digits and numbers from papers \n",
        "def regex_remove_digits(papers_contents_list):      \n",
        "    # Remove any digits for the corpus\n",
        "    all_time_window_papers_content_list = [re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", time_slice_paper) \n",
        "                                                    for time_slice_paper in papers_contents_list] \n",
        "    # Remove words with length less than 3 \n",
        "\n",
        "    # https://stackoverflow.com/questions/24332025/remove-words-of-length-less-than-4-from-string\n",
        "    all_time_window_papers_content_list = [re.sub(r'\\b\\w{1,2}\\b', '', time_slice_paper) \n",
        "                                          for time_slice_paper in all_time_window_papers_content_list]\n",
        "\n",
        "    return all_time_window_papers_content_list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4rWzW9Zl7FNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom Stopwords List for Scientific Literature \n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "path_to_stop_words = '/gdrive/My Drive/Master_dataset/stopwords_10000_most_frequent_filtered.txt'\n",
        "\n",
        "with open(path_to_stop_words, \"r\") as file1:\n",
        "    FileasList = file1.readlines()\n",
        "\n",
        "\n",
        "stopwords = [s.strip('\\n') for s in FileasList]\n",
        "print(len(stopwords))\n",
        "\n",
        "\n",
        "scientific_literature_stopwords = text.ENGLISH_STOP_WORDS.union(stopwords)\n",
        "\n",
        "len(scientific_literature_stopwords)\n"
      ],
      "metadata": {
        "id": "EYyOHKZ1QY0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f32d47-e113-49ca-f328-e66a294f382c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9958"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all paper content and titles for bigram and unigram generation\n",
        "all_time_window_papers_content_list = regex_remove_digits(papers_contents_list)\n",
        "all_time_window_papers_title_list = regex_remove_digits(papers_titles_list)\n"
      ],
      "metadata": {
        "id": "EM2Ek6JKQVJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Bag Of Candidate Keywords For All Time Windows"
      ],
      "metadata": {
        "id": "uaAZrFV9eAu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_time_window_papers_titles = \" \".join(all_time_window_papers_title_list)"
      ],
      "metadata": {
        "id": "9vVvUZgCRXXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#About 900 stopwords\n",
        "stop_words = list(stopwords.words('english')) #About 150 stopwords\n",
        "stop_words.extend(scientific_literature_stopwords)\n",
        "\n",
        "\n",
        "\n",
        "token = nltk.word_tokenize(all_time_window_papers_titles)\n",
        "output = [w for w in token if not w in stop_words]\n",
        "bigrams = ngrams(output,2)\n",
        "\n",
        "\n",
        "# candidate_keywords = [ for n in ngrams]\n",
        "ngrams = Counter(bigrams).most_common()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FmvaKqj7CYQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords = [( \" \".join(n[0]) , n[1] )for n in ngrams]\n",
        "candidate_keywords = candidate_keywords[:100]\n",
        "\n",
        "\n",
        "\n",
        "###################################################"
      ],
      "metadata": {
        "id": "ZO9EFTixGRsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords"
      ],
      "metadata": {
        "id": "Pc61_bwVLrDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort all the keywords for every time slice\n",
        "\n",
        "\n",
        "####################################\n",
        "\n",
        "\n",
        "title_ngram_candidate_keywords_time_slices_sorted = [sorted(word_frequency.items(),\n",
        "        key=lambda item: item[1], reverse=True) for word_frequency in paper_title_ngram_candidate_keywords_time_slice]\n",
        "\n",
        "\n",
        "title_ngram_candidate_keywords_time_slices_sorted[:100]\n",
        "\n",
        "\n",
        "#####################################"
      ],
      "metadata": {
        "id": "EECfYbyvdYkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate BERT Embeddings for all time windows\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# List of Candidate Keywords [ [1st time slice candidate keywords], [2nd time slice candidate keywords], .....]\n",
        "content_time_slices_sent_tokens_list = time_slices_sent_tokens_list\n",
        "\n",
        "\n",
        "paper_content_bert_embeddings_all_time_slices_list = [ model.encode(time_slice_content[:100000]) for time_slice_content in content_time_slices_sent_tokens_list ]\n",
        "\n"
      ],
      "metadata": {
        "id": "SAKtIdbDzG7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paper_content_bert_embeddings_all_time_slices_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL3CrYVUzB7L",
        "outputId": "8cbf4f15-bab4-4b90-8051-11998df6b3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get BERT EMbeddings for title ngrams\n",
        "title_ngrams_bert_embeddings_all_time_slices_list = [ model.encode([tup[0] for tup in time_slice_ngrams]) for time_slice_ngrams in title_ngram_candidate_keywords_time_slices_sorted ]\n",
        "\n",
        "\n",
        "title_ngrams_bert_embeddings_all_time_slices_list"
      ],
      "metadata": {
        "id": "pdmiU7aJG84r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_ngrams_bert_embeddings_all_time_slices_list = title_ngrams_bert_embeddings_all_time_slices_list[0]\n",
        "\n",
        "title_ngrams_bert_embeddings_all_time_slices_list"
      ],
      "metadata": {
        "id": "M-0BTDsLKQPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(title_ngrams_bert_embeddings_all_time_slices_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE-6P8GWQpZo",
        "outputId": "6d49f2c0-8b36-4be8-c3c2-1fc399d3c5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Trained Variables in Google Drive as pickle\n",
        "\n",
        "saved_map = {\n",
        "    \"paper_content_bert_embeddings_all_time_slices_list\" : paper_content_bert_embeddings_all_time_slices_list,\n",
        "    \"title_ngrams_bert_embeddings_all_time_slices_list\" : title_ngrams_bert_embeddings_all_time_slices_list\n",
        "}\n",
        "\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/variables.pickle', 'wb') as f:\n",
        "     pickle.dump(saved_map, f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aOfPAvcsROEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the map from globals.\n",
        "del saved_map"
      ],
      "metadata": {
        "id": "8wHJ9V0lUqba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pickled variable saved in Drive.\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/variables.pickle', 'rb') as f:\n",
        "  saved_map = pickle.load(f)\n",
        "\n",
        "paper_content_bert_embeddings_all_time_slices_list_ = saved_map[\"paper_content_bert_embeddings_all_time_slices_list\"]"
      ],
      "metadata": {
        "id": "CqMQjkD6UvAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paper_content_bert_embeddings_all_time_slices_list_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaT2BxFBU8fp",
        "outputId": "f264fcc4-a2a1-4590-85ce-14cad14f5422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2298"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 : Calculate Cosine Similarity of Candidate Keyowrds"
      ],
      "metadata": {
        "id": "GdSZMLzZb5v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Textual Similarity b/w corpus and candidate keywords\n",
        "from sentence_transformers import util\n",
        "\n",
        "cosine_scores = util.cos_sim(title_ngrams_bert_embeddings_all_time_slices_list, title_ngrams_bert_embeddings_all_time_slices_list)\n",
        "\n",
        "cosine_scores_list = paper_content_bert_embeddings_all_time_slices_list_\n",
        "\n",
        "top_n = 200\n",
        "# keywords = [candidate_keywords_bow[index] for index in cosine_scores.argsort()[0][-top_n:]]\n",
        "keywords\n",
        "\n",
        "\n",
        "# cosine_scores.argsort()[0][-top_n:]\n",
        "cosine_scores.argsort()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1cA73Q9cAgR",
        "outputId": "d24dad68-d3ba-4b16-a861-a73c987f00f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[343, 332, 344,  ..., 288, 220,   0],\n",
              "        [237, 257, 258,  ..., 355, 352,   1],\n",
              "        [243, 370, 257,  ...,  18, 343,   2],\n",
              "        ...,\n",
              "        [170, 344, 300,  ..., 224, 398, 397],\n",
              "        [243, 344, 188,  ..., 224, 397, 398],\n",
              "        [258, 386,  23,  ..., 215, 359, 399]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST 3 - BERT EMBEDDING GENERATE"
      ],
      "metadata": {
        "id": "kTigylDrZ2xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_ngram_candidate_keywords_time_slices_sorted = title_ngram_candidate_keywords_time_slices_sorted[0]"
      ],
      "metadata": {
        "id": "1kvz3ODWgWRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_ngram_candidate_keywords_time_slices_sorted_ = [ngram[0] for ngram in candidate_keywords]\n",
        "t = \"\\n\".join(title_ngram_candidate_keywords_time_slices_sorted_)\n",
        "t"
      ],
      "metadata": {
        "id": "4fcx51Krc-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install Unidecode"
      ],
      "metadata": {
        "id": "j6BqKd5ZheKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c06b772-8dd6-4a6f-e463-3091126324b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.12.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.24.48)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.48 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.27.48)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.48->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.48->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.48->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     || 235 kB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "from collections import OrderedDict\n",
        "import unidecode\n",
        "import numpy as np\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline"
      ],
      "metadata": {
        "id": "x6P0dfVehoGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "import torch\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "mTl8ffpftcpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dbe055c9-c1b0-4779-dc26-ec0052cdec50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Use the pre-trained Base BERT model \n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.cuda()\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "FKo54yLjzQut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff814b6c-eb54-4937-8123-2b63211e53ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 407873900/407873900 [00:06<00:00, 60863021.85B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class Data():\n",
        "\n",
        "    def __getitem__(self, content=None):\n",
        "         if content!=None:\n",
        "             self.doc = \"\".join(content)\n",
        "         return self.doc\n",
        "     \n",
        "    def _preprocess(self,targets,corpus):\n",
        "        self.index=[]\n",
        "        self.t_index=OrderedDict()\n",
        "        for target in targets:\n",
        "            \n",
        "            for _,item in enumerate(corpus):\n",
        "                # if target in item:\n",
        "                  if item.lower().find(target) != -1:\n",
        "                # if bool(re.search(target, item)):\n",
        "\n",
        "                      count_target=item.count(target)\n",
        "                  #   Avoiding the sentences with multiple occurrences of the target term for the time being###\n",
        "                      if count_target==1:\n",
        "                        if target not in self.t_index.keys():\n",
        "                            self.t_index[target]=[_]\n",
        "                        else:\n",
        "                            self.t_index[target].append(_)\n",
        "                        self.index.append(_)\n",
        "        return self.index,self.t_index"
      ],
      "metadata": {
        "id": "7FhI9iflZ-2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "LOAD & EXTRACT DATA\n",
        "'''\n",
        "import os\n",
        "\n",
        "\n",
        "# OUTPUT_DIR = root_dir+'Colab Notebooks/Challenge_Semeval/CLUSTERING/English_test/' # the path thatcontains the (Corpus1_text, Corpus2_text, Targets)\n",
        "# p1 = os.path.join(OUTPUT_DIR, 'ccoha1.txt')\n",
        "# p2 = os.path.join(OUTPUT_DIR, 'ccoha2.txt')\n",
        "# t = os.path.join(OUTPUT_DIR, 'targets.txt')\n",
        "\n",
        "# INPUT_DIR = '.\\\\evaluation\\\\semeval2020_ulscd_eng\\\\'\n",
        "# p1 = os.path.join(INPUT_DIR, 'corpus1\\\\ccoha1.txt')\n",
        "# p2 = os.path.join(INPUT_DIR, 'corpus2\\\\ccoha2.txt')\n",
        "# #TARGET_DIR = '.\\\\targets\\\\'\n",
        "# t = os.path.join(INPUT_DIR, 'targets.txt')\n",
        "# p1='ccoha1.txt'\n",
        "# p2='ccoha2.txt'\n",
        "# t='targets.txt'\n",
        "\n",
        "p1 = nips_papers_partitions[0][\"paper_text\"].tolist()\n",
        "p2 = nips_papers_partitions[1][\"paper_text\"].tolist()\n",
        "p3 = nips_papers_partitions[2][\"paper_text\"].tolist()\n",
        "p4 = nips_papers_partitions[3][\"paper_text\"].tolist()\n",
        "p5 = nips_papers_partitions[4][\"paper_text\"].tolist()\n",
        "p6 = nips_papers_partitions[5][\"paper_text\"].tolist()\n",
        "p7 = nips_papers_partitions[6][\"paper_text\"].tolist()\n",
        "p8 = nips_papers_partitions[7][\"paper_text\"].tolist()\n",
        "p9 = nips_papers_partitions[8][\"paper_text\"].tolist()\n",
        "p10 = nips_papers_partitions[9][\"paper_text\"].tolist()\n",
        "\n",
        "\n",
        "t = t\n",
        "datasets = Data() \n",
        "\n",
        "# doc1 =  [\"Sentence1\", \"Sentence2\".....]\n",
        "doc1=datasets.__getitem__(p1).split('\\n')   \n",
        "doc2=datasets.__getitem__(p2).split('\\n')\n",
        "doc3=datasets.__getitem__(p3).split('\\n')\n",
        "doc4=datasets.__getitem__(p4).split('\\n')\n",
        "doc5=datasets.__getitem__(p5).split('\\n')\n",
        "doc6=datasets.__getitem__(p6).split('\\n')\n",
        "doc7=datasets.__getitem__(p7).split('\\n')\n",
        "doc8=datasets.__getitem__(p8).split('\\n')\n",
        "doc9=datasets.__getitem__(p9).split('\\n')\n",
        "doc10=datasets.__getitem__(p10).split('\\n')\n",
        "\n",
        "\n",
        "t1=datasets.__getitem__(t).split('\\n')\n",
        "target_act=[x for x in t1 if len(x)>1]\n",
        "t1=[x.lower() for x in t1 if len(x)>1]\n",
        "\n",
        "index1=datasets._preprocess(t1,doc1)\n",
        "index2=datasets._preprocess(t1,doc2)\n",
        "index3=datasets._preprocess(t1,doc3)\n",
        "index4=datasets._preprocess(t1,doc4)\n",
        "index5=datasets._preprocess(t1,doc5)\n",
        "index6=datasets._preprocess(t1,doc6)\n",
        "index7=datasets._preprocess(t1,doc7)\n",
        "index8=datasets._preprocess(t1,doc8)\n",
        "index9=datasets._preprocess(t1,doc9)\n",
        "index10=datasets._preprocess(t1,doc10)\n",
        "\n",
        "\n",
        "index_t1=index1[1]\n",
        "index_t2=index2[1]\n",
        "index_t3=index3[1]\n",
        "index_t4=index4[1]\n",
        "index_t5=index5[1]\n",
        "index_t6=index6[1]\n",
        "index_t7=index7[1]\n",
        "index_t8=index8[1]\n",
        "index_t9=index9[1]\n",
        "index_t10=index10[1]\n",
        "\n",
        "print('The target words are:',t1)\n",
        "target_words=t1\n",
        "\n",
        "print('The index_t1 are ', index_t1)\n",
        "print('The index_t2 are ', index_t2)\n",
        "\n",
        "\n",
        "#conversions\n",
        "target_uni=[unidecode.unidecode(m) for m in t1]\n",
        "target_toks=[]\n",
        "# print(target_uni)\n",
        "for k in t1:\n",
        "  target_toks.append(tokenizer.tokenize(k))\n",
        "print('converted target toks',target_toks)"
      ],
      "metadata": {
        "id": "WBbu-VZwaN3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e5e581-7614-4e85-c1a6-3dc5ff6fb116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target words are: ['neural networks', 'reinforcement learning', 'neural network', 'gaussian process', 'graphical models', 'support vector', 'gaussian processes', 'active learning', 'variational inference', 'monte carlo', 'online learning', 'speech recognition', 'recurrent neural', 'component analysis', 'gradient descent', 'hidden markov', ': the', 'deep learning', 'learning :', 'markov models', 'vector machines', 'analog vlsi', 'stochastic gradient', 'markov decision', 'feature selection', ': learning', 'networks learning', 'random fields', 'machine learning', 'networks :', 'belief propagation', 'kernel learning', 'unsupervised learning', 'neural networks', 'model selection', 'matrix completion', 'dynamic programming', 'function approximation', 'decision processes', 'object recognition', 'time series', 'mixture models', 'latent variable', 'metric learning', 'deep neural', 'spiking neurons', 'bayesian inference', 'density estimation', 'approximate inference', 'convex optimization', 'supervised learning', 'dynamical systems', 'convolutional neural', 'generative models', 'large scale', 'matrix factorization', ': application', 'stochastic optimization', 'natural images', 'spectral clustering', 'learning the', 'dimensionality reduction', 'principal component', 'learning sparse', 'object detection', 'map inference', 'visual cortex', 'recurrent networks', 'radial basis', 'risk minimization', 'nearest neighbor', 'independent component', 'high dimensional', 'large margin', 'structured prediction', 'learning algorithms', 'neural net', 'learning multiple', 'bayesian model', 'models learning', 'bayesian networks', 'policy gradient', 'variational bayesian', 'process regression', 'sparse coding', 'domain adaptation', 'learning deep', 'recognition using', 'artificial neural', 'mean field', 'maximum likelihood', 'missing data', 'sample complexity', 'exponential family', 'deep networks', 'coordinate descent', 'associative memory', 'basis function', 'feature extraction', 'boltzmann machines']\n",
            "The index_t1 are  OrderedDict([('neural networks', [55, 59, 67, 93, 527, 609, 611, 644, 645, 1192, 1665, 1689, 1773, 2651, 2700, 3665, 4854, 4868, 5136, 5181, 5328, 5340, 5398, 5428, 6241, 6357, 6667, 6701, 6721, 6801, 7262, 7267, 7275, 7647, 7825, 8280, 8669, 8671, 8680, 8789, 8794, 9999, 10001, 10002, 10005, 10018, 10072, 11879, 12834, 14032, 14697, 14699, 15068, 15364, 15372, 15376, 15892, 15895, 15950, 15957, 16257, 16270, 17420, 18681, 18733, 19662, 20650, 21159, 22283, 22323, 22347, 22354, 22356, 22365, 22796, 26348, 26914, 27244, 28050, 28902, 29367, 30442, 30483, 30486, 30546, 30558, 30561, 30915, 30936, 30938, 32606, 32657, 32661, 32681, 33233, 33258, 33329, 33360, 33431, 33441, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34268, 34971, 35531, 35548, 35858, 35896, 36337, 36395, 36413, 36892, 36897, 36899, 36910, 36938, 37320, 37504, 37509, 37511, 38128, 38897, 38912, 42588, 44434, 44446, 46317, 47396, 48398, 48538, 48987, 49005, 49061, 49076, 49772, 49774, 49798, 49840, 50496, 50576, 50611, 50637, 52209, 52289, 52370, 53161, 53374, 56521, 56720, 56724, 56840, 56884, 56998, 57005, 57781, 57801, 58481, 59008, 59042, 59053, 59055, 59651, 59856, 61183, 61192, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 64670, 65360, 66391, 66400, 66452, 66854, 66859, 66863, 66868, 67653, 69142, 69149, 69446, 69483, 69960, 69962, 69980, 71940, 72476, 72483, 72486, 73170, 73175, 73279, 73369, 75827, 75833, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76351, 76397, 77195, 77207, 77593, 77599, 77611, 77625, 79379, 79409, 79510, 79825, 81758, 82044, 82566, 82594, 82599, 83219, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86635, 87042, 87086, 87462, 87473, 88956, 89195, 89219, 89266, 90718, 92327, 92357, 92359, 92366, 92372, 92373, 92376, 92379, 92380, 92631, 92665, 92676, 92819, 92824, 92873, 92967, 93699, 93701, 93708, 93714, 93728, 94100, 94154, 94158, 94170, 94235, 94238, 94240, 94577, 95681, 95718, 95746, 95967, 96006, 96093, 97183, 97187, 97908, 97974, 97987, 97996, 99036, 99090, 99125, 99258, 101124, 101890, 101893, 103041, 103076, 103114, 103327, 103481, 106635, 108079, 108440, 108459, 108461, 108503, 108510, 108516, 108727, 108927, 108956, 109826, 109966, 110133, 111659, 111660, 112455, 113161, 117952, 118424, 119251, 121389, 121392, 121393, 121402, 121403, 121430, 121438, 121439, 121441, 121442, 121443, 121501, 121502, 121507, 121509, 121602, 121609, 121610, 121640, 121651, 121672, 121689, 121698, 121699, 121700, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122255, 122264, 122267, 122279, 122815, 122820, 122829, 123360, 123391, 123416, 123454, 123914, 124793, 124802, 125275, 125333, 125385, 125754, 125755, 125757, 125828, 129598, 129995, 129999, 130107, 130186, 130192, 130211, 130217, 130282, 130424, 130435, 130445, 130471, 130480, 130490, 130493, 131234, 131455, 131469, 131472, 131932, 132120, 132153, 133540, 135026, 135029, 135072, 135243, 135306, 135647, 135686, 135787, 135788, 135885, 136727, 136739, 136786, 137044, 137055, 137058, 137063, 137068, 137095, 139207, 140011, 140012, 140425, 140430, 140475, 140476, 140493, 140499, 140540, 140954, 140956, 141072, 141098, 141295, 143950, 144992, 145013, 146825, 55, 59, 67, 93, 527, 609, 611, 644, 645, 1192, 1665, 1689, 1773, 2651, 2700, 3665, 4854, 4868, 5136, 5181, 5328, 5340, 5398, 5428, 6241, 6357, 6667, 6701, 6721, 6801, 7262, 7267, 7275, 7647, 7825, 8280, 8669, 8671, 8680, 8789, 8794, 9999, 10001, 10002, 10005, 10018, 10072, 11879, 12834, 14032, 14697, 14699, 15068, 15364, 15372, 15376, 15892, 15895, 15950, 15957, 16257, 16270, 17420, 18681, 18733, 19662, 20650, 21159, 22283, 22323, 22347, 22354, 22356, 22365, 22796, 26348, 26914, 27244, 28050, 28902, 29367, 30442, 30483, 30486, 30546, 30558, 30561, 30915, 30936, 30938, 32606, 32657, 32661, 32681, 33233, 33258, 33329, 33360, 33431, 33441, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34268, 34971, 35531, 35548, 35858, 35896, 36337, 36395, 36413, 36892, 36897, 36899, 36910, 36938, 37320, 37504, 37509, 37511, 38128, 38897, 38912, 42588, 44434, 44446, 46317, 47396, 48398, 48538, 48987, 49005, 49061, 49076, 49772, 49774, 49798, 49840, 50496, 50576, 50611, 50637, 52209, 52289, 52370, 53161, 53374, 56521, 56720, 56724, 56840, 56884, 56998, 57005, 57781, 57801, 58481, 59008, 59042, 59053, 59055, 59651, 59856, 61183, 61192, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 64670, 65360, 66391, 66400, 66452, 66854, 66859, 66863, 66868, 67653, 69142, 69149, 69446, 69483, 69960, 69962, 69980, 71940, 72476, 72483, 72486, 73170, 73175, 73279, 73369, 75827, 75833, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76351, 76397, 77195, 77207, 77593, 77599, 77611, 77625, 79379, 79409, 79510, 79825, 81758, 82044, 82566, 82594, 82599, 83219, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86635, 87042, 87086, 87462, 87473, 88956, 89195, 89219, 89266, 90718, 92327, 92357, 92359, 92366, 92372, 92373, 92376, 92379, 92380, 92631, 92665, 92676, 92819, 92824, 92873, 92967, 93699, 93701, 93708, 93714, 93728, 94100, 94154, 94158, 94170, 94235, 94238, 94240, 94577, 95681, 95718, 95746, 95967, 96006, 96093, 97183, 97187, 97908, 97974, 97987, 97996, 99036, 99090, 99125, 99258, 101124, 101890, 101893, 103041, 103076, 103114, 103327, 103481, 106635, 108079, 108440, 108459, 108461, 108503, 108510, 108516, 108727, 108927, 108956, 109826, 109966, 110133, 111659, 111660, 112455, 113161, 117952, 118424, 119251, 121389, 121392, 121393, 121402, 121403, 121430, 121438, 121439, 121441, 121442, 121443, 121501, 121502, 121507, 121509, 121602, 121609, 121610, 121640, 121651, 121672, 121689, 121698, 121699, 121700, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122255, 122264, 122267, 122279, 122815, 122820, 122829, 123360, 123391, 123416, 123454, 123914, 124793, 124802, 125275, 125333, 125385, 125754, 125755, 125757, 125828, 129598, 129995, 129999, 130107, 130186, 130192, 130211, 130217, 130282, 130424, 130435, 130445, 130471, 130480, 130490, 130493, 131234, 131455, 131469, 131472, 131932, 132120, 132153, 133540, 135026, 135029, 135072, 135243, 135306, 135647, 135686, 135787, 135788, 135885, 136727, 136739, 136786, 137044, 137055, 137058, 137063, 137068, 137095, 139207, 140011, 140012, 140425, 140430, 140475, 140476, 140493, 140499, 140540, 140954, 140956, 141072, 141098, 141295, 143950, 144992, 145013, 146825]), ('reinforcement learning', [19716, 19802, 20214, 20240, 20343, 20345, 20605, 20655, 51729, 51737, 60828, 60830, 109822, 109838, 109844, 109968, 109972, 109974, 109976, 110133, 119714, 119732, 119742, 120170, 120344, 120345, 120372]), ('neural network', [10, 55, 59, 67, 93, 178, 527, 609, 611, 622, 644, 645, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1934, 1950, 1952, 1957, 1972, 2583, 2651, 2653, 2654, 2700, 2706, 2796, 2814, 2817, 2824, 2933, 3086, 3128, 3607, 3665, 3672, 3705, 3855, 3876, 4854, 4855, 4868, 4870, 4891, 5136, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 6241, 6323, 6357, 6667, 6701, 6721, 6792, 6801, 6802, 6851, 7262, 7267, 7273, 7275, 7290, 7454, 7456, 7641, 7647, 7825, 8280, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9383, 9534, 9749, 9969, 9974, 9975, 9999, 10001, 10002, 10005, 10013, 10016, 10018, 10045, 10072, 11879, 12245, 12834, 12908, 13276, 13351, 14032, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15892, 15895, 15950, 15957, 15979, 16062, 16257, 16270, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17529, 18681, 18733, 19659, 19662, 20650, 20674, 21159, 21240, 22283, 22323, 22347, 22354, 22356, 22365, 22387, 22779, 22796, 23038, 23159, 23168, 23175, 26348, 26844, 26864, 26914, 27188, 27244, 28050, 28667, 28793, 28902, 29003, 29038, 29058, 29060, 29285, 29367, 29833, 30442, 30445, 30483, 30484, 30486, 30496, 30546, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30854, 30915, 30936, 30938, 30943, 30963, 32144, 32166, 32606, 32657, 32661, 32681, 33225, 33233, 33247, 33251, 33258, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34253, 34258, 34268, 34301, 34417, 34891, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35896, 36322, 36325, 36331, 36337, 36382, 36395, 36413, 36416, 36493, 36548, 36747, 36750, 36784, 36802, 36892, 36897, 36899, 36910, 36913, 36919, 36929, 36938, 37053, 37121, 37157, 37320, 37369, 37385, 37420, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 38128, 38897, 38898, 38904, 38908, 38912, 38919, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43706, 43761, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45657, 46258, 46317, 47396, 48398, 48405, 48408, 48538, 48592, 48594, 48640, 48647, 48706, 48770, 48876, 48879, 48891, 48900, 48901, 48987, 49002, 49005, 49016, 49021, 49025, 49061, 49063, 49076, 49094, 49294, 49542, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50611, 50637, 51186, 51201, 51214, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55952, 56521, 56720, 56724, 56840, 56857, 56865, 56884, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57781, 57801, 58223, 58275, 58465, 58481, 59008, 59042, 59053, 59055, 59639, 59651, 59856, 59926, 60715, 61176, 61183, 61192, 61504, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 62891, 62906, 64670, 65360, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69142, 69149, 69446, 69483, 69673, 69960, 69962, 69980, 70832, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72473, 72476, 72483, 72486, 72487, 72550, 72588, 73156, 73167, 73170, 73171, 73175, 73279, 73369, 74215, 74797, 74832, 75041, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76332, 76351, 76397, 76413, 76528, 76617, 76719, 77195, 77207, 77218, 77228, 77593, 77599, 77610, 77611, 77625, 78264, 78279, 78522, 78545, 79379, 79409, 79510, 79825, 81267, 81758, 82044, 82566, 82594, 82599, 83219, 83259, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87086, 87462, 87473, 87918, 87932, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 90486, 90598, 90622, 90638, 90718, 90725, 92322, 92327, 92357, 92359, 92361, 92366, 92372, 92373, 92376, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92676, 92819, 92824, 92873, 92967, 93655, 93699, 93701, 93708, 93714, 93717, 93728, 93731, 94080, 94100, 94142, 94151, 94154, 94158, 94170, 94221, 94235, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95672, 95681, 95746, 95854, 95967, 96006, 96014, 96024, 96093, 96213, 96661, 96685, 97183, 97187, 97199, 97225, 97908, 97974, 97987, 97996, 98367, 99036, 99090, 99123, 99125, 99258, 99266, 100805, 101124, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103492, 103493, 103590, 103684, 103728, 103734, 103742, 106635, 106645, 108061, 108072, 108079, 108103, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108727, 108927, 108937, 108956, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 111656, 111659, 111660, 112074, 112438, 112455, 113161, 113753, 115874, 115878, 117952, 118424, 119251, 119722, 120918, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122247, 122254, 122264, 122267, 122279, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123416, 123454, 123914, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125375, 125385, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125828, 125829, 125831, 126020, 126025, 126027, 126087, 126100, 126126, 127242, 127457, 128631, 129031, 129598, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130445, 130471, 130480, 130490, 130493, 130627, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134433, 134473, 135026, 135029, 135072, 135239, 135243, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136727, 136739, 136760, 136762, 136772, 136786, 136820, 137044, 137055, 137058, 137063, 137068, 137095, 138161, 138378, 138424, 138744, 138759, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139448, 139994, 140011, 140012, 140016, 140385, 140425, 140430, 140475, 140476, 140484, 140493, 140495, 140499, 140540, 140954, 140956, 141004, 141011, 141072, 141098, 141295, 142457, 142465, 143092, 143149, 143183, 143265, 143303, 143313, 143398, 143410, 143411, 143492, 143924, 143950, 144992, 145013, 145324, 145362, 145733, 146825]), ('active learning', [43726, 43898, 130427]), ('monte carlo', [76705]), ('online learning', [96036]), ('speech recognition', [12291, 12353, 12894, 15377, 15396, 15459, 18676, 31446, 32154, 32157, 34962, 35897, 44444, 47157, 47360, 50332, 50392, 50393, 54326, 54419, 54967, 56823, 60706, 60749, 61529, 61548, 61821, 61849, 61861, 61865, 61883, 74274, 74289, 75156, 75175, 76868, 76908, 77147, 77593, 77609, 77610, 77618, 77739, 78175, 83221, 83232, 88958, 89938, 90529, 90530, 90622, 90660, 90662, 90664, 90668, 90674, 90680, 91795, 91800, 91807, 91817, 91827, 92265, 92306, 103036, 103038, 103052, 103062, 103064, 103301, 108064, 108084, 108440, 108442, 109410, 109426, 109788, 110109, 111647, 111651, 111655, 111659, 118086, 124675, 124803, 125272, 128008, 128319, 128418, 128633, 129013, 129600, 136728, 136741, 136873, 136879, 136969, 137044, 137052, 137068, 144416, 144539, 144999]), ('recurrent neural', [4245, 14699, 15950, 66391, 69483, 78264, 82566, 90718, 108416, 122815, 122829, 129999, 137063, 143150, 143183, 146825]), ('component analysis', [41496, 48534, 90930, 90955, 91252, 91277, 143476]), ('gradient descent', [703, 704, 788, 3675, 3799, 3903, 3986, 4133, 4179, 10703, 10741, 11803, 12018, 13158, 15391, 16733, 16943, 16994, 17013, 17019, 17025, 17084, 17250, 21878, 21927, 22212, 22252, 22257, 23162, 23219, 23285, 23330, 23334, 23339, 32497, 35169, 37875, 37880, 37981, 42088, 46692, 46756, 49237, 49238, 49270, 49273, 54331, 54332, 54377, 58752, 58754, 59077, 59169, 59608, 66268, 67641, 67686, 67818, 67944, 68021, 68595, 71212, 71614, 71658, 73838, 73980, 79384, 79867, 79889, 79917, 83150, 90932, 90960, 91254, 91282, 96002, 97429, 97453, 97754, 102883, 112081, 112083, 114207, 114278, 114365, 117660, 117879, 118058, 122251, 122692, 123485, 123820, 123924, 129778, 134373, 137962, 139284, 139306, 140541, 142595, 142624, 142635, 143143, 143214, 143319, 143787]), (': the', [19, 1015, 1630, 2848, 4066, 4103, 11362, 11367, 11604, 11659, 11729, 16076, 16604, 17525, 20840, 21117, 21119, 23977, 26744, 28256, 28596, 29303, 36275, 37558, 38035, 38763, 41230, 41233, 43933, 45388, 45766, 45869, 45871, 45887, 45938, 46300, 46667, 49163, 49272, 51255, 51455, 55943, 55950, 58960, 59673, 61583, 61794, 62155, 63000, 63004, 63100, 64181, 64182, 64297, 65689, 65979, 66076, 66185, 66860, 71900, 73905, 77622, 78626, 78634, 82431, 85780, 87564, 87890, 90526, 91426, 91555, 99255, 101728, 102500, 102880, 103836, 104064, 107114, 108349, 108674, 108732, 108781, 108910, 109104, 111920, 117119, 117399, 117513, 117822, 120971, 121788, 123373, 123568, 123663, 123676, 124452, 124477, 124613, 127103, 127110, 128009, 131477, 133173, 134995, 135606, 135681, 136909, 137096, 138401, 138402, 138403, 139382, 139404, 139435, 140557, 142341, 145347, 145635, 146452]), ('analog vlsi', [140488]), ('stochastic gradient', [704, 12018, 23339, 61009]), ('feature selection', [73282, 134033, 139945]), (': learning', [117793, 130296]), ('networks learning', [23559, 23653, 84028, 84030, 101903, 101972, 101974, 140648, 140692, 140848]), ('random fields', [2816]), ('machine learning', [19826, 23149, 23237, 28594, 47156, 51755, 92320, 92323, 92337, 92363, 92405, 110156, 129634, 134371]), ('unsupervised learning', [20353, 20629, 26312, 26333, 28058, 51734, 51768, 60546, 61502, 61504, 64785, 70013, 91774, 101851, 104005, 112057, 112503, 114965, 120918, 120925, 123397, 128954, 132141, 142357, 142444, 143457, 143492]), ('dynamic programming', [15369, 15459, 15460, 92015, 92016, 92296, 109868, 137730]), ('function approximation', [71123, 97259, 99114, 102877, 109836, 131612, 131618, 133844]), ('object recognition', [19212, 19228, 19667, 19668, 19671, 66112, 90477, 114997, 115208, 120424, 120787, 139209, 141563, 142137, 142145, 142432, 142478]), ('time series', [10006, 10022, 10036, 10037, 10213, 10231, 10233, 10238, 10250, 10310, 10605, 16413, 16456, 54240, 58392, 58412, 58442, 58445, 58448, 58451, 58457, 58473, 71920, 101222, 101231, 102649, 112133, 138067, 138769, 138887, 138889, 138893, 138906]), ('mixture models', [111273]), ('spiking neurons', [106618, 136127, 136165]), ('convex optimization', [90917, 91239]), ('supervised learning', [628, 19713, 19814, 19819, 20208, 20218, 20220, 20353, 20629, 26312, 26333, 28033, 28058, 28533, 28627, 28633, 28643, 28654, 32147, 51732, 51734, 51768, 54422, 58202, 59027, 59042, 59043, 59076, 59605, 60545, 60546, 60553, 61502, 61504, 64783, 64785, 65294, 70013, 71120, 71146, 77067, 84022, 91774, 99540, 101851, 104005, 109819, 109843, 112057, 112503, 113650, 114031, 114965, 117450, 119251, 119730, 120343, 120918, 120925, 123137, 123299, 123397, 128954, 130471, 130719, 132141, 137912, 139659, 141110, 142357, 142366, 142444, 142500, 143457, 143492]), ('dynamical systems', [3666, 3680, 4181, 4384, 10028, 10312, 16167, 26425, 36891, 36900, 36904, 36909, 37504, 52210, 52221, 52353, 52355, 52376, 52399, 52540, 52603, 53164, 53167, 56811, 56865, 56869, 56874, 56882, 56887, 85067, 85068, 109956, 131100, 131197, 131252, 134992, 138179, 146711, 146712]), ('large scale', [11887, 34244, 37504, 53731, 55320, 69467, 77617, 78175, 86570, 105360, 105667, 106118, 112059, 143996, 144394]), (': application', [61883, 83232]), ('natural images', [32401]), ('learning the', [11234, 11651, 20269, 21930, 28036, 29980, 34543, 42298, 42468, 52126, 59542, 60324, 60690, 72010, 78155, 99164, 101764, 102066, 112537, 120348, 122877, 122980, 123220, 130062, 130084, 130103, 131216, 133541, 134988, 140648, 140848, 141764]), ('dimensionality reduction', [56790, 89935, 112412, 112413, 128327, 128330, 143459, 143485, 143493]), ('principal component', [41496, 48534, 48743, 61381, 90930, 90955, 91252, 91277, 143476, 143489]), ('visual cortex', [1202, 1211, 1229, 1244, 1679, 46250, 53368, 53370, 53594, 53795, 61378, 64679, 65327, 75119, 82051, 82053, 82065, 82077, 83693, 83759, 83855, 83984, 89334, 89809, 91389, 91400, 91430, 91435, 91740, 104755, 105243, 110691, 111089, 120397, 120429, 120898, 124255, 134018, 134245, 134419, 143918, 143923, 143945, 143975, 143976, 144000, 144010, 144058, 144061, 144063, 144064, 144071, 144076, 144082, 144092, 144143, 144154, 144187, 144365, 144377, 144381, 144384, 146310, 146334, 146340, 146343]), ('recurrent networks', [15959, 16174, 34560, 38459, 42322, 68745, 69056, 76900, 77171, 82562, 90693, 114832, 118057, 122239, 122577, 136939, 137047]), ('radial basis', [71561, 71563, 100826, 112049, 112488, 133843, 142500]), ('nearest neighbor', [6202, 6211, 6215, 7585, 15373, 31441, 31448, 31458, 31935, 31938, 32016, 32127, 32138, 32139, 38370, 39125, 39392, 41003, 64521, 66551, 72583, 72587, 73082, 73166, 73942, 74880, 74885, 75024, 82608, 82903, 91508, 91517, 100182, 100546, 100739, 102607, 102608, 102609, 102639, 102642, 102643, 102645, 102647, 102648, 102651, 102653, 102654, 102663, 102685, 102757, 103326, 104809, 104968, 111137, 119578, 129011, 129038, 129201, 129222, 129318, 129373, 129483, 129550, 142502, 142568, 142593, 142774]), ('independent component', [7614]), ('high dimensional', [10650, 29034, 29200, 36919, 36930, 37515, 102053, 112103, 112107, 112120, 112402, 113092, 120727, 131482, 143465, 143466, 143885]), ('learning algorithms', [3677, 3715, 5055, 5060, 7606, 7653, 10587, 11909, 17446, 19709, 19737, 20196, 23147, 23329, 26796, 28067, 28079, 28596, 28704, 37448, 41982, 41986, 42486, 44531, 44812, 47405, 49076, 51728, 51764, 60243, 68519, 70000, 71120, 71146, 72006, 72040, 72219, 72421, 73176, 77761, 82099, 84519, 84912, 85751, 88254, 89611, 89786, 94277, 96004, 98367, 100835, 101792, 109836, 109844, 112418, 119264, 119335, 119583, 120358, 122267, 122285, 122786, 123137, 123299, 127496, 127503, 127510, 127528, 127615, 127945, 130484, 130543, 131933, 135061, 140373]), ('neural net', [10, 55, 59, 67, 93, 178, 527, 609, 611, 622, 644, 645, 649, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1934, 1950, 1952, 1957, 1972, 2583, 2653, 2654, 2662, 2669, 2688, 2700, 2706, 2796, 2814, 2817, 2824, 2833, 2933, 2990, 3009, 3086, 3128, 3607, 3665, 3672, 3705, 3855, 3876, 4256, 4854, 4855, 4868, 4870, 4891, 5136, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 6241, 6323, 6357, 6667, 6701, 6721, 6792, 6801, 6802, 6851, 7262, 7267, 7273, 7275, 7290, 7454, 7456, 7641, 7647, 7825, 8280, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9383, 9534, 9749, 9966, 9969, 9974, 9975, 9999, 10001, 10002, 10003, 10005, 10007, 10009, 10013, 10016, 10018, 10045, 10048, 10050, 10051, 10052, 10055, 10057, 10072, 10077, 10259, 10261, 10288, 10299, 10308, 10314, 10321, 10554, 10586, 10589, 10595, 10596, 10610, 10615, 10617, 10636, 10660, 10669, 11879, 12245, 12834, 12908, 13276, 13351, 14032, 14036, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15403, 15404, 15456, 15892, 15895, 15950, 15957, 15979, 16062, 16257, 16270, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17529, 18086, 18129, 18681, 18733, 19659, 19662, 20650, 20674, 20707, 21139, 21159, 21240, 22283, 22323, 22347, 22354, 22356, 22365, 22387, 22779, 22796, 23038, 23159, 23168, 23175, 25506, 26348, 26844, 26864, 26914, 27102, 27188, 27244, 28050, 28667, 28747, 28793, 28902, 29003, 29038, 29058, 29060, 29285, 29367, 29833, 30442, 30445, 30483, 30484, 30486, 30496, 30502, 30546, 30556, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30839, 30843, 30854, 30915, 30936, 30938, 30943, 30963, 31448, 31459, 31772, 32144, 32151, 32155, 32166, 32606, 32657, 32661, 32681, 33225, 33233, 33247, 33251, 33258, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34253, 34258, 34268, 34301, 34417, 34891, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35882, 35887, 35896, 36059, 36310, 36322, 36325, 36331, 36337, 36382, 36395, 36413, 36416, 36493, 36548, 36747, 36750, 36784, 36802, 36812, 36892, 36897, 36899, 36910, 36913, 36919, 36929, 36938, 37053, 37121, 37157, 37320, 37369, 37385, 37420, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 38128, 38897, 38898, 38904, 38908, 38912, 38919, 39995, 41958, 41970, 41981, 42149, 42170, 42173, 42176, 42179, 42188, 42224, 42247, 42256, 42303, 42310, 42323, 42441, 42442, 42445, 42446, 42453, 42475, 42480, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43706, 43761, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45640, 45645, 45657, 46258, 46317, 47396, 47403, 48398, 48405, 48408, 48538, 48592, 48594, 48640, 48647, 48706, 48770, 48876, 48879, 48891, 48900, 48901, 48987, 49002, 49005, 49016, 49021, 49025, 49061, 49063, 49076, 49094, 49294, 49542, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50611, 50637, 51186, 51201, 51214, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55387, 55918, 55952, 56521, 56720, 56724, 56804, 56811, 56840, 56857, 56865, 56884, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57781, 57801, 58223, 58275, 58465, 58481, 59008, 59042, 59053, 59055, 59639, 59651, 59751, 59856, 59926, 60715, 61176, 61183, 61192, 61496, 61504, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 62891, 62906, 64670, 65360, 65744, 65770, 66023, 66024, 66030, 66031, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69141, 69142, 69149, 69446, 69483, 69673, 69960, 69962, 69980, 70832, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72362, 72438, 72473, 72476, 72483, 72486, 72487, 72550, 72555, 72567, 72588, 73156, 73161, 73163, 73165, 73167, 73170, 73171, 73175, 73279, 73369, 73804, 74215, 74270, 74284, 74793, 74797, 74832, 75041, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76332, 76351, 76397, 76413, 76528, 76617, 76681, 76719, 77195, 77207, 77218, 77228, 77593, 77599, 77610, 77611, 77625, 77782, 78264, 78279, 78522, 78545, 79379, 79409, 79510, 79825, 80243, 80684, 81267, 81758, 82044, 82566, 82594, 82599, 83219, 83259, 84022, 84039, 84059, 84406, 84462, 84463, 84513, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87086, 87462, 87473, 87918, 87932, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 89294, 90486, 90598, 90622, 90638, 90718, 90725, 92322, 92327, 92328, 92357, 92359, 92361, 92366, 92372, 92373, 92376, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92674, 92676, 92677, 92680, 92700, 92773, 92819, 92823, 92824, 92863, 92865, 92873, 92881, 92884, 92922, 92923, 92928, 92930, 92935, 92939, 92948, 92952, 92967, 92968, 93655, 93699, 93701, 93708, 93714, 93717, 93728, 93731, 94080, 94100, 94142, 94151, 94154, 94158, 94170, 94221, 94235, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95632, 95672, 95681, 95746, 95854, 95967, 96006, 96014, 96024, 96093, 96097, 96213, 96661, 96685, 97183, 97187, 97199, 97225, 97908, 97974, 97987, 97996, 98367, 99036, 99090, 99123, 99125, 99258, 99266, 100178, 100184, 100191, 100194, 100210, 100734, 100738, 100805, 101124, 101134, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103491, 103492, 103493, 103590, 103684, 103728, 103734, 103742, 106159, 106174, 106178, 106179, 106191, 106591, 106635, 106645, 108061, 108072, 108079, 108103, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108727, 108927, 108937, 108956, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 111130, 111132, 111134, 111136, 111139, 111165, 111273, 111653, 111656, 111659, 111660, 112074, 112438, 112455, 113161, 113753, 115260, 115874, 115878, 117558, 117952, 118424, 118881, 119251, 119722, 120417, 120918, 120958, 120975, 120977, 120978, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122247, 122254, 122264, 122267, 122279, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123416, 123454, 123914, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125375, 125385, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125828, 125829, 125831, 125988, 126020, 126025, 126027, 126087, 126100, 126126, 127242, 127457, 127507, 128631, 129011, 129031, 129036, 129559, 129569, 129591, 129598, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130443, 130445, 130471, 130480, 130490, 130493, 130627, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134005, 134021, 134116, 134249, 134433, 134473, 135026, 135029, 135072, 135239, 135243, 135303, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136727, 136739, 136760, 136762, 136772, 136786, 136812, 136820, 137044, 137055, 137058, 137063, 137068, 137095, 138161, 138378, 138424, 138744, 138756, 138759, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139448, 139994, 140011, 140012, 140016, 140385, 140425, 140430, 140475, 140476, 140484, 140493, 140495, 140499, 140540, 140954, 140956, 141004, 141011, 141072, 141098, 141295, 141315, 141321, 141416, 142457, 142465, 143092, 143138, 143140, 143141, 143149, 143150, 143172, 143183, 143223, 143232, 143262, 143268, 143269, 143271, 143285, 143288, 143303, 143313, 143357, 143360, 143398, 143410, 143411, 143492, 143924, 143950, 144992, 145013, 145324, 145362, 145733, 146825]), ('learning multiple', [3888, 3927, 4167]), ('recognition using', [19221, 76945, 90674, 108442, 118424, 137058, 142469]), ('artificial neural', [15376, 15388, 15895, 18681, 20674, 21139, 23175, 26844, 26914, 33248, 33251, 33258, 33260, 33277, 33329, 33431, 33457, 33462, 33468, 33472, 34021, 34253, 34258, 34948, 34959, 35532, 35704, 39555, 39568, 52209, 52211, 52218, 52257, 52289, 52370, 52391, 52414, 53161, 53374, 59028, 65768, 67647, 69960, 74270, 74284, 75827, 75833, 75863, 75873, 75889, 76351, 76397, 82594, 82599, 83219, 83227, 87086, 88961, 92819, 93701, 95531, 100191, 110131, 119251, 119263, 120926, 127242, 134249, 135243, 138378, 140484, 143148, 145013]), ('mean field', [986, 987, 992, 999, 1000, 1191, 53371, 53464, 53504, 53508, 53532, 53562, 53565, 53585, 53638, 53689, 53709, 53787, 53792, 53805, 79373, 79375, 79377, 79401, 79416, 79418, 79419, 79469, 79485, 79510, 79567, 79713, 79716, 79720, 79782, 79823, 79828, 127495, 127510, 129613, 129623, 129626, 129635, 129849, 129946, 129980, 129994, 129996, 132234, 135646, 135684, 135765, 135789, 135819, 135886, 143608]), ('maximum likelihood', [5436, 5543, 5545, 5571, 10883, 10913, 17430, 17432, 31833, 31841, 31930, 32024, 32746, 58320, 73166, 92774, 108372, 111186, 112046, 112207, 112211, 112227, 112258, 112381, 112423, 115554, 138046, 139700, 139764, 139768, 139905]), ('deep networks', [119329]), ('associative memory', [1759, 2137, 3684, 4070, 4150, 5086, 5176, 5178, 5345, 5376, 6233, 8649, 11777, 11778, 11835, 11843, 13017, 13018, 13354, 13618, 15952, 15973, 15974, 15979, 15991, 16076, 16166, 16241, 19212, 19221, 19223, 19246, 19421, 19433, 19436, 19548, 19551, 19646, 19652, 19653, 19657, 19659, 19665, 19671, 19686, 19734, 29008, 29024, 29052, 29859, 29867, 30926, 30977, 31372, 35931, 35938, 35941, 35942, 35944, 35951, 35955, 35959, 35963, 35982, 35986, 35987, 35990, 35995, 35997, 35998, 36002, 36037, 36054, 36058, 36064, 36071, 36088, 36185, 36188, 36201, 36281, 36283, 36286, 36291, 36299, 36301, 36805, 43709, 43739, 43756, 44501, 45528, 47395, 47413, 47526, 47542, 47661, 47681, 47732, 47880, 49079, 50281, 50506, 50554, 50586, 56543, 56771, 56898, 56916, 57033, 69477, 70457, 81183, 82088, 85418, 85429, 85453, 85456, 85458, 85462, 85466, 85793, 97994, 103702, 104173, 104705, 106780, 106978, 116659, 116850, 116853, 116863, 116889, 116891, 119228, 120392, 120453, 120479, 120482, 120804, 120900, 123396, 133190, 133191, 135561, 135583, 137098, 137099, 137118, 145828, 145958, 145980, 145993, 146265]), ('basis function', [71561, 71563, 90709, 100826, 111337, 111545, 111547, 111552, 111615, 112049, 112488, 142500]), ('feature extraction', [12918, 13020, 13027, 13032, 13154, 39489, 66394, 75067, 103998, 104107, 139640, 139643, 139644, 139648, 139660, 143459, 143485, 143493, 143497, 143511, 143574, 143826, 143876])])\n",
            "The index_t2 are  OrderedDict([('neural networks', [10, 30, 59, 78, 191, 1373, 2402, 2870, 3433, 3824, 4189, 4361, 4369, 6398, 6413, 6457, 8675, 9042, 9337, 9388, 9495, 9511, 9567, 9570, 9967, 11498, 11657, 11661, 11943, 11949, 11950, 12801, 12825, 15539, 15854, 15888, 16318, 16345, 16843, 16878, 16887, 16894, 16913, 17079, 17179, 17525, 18031, 18060, 18489, 20401, 20422, 20454, 20467, 20469, 20561, 20983, 21035, 21552, 21560, 21834, 22798, 24025, 25091, 25124, 26169, 27051, 27065, 27067, 27440, 27465, 27850, 27867, 27868, 28313, 28773, 29543, 29551, 29991, 30005, 30814, 30826, 30827, 31020, 31028, 31261, 32437, 32546, 35341, 37523, 37824, 37838, 37839, 37840, 37841, 38167, 40479, 40962, 42728, 42744, 43307, 43325, 43328, 43744, 43795, 44547, 44995, 45722, 45753, 47411, 48067, 48186, 48194, 48198, 48528, 48533, 48554, 48650, 48675, 48801, 48818, 49012, 49046, 49056, 49078, 49559, 50848, 51206, 51658, 51713, 52506, 52511, 53149, 53182, 53361, 53680, 53753, 53849, 54096, 54252, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55964, 57356, 57792, 58136, 59090, 60364, 60406, 60857, 61286, 61669, 63078, 63091, 63133, 63147, 63168, 63170, 63442, 63449, 63451, 64446, 64461, 64489, 64923, 64935, 68319, 68793, 68809, 70255, 71891, 72421, 73650, 73677, 75905, 75929, 78377, 79276, 79538, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 83185, 84715, 85380, 86554, 86960, 86988, 87950, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89565, 89603, 89613, 89662, 89706, 91170, 91748, 96275, 96278, 96295, 96758, 96759, 96842, 96848, 97129, 97235, 97239, 97307, 97415, 97440, 98408, 98455, 98878, 98883, 99302, 99933, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101074, 101085, 101091, 101166, 101641, 101657, 102171, 103310, 105836, 105838, 105848, 106017, 106327, 106328, 106340, 106834, 106840, 107592, 107595, 107596, 107632, 107749, 111130, 111175, 111178, 112264, 112278, 112790, 113934, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117857, 119500, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 123277, 123312, 123327, 123331, 123340, 123440, 123578, 123657, 123849, 124249, 124252, 124275, 124705, 124739, 125008, 125009, 125011, 125435, 125775, 125844, 126356, 126387, 126402, 126426, 126427, 126428, 126557, 126790, 126791, 126834, 126838, 126851, 126866, 127283, 127420, 127430, 127432, 127436, 127476, 127488, 128182, 128395, 128852, 130274, 130336, 130726, 131362, 131936, 132954, 133394, 135411, 135599, 135646, 135658, 135669, 136307, 136711, 137026, 137076, 137127, 137133, 137165, 138108, 139777, 139869, 140047, 140090, 140576, 141667, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144975, 145067, 145365, 145368, 145370, 145379, 145568, 145575, 145580, 146492, 146553, 146582, 146595, 146599, 150809, 150812, 150847, 150869, 152225, 152249, 152703, 153245, 153275, 153294, 153698, 156354, 156912, 157514, 157537, 158652, 158664, 158681, 158684, 159215, 161493, 161651, 161652, 161658, 161660, 161726, 161731, 161733, 161737, 161745, 161784, 161823, 161869, 162891, 162908, 163677, 163687, 164152, 164890, 165043, 166669, 167039, 167265, 167490, 167573, 168033, 168094, 168108, 168109, 168122, 168125, 168325, 168416, 168419, 172384, 177424, 177849, 177883, 178220, 178258, 178441, 178457, 179092, 179558, 179577, 179583, 180681, 181215, 182196, 182583, 182763, 183064, 183623, 183827, 183866, 184797, 184799, 184802, 185306, 185324, 185348, 185750, 185787, 186223, 189130, 189581, 190036, 190694, 190726, 190730, 191205, 191219, 191699, 191713, 191729, 192193, 192762, 192874, 192877, 193199, 193568, 193665, 194048, 194711, 195171, 195823, 195829, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197618, 198752, 198765, 199310, 199316, 199330, 199334, 199343, 200871, 200873, 201113, 202459, 202492, 202621, 202624, 203011, 204978, 206966, 207233, 207827, 208522, 209049, 209055, 209517, 209595, 10, 30, 59, 78, 191, 1373, 2402, 2870, 3433, 3824, 4189, 4361, 4369, 6398, 6413, 6457, 8675, 9042, 9337, 9388, 9495, 9511, 9567, 9570, 9967, 11498, 11657, 11661, 11943, 11949, 11950, 12801, 12825, 15539, 15854, 15888, 16318, 16345, 16843, 16878, 16887, 16894, 16913, 17079, 17179, 17525, 18031, 18060, 18489, 20401, 20422, 20454, 20467, 20469, 20561, 20983, 21035, 21552, 21560, 21834, 22798, 24025, 25091, 25124, 26169, 27051, 27065, 27067, 27440, 27465, 27850, 27867, 27868, 28313, 28773, 29543, 29551, 29991, 30005, 30814, 30826, 30827, 31020, 31028, 31261, 32437, 32546, 35341, 37523, 37824, 37838, 37839, 37840, 37841, 38167, 40479, 40962, 42728, 42744, 43307, 43325, 43328, 43744, 43795, 44547, 44995, 45722, 45753, 47411, 48067, 48186, 48194, 48198, 48528, 48533, 48554, 48650, 48675, 48801, 48818, 49012, 49046, 49056, 49078, 49559, 50848, 51206, 51658, 51713, 52506, 52511, 53149, 53182, 53361, 53680, 53753, 53849, 54096, 54252, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55964, 57356, 57792, 58136, 59090, 60364, 60406, 60857, 61286, 61669, 63078, 63091, 63133, 63147, 63168, 63170, 63442, 63449, 63451, 64446, 64461, 64489, 64923, 64935, 68319, 68793, 68809, 70255, 71891, 72421, 73650, 73677, 75905, 75929, 78377, 79276, 79538, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 83185, 84715, 85380, 86554, 86960, 86988, 87950, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89565, 89603, 89613, 89662, 89706, 91170, 91748, 96275, 96278, 96295, 96758, 96759, 96842, 96848, 97129, 97235, 97239, 97307, 97415, 97440, 98408, 98455, 98878, 98883, 99302, 99933, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101074, 101085, 101091, 101166, 101641, 101657, 102171, 103310, 105836, 105838, 105848, 106017, 106327, 106328, 106340, 106834, 106840, 107592, 107595, 107596, 107632, 107749, 111130, 111175, 111178, 112264, 112278, 112790, 113934, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117857, 119500, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 123277, 123312, 123327, 123331, 123340, 123440, 123578, 123657, 123849, 124249, 124252, 124275, 124705, 124739, 125008, 125009, 125011, 125435, 125775, 125844, 126356, 126387, 126402, 126426, 126427, 126428, 126557, 126790, 126791, 126834, 126838, 126851, 126866, 127283, 127420, 127430, 127432, 127436, 127476, 127488, 128182, 128395, 128852, 130274, 130336, 130726, 131362, 131936, 132954, 133394, 135411, 135599, 135646, 135658, 135669, 136307, 136711, 137026, 137076, 137127, 137133, 137165, 138108, 139777, 139869, 140047, 140090, 140576, 141667, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144975, 145067, 145365, 145368, 145370, 145379, 145568, 145575, 145580, 146492, 146553, 146582, 146595, 146599, 150809, 150812, 150847, 150869, 152225, 152249, 152703, 153245, 153275, 153294, 153698, 156354, 156912, 157514, 157537, 158652, 158664, 158681, 158684, 159215, 161493, 161651, 161652, 161658, 161660, 161726, 161731, 161733, 161737, 161745, 161784, 161823, 161869, 162891, 162908, 163677, 163687, 164152, 164890, 165043, 166669, 167039, 167265, 167490, 167573, 168033, 168094, 168108, 168109, 168122, 168125, 168325, 168416, 168419, 172384, 177424, 177849, 177883, 178220, 178258, 178441, 178457, 179092, 179558, 179577, 179583, 180681, 181215, 182196, 182583, 182763, 183064, 183623, 183827, 183866, 184797, 184799, 184802, 185306, 185324, 185348, 185750, 185787, 186223, 189130, 189581, 190036, 190694, 190726, 190730, 191205, 191219, 191699, 191713, 191729, 192193, 192762, 192874, 192877, 193199, 193568, 193665, 194048, 194711, 195171, 195823, 195829, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197618, 198752, 198765, 199310, 199316, 199330, 199334, 199343, 200871, 200873, 201113, 202459, 202492, 202621, 202624, 203011, 204978, 206966, 207233, 207827, 208522, 209049, 209055, 209517, 209595]), ('reinforcement learning', [3494, 3749, 3765, 3824, 23254, 23259, 23383, 23476, 23509, 23513, 23516, 31790, 31807, 31816, 31837, 31843, 31962, 32203, 32217, 32226, 54732, 78331, 78384, 87974, 87994, 88103, 107815, 121190, 121201, 121203, 121208, 121234, 121239, 121584, 121640, 141883, 142175, 162363, 162373, 166996, 168148, 169045, 169051, 169064, 169065, 169073, 169087, 169090, 169571, 169577, 169591, 169613, 170189, 170202, 170476, 170551, 170561, 174241, 174247, 174263, 174272, 174276, 174277, 174283, 174285, 174510, 174511, 174662, 174732, 174770, 182099, 185314, 185747, 189674, 189677, 194138, 194193, 194627]), ('neural network', [10, 30, 45, 59, 78, 115, 191, 290, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2870, 3429, 3433, 3456, 3824, 4189, 4200, 4217, 4361, 4369, 4444, 6398, 6413, 6457, 7563, 7577, 7590, 7836, 8231, 8245, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9368, 9388, 9434, 9444, 9495, 9511, 9567, 9570, 9967, 10287, 11498, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12801, 12825, 13163, 13832, 13858, 15539, 15579, 15854, 15888, 16016, 16318, 16345, 16352, 16395, 16581, 16584, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17254, 17324, 17414, 17447, 17525, 18031, 18060, 18489, 18554, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20653, 20718, 20983, 21026, 21035, 21457, 21552, 21560, 21604, 21834, 22153, 22161, 22164, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24025, 25091, 25124, 26169, 26179, 27051, 27065, 27067, 27119, 27297, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28313, 28634, 28773, 29016, 29039, 29442, 29488, 29543, 29551, 29556, 29991, 30005, 30028, 30345, 30378, 30382, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30891, 30895, 30981, 31020, 31024, 31028, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 34034, 34040, 34602, 34633, 34634, 34653, 34676, 35319, 35320, 35341, 37098, 37112, 37188, 37469, 37485, 37523, 37790, 37803, 37824, 37825, 37838, 37840, 37841, 38138, 38144, 38149, 38150, 38162, 38167, 38655, 39238, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43744, 43775, 43795, 44125, 44547, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45722, 45753, 47250, 47411, 47661, 48067, 48172, 48183, 48186, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49046, 49056, 49078, 49091, 49559, 50392, 50395, 50399, 50415, 50432, 50539, 50691, 50694, 50696, 50706, 50767, 50775, 50777, 50848, 50931, 51206, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53149, 53173, 53182, 53361, 53680, 53741, 53743, 53753, 53798, 53849, 54067, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54362, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55103, 55108, 55122, 55964, 56080, 57356, 57364, 57380, 57391, 57438, 57768, 57792, 58127, 58129, 58131, 58136, 58144, 58148, 58149, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58577, 58581, 58589, 58633, 58852, 59088, 59090, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63091, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63283, 63315, 63373, 63392, 63416, 63423, 63442, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64866, 64876, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 67789, 67803, 67867, 68319, 68793, 68809, 69930, 70021, 70200, 70255, 70386, 70398, 70405, 70707, 70994, 71891, 72405, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73248, 73301, 73303, 73305, 73332, 73335, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 75069, 75853, 75905, 75929, 77962, 77966, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80450, 80466, 80488, 81117, 81123, 81132, 81859, 81870, 82303, 82309, 82747, 82749, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87704, 87774, 87950, 88015, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89662, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91170, 91358, 91748, 91777, 91781, 92363, 92395, 92397, 92421, 96250, 96275, 96278, 96284, 96295, 96497, 96528, 96541, 96758, 96759, 96834, 96842, 96848, 96852, 96904, 96913, 96926, 97120, 97129, 97224, 97235, 97236, 97239, 97241, 97307, 97310, 97415, 97416, 97440, 97493, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98850, 98866, 98878, 98883, 99302, 99330, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101084, 101085, 101091, 101166, 101641, 101657, 101839, 102171, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103529, 103616, 103862, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 106017, 106327, 106328, 106337, 106340, 106455, 106489, 106546, 106797, 106834, 106840, 106899, 107588, 107592, 107595, 107596, 107629, 107632, 107669, 107671, 107720, 107723, 107744, 107749, 107769, 108237, 109776, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111720, 112221, 112250, 112264, 112278, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117857, 119375, 119379, 119473, 119500, 119503, 119505, 119927, 119981, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124739, 124741, 124909, 124913, 125008, 125009, 125011, 125435, 125467, 125775, 125844, 125847, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126831, 126834, 126838, 126851, 126866, 127283, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128188, 128378, 128395, 128420, 128436, 128852, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131936, 131953, 132020, 132297, 132872, 132888, 132903, 132954, 133394, 133480, 133878, 133896, 134543, 135398, 135411, 135599, 135624, 135646, 135658, 135669, 136149, 136300, 136314, 136400, 136644, 136711, 137026, 137076, 137108, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140613, 140614, 140669, 141667, 141683, 142241, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144951, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 146129, 146130, 146155, 146244, 146439, 146492, 146553, 146573, 146582, 146595, 146597, 146599, 147072, 147816, 147899, 150129, 150809, 150812, 150847, 150869, 151108, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152703, 152707, 152746, 152946, 153078, 153083, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156258, 156354, 156491, 156497, 156506, 156912, 157511, 157512, 157514, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159286, 159850, 160065, 160069, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161724, 161726, 161731, 161733, 161737, 161745, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161993, 162276, 162306, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165043, 166217, 166256, 166283, 166669, 167039, 167067, 167089, 167106, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167622, 167628, 167744, 167749, 167750, 168033, 168040, 168094, 168108, 168109, 168122, 168125, 168140, 168325, 168380, 168384, 168397, 168411, 168416, 168419, 168423, 172384, 172415, 173746, 176754, 176774, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178427, 178437, 178441, 178452, 178457, 179092, 179558, 179559, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180675, 180681, 180711, 181215, 181245, 181279, 181942, 182196, 182583, 182763, 182870, 183064, 183184, 183329, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185638, 185706, 185750, 185787, 186223, 187223, 187620, 187671, 188243, 188435, 189130, 189151, 189376, 189436, 189499, 189562, 189578, 189581, 189594, 190015, 190036, 190694, 190726, 190730, 190741, 191205, 191219, 191699, 191713, 191729, 192147, 192193, 192230, 192236, 192243, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193209, 193240, 193259, 193568, 193665, 193685, 193728, 194048, 194180, 194199, 194711, 195160, 195168, 195171, 195419, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197404, 197618, 197629, 197921, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199343, 199362, 199418, 200441, 200456, 200861, 200871, 200873, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202827, 203011, 204044, 204049, 204523, 204978, 205021, 205555, 205558, 205982, 205995, 206611, 206666, 206966, 207056, 207233, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('active learning', [111109]), ('monte carlo', [207829]), ('online learning', [110685, 203165]), ('speech recognition', [3857, 3867, 3888, 3903, 3908, 3954, 4090, 4131, 7214, 9080, 9366, 9510, 12820, 13134, 13833, 18519, 27920, 27943, 28282, 30888, 32510, 37836, 44996, 45000, 45247, 48473, 48525, 48529, 52006, 57784, 57805, 59091, 60363, 60366, 60381, 60393, 60394, 60395, 60776, 62289, 62295, 62305, 62477, 62585, 62638, 62641, 62644, 62653, 62672, 62675, 62677, 62682, 62722, 62727, 62874, 63032, 63033, 70758, 71178, 73756, 73978, 74064, 75489, 77659, 77975, 79199, 79272, 79278, 83865, 87298, 87315, 89590, 89599, 89606, 91841, 91846, 92340, 115393, 116863, 116900, 116914, 116938, 116995, 117172, 117225, 117230, 117240, 117245, 117260, 117263, 119998, 120002, 120048, 120226, 120415, 120447, 123932, 124134, 124222, 124249, 129306, 129308, 129316, 135336, 135337, 135391, 135392, 135415, 135480, 135599, 135609, 135612, 135615, 137126, 146192, 148278, 148666, 156260, 156919, 164791, 165028, 165038, 165041, 165046, 165048, 167750, 167775, 168597, 168633, 168697, 168991, 169017, 190032, 193673, 193759, 194749, 196726, 206076, 206160, 207868, 207876, 207878, 207892, 207904, 208048, 208056, 208246, 208382, 208385, 210153, 210210, 210565]), ('recurrent neural', [9967, 28773, 29016, 34653, 35341, 43346, 48194, 48198, 50765, 50848, 53149, 55075, 78377, 80450, 80466, 80488, 81123, 81132, 81859, 81870, 82747, 82749, 82758, 88066, 88254, 88277, 88325, 89594, 96842, 96848, 96904, 96926, 97129, 120017, 122703, 123277, 123312, 123440, 126851, 126866, 127420, 127430, 127432, 136785, 137133, 150847, 150869, 158652, 158681, 166283, 167039, 167592, 177883, 182763, 183188, 184802, 198752, 198765, 199330, 199334, 199343]), ('component analysis', [33520, 33529, 63391, 86967, 86969, 87054, 87104, 111782, 112216, 177358, 178535, 202443, 202456]), ('gradient descent', [3546, 3676, 3793, 3818, 7150, 7157, 7226, 7236, 7342, 8182, 8186, 8258, 10412, 17187, 19740, 20488, 21346, 22187, 23749, 25814, 26445, 26595, 26605, 26607, 26617, 26620, 26622, 26653, 26770, 26791, 26798, 26823, 28256, 32364, 32395, 33176, 33182, 33680, 34109, 34168, 34283, 38264, 38586, 38609, 39252, 39310, 39324, 39680, 42300, 42353, 42505, 44658, 45782, 48753, 52496, 52524, 52772, 53114, 54691, 54692, 54727, 54733, 54746, 54752, 54759, 54809, 55032, 55046, 60844, 60878, 60928, 61105, 61213, 63869, 65024, 65548, 65550, 65563, 69102, 73843, 73846, 74919, 74991, 75024, 75265, 75299, 76729, 76731, 76744, 78037, 78066, 78075, 78091, 78139, 80169, 80324, 80583, 81373, 82618, 83523, 83535, 86752, 87024, 87087, 87965, 90877, 92858, 96978, 99019, 99091, 102482, 102565, 111979, 111982, 112002, 113916, 113923, 113937, 113939, 113950, 114103, 119159, 120298, 123485, 124470, 126953, 129363, 129372, 129390, 129391, 129420, 129663, 131701, 131770, 131783, 131784, 131787, 131808, 131830, 132391, 132444, 132473, 132510, 132517, 132839, 140805, 144339, 148145, 156464, 156468, 156844, 158241, 158696, 164035, 164123, 164129, 164231, 165247, 167863, 168830, 171109, 171746, 176828, 177006, 177210, 177417, 177432, 177569, 177865, 177872, 182027, 182109, 182113, 182139, 182160, 182162, 182164, 182199, 182220, 182250, 182251, 182374, 182407, 182414, 182433, 182455, 182457, 182458, 186564, 186621, 187625, 187653, 188404, 188413, 188435, 189119, 190868, 191305, 193574, 194633, 195127, 197700, 197711, 197737, 197851, 197955, 198096, 201509, 201541, 201542, 201578, 201587, 201666, 201768, 201927, 201935, 201943, 201959, 204507, 204519, 204888, 207323, 207573, 207592, 207630, 207666, 208579, 208869, 208943, 209972, 210414]), ('hidden markov', [165025, 165028]), (': the', [1363, 2530, 2532, 2548, 3000, 3535, 6112, 6418, 6451, 6470, 7855, 9262, 9424, 9428, 9431, 9680, 10741, 11650, 14536, 18973, 19742, 19930, 23572, 23759, 23760, 23764, 25790, 26146, 26872, 27913, 28108, 29498, 31209, 31972, 39469, 39761, 40386, 41946, 42094, 42261, 44115, 44577, 44656, 44787, 44816, 44832, 48041, 53447, 53472, 53507, 56027, 56217, 60910, 61889, 63771, 63869, 65461, 65750, 66539, 68560, 71152, 73780, 73788, 73936, 73969, 74137, 74194, 74369, 74392, 74714, 75486, 76642, 76931, 77621, 78193, 78577, 79255, 79430, 79712, 81182, 86266, 92417, 92418, 92420, 92425, 92746, 98409, 100217, 102777, 107635, 107913, 107971, 108374, 110537, 111007, 111828, 111980, 112143, 114240, 114955, 115266, 116188, 117181, 118761, 119216, 119313, 119384, 119982, 120231, 120312, 120983, 121101, 121548, 124965, 127914, 127962, 128167, 128233, 131918, 139621, 139707, 140745, 140804, 140909, 140914, 140916, 141778, 141896, 147849, 148800, 148808, 150705, 150763, 150909, 151351, 152016, 152033, 152057, 155646, 155786, 160074, 160544, 160771, 161946, 161979, 162019, 162423, 163979, 165697, 166001, 167635, 169875, 171353, 175213, 177579, 177593, 178295, 180988, 183521, 184169, 188847, 189346, 189376, 189428, 189513, 190718, 190823, 190830, 191309, 191987, 192800, 192810, 192866, 193856, 194746, 195464, 195816, 197367, 197399, 197458, 197868, 198586, 198637, 198667, 201688, 201689, 201696, 202524, 202810, 202832, 203115, 203871, 204858, 205083, 205128, 208500, 208815, 209643]), ('markov models', [87298, 165028]), ('analog vlsi', [189128]), ('stochastic gradient', [7138, 7150, 7226, 7236, 7338, 34109, 34168, 34283, 62389, 65548, 65550, 65563, 76729, 76731, 76744, 114010, 129372, 150169, 164231, 168830, 198096, 204507, 207573]), ('feature selection', [23716, 52212, 52213, 52437, 115004, 144974, 145546]), (': learning', [7868, 63508, 107904, 157501, 165062, 169840]), ('networks learning', [7822]), ('random fields', [68801, 93188, 107119, 132011, 132285]), ('machine learning', [7213, 15567, 54649, 60859, 83838, 83851, 84651, 99312, 101053, 101405, 104453, 105333, 108046, 108230, 117857, 131953, 132885, 140090, 150646, 156353, 156848, 204701]), ('unsupervised learning', [24070, 28296, 28639, 34057, 38655, 45577, 53694, 56410, 64407, 70405, 70504, 84376, 84772, 85399, 91093, 101839, 102268, 102647, 112123, 112249, 125776, 134315, 137443, 137444, 146611, 190849, 194666, 194844, 194898, 206754, 207328, 207353]), ('model selection', [665, 11723, 11938, 87938, 116082, 132000, 139706, 153296, 153683, 159208, 162891, 162895, 162898, 162908, 162937, 163106, 171059, 172398, 172400, 172401, 172403, 172404, 172406, 172416, 172434, 172439, 172441, 172443, 172517, 172559, 172611, 172703, 172842, 172952, 172954, 172955, 192257, 192707, 192708, 192743]), ('dynamic programming', [9122, 23222, 23237, 23257, 23364, 23512, 23965, 23972, 48482, 62330, 68838, 69342, 69934, 70353, 78363, 78382, 91850, 92019, 103576, 103577, 121205, 135289, 135624, 141845, 148285, 156999, 157143, 157208, 160560, 160562, 160564, 160572, 162363, 164906, 167764, 170203, 170554, 170556, 185740, 185763, 189242, 189244, 194152, 194154, 194160, 194193, 194614, 203099, 206182]), ('function approximation', [456, 739, 13900, 20023, 20226, 37522, 40985, 41124, 41141, 47650, 65019, 65477, 65482, 65483, 71440, 76658, 76663, 76664, 83805, 83808, 118998, 127936, 128236, 132932, 132967, 133249, 133264, 133267, 133393, 133400, 137570, 157498, 178204, 185474, 191068, 191315]), ('decision processes', [11976, 167113]), ('object recognition', [10020, 14113, 28336, 41930, 50776, 64937, 67470, 77607, 77636, 77918, 77943, 77949, 77970, 77983, 81897, 91189, 91193, 91205, 103122, 103135, 103136, 103160, 103171, 103527, 104394, 111811, 118453, 149588, 152704, 152729, 153230, 156251, 161949, 162162, 162183, 194711, 194744, 195180]), ('time series', [25065, 25541, 25889, 26112, 26126, 26157, 26596, 26829, 26830, 26832, 44255, 44285, 57439, 57443, 57444, 57447, 61323, 64966, 65289, 65409, 75104, 75822, 87407, 123309, 123322, 123324, 123328, 123331, 123341, 123432, 123465, 123644, 123849, 123864, 124389, 124601, 124655, 125900, 125907, 125923, 127285, 136151, 136327, 136333, 136676, 136720, 136915, 136918, 136946, 136948, 137065, 141592, 145603, 145629, 145777, 145817, 145832, 157024, 165072, 165203, 165345, 167766, 168035, 178396, 190820, 190961, 191055, 191163, 191296, 191308, 191309, 191575, 194102, 200274]), ('mixture models', [13967, 14030, 42709, 84381, 91784, 164104]), ('metric learning', [37521, 37754, 37808, 74911, 132007, 132301, 167084]), ('spiking neurons', [17606, 17803, 144110, 144257, 144261, 196896]), ('density estimation', [11944, 37515, 37755, 84363, 84513, 84720, 84731, 85358, 91818, 91856, 91858, 92030, 92331, 105561, 105824, 116940, 117223, 126360, 132277, 139623, 139972]), ('convex optimization', [26524]), ('supervised learning', [405, 449, 1003, 3765, 6428, 14305, 24070, 28296, 28639, 28670, 34027, 34057, 37118, 38646, 38655, 42197, 45577, 45741, 45753, 53583, 53694, 56410, 63222, 63300, 64407, 69037, 69090, 70387, 70399, 70405, 70504, 70551, 78377, 84339, 84376, 84388, 84534, 84739, 84772, 85265, 85355, 85399, 87407, 88245, 90834, 91015, 91093, 98408, 101839, 102171, 102224, 102229, 102268, 102278, 102288, 102290, 102292, 102294, 102301, 102324, 102338, 102436, 102444, 102471, 102483, 102572, 102650, 102655, 102657, 102659, 102660, 102672, 102676, 107842, 107888, 107907, 110693, 112123, 112249, 115092, 120969, 125776, 129453, 134315, 137444, 137519, 141762, 146130, 146184, 146552, 146611, 174260, 182009, 189630, 190848, 190849, 190860, 191157, 192205, 194086, 194096, 194666, 194844, 194898, 195204, 195418, 195829, 198289, 203634, 206667, 206677, 206751, 206754, 206785, 207328, 207353, 207371, 207572, 208870, 209092]), ('dynamical systems', [8260, 14788, 15361, 21953, 31482, 33519, 43348, 43359, 43649, 43744, 49547, 49568, 57362, 80487, 101672, 143457, 143499, 143526, 151113, 165439, 166637, 166672, 169046, 181215, 181290, 181878, 193630]), ('large scale', [130275, 139503, 166610, 170437]), (': application', [180681]), ('stochastic optimization', [7215, 129774, 137167, 207832]), ('natural images', [49612, 49620, 49646, 49815, 49853, 49893, 49961, 49962, 49964, 50147, 106917, 147070]), ('learning the', [2131, 5692, 5703, 5720, 6416, 6453, 8033, 11118, 14337, 14455, 19570, 19897, 19946, 29993, 29997, 33265, 33445, 43489, 48751, 53090, 60329, 60859, 64403, 69001, 71362, 71386, 75976, 82596, 83881, 83882, 83884, 84378, 84775, 93140, 99331, 100470, 100476, 102559, 102656, 107798, 113838, 113867, 122185, 127417, 127902, 129963, 131418, 137527, 140047, 148282, 150642, 156711, 157501, 161591, 165062, 165071, 165214, 165282, 165283, 165295, 165296, 165311, 165352, 167819, 167825, 169051, 185313, 185368, 185506, 185517, 187082, 198969]), ('dimensionality reduction', [32254, 32258, 32268, 32426, 32427, 32457, 64330, 77638, 77639, 77669, 77670, 77925, 192144, 200113]), ('principal component', [32286, 32432, 33520, 33527, 33529, 33531, 33532, 33535, 33541, 33592, 33822, 33824, 34041, 34045, 34047, 38294, 60901, 60943, 63391, 64224, 86967, 86969, 87054, 87068, 87070, 87076, 87104, 87262, 87263, 87266, 87288, 87296, 91935, 91940, 92335, 98281, 98282, 98286, 111772, 111782, 111784, 111786, 112216, 112230, 112242, 115007, 115098, 118618, 137517, 146637, 155937, 176746, 176781, 176782, 176790, 176808, 177129, 177173, 177207, 177266, 177358, 177378, 177381, 178535, 200050, 200101, 200297, 200340, 202388, 202392, 202393, 202395, 202443, 202456, 203765, 203772, 203811, 203873, 207825]), ('visual cortex', [17576, 17614, 17949, 25114, 25117, 25165, 25167, 25193, 25247, 25463, 25473, 25481, 25484, 25492, 25498, 30028, 30040, 30041, 32527, 38931, 38935, 38950, 38953, 41476, 41483, 45424, 49619, 49643, 49647, 49790, 49914, 57827, 58043, 58091, 66744, 66753, 66759, 67184, 67186, 71893, 71914, 72365, 72391, 72394, 72402, 77942, 80139, 82301, 82305, 86515, 90349, 98075, 98285, 98286, 98303, 98414, 103874, 104028, 104265, 104386, 104387, 104415, 104422, 104424, 110649, 118453, 120922, 143880, 143884, 143905, 143923, 144009, 144038, 144289, 149545, 151141, 151784, 156211, 159232, 159244, 162302, 162305, 162309, 162332, 163709, 163745, 163877, 164089, 164096, 167041, 171911, 187280, 199379, 199516, 204047, 204947]), ('recurrent networks', [31512, 31532, 43735, 50931, 52532, 54800, 54919, 75106, 81215, 81258, 81850, 81856, 81862, 82367, 82742, 87975, 87996, 88118, 88305, 91825, 96915, 97084, 109741, 109758, 109768, 109832, 109957, 110075, 110140, 123311, 123315, 123329, 123549, 123596, 123647, 123666, 126867, 126869, 126871, 126977, 158125, 158131, 158135, 158633, 158677, 164239, 164725, 166968, 167033, 167034, 177415, 177418, 177429, 177577, 177729, 177879, 177880, 178540, 179033, 179057, 182003, 183330, 195761, 205997]), ('radial basis', [801, 827, 836, 13135, 13163, 13197, 13198, 19749, 19977, 20020, 20241, 20258, 24469, 26588, 26857, 28422, 28509, 28512, 32588, 32605, 33491, 37514, 37522, 37524, 37638, 37651, 37673, 37693, 37717, 37720, 37791, 37792, 47403, 48553, 48570, 48675, 52275, 53575, 57310, 64971, 69154, 74731, 84001, 86978, 87373, 87439, 89613, 102219, 102225, 102230, 102484, 103185, 103187, 113872, 116853, 116915, 116968, 120934, 131931, 132051, 132052, 132063, 133247, 133305, 137158, 137192, 139737, 150133, 150134, 150156, 153403, 161074, 161088, 161587, 161600, 170574, 179225, 180660, 191190, 192732, 192977, 197357, 197605, 198309, 198310, 198311, 198391, 198401, 198562, 198620, 198669, 198685, 198689, 209517]), ('risk minimization', [127883, 127884, 127915, 127981, 128167, 128401, 131418, 140044]), ('nearest neighbor', [1744, 1755, 1764, 1776, 1782, 13137, 13164, 13165, 13181, 17622, 17779, 17799, 17904, 20227, 26606, 26628, 29715, 30010, 37572, 37601, 38146, 38794, 38865, 52012, 52437, 57971, 61929, 63285, 70120, 76589, 102378, 102429, 102466, 114501, 115024, 128985, 128986, 129006, 129007, 129008, 142642, 142648, 155939, 161074, 161419, 161476, 161491, 161493, 161507, 161531, 161585, 161593, 161595, 171726, 185619, 191716, 191973, 191979, 191982, 192023, 209978]), ('high dimensional', [526, 13473, 13475, 13835, 13846, 32267, 32269, 32289, 55984, 74898, 77626, 77669, 77671, 77697, 83809, 91111, 126855, 126859, 132898, 155902, 156043, 156082, 156154, 156192, 156196, 159904, 160437, 161548, 167013, 171024, 177558, 178205, 178514, 200279, 200381, 208456]), ('learning algorithms', [5758, 6041, 6042, 6984, 8351, 19166, 21543, 21575, 21595, 23237, 23372, 26872, 31417, 31575, 31739, 32226, 34080, 34326, 34521, 37808, 39250, 39323, 54337, 54649, 54656, 56457, 68850, 68874, 82417, 83878, 84357, 84773, 84779, 88332, 100154, 100447, 101023, 101027, 101652, 102268, 102308, 102684, 109772, 111782, 111827, 126851, 129380, 129839, 132007, 132301, 140777, 141762, 148512, 156979, 166965, 167011, 169073, 169591, 170561, 176773, 178183, 185755, 190762, 190779, 190845, 190905, 192885, 194152, 202489, 203634, 204073, 204076, 204087, 204111, 204313, 205728, 207361, 207807]), ('neural net', [10, 30, 45, 59, 78, 115, 191, 290, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2817, 2830, 2832, 2870, 3123, 3311, 3320, 3429, 3433, 3456, 3824, 3925, 4189, 4200, 4217, 4361, 4369, 4444, 6398, 6413, 6457, 7108, 7563, 7577, 7590, 7836, 8231, 8245, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9365, 9368, 9388, 9434, 9444, 9495, 9511, 9567, 9570, 9967, 10287, 11219, 11223, 11240, 11249, 11498, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12801, 12825, 13163, 13832, 13858, 15539, 15579, 15854, 15870, 15882, 15888, 16011, 16016, 16318, 16345, 16352, 16395, 16581, 16584, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17254, 17324, 17414, 17447, 17525, 18031, 18060, 18489, 18554, 18818, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20653, 20718, 20983, 21026, 21035, 21457, 21552, 21560, 21604, 21834, 22153, 22161, 22164, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24010, 24025, 25091, 25124, 26169, 26179, 27051, 27065, 27067, 27119, 27297, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28279, 28313, 28634, 28773, 29016, 29039, 29442, 29488, 29543, 29551, 29556, 29991, 30005, 30028, 30345, 30378, 30382, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30891, 30895, 30981, 31020, 31024, 31028, 31089, 31139, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 34034, 34040, 34563, 34602, 34633, 34634, 34653, 34676, 35319, 35320, 35341, 36204, 36216, 36231, 36238, 36290, 36321, 36384, 36388, 36397, 36399, 36431, 37098, 37112, 37188, 37469, 37485, 37523, 37790, 37803, 37824, 37825, 37838, 37840, 37841, 38063, 38138, 38144, 38149, 38150, 38162, 38214, 38222, 38226, 38465, 38503, 38504, 38655, 39238, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43744, 43775, 43795, 44125, 44547, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45722, 45753, 47250, 47411, 47661, 48067, 48172, 48183, 48186, 48189, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49046, 49056, 49062, 49078, 49091, 49559, 50392, 50395, 50399, 50415, 50432, 50539, 50691, 50694, 50696, 50706, 50767, 50775, 50777, 50848, 50931, 51206, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53131, 53149, 53173, 53182, 53361, 53680, 53741, 53743, 53753, 53798, 53849, 53865, 54013, 54063, 54067, 54073, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54362, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55103, 55108, 55122, 55964, 56080, 57356, 57364, 57380, 57391, 57438, 57768, 57792, 58127, 58129, 58131, 58136, 58144, 58148, 58149, 58223, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58577, 58581, 58589, 58633, 58645, 58652, 58852, 59049, 59070, 59083, 59088, 59090, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63091, 63114, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63283, 63315, 63373, 63392, 63416, 63423, 63442, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64866, 64876, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 67431, 67459, 67585, 67606, 67608, 67610, 67674, 67675, 67676, 67678, 67679, 67738, 67739, 67745, 67748, 67789, 67803, 67867, 68319, 68793, 68809, 69930, 70021, 70200, 70209, 70255, 70386, 70398, 70405, 70707, 70994, 71379, 71891, 72399, 72405, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73248, 73301, 73303, 73305, 73332, 73335, 73379, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 73718, 75069, 75105, 75838, 75853, 75905, 75929, 75930, 76588, 76590, 77962, 77966, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80450, 80466, 80488, 81117, 81123, 81132, 81859, 81870, 82303, 82309, 82351, 82413, 82747, 82749, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87704, 87774, 87950, 87965, 88015, 88066, 88200, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89662, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91170, 91358, 91748, 91777, 91781, 92363, 92395, 92397, 92421, 96250, 96275, 96278, 96284, 96293, 96295, 96497, 96528, 96541, 96758, 96759, 96834, 96836, 96840, 96842, 96848, 96852, 96904, 96913, 96926, 97119, 97120, 97129, 97132, 97224, 97235, 97236, 97238, 97239, 97241, 97257, 97307, 97310, 97415, 97416, 97440, 97493, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98850, 98866, 98870, 98878, 98883, 99302, 99330, 99360, 99891, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101084, 101085, 101091, 101166, 101641, 101652, 101657, 101839, 102156, 102171, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103529, 103616, 103862, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 106017, 106327, 106328, 106337, 106340, 106455, 106489, 106546, 106777, 106794, 106797, 106834, 106840, 106899, 107588, 107592, 107595, 107596, 107629, 107632, 107669, 107671, 107720, 107723, 107744, 107749, 107769, 108237, 109776, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111720, 112221, 112250, 112264, 112278, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117856, 117857, 117873, 117877, 118122, 118135, 118150, 118158, 119375, 119379, 119473, 119500, 119503, 119505, 119927, 119981, 119983, 120002, 120019, 120225, 120416, 120967, 120971, 120980, 121014, 121135, 121664, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124730, 124739, 124741, 124909, 124913, 124922, 125008, 125009, 125011, 125072, 125074, 125435, 125467, 125775, 125844, 125847, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126819, 126831, 126834, 126838, 126851, 126866, 127283, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128187, 128188, 128206, 128378, 128395, 128420, 128436, 128852, 129418, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131936, 131953, 132020, 132297, 132872, 132888, 132903, 132954, 133394, 133480, 133878, 133896, 134543, 135398, 135411, 135599, 135624, 135646, 135658, 135669, 136149, 136300, 136314, 136400, 136644, 136683, 136711, 137026, 137076, 137101, 137108, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140613, 140614, 140669, 141667, 141683, 142241, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144951, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 146129, 146130, 146155, 146157, 146244, 146439, 146492, 146553, 146573, 146582, 146595, 146597, 146599, 147072, 147810, 147816, 147899, 150129, 150809, 150812, 150847, 150869, 151108, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152703, 152707, 152746, 152946, 153078, 153083, 153217, 153220, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156248, 156254, 156258, 156304, 156354, 156491, 156497, 156506, 156912, 157511, 157512, 157514, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159286, 159850, 160065, 160069, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161724, 161726, 161731, 161733, 161737, 161745, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161993, 162276, 162306, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165043, 165076, 166217, 166256, 166283, 166669, 167039, 167067, 167089, 167106, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167610, 167622, 167628, 167744, 167749, 167750, 168033, 168036, 168040, 168094, 168108, 168109, 168122, 168125, 168140, 168325, 168329, 168380, 168384, 168397, 168411, 168416, 168419, 168423, 171083, 171086, 171091, 171131, 171148, 171176, 171295, 171428, 171455, 172384, 172415, 173746, 174745, 176754, 176774, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178427, 178437, 178441, 178452, 179092, 179553, 179558, 179559, 179565, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180675, 180681, 180711, 181215, 181245, 181279, 181942, 182196, 182583, 182763, 182870, 183064, 183184, 183329, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 185302, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185638, 185706, 185750, 185787, 186223, 187065, 187223, 187620, 187671, 188243, 188435, 189130, 189151, 189376, 189436, 189499, 189562, 189578, 189581, 189594, 190015, 190036, 190694, 190726, 190730, 190741, 191205, 191219, 191699, 191713, 191729, 191868, 192147, 192157, 192163, 192193, 192230, 192236, 192243, 192245, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193209, 193240, 193259, 193568, 193665, 193684, 193685, 193688, 193694, 193728, 193750, 193854, 193881, 193991, 194048, 194180, 194199, 194711, 195160, 195168, 195171, 195304, 195419, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197404, 197618, 197629, 197921, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199343, 199362, 199418, 200441, 200456, 200861, 200871, 200873, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202827, 203011, 204044, 204049, 204523, 204978, 205021, 205555, 205558, 205577, 205588, 205708, 205727, 205958, 205982, 205995, 206611, 206666, 206966, 207056, 207233, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('sparse coding', [45961, 56342, 146822]), ('recognition using', [2402, 9504, 9505, 9506, 13088, 28647, 48529, 48533, 57797, 57810, 62305, 64312, 64937, 79185, 92340, 92349, 97640, 103509, 117260, 120442, 124249, 124252, 146597, 147361, 156254, 156257, 156319, 189587, 195180]), ('artificial neural', [3925, 11943, 12801, 12825, 15579, 16878, 16894, 16922, 17175, 17179, 18031, 18060, 20454, 21560, 32579, 37098, 38668, 42193, 42219, 42728, 42744, 43325, 53361, 54263, 60351, 63087, 70994, 72421, 79657, 92340, 99360, 100361, 100380, 102722, 105848, 136297, 136300, 136400, 138108, 145568, 146130, 146149, 155907, 156981, 159215, 161631, 161651, 167267, 167577, 168402, 180711, 185302, 186921, 191729, 192768, 193201, 193202, 194048, 197273, 200873, 202042, 202459, 207827]), ('mean field', [32400, 50768, 50933, 50942, 68350, 68367, 68389, 68541, 68591, 68779, 68801, 84660, 85380, 92803, 93056, 93105, 93140, 93188, 113332, 150811, 182452, 182456]), ('maximum likelihood', [4221, 37104, 37443, 37460, 37462, 37472, 57650, 57655, 57656, 57657, 57774, 84359, 84586, 86833, 87931, 100138, 110321, 115388, 116898, 116914, 117167, 117171, 117177, 117179, 120229, 126363, 127984, 134693, 139565, 139706, 148284, 148369, 148466, 160594, 162396, 171214, 172478, 172974, 185789]), ('sample complexity', [5697, 5756, 113377, 113638, 113836, 113870, 135665, 135700, 136087, 140564, 209544, 209549]), ('associative memory', [7565, 7591, 7625, 9596, 9636, 9987, 9988, 9991, 12081, 12106, 27865, 27872, 31411, 32909, 35658, 35671, 35677, 35726, 35781, 36177, 36187, 47676, 47681, 47712, 48048, 52815, 64938, 90358, 99897, 103513, 121584, 128851, 150675, 166649, 166669, 166689, 166716, 167030, 177416, 177432, 177455, 177544, 177862, 177874, 202477, 202624, 202651, 202693, 204948]), ('basis function', [482, 493, 494, 501, 527, 531, 535, 566, 567, 581, 588, 591, 599, 811, 816, 817, 821, 822, 827, 836, 13135, 13163, 13180, 13197, 13201, 13663, 13835, 19589, 19749, 19977, 20020, 20241, 20258, 23092, 23109, 24469, 24484, 24687, 25073, 25076, 26588, 26636, 26857, 32588, 32605, 33491, 37524, 37638, 37643, 37647, 37649, 37650, 37651, 37673, 37693, 37719, 37720, 37791, 40996, 41000, 47331, 47340, 47342, 47343, 47348, 47391, 47395, 47403, 47406, 47421, 47430, 47438, 47451, 47653, 48553, 48570, 48675, 48678, 48683, 48686, 52275, 57310, 64971, 65018, 65021, 74731, 78399, 78409, 78445, 78454, 78475, 78509, 78513, 78516, 78517, 78518, 78536, 78537, 78538, 78591, 78593, 78595, 78599, 78667, 78668, 78732, 78805, 78860, 79049, 79052, 79136, 79144, 79148, 84001, 86978, 87373, 87439, 89230, 89613, 92891, 102225, 102230, 102236, 102264, 102484, 102646, 103185, 103187, 105557, 106881, 113872, 116853, 116915, 116968, 116970, 117258, 120934, 131931, 132051, 132052, 132058, 132063, 132064, 132142, 137158, 137192, 139737, 150133, 150156, 153403, 161074, 161088, 161587, 161600, 170574, 170591, 171034, 178174, 178210, 179225, 180660, 191156, 191190, 192977, 193911, 195490, 198309, 198310, 198311, 198318, 198322, 198323, 198379, 198384, 198387, 198388, 198390, 198391, 198512, 198519, 198542, 198543, 198544, 198549, 198551, 198552, 198553, 198560, 198561, 198564, 198565, 198571, 198572, 198618, 198620, 198667, 198669, 198685, 198687, 198689, 208446, 208496, 208497, 208505, 208518, 208524, 208536, 208574, 208628, 208629, 208639, 208645, 208677, 208890, 208893, 208929, 208942, 208947, 209517, 209587, 209730]), ('feature extraction', [2405, 8714, 9043, 9336, 17119, 23804, 32260, 32268, 32418, 32432, 32498, 34036, 34208, 36433, 64015, 64908, 67635, 67722, 67746, 70426, 70441, 77600, 77603, 77631, 77638, 77652, 77697, 77926, 77975, 96847, 97415, 106467, 111177, 111178, 112225, 125497, 125612, 125613, 130977, 156259, 176754, 206668, 206735, 206742, 206748])])\n",
            "converted target toks [['neural', 'networks'], ['reinforcement', 'learning'], ['neural', 'network'], ['ga', '##uss', '##ian', 'process'], ['graphical', 'models'], ['support', 'vector'], ['ga', '##uss', '##ian', 'processes'], ['active', 'learning'], ['variation', '##al', 'inference'], ['monte', 'carlo'], ['online', 'learning'], ['speech', 'recognition'], ['rec', '##urrent', 'neural'], ['component', 'analysis'], ['gradient', 'descent'], ['hidden', 'marko', '##v'], [':', 'the'], ['deep', 'learning'], ['learning', ':'], ['marko', '##v', 'models'], ['vector', 'machines'], ['analog', 'v', '##ls', '##i'], ['st', '##och', '##astic', 'gradient'], ['marko', '##v', 'decision'], ['feature', 'selection'], [':', 'learning'], ['networks', 'learning'], ['random', 'fields'], ['machine', 'learning'], ['networks', ':'], ['belief', 'propagation'], ['kernel', 'learning'], ['un', '##su', '##per', '##vis', '##ed', 'learning'], ['neural', 'networks'], ['model', 'selection'], ['matrix', 'completion'], ['dynamic', 'programming'], ['function', 'approximation'], ['decision', 'processes'], ['object', 'recognition'], ['time', 'series'], ['mixture', 'models'], ['late', '##nt', 'variable'], ['metric', 'learning'], ['deep', 'neural'], ['sp', '##iki', '##ng', 'neurons'], ['bay', '##esian', 'inference'], ['density', 'estimation'], ['approximate', 'inference'], ['convex', 'optimization'], ['supervised', 'learning'], ['dynamic', '##al', 'systems'], ['con', '##vo', '##lu', '##tion', '##al', 'neural'], ['genera', '##tive', 'models'], ['large', 'scale'], ['matrix', 'factor', '##ization'], [':', 'application'], ['st', '##och', '##astic', 'optimization'], ['natural', 'images'], ['spectral', 'cluster', '##ing'], ['learning', 'the'], ['dimensional', '##ity', 'reduction'], ['principal', 'component'], ['learning', 'sparse'], ['object', 'detection'], ['map', 'inference'], ['visual', 'cortex'], ['rec', '##urrent', 'networks'], ['radial', 'basis'], ['risk', 'mini', '##mi', '##zation'], ['nearest', 'neighbor'], ['independent', 'component'], ['high', 'dimensional'], ['large', 'margin'], ['structured', 'prediction'], ['learning', 'algorithms'], ['neural', 'net'], ['learning', 'multiple'], ['bay', '##esian', 'model'], ['models', 'learning'], ['bay', '##esian', 'networks'], ['policy', 'gradient'], ['variation', '##al', 'bay', '##esian'], ['process', 'regression'], ['sparse', 'coding'], ['domain', 'adaptation'], ['learning', 'deep'], ['recognition', 'using'], ['artificial', 'neural'], ['mean', 'field'], ['maximum', 'likelihood'], ['missing', 'data'], ['sample', 'complexity'], ['exponential', 'family'], ['deep', 'networks'], ['coordinate', 'descent'], ['ass', '##oc', '##ia', '##tive', 'memory'], ['basis', 'function'], ['feature', 'extraction'], ['bolt', '##zman', '##n', 'machines']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(t1)\n",
        "print(len(index_t1))\n",
        "print(len(index_t2))\n",
        "# target_toks\n",
        "\n",
        "len(list(index_t1.values())[1])\n"
      ],
      "metadata": {
        "id": "dkhf0E9Zoo1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3231b2c3-4b97-4778-b4d6-265d9de0ad85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n",
            "99\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "578"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _pre_bert(doc,index,t):\n",
        "  \n",
        "  # index =  index_t1 -> { target_w1: index, target_w2: index2, target_w1 : index5 } -  index = Sentence index in which target word appears\n",
        "  s=[\"Not Found\"]  \n",
        "  \n",
        "  if t in index.keys():\n",
        "      s=[doc[ind] for ind in index[t]]\n",
        "\n",
        "  print('len of sentences',len(s))\n",
        "  l=len(s)\n",
        "  marked_text = [\"[CLS] \" + text + \" [SEP]\" for text in s]\n",
        "  tokenized_text = [tokenizer.tokenize(m) for m in marked_text]\n",
        "  \n",
        "  tokenized_text=[x[:512] if len(x)>512 else x for x in tokenized_text]\n",
        "  indexed_tokens = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n",
        "  segments_ids = [[1] * len(x) for x in tokenized_text]\n",
        "  return s,marked_text,tokenized_text,indexed_tokens,segments_ids,l\n",
        "\n",
        "\n",
        "def _bert_features(tokens_tensor, segments_tensors,tokenized_text):\n",
        "  # print(len(tokens_tensor[0]))\n",
        "  with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
        "  # print (\"Number of layers:\", len(encoded_layers))\n",
        "  layer_i = 0\n",
        "\n",
        "  # # print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "  batch_i = 0\n",
        "\n",
        "  # print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "  token_i = 0\n",
        "\n",
        "  # print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
        "  # Convert the hidden state embeddings into single token vectors\n",
        "\n",
        "  # Holds the list of 12 layer embeddings for each token\n",
        "  # Will have the shape: [# tokens, # layers, # features]\n",
        "  token_embeddings = [] \n",
        "\n",
        "  # For each token in the sentence...\n",
        "  # tokenized_text=[x for x in tokenized_text if x not in ['_', 'n', '##n','v', '##b']]\n",
        "  for token_i in range(len(tokenized_text)):\n",
        "    \n",
        "    # Holds 12 layers of hidden states for each token \n",
        "    hidden_layers = [] \n",
        "    \n",
        "    # For each of the 12 layers...\n",
        "    for layer_i in range(len(encoded_layers)):\n",
        "      \n",
        "      # Lookup the vector for `token_i` in `layer_i`\n",
        "      vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "      \n",
        "      hidden_layers.append(vec)\n",
        "      \n",
        "    token_embeddings.append(hidden_layers)\n",
        "\n",
        "  # Sanity check the dimensions:\n",
        "  # print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
        "  # print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
        "  return token_embeddings\n",
        "# s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "def _get_embeddings(pre,tg):\n",
        "  m_embed_full=[]\n",
        "  # print('len(pre[0])',len(pre[0]))\n",
        "  # print(tg)\n",
        "  for _,item in enumerate(pre[0]):\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    # print(item)\n",
        "    token_list=pre[2][_]\n",
        "    \n",
        "    tokens_tensor = torch.tensor([pre[3][_]])\n",
        "    segments_tensors = torch.tensor([pre[4][_]])\n",
        "    # Predict hidden states features for each layer\n",
        "    token_embeddings=_bert_features(tokens_tensor, segments_tensors,pre[2][_])\n",
        "    concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
        "\n",
        "    summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]\n",
        "    \n",
        "    #consider the tokenized target\n",
        "  \n",
        "    indxs=[]\n",
        "    # print(token_list)\n",
        "    for tok in tg:\n",
        "      '''\n",
        "      remove -1,-2,-3\n",
        "      '''\n",
        "      if tok in token_list:\n",
        "        if tok not in ['_', 'n', '##n','v', '##b']:\n",
        "          indxs.append(token_list.index(tok))\n",
        "\n",
        "    # print('indxs',indxs)\n",
        "    if len(indxs)==1:\n",
        "      #bert_embed=concatenated_last_4_layers [indxs[0]]\n",
        "      bert_embed=summed_last_4_layers [indxs[0]]\n",
        "\n",
        "      m_embed_full.append(bert_embed)\n",
        "    elif len(indxs)>1:\n",
        "      b_emb=[]\n",
        "      for ind in indxs:\n",
        "        #b_emb.append(concatenated_last_4_layers[ind])\n",
        "        b_emb.append(summed_last_4_layers[ind])\n",
        "        \n",
        "      bert_embed= torch.sum(torch.stack(b_emb), 0)\n",
        "      m_embed_full.append(bert_embed)\n",
        "    # indx=token_list.index(tg.lower())\n",
        "    # indx = [i for (i, elem) in enumerate(pre[2][_]) if t in elem]\n",
        "    # print('indx',indx)\n",
        "    # print(pre[1][_],indx)\n",
        "\n",
        "    # if len(indx)>0:\n",
        "    # bert_embed=concatenated_last_4_layers[indx[0]]\n",
        "    \n",
        "    # cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
        "    \n",
        "    \n",
        "  return  m_embed_full, summed_last_4_layers\n",
        "# For a particular target word,do clustering and find if there is a sense change\n"
      ],
      "metadata": {
        "id": "ec5y4w-gqamr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding for all time windows\n",
        "\n",
        "sents_all=[]\n",
        "\n",
        "# Holds all bert embeddings \n",
        "# [] -> [[embedding1], [embedding2],...]\n",
        "X=[]\n",
        "\n",
        "def embeddings_extract(target_words,target_toks,doc1,index_t1):\n",
        "  t=target_words\n",
        "  X_C1=[]\n",
        "  lens1=[]\n",
        "  for k,t in enumerate(target_words) :\n",
        "    berts=[]\n",
        "    sents=[]\n",
        "    print('The target word is',t)    \n",
        "    \n",
        "    #get the sentences from corpus c1 and c2 for the specific target word 't'\n",
        "    \n",
        "    # This will generate tokenized sentences, tokens for the specific word. Or sentences containing specific word\n",
        "    pre1=_pre_bert(doc1,index_t1,t)\n",
        "\n",
        "    # lens1.append(pre1[-1])\n",
        "    # lens2.append(pre2[-1])\n",
        "    # print(pre1)\n",
        "    \n",
        "    sents.extend(pre1[0])\n",
        "    #aggregate all the embeddings\n",
        "    # s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "\n",
        "    '''\n",
        "    Get the embeddings of the targets from corpus 1 and 2\n",
        "    '''\n",
        "    _ , b1=_get_embeddings(pre1,target_toks[k])\n",
        "    print('len of t1',len(b1))\n",
        "    \n",
        "    '''\n",
        "    store the lenghts of no. of sentences extracted for each target word for each corpus\n",
        "    '''\n",
        "    lens1.append(len(b1))\n",
        "    \n",
        "    berts.extend(b1)\n",
        "    print('len of each target word extractions is',len(berts))\n",
        "    X.append(berts)\n",
        "\n",
        "    # ______________ Placeholder to flatten the tensors into 1-D tensor for the \n",
        "    #           respective sentence tensors of specific keyword _______________ (b1)\n",
        "\n",
        "    X_C1.append(b1)# the embeddings for C1\n",
        "    sents_all.append(sents)\n",
        "  return X,X_C1,lens1,sents_all\n",
        "\n"
      ],
      "metadata": {
        "id": "encxlY89yzVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "# embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "\n",
        "# lens=[len_c1]\n",
        "# # lens.append(len_c2)\n",
        "# print('saved')\n",
        "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "LLgkz2ZztHOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sWzlJE8F5UGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT Embeddings\n",
        "\n",
        "embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "embed_full,embed_C2,len_c2,sents=embeddings_extract(target_words,target_toks,doc2,index_t2)\n",
        "embed_full,embed_C3,len_c3,sents=embeddings_extract(target_words,target_toks,doc3,index_t3)\n",
        "embed_full,embed_C4,len_c4,sents=embeddings_extract(target_words,target_toks,doc4,index_t4)\n",
        "embed_full,embed_C5,len_c5,sents=embeddings_extract(target_words,target_toks,doc5,index_t5)\n",
        "embed_full,embed_C6,len_c6,sents=embeddings_extract(target_words,target_toks,doc6,index_t6)\n",
        "embed_full,embed_C7,len_c7,sents=embeddings_extract(target_words,target_toks,doc7,index_t7)\n",
        "embed_full,embed_C8,len_c8,sents=embeddings_extract(target_words,target_toks,doc8,index_t8)\n",
        "embed_full,embed_C9,len_c9,sents=embeddings_extract(target_words,target_toks,doc9,index_t9)\n",
        "embed_full,embed_C10,len_c10,sents=embeddings_extract(target_words,target_toks,doc10,index_t10)\n"
      ],
      "metadata": {
        "id": "KPcYgXrINfhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_map3 = {\n",
        "\n",
        "    \"embed_C1\":embed_C1,\n",
        "    \"embed_C2\":embed_C2,\n",
        "    \"embed_C3\":embed_C3,\n",
        "    \"embed_C4\":embed_C4,\n",
        "    \"embed_C5\":embed_C5,\n",
        "    \"embed_C6\":embed_C6,\n",
        "    \"embed_C7\":embed_C7,\n",
        "    \"embed_C8\":embed_C8,\n",
        "    \"embed_C9\":embed_C9,\n",
        "    \"embed_C10\":embed_C10,\n",
        "    \"sents\":sents,\n",
        "    \"embed_full\":embed_full\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_1.pickle', 'wb+') as f:\n",
        "     pickle.dump(saved_map3, f)"
      ],
      "metadata": {
        "id": "90ABnsNnpfoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply K-NN with Cosine Similarity "
      ],
      "metadata": {
        "id": "0Pd6JvLB5k9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "UmdHFHk3ytYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_1.pickle', 'rb+') as f:\n",
        "  saved_map = pickle.load(f)"
      ],
      "metadata": {
        "id": "2FS2lzDHwl5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(saved_map[\"embed_C7\"][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tER4rF1JhoJr",
        "outputId": "8ca894d9-a515-4ab4-b4fb-20791379685e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_C1 = saved_map[\"embed_C1\"]\n",
        "embed_C2 = saved_map[\"embed_C2\"]\n",
        "embed_C3 = saved_map[\"embed_C3\"]\n",
        "embed_C4 = saved_map[\"embed_C4\"]\n",
        "embed_C5 = saved_map[\"embed_C5\"]\n",
        "embed_C6 = saved_map[\"embed_C6\"]\n",
        "embed_C7 = saved_map[\"embed_C7\"]\n",
        "embed_C8 = saved_map[\"embed_C8\"]\n",
        "embed_C9 = saved_map[\"embed_C9\"]\n",
        "embed_C10 = saved_map[\"embed_C10\"]"
      ],
      "metadata": {
        "id": "CPaPK6goyQUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-NN to calculate the Nearest neighbor of keywords\n",
        "\n",
        "def convert_tensors_tolist(mapping):\n",
        "  for i, word_sentences in enumerate(mapping):\n",
        "        # Use below line whe converting tensors to numpy array\n",
        "        X1=np.array([np.array(x.to('cpu')) for x in word_sentences])\n",
        "\n",
        "        # X1=np.array([np.array(x) for x in word_sentences])\n",
        "        X1=X1.sum(axis=0).tolist()\n",
        "        mapping[i] = X1\n",
        "  return mapping"
      ],
      "metadata": {
        "id": "5bVz7KBItoEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### FLATTEN tensors of sentences of respective words to 1-D\n",
        "\n",
        "# embed_C1_ = convert_tensors_tolist(embed_C1)\n",
        "embed_C2_ = convert_tensors_tolist(embed_C2)\n",
        "embed_C3_ = convert_tensors_tolist(embed_C3)\n",
        "embed_C4_ = convert_tensors_tolist(embed_C4)\n",
        "embed_C5_ = convert_tensors_tolist(embed_C5)\n",
        "embed_C6_ = convert_tensors_tolist(embed_C6)\n",
        "embed_C7_ = convert_tensors_tolist(embed_C7)\n",
        "embed_C8_ = convert_tensors_tolist(embed_C8)\n",
        "embed_C9_ = convert_tensors_tolist(embed_C9)\n",
        "embed_C10_ = convert_tensors_tolist(embed_C10)\n",
        "\n"
      ],
      "metadata": {
        "id": "PEb6gAo3BTJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed_C2_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQZIuXhYIl-T",
        "outputId": "da9f0e54-2998-4d6f-e731-7d6aea184ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def nn_(X):\n",
        "  model = NearestNeighbors(n_neighbors=10,\n",
        "                          metric='cosine',\n",
        "                          algorithm='brute',\n",
        "                          n_jobs=-1)\n",
        "\n",
        "  n_n = model.fit(X)  \n",
        "  distance, indeces = model.kneighbors(X)\n",
        "\n",
        "\n",
        "  return indeces\n"
      ],
      "metadata": {
        "id": "VZVMkWUeRBJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indeces_1 = nn_(embed_C1_)\n",
        "indeces_2 = nn_(embed_C2_)\n",
        "indeces_3 = nn_(embed_C3_)\n",
        "indeces_4 = nn_(embed_C4_)\n",
        "indeces_5 = nn_(embed_C5_)\n",
        "indeces_6 = nn_(embed_C6_)\n",
        "indeces_7 = nn_(embed_C7_)\n",
        "indeces_8 = nn_(embed_C8_)\n",
        "indeces_9 = nn_(embed_C9_)\n",
        "indeces_10 = nn_(embed_C10_)\n",
        "\n"
      ],
      "metadata": {
        "id": "rGjvILCoRe6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec2dynamics_keywords = ['Neural Network', 'Reinforcement Learning', 'Active Learning', 'Monte Carlo', 'Learning Deep',\n",
        "                          'Machine Learning', 'Supervised Learning', 'Time Series', 'Artificial Neural',\n",
        "                         'Gaussian Process', 'Active Learning', 'Gradient Descent', 'Hidden Markov',\n",
        "                         'Nearest Neighbor', 'Dynamical Systems', 'Dimensionality Reduction',\n",
        "                         'Unsupervised Learning', 'Graphical Models', 'Dynamic Programming', 'Component Analysis']"
      ],
      "metadata": {
        "id": "hqzzfXfjQ4RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keywords_np = np.array(candidate_keywords)\n",
        "\n",
        "candidate_keywords_ = np.array([keyword[0] for keyword in candidate_keywords])\n",
        "\n",
        "candidate_keywords_"
      ],
      "metadata": {
        "id": "Aco3xvQpSRV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bbd5b3-5e08-4ed4-96f6-924eacad2d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Neural Networks', 'Reinforcement Learning', 'Neural Network',\n",
              "       'Gaussian Process', 'Graphical Models', 'Support Vector',\n",
              "       'Gaussian Processes', 'Active Learning', 'Variational Inference',\n",
              "       'Monte Carlo', 'Online Learning', 'Speech Recognition',\n",
              "       'Recurrent Neural', 'Component Analysis', 'Gradient Descent',\n",
              "       'Hidden Markov', ': The', 'Deep Learning', 'Learning :',\n",
              "       'Markov Models', 'Vector Machines', 'Analog VLSI',\n",
              "       'Stochastic Gradient', 'Markov Decision', 'Feature Selection',\n",
              "       ': Learning', 'Networks Learning', 'Random Fields',\n",
              "       'Machine Learning', 'Networks :', 'Belief Propagation',\n",
              "       'Kernel Learning', 'Unsupervised Learning', 'neural networks',\n",
              "       'Model Selection', 'Matrix Completion', 'Dynamic Programming',\n",
              "       'Function Approximation', 'Decision Processes',\n",
              "       'Object Recognition', 'Time Series', 'Mixture Models',\n",
              "       'Latent Variable', 'Metric Learning', 'Deep Neural',\n",
              "       'Spiking Neurons', 'Bayesian Inference', 'Density Estimation',\n",
              "       'Approximate Inference', 'Convex Optimization',\n",
              "       'Supervised Learning', 'Dynamical Systems', 'Convolutional Neural',\n",
              "       'Generative Models', 'Large Scale', 'Matrix Factorization',\n",
              "       ': Application', 'Stochastic Optimization', 'Natural Images',\n",
              "       'Spectral Clustering', 'Learning The', 'Dimensionality Reduction',\n",
              "       'Principal Component', 'Learning Sparse', 'Object Detection',\n",
              "       'MAP Inference', 'Visual Cortex', 'Recurrent Networks',\n",
              "       'Radial Basis', 'Risk Minimization', 'Nearest Neighbor',\n",
              "       'Independent Component', 'High Dimensional', 'Large Margin',\n",
              "       'Structured Prediction', 'Learning Algorithms', 'Neural Net',\n",
              "       'Learning Multiple', 'Bayesian Model', 'Models Learning',\n",
              "       'Bayesian Networks', 'Policy Gradient', 'Variational Bayesian',\n",
              "       'Process Regression', 'Sparse Coding', 'Domain Adaptation',\n",
              "       'Learning Deep', 'Recognition Using', 'Artificial Neural',\n",
              "       'Mean Field', 'Maximum Likelihood', 'Missing Data',\n",
              "       'Sample Complexity', 'Exponential Family', 'Deep Networks',\n",
              "       'Coordinate Descent', 'Associative Memory', 'Basis Function',\n",
              "       'Feature Extraction', 'Boltzmann Machines'], dtype='<U24')"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(vec2dynamics_keywords) - set(candidate_keywords_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZG38qs5TmkQ",
        "outputId": "c61c5d18-a69a-450f-82b4-5f758e2f6837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monitering_keywords = list(set(vec2dynamics_keywords).intersection(set(candidate_keywords_)))"
      ],
      "metadata": {
        "id": "Kn3otZ9NSfwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(monitering_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45O_nIsPU6S0",
        "outputId": "aa97bb6a-f5ff-4cfc-bae5-8219be846073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Active Learning',\n",
              " 'Graphical Models',\n",
              " 'Learning Deep',\n",
              " 'Monte Carlo',\n",
              " 'Component Analysis',\n",
              " 'Gradient Descent',\n",
              " 'Unsupervised Learning',\n",
              " 'Dynamic Programming',\n",
              " 'Reinforcement Learning',\n",
              " 'Dimensionality Reduction',\n",
              " 'Neural Network',\n",
              " 'Supervised Learning',\n",
              " 'Machine Learning',\n",
              " 'Time Series',\n",
              " 'Artificial Neural',\n",
              " 'Hidden Markov',\n",
              " 'Dynamical Systems',\n",
              " 'Nearest Neighbor',\n",
              " 'Gaussian Process']"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_nearest_keywords(indeces, keywords_np=candidate_keywords_):\n",
        "  tup_nearest_neighbor = []\n",
        "  for index, candidate_keyword in enumerate(keywords_np):\n",
        "      # Take the current index of the keyword and get the list of 10 nearest index from KNN algorithm\n",
        "      nearest_neighbors_indeces_of_current_keyword = indeces[index]\n",
        "\n",
        "      # Filter the keyword list using the list of indeces obtained in previous step\n",
        "      nearest_keywords = keywords_np[nearest_neighbors_indeces_of_current_keyword]\n",
        "\n",
        "      # Create tuple with first element as the keyword for current iteration and 2nd element as list of its nearest neighbors\n",
        "      tup_nearest_neighbor.append({candidate_keyword : set(nearest_keywords)})\n",
        "\n",
        "\n",
        "  return tup_nearest_neighbor"
      ],
      "metadata": {
        "id": "LbPZ_ZUoQ7E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn_1 = get_nearest_keywords(indeces_1)\n",
        "nn_2 = get_nearest_keywords(indeces_2)\n",
        "nn_3 = get_nearest_keywords(indeces_3)\n",
        "nn_4 = get_nearest_keywords(indeces_4)\n",
        "nn_5 = get_nearest_keywords(indeces_5)\n",
        "nn_6 = get_nearest_keywords(indeces_6)\n",
        "nn_7 = get_nearest_keywords(indeces_7)\n",
        "nn_8 = get_nearest_keywords(indeces_8)\n",
        "nn_9 = get_nearest_keywords(indeces_9)\n",
        "nn_10 = get_nearest_keywords(indeces_10)\n"
      ],
      "metadata": {
        "id": "EqQF0JRVxUDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_target_nn(nn, monitering_keywords = monitering_keywords):\n",
        "    return [n for n in nn for key in list(n.keys()) if key in monitering_keywords]\n",
        "    "
      ],
      "metadata": {
        "id": "BnWxBHdAg6xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2_ = get_target_nn(nn_2)\n",
        "nn_3_ = get_target_nn(nn_3)\n",
        "nn_4_ = get_target_nn(nn_4)\n",
        "nn_5_ = get_target_nn(nn_5)\n",
        "nn_6_ = get_target_nn(nn_6)\n",
        "nn_7_ = get_target_nn(nn_7)\n",
        "nn_8_ = get_target_nn(nn_8)\n",
        "nn_9_ = get_target_nn(nn_9)\n",
        "nn_10_ = get_target_nn(nn_10)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QBae2ny_XDFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_10_"
      ],
      "metadata": {
        "id": "rNv_LeWZYx_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nn_10_[0][\"Reinforcement Learning\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86ZMV8dhYoPa",
        "outputId": "e914801a-95f6-4fe1-a3b3-432a5b0581e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_slice_nn = [nn_2_, nn_3_, nn_4_ , nn_5_ , nn_6_, nn_7_ , nn_8_ , nn_9_ , nn_10_]"
      ],
      "metadata": {
        "id": "Igv6VTt1qIWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def log_stability(A, B):\n",
        "    a = len(A.intersection(B))\n",
        "    b = len(A-B)\n",
        "\n",
        "    if a != 0 and b!=0:\n",
        "      return ( math.log( len(A.intersection(B)) , 10) / math.log ( 0.5 * len((A - B) ) , 10)  )\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "def calc_stability(nn):\n",
        "    i = 0\n",
        "    # print(nn)\n",
        "    stability = []\n",
        "    for _,n in enumerate(nn):\n",
        "       i = _ + 1\n",
        "      #  print(len(nn))\n",
        "       if i < len(nn):\n",
        "          # print(i)\n",
        "          stability.append( log_stability(nn[_], nn[i]) )\n",
        "\n",
        "    # print(stability)\n",
        "    return stability\n",
        "\n",
        "def extract_keyword_nns(target_nn_10tw, keyword):\n",
        "    keyword_neighbors_all_windows = []\n",
        "    for _ , target_nn in enumerate(target_nn_10tw):\n",
        "      # print(list(target_nn[_].keys()))\n",
        "\n",
        "      keyword_neighbors_all_windows.extend([target[keyword] for index, target in enumerate(target_nn) if list(target.keys())[0] == keyword ])\n",
        "    \n",
        "\n",
        "    # print(keyword_neighbors_all_windows)\n",
        "    s = calc_stability(keyword_neighbors_all_windows)\n",
        "    \n",
        "    return s\n",
        "\n",
        "def extract_stability(target_nn_10tw):\n",
        "    s_n = []\n",
        "    for _ , keyword in enumerate(monitering_keywords):\n",
        "      #  print(extract_keyword_nns(target_nn_10tw, keyword) )\n",
        "       s_n.append( { keyword: extract_keyword_nns(target_nn_10tw, keyword) } )\n",
        "        # s_n.extend( { keyword : extract_keyword_nns(target_nn_10tw, keyword) } )\n",
        "\n",
        "    return s_n"
      ],
      "metadata": {
        "id": "yqLHw5F5XbA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_stab = extract_stability(all_slice_nn)\n",
        "keyword_stab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5EfLzPzzbFh",
        "outputId": "bce940dc-4c06-43d6-bbd3-399a91e73dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Active Learning': [0.0,\n",
              "   0.0,\n",
              "   1.2618595071429146,\n",
              "   0.5,\n",
              "   1.2618595071429146,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Graphical Models': [0,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   1.2618595071429146,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Learning Deep': [1.7564707973660298,\n",
              "   0.5,\n",
              "   1.7564707973660298,\n",
              "   2.584962500721156,\n",
              "   0,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0]},\n",
              " {'Monte Carlo': [0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5]},\n",
              " {'Component Analysis': [1.7564707973660298,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0]},\n",
              " {'Gradient Descent': [0.8769514395748774, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.5]},\n",
              " {'Unsupervised Learning': [0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.8769514395748774]},\n",
              " {'Dynamic Programming': [0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774]},\n",
              " {'Reinforcement Learning': [0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.0,\n",
              "   0.8769514395748774]},\n",
              " {'Dimensionality Reduction': [0.8769514395748774,\n",
              "   0.5,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146,\n",
              "   0.5,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5]},\n",
              " {'Neural Network': [1.2618595071429146,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   1.7564707973660298,\n",
              "   1.7564707973660298,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.8769514395748774]},\n",
              " {'Supervised Learning': [0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0]},\n",
              " {'Machine Learning': [0.8769514395748774,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Time Series': [0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146]},\n",
              " {'Artificial Neural': [0.5,\n",
              "   0.8769514395748774,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.5]},\n",
              " {'Hidden Markov': [0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   1.2618595071429146,\n",
              "   0.5,\n",
              "   0.8769514395748774]},\n",
              " {'Dynamical Systems': [0.8769514395748774,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.8769514395748774]},\n",
              " {'Nearest Neighbor': [0.8769514395748774,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.0,\n",
              "   0.0,\n",
              "   0.8769514395748774]},\n",
              " {'Gaussian Process': [1.7564707973660298,\n",
              "   0.5,\n",
              "   0,\n",
              "   1.2618595071429146,\n",
              "   0.5,\n",
              "   2.584962500721156,\n",
              "   0.8769514395748774,\n",
              "   1.2618595071429146]}]"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_stability(nn_8_[0][\"Reinforcement Learning\"], nn_7_[0][\"Reinforcement Learning\"])\n"
      ],
      "metadata": {
        "id": "ROcoZZiyzZaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = [n for n in nn_2_] \n",
        "\n",
        "\n",
        "\n",
        "list(nn_2_[0].keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O0LyJM3F04gM",
        "outputId": "1e2a781d-b9df-497e-d863-11a9f7be4a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reinforcement Learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    }
  ]
}