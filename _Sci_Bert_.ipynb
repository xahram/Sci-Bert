{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_Sci_Bert_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xahram/Sci-Bert/blob/main/_Sci_Bert_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First step is to load the NIPS data that is uploaded in the Google Drive"
      ],
      "metadata": {
        "id": "oPZ9rjzVQFYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive folder into the directory to access files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmrUd6BcBAKB",
        "outputId": "7f2d928e-c4b4-45f2-b9fb-dded5f0df63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import time \n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n"
      ],
      "metadata": {
        "id": "YZGpDT8-BrZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e89c2a-bdd8-4ed7-f884-4dc0a38da75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the NIPS dataset from the drive\n",
        "\n",
        "nips_papers_df = pd.read_csv('/gdrive/My Drive/Master_dataset/papers.csv')  \n",
        "nips_papers_df.head()\n",
        "\n",
        "nips_papers = nips_papers_df.infer_objects()\n",
        "\n",
        "nips_papers.dtypes\n",
        "\n",
        "nips_papers[\"year\"] = pd.to_datetime(nips_papers[\"year\"], format=\"%Y\")\n",
        "# nips_papers['year'] = nips_papers['year'].dt.year\n",
        "nips_papers.sort_values(by='year')\n",
        "\n",
        "print(nips_papers.dtypes)\n",
        "\n",
        "max(nips_papers[\"year\"])\n",
        "min(nips_papers[\"year\"])\n",
        "\n",
        "nips_papers = nips_papers.sort_values(by = \"year\")\n"
      ],
      "metadata": {
        "id": "z0H4P5yIBexP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc9b72b-38a2-44b6-bd3f-6deaf86549b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                     int64\n",
            "year          datetime64[ns]\n",
            "title                 object\n",
            "event_type            object\n",
            "pdf_name              object\n",
            "abstract              object\n",
            "paper_text            object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import close\n",
        "# Slice Data Frame by 3 year interval\n",
        "\n",
        "\n",
        "# print(len(nips_papers))\n",
        "\n",
        "# Partition/Group Papers into df by the interval/freq of 3 years, closed = left to start combinbing from the 1987\n",
        "nips_papers_3y_grouped = nips_papers.groupby(pd.Grouper(key='year', freq='3Y', sort=True, closed=\"left\"))\n",
        "\n",
        "\n",
        "\n",
        "# Save partitions in the Dictionary format with 10 intervals\n",
        "nips_papers_partitions = {}\n",
        "initial_partition_id = 0\n",
        "for i, g  in nips_papers_3y_grouped:\n",
        "    nips_papers_partitions[initial_partition_id] = g\n",
        "    initial_partition_id = initial_partition_id + 1\n",
        "\n",
        "\n",
        "print(nips_papers_partitions)\n",
        "# nips_papers_three_year_partition[0].tail()\n",
        "\n",
        "\n",
        "#for i, g in nips_papers.groupby(pd.Grouper(key=nips_papers[\"year\"], freq='A')):\n",
        "#     print(g)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4A_aWwViSXFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8769dc-b323-480a-c296-1142d93b272f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0:        id       year                                              title  \\\n",
            "0       1 1987-01-01  Self-Organization of Associative Database and ...   \n",
            "328    13 1987-01-01   Temporal Patterns of Activity in Neural Networks   \n",
            "6853   72 1987-01-01  Ensemble' Boltzmann Units have Collective Comp...   \n",
            "6743   71 1987-01-01  Centric Models of the Orientation Map in Prima...   \n",
            "6632   70 1987-01-01  On the Power of Neural Networks for Solving Ha...   \n",
            "...   ...        ...                                                ...   \n",
            "1650  250 1989-01-01                               Optimal Brain Damage   \n",
            "1661  251 1989-01-01  A Self-organizing Associative Memory System fo...   \n",
            "1672  252 1989-01-01  Can Simple Cells Learn Curves? A Hebbian Model...   \n",
            "1683  253 1989-01-01  Subgrouping Reduces Complexity and Speeds Up L...   \n",
            "1638  249 1989-01-01  Neural Network Analysis of Distributed Represe...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "0           NaN  1-self-organization-of-associative-database-an...   \n",
            "328         NaN  13-temporal-patterns-of-activity-in-neural-net...   \n",
            "6853        NaN  72-ensemble-boltzmann-units-have-collective-co...   \n",
            "6743        NaN  71-centric-models-of-the-orientation-map-in-pr...   \n",
            "6632        NaN  70-on-the-power-of-neural-networks-for-solving...   \n",
            "...         ...                                                ...   \n",
            "1650        NaN                       250-optimal-brain-damage.pdf   \n",
            "1661        NaN  251-a-self-organizing-associative-memory-syste...   \n",
            "1672        NaN  252-can-simple-cells-learn-curves-a-hebbian-mo...   \n",
            "1683        NaN  253-subgrouping-reduces-complexity-and-speeds-...   \n",
            "1638        NaN  249-neural-network-analysis-of-distributed-rep...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
            "328   Abstract Missing  297\\n\\nTEMPORAL PATTERNS OF ACTIVITY IN\\nNEURA...  \n",
            "6853  Abstract Missing  223\\n\\n'Ensemble' Boltzmann Units\\nhave Collec...  \n",
            "6743  Abstract Missing  62\\n\\nCentric Models of the Orientation Map in...  \n",
            "6632  Abstract Missing  137\\n\\nOn the Power of Neural Networks for\\nSo...  \n",
            "...                ...                                                ...  \n",
            "1650  Abstract Missing  598\\n\\nLe Cun, Denker and Solla\\n\\nOptimal Bra...  \n",
            "1661  Abstract Missing  332\\n\\nHormel\\n\\nA Sell-organizing Associative...  \n",
            "1672  Abstract Missing  Can Simple Cells Learn Curves? A Hebbian Model...  \n",
            "1683  Abstract Missing  638\\n\\nZipser\\n\\nSubgrouping Reduces Complexit...  \n",
            "1638  Abstract Missing  28\\n\\nLockery t Fang and Sejnowski\\n\\nNeu.?al ...  \n",
            "\n",
            "[285 rows x 7 columns], 1:        id       year                                              title  \\\n",
            "3212  391 1990-01-01  Designing Linear Threshold Based Neural Networ...   \n",
            "3401  408 1990-01-01                           Adaptive Spline Networks   \n",
            "3278  397 1990-01-01  Integrated Segmentation and Recognition of Han...   \n",
            "3390  407 1990-01-01         Convergence of a Neural Network Classifier   \n",
            "3245  394 1990-01-01  Chaitin-Kolmogorov Complexity and Generalizati...   \n",
            "...   ...        ...                                                ...   \n",
            "5946  638 1992-01-01  Network Structuring and Training Using Rule-ba...   \n",
            "5769  622 1992-01-01    Information, Prediction, and Query by Committee   \n",
            "5758  621 1992-01-01  Some Solutions to the Missing Feature Problem ...   \n",
            "5747  620 1992-01-01  Connected Letter Recognition with a Multi-Stat...   \n",
            "5802  625 1992-01-01  Visual Motion Computation in Analog VLSI Using...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3212        NaN  391-designing-linear-threshold-based-neural-ne...   \n",
            "3401        NaN                   408-adaptive-spline-networks.pdf   \n",
            "3278        NaN  397-integrated-segmentation-and-recognition-of...   \n",
            "3390        NaN  407-convergence-of-a-neural-network-classifier...   \n",
            "3245        NaN  394-chaitin-kolmogorov-complexity-and-generali...   \n",
            "...         ...                                                ...   \n",
            "5946        NaN  638-network-structuring-and-training-using-rul...   \n",
            "5769        NaN  622-information-prediction-and-query-by-commit...   \n",
            "5758        NaN  621-some-solutions-to-the-missing-feature-prob...   \n",
            "5747        NaN  620-connected-letter-recognition-with-a-multi-...   \n",
            "5802        NaN  625-visual-motion-computation-in-analog-vlsi-u...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "3212  Abstract Missing  Designing Linear Threshold Based Neural\\nNetwo...  \n",
            "3401  Abstract Missing  ADAPTIVE SPLINE NETWORKS\\n\\nJerome H. Friedman...  \n",
            "3278  Abstract Missing  Integrated Segmentation and Recognition of\\nHa...  \n",
            "3390  Abstract Missing  Convergence of a Neural Network Classifier\\n\\n...  \n",
            "3245  Abstract Missing  Chaitin-Kolmogorov Complexity\\nand Generalizat...  \n",
            "...                ...                                                ...  \n",
            "5946  Abstract Missing  Network Structuring And Training Using\\nRule-b...  \n",
            "5769  Abstract Missing  Information, prediction, and query by\\ncommitt...  \n",
            "5758  Abstract Missing  Some Solutions to the Missing Feature Problem\\...  \n",
            "5747  Abstract Missing  Connected Letter Recognition with a\\nMulti-Sta...  \n",
            "5802  Abstract Missing  Visual Motion Computation in Analog\\nVLSI usin...  \n",
            "\n",
            "[414 rows x 7 columns], 2:         id       year                                              title  \\\n",
            "7006   782 1993-01-01  Optimal Unsupervised Motor Learning Predicts t...   \n",
            "7005   781 1993-01-01  A Comparison of Dynamic Reposing and Tangent D...   \n",
            "7004   780 1993-01-01         Dynamic Modulation of Neurons and Networks   \n",
            "7002   779 1993-01-01    Address Block Location with a Neural Net System   \n",
            "7001   778 1993-01-01  A Learning Analog Neural Network Chip with Con...   \n",
            "...    ...        ...                                                ...   \n",
            "69    1060 1995-01-01  Statistical Theory of Overtraining - Is Cross-...   \n",
            "63    1055 1995-01-01  Adaptive Retina with Center-Surround Receptive...   \n",
            "150   1135 1995-01-01               Information through a Spiking Neuron   \n",
            "62    1054 1995-01-01  Implementation Issues in the Fourier Transform...   \n",
            "65    1057 1995-01-01  When is an Integrate-and-fire Neuron like a Po...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "7006        NaN  782-optimal-unsupervised-motor-learning-predic...   \n",
            "7005        NaN  781-a-comparison-of-dynamic-reposing-and-tange...   \n",
            "7004        NaN  780-dynamic-modulation-of-neurons-and-networks...   \n",
            "7002        NaN  779-address-block-location-with-a-neural-net-s...   \n",
            "7001        NaN  778-a-learning-analog-neural-network-chip-with...   \n",
            "...         ...                                                ...   \n",
            "69          NaN  1060-statistical-theory-of-overtraining-is-cro...   \n",
            "63          NaN  1055-adaptive-retina-with-center-surround-rece...   \n",
            "150         NaN      1135-information-through-a-spiking-neuron.pdf   \n",
            "62          NaN  1054-implementation-issues-in-the-fourier-tran...   \n",
            "65          NaN  1057-when-is-an-integrate-and-fire-neuron-like...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "7006  Abstract Missing  Optimal Unsupervised Motor Learning\\nPredicts ...  \n",
            "7005  Abstract Missing  A Comparison of Dynamic Reposing and\\nTangent ...  \n",
            "7004  Abstract Missing  Dynamic Modulation of Neurons and Networks\\n\\n...  \n",
            "7002  Abstract Missing  Address Block Location with a Neural Net Syste...  \n",
            "7001  Abstract Missing  A Learning Analog Neural Network Chip\\nwith Co...  \n",
            "...                ...                                                ...  \n",
            "69    Abstract Missing  Statistical Theory of Overtraining - Is\\nCross...  \n",
            "63    Abstract Missing  Adaptive Retina with Center-Surround\\nReceptiv...  \n",
            "150   Abstract Missing  Information through a Spiking Neuron\\n\\nCharle...  \n",
            "62    Abstract Missing  Implementation Issues in the Fourier\\nTransfor...  \n",
            "65    Abstract Missing  When is an Integrate-and-fire Neuron\\nlike a P...  \n",
            "\n",
            "[450 rows x 7 columns], 3:        id       year                                              title  \\\n",
            "288  1263 1996-01-01  Training Algorithms for Hidden Markov Models u...   \n",
            "290  1265 1996-01-01  A Silicon Model of Amplitude Modulation Detect...   \n",
            "291  1266 1996-01-01  Learning Temporally Persistent Hierarchical Re...   \n",
            "289  1264 1996-01-01                       Hidden Markov Decision Trees   \n",
            "279  1255 1996-01-01  A Model of Recurrent Interactions in Primary V...   \n",
            "..    ...        ...                                                ...   \n",
            "534  1489 1998-01-01            A Neuromorphic Monaural Sound Localizer   \n",
            "536  1490 1998-01-01  Very Fast EM-Based Mixture Model Clustering Us...   \n",
            "537  1491 1998-01-01        Kernel PCA and De-Noising in Feature Spaces   \n",
            "538  1492 1998-01-01  Viewing Classifier Systems as Model Free Learn...   \n",
            "532  1487 1998-01-01  A Reinforcement Learning Algorithm in Partiall...   \n",
            "\n",
            "    event_type                                           pdf_name  \\\n",
            "288        NaN  1263-training-algorithms-for-hidden-markov-mod...   \n",
            "290        NaN  1265-a-silicon-model-of-amplitude-modulation-d...   \n",
            "291        NaN  1266-learning-temporally-persistent-hierarchic...   \n",
            "289        NaN              1264-hidden-markov-decision-trees.pdf   \n",
            "279        NaN  1255-a-model-of-recurrent-interactions-in-prim...   \n",
            "..         ...                                                ...   \n",
            "534        NaN   1489-a-neuromorphic-monaural-sound-localizer.pdf   \n",
            "536        NaN  1490-very-fast-em-based-mixture-model-clusteri...   \n",
            "537        NaN  1491-kernel-pca-and-de-noising-in-feature-spac...   \n",
            "538        NaN  1492-viewing-classifier-systems-as-model-free-...   \n",
            "532        NaN  1487-a-reinforcement-learning-algorithm-in-par...   \n",
            "\n",
            "             abstract                                         paper_text  \n",
            "288  Abstract Missing  Training Algorithms for Hidden Markov Models\\n...  \n",
            "290  Abstract Missing  A Silicon Model of\\nAmplitude Modulation Detec...  \n",
            "291  Abstract Missing  Learning temporally persistent\\nhierarchical r...  \n",
            "289  Abstract Missing  Hidden Markov decision trees\\nMichael I. Jorda...  \n",
            "279  Abstract Missing  A Model of Recurrent Interactions in\\nPrimary ...  \n",
            "..                ...                                                ...  \n",
            "534  Abstract Missing  A N euromorphic Monaural Sound\\nLocalizer\\nJoh...  \n",
            "536  Abstract Missing  Very Fast EM-based Mixture Model\\nClustering u...  \n",
            "537  Abstract Missing  Kernel peA and De-Noising in Feature Spaces\\n\\...  \n",
            "538  Abstract Missing  Viewing Classifier Systems\\nas Model Free Lear...  \n",
            "532  Abstract Missing  A Reinforcement Learning Algorithm\\nin Partial...  \n",
            "\n",
            "[453 rows x 7 columns], 4:         id       year                                              title  \\\n",
            "803   1735 1999-01-01                     Uniqueness of the SVM Solution   \n",
            "807   1739 1999-01-01  Algebraic Analysis for Non-regular Learning Ma...   \n",
            "804   1736 1999-01-01  Nonlinear Discriminant Analysis Using Kernel F...   \n",
            "805   1737 1999-01-01                                Potential Boosters?   \n",
            "781   1715 1999-01-01  Invariant Feature Extraction and Classificatio...   \n",
            "...    ...        ...                                                ...   \n",
            "1125  2026 2001-01-01  Modeling Temporal Structure in Classical Condi...   \n",
            "1126  2027 2001-01-01  TAP Gibbs Free Energy, Belief Propagation and ...   \n",
            "1128  2029 2001-01-01  Hyperbolic Self-Organizing Maps for Semantic N...   \n",
            "1121  2022 2001-01-01  Learning Lateral Interactions for Feature Bind...   \n",
            "1086  1992 2001-01-01         Spectral Relaxation for K-means Clustering   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "803         NaN            1735-uniqueness-of-the-svm-solution.pdf   \n",
            "807         NaN  1739-algebraic-analysis-for-non-regular-learni...   \n",
            "804         NaN  1736-nonlinear-discriminant-analysis-using-ker...   \n",
            "805         NaN                        1737-potential-boosters.pdf   \n",
            "781         NaN  1715-invariant-feature-extraction-and-classifi...   \n",
            "...         ...                                                ...   \n",
            "1125        NaN  2026-modeling-temporal-structure-in-classical-...   \n",
            "1126        NaN  2027-tap-gibbs-free-energy-belief-propagation-...   \n",
            "1128        NaN  2029-hyperbolic-self-organizing-maps-for-seman...   \n",
            "1121        NaN  2022-learning-lateral-interactions-for-feature...   \n",
            "1086        NaN  1992-spectral-relaxation-for-k-means-clusterin...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "803   Abstract Missing  Uniqueness of the SVM Solution\\n\\nChristopher ...  \n",
            "807   Abstract Missing  Algebraic Analysis for Non-Regular\\nLearning M...  \n",
            "804   Abstract Missing  Nonlinear Discriminant Analysis using\\nKernel ...  \n",
            "805   Abstract Missing  Potential Boosters ?\\nNigel Duffy\\nDepartment ...  \n",
            "781   Abstract Missing  U nmixing Hyperspectral Data\\n\\nLucas Parra, C...  \n",
            "...                ...                                                ...  \n",
            "1125  Abstract Missing  Modeling Temporal Structure in Classical\\nCond...  \n",
            "1126  Abstract Missing  TAP Gibbs Free Energy, Belief Propagation and\\...  \n",
            "1128  Abstract Missing  Hyperbolic Self-Organizing Maps for Semantic\\n...  \n",
            "1121  Abstract Missing  Learning Lateral Interactions for\\nFeature Bin...  \n",
            "1086  Abstract Missing  Spectral Relaxation for K-means\\nClustering\\n\\...  \n",
            "\n",
            "[499 rows x 7 columns], 5:         id       year                                              title  \\\n",
            "1319  2200 2002-01-01                 A Bilinear Model for Sparse Coding   \n",
            "1392  2267 2002-01-01  Data-Dependent Bounds for Bayesian Mixture Met...   \n",
            "1393  2268 2002-01-01  Shape Recipes: Scene Representations that Refe...   \n",
            "1394  2269 2002-01-01  Ranking with Large Margin Principle: Two Appro...   \n",
            "1396  2270 2002-01-01  An Estimation-Theoretic Framework for the Pres...   \n",
            "...    ...        ...                                                ...   \n",
            "1717  2560 2004-01-01                         Adaptive Manifold Learning   \n",
            "1718  2561 2004-01-01                       Dependent Gaussian Processes   \n",
            "1704  2549 2004-01-01  The Power of Selective Memory: Self-Bounded Le...   \n",
            "1719  2562 2004-01-01  Edge of Chaos Computation in Mixed-Mode VLSI -...   \n",
            "1713  2557 2004-01-01  Conditional Models of Identity Uncertainty wit...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "1319        NaN        2200-a-bilinear-model-for-sparse-coding.pdf   \n",
            "1392        NaN  2267-data-dependent-bounds-for-bayesian-mixtur...   \n",
            "1393        NaN  2268-shape-recipes-scene-representations-that-...   \n",
            "1394        NaN  2269-ranking-with-large-margin-principle-two-a...   \n",
            "1396        NaN  2270-an-estimation-theoretic-framework-for-the...   \n",
            "...         ...                                                ...   \n",
            "1717        NaN                2560-adaptive-manifold-learning.pdf   \n",
            "1718        NaN              2561-dependent-gaussian-processes.pdf   \n",
            "1704        NaN  2549-the-power-of-selective-memory-self-bounde...   \n",
            "1719        NaN  2562-edge-of-chaos-computation-in-mixed-mode-v...   \n",
            "1713        NaN  2557-conditional-models-of-identity-uncertaint...   \n",
            "\n",
            "              abstract                                         paper_text  \n",
            "1319  Abstract Missing  A Bilinear Model for Sparse Coding\\n\\nDavid B....  \n",
            "1392  Abstract Missing  Data-Dependent Bounds for Bayesian\\nMixture Me...  \n",
            "1393  Abstract Missing  Shape Recipes: Scene Representations that Refe...  \n",
            "1394  Abstract Missing  Ranking with Large Margin Principle: Two\\nAppr...  \n",
            "1396  Abstract Missing  An Estimation-Theoretic Framework for\\nthe Pre...  \n",
            "...                ...                                                ...  \n",
            "1717  Abstract Missing  Adaptive Manifold Learning\\n\\nJing Wang, Zheny...  \n",
            "1718  Abstract Missing  Dependent Gaussian Processes\\n\\nPhillip Boyle ...  \n",
            "1704  Abstract Missing  The Power of Selective Memory:\\nSelf-Bounded L...  \n",
            "1719  Abstract Missing  Edge of Chaos Computation in\\nMixed-Mode VLSI ...  \n",
            "1713  Abstract Missing  Conditional Models of Identity Uncertainty\\nwi...  \n",
            "\n",
            "[612 rows x 7 columns], 6:         id       year                                              title  \\\n",
            "2012  2828 2005-01-01  Asymptotics of Gaussian Regularized Least Squares   \n",
            "2013  2829 2005-01-01     Two view learning: SVM-2K, Theory and Practice   \n",
            "2015  2830 2005-01-01         Saliency Based on Information Maximization   \n",
            "2016  2831 2005-01-01     Faster Rates in Regression via Active Learning   \n",
            "2017  2832 2005-01-01                           Layered Dynamic Textures   \n",
            "...    ...        ...                                                ...   \n",
            "2462  3233 2007-01-01  Fitted Q-iteration in continuous action-space ...   \n",
            "2463  3234 2007-01-01      Topmoumoute Online Natural Gradient Algorithm   \n",
            "2464  3235 2007-01-01  Sparse Overcomplete Latent Variable Decomposit...   \n",
            "2465  3236 2007-01-01  Second Order Bilinear Discriminant Analysis fo...   \n",
            "2466  3237 2007-01-01  Learning Horizontal Connections in a Sparse Co...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2012        NaN  2828-asymptotics-of-gaussian-regularized-least...   \n",
            "2013        NaN  2829-two-view-learning-svm-2k-theory-and-pract...   \n",
            "2015        NaN  2830-saliency-based-on-information-maximizatio...   \n",
            "2016        NaN  2831-faster-rates-in-regression-via-active-lea...   \n",
            "2017        NaN                  2832-layered-dynamic-textures.pdf   \n",
            "...         ...                                                ...   \n",
            "2462        NaN  3233-fitted-q-iteration-in-continuous-action-s...   \n",
            "2463        NaN  3234-topmoumoute-online-natural-gradient-algor...   \n",
            "2464        NaN  3235-sparse-overcomplete-latent-variable-decom...   \n",
            "2465        NaN  3236-second-order-bilinear-discriminant-analys...   \n",
            "2466        NaN  3237-learning-horizontal-connections-in-a-spar...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2012                                   Abstract Missing   \n",
            "2013                                   Abstract Missing   \n",
            "2015                                   Abstract Missing   \n",
            "2016                                   Abstract Missing   \n",
            "2017                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "2462  We consider continuous state, continuous actio...   \n",
            "2463  Guided by the goal of obtaining an optimizatio...   \n",
            "2464  An important problem in many fields is the ana...   \n",
            "2465  Traditional analysis methods for single-trial ...   \n",
            "2466  It has been shown that adapting a dictionary o...   \n",
            "\n",
            "                                             paper_text  \n",
            "2012  Asymptotics of Gaussian Regularized\\nLeast-Squ...  \n",
            "2013  Two view learning: SVM-2K, Theory and\\nPractic...  \n",
            "2015  Saliency Based on Information Maximization\\n\\n...  \n",
            "2016  Faster Rates in Regression via Active Learning...  \n",
            "2017  Layered Dynamic Textures\\n\\nAntoni B. Chan\\nNu...  \n",
            "...                                                 ...  \n",
            "2462  Fitted Q-iteration in continuous action-space ...  \n",
            "2463  Topmoumoute online natural gradient algorithm\\...  \n",
            "2464  Sparse Overcomplete Latent Variable Decomposit...  \n",
            "2465  Second Order Bilinear Discriminant Analysis fo...  \n",
            "2466  Learning Horizontal Connections in a Sparse Co...  \n",
            "\n",
            "[628 rows x 7 columns], 7:         id       year                                              title  \\\n",
            "2810  3548 2008-01-01  Nonlinear causal discovery with additive noise...   \n",
            "2809  3547 2008-01-01  Goal-directed decision making in prefrontal co...   \n",
            "2808  3546 2008-01-01  Nonparametric Bayesian Learning of Switching L...   \n",
            "2807  3545 2008-01-01     Policy Search for Motor Primitives in Robotics   \n",
            "2806  3544 2008-01-01       Inferring rankings under constrained sensing   \n",
            "...    ...        ...                                                ...   \n",
            "3334  4019 2010-01-01  Two-Layer Generalization Analysis for Ranking ...   \n",
            "3444  4119 2010-01-01  b-Bit Minwise Hashing for Estimating Three-Way...   \n",
            "3336  4020 2010-01-01  Over-complete representations on recurrent neu...   \n",
            "3329  4014 2010-01-01       Agnostic Active Learning Without Constraints   \n",
            "3279  3970 2010-01-01  Sodium entry efficiency during action potentia...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "2810        NaN  3548-nonlinear-causal-discovery-with-additive-...   \n",
            "2809        NaN  3547-goal-directed-decision-making-in-prefront...   \n",
            "2808        NaN  3546-nonparametric-bayesian-learning-of-switch...   \n",
            "2807        NaN  3545-policy-search-for-motor-primitives-in-rob...   \n",
            "2806        NaN  3544-inferring-rankings-under-constrained-sens...   \n",
            "...         ...                                                ...   \n",
            "3334        NaN  4019-two-layer-generalization-analysis-for-ran...   \n",
            "3444        NaN  4119-b-bit-minwise-hashing-for-estimating-thre...   \n",
            "3336        NaN  4020-over-complete-representations-on-recurren...   \n",
            "3329        NaN  4014-agnostic-active-learning-without-constrai...   \n",
            "3279        NaN  3970-sodium-entry-efficiency-during-action-pot...   \n",
            "\n",
            "                                               abstract  \\\n",
            "2810  The discovery of causal relationships between ...   \n",
            "2809  Research in animal learning and behavioral neu...   \n",
            "2808  Many nonlinear dynamical phenomena can be effe...   \n",
            "2807  Many motor skills in humanoid robotics can be ...   \n",
            "2806                                   Abstract Missing   \n",
            "...                                                 ...   \n",
            "3334  This paper is concerned with the generalizatio...   \n",
            "3444  Computing two-way and multi-way set similariti...   \n",
            "3336  A striking aspect of cortical neural networks ...   \n",
            "3329  We present and analyze an agnostic active lear...   \n",
            "3279  Sodium entry during an action potential determ...   \n",
            "\n",
            "                                             paper_text  \n",
            "2810  Nonlinear causal discovery with additive noise...  \n",
            "2809  Goal-directed decision making in prefrontal\\nc...  \n",
            "2808  Nonparametric Bayesian Learning of Switching\\n...  \n",
            "2807  Policy Search for Motor Primitives in Robotics...  \n",
            "2806  Inferring rankings under constrained sensing\\n...  \n",
            "...                                                 ...  \n",
            "3334  Two-layer Generalization Analysis for Ranking ...  \n",
            "3444  b-Bit Minwise Hashing for Estimating Three-Way...  \n",
            "3336  Over-complete representations on recurrent neu...  \n",
            "3329  Agnostic Active Learning Without Constraints\\n...  \n",
            "3279  Sodium entry efficiency during action potentia...  \n",
            "\n",
            "[804 rows x 7 columns], 8:         id       year                                              title  \\\n",
            "3620  4278 2011-01-01  Learning in Hilbert vs. Banach Spaces: A Measu...   \n",
            "3798  4439 2011-01-01             Generalized Beta Mixtures of Gaussians   \n",
            "3744  4390 2011-01-01  Hogwild: A Lock-Free Approach to Parallelizing...   \n",
            "3742  4389 2011-01-01      An Exact Algorithm for F-Measure Maximization   \n",
            "3741  4388 2011-01-01                 Prediction strategies without loss   \n",
            "...    ...        ...                                                ...   \n",
            "4618  5179 2013-01-01  Learning Trajectory Preferences for  Manipulat...   \n",
            "4642  5200 2013-01-01         Non-Linear Domain Adaptation with Boosting   \n",
            "4638  5198 2013-01-01  Higher Order Priors for Joint Intrinsic Image,...   \n",
            "4643  5201 2013-01-01  Modeling Clutter Perception using Parametric P...   \n",
            "4516  5087 2013-01-01  Efficient Optimization for Sparse Gaussian Pro...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "3620        NaN  4278-learning-in-hilbert-vs-banach-spaces-a-me...   \n",
            "3798        NaN    4439-generalized-beta-mixtures-of-gaussians.pdf   \n",
            "3744        NaN  4390-hogwild-a-lock-free-approach-to-paralleli...   \n",
            "3742        NaN  4389-an-exact-algorithm-for-f-measure-maximiza...   \n",
            "3741        NaN        4388-prediction-strategies-without-loss.pdf   \n",
            "...         ...                                                ...   \n",
            "4618     Poster  5179-learning-trajectory-preferences-for-manip...   \n",
            "4642     Poster  5200-non-linear-domain-adaptation-with-boostin...   \n",
            "4638     Poster  5198-higher-order-priors-for-joint-intrinsic-i...   \n",
            "4643     Poster  5201-modeling-clutter-perception-using-paramet...   \n",
            "4516     Poster  5087-efficient-optimization-for-sparse-gaussia...   \n",
            "\n",
            "                                               abstract  \\\n",
            "3620  The goal of this paper is to investigate the a...   \n",
            "3798  In recent years, a rich variety of shrinkage p...   \n",
            "3744  Stochastic Gradient Descent (SGD) is a popular...   \n",
            "3742  The F-measure, originally introduced in inform...   \n",
            "3741  Consider a sequence of bits where we are tryin...   \n",
            "...                                                 ...   \n",
            "4618  We consider the problem of learning good traje...   \n",
            "4642  A common assumption in machine vision is that ...   \n",
            "4638  Many methods have been proposed to recover the...   \n",
            "4643  Visual clutter, the perception of an image as ...   \n",
            "4516  We propose an efficient discrete optimization ...   \n",
            "\n",
            "                                             paper_text  \n",
            "3620  Learning in Hilbert vs. Banach Spaces: A Measu...  \n",
            "3798  Generalized Beta Mixtures of Gaussians\\nArtin ...  \n",
            "3744  H OGWILD !: A Lock-Free Approach to Paralleliz...  \n",
            "3742  An Exact Algorithm for F-Measure Maximization\\...  \n",
            "3741  Prediction strategies without loss\\n\\nRina Pan...  \n",
            "...                                                 ...  \n",
            "4618  Learning Trajectory Preferences for Manipulato...  \n",
            "4642  Non-Linear Domain Adaptation with Boosting\\n\\n...  \n",
            "4638  Higher Order Priors for Joint Intrinsic Image,...  \n",
            "4643  Modeling Clutter Perception using Parametric\\n...  \n",
            "4516  Efficient Optimization for\\nSparse Gaussian Pr...  \n",
            "\n",
            "[1034 rows x 7 columns], 9:         id       year                                              title  \\\n",
            "4813  5358 2014-01-01  Probabilistic low-rank matrix completion on fi...   \n",
            "4805  5350 2014-01-01  Learning to Discover Efficient Mathematical Id...   \n",
            "4806  5351 2014-01-01  Searching for Higgs Boson Decay Modes with Dee...   \n",
            "4807  5352 2014-01-01  Semi-supervised Learning with Deep Generative ...   \n",
            "4808  5353 2014-01-01  Two-Stream Convolutional Networks for Action R...   \n",
            "...    ...        ...                                                ...   \n",
            "6042  6466 2016-01-01  Bayesian optimization for automated model sele...   \n",
            "6029  6454 2016-01-01  A Non-parametric Learning Method for Confident...   \n",
            "6041  6465 2016-01-01  R-FCN: Object Detection via Region-based Fully...   \n",
            "6040  6464 2016-01-01       Learning Deep Embeddings with Histogram Loss   \n",
            "6043  6467 2016-01-01  Generalization of ERM in Stochastic Convex Opt...   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "4813     Poster  5358-probabilistic-low-rank-matrix-completion-...   \n",
            "4805  Spotlight  5350-learning-to-discover-efficient-mathematic...   \n",
            "4806  Spotlight  5351-searching-for-higgs-boson-decay-modes-wit...   \n",
            "4807  Spotlight  5352-semi-supervised-learning-with-deep-genera...   \n",
            "4808  Spotlight  5353-two-stream-convolutional-networks-for-act...   \n",
            "...         ...                                                ...   \n",
            "6042     Poster  6466-bayesian-optimization-for-automated-model...   \n",
            "6029     Poster  6454-a-non-parametric-learning-method-for-conf...   \n",
            "6041     Poster  6465-r-fcn-object-detection-via-region-based-f...   \n",
            "6040     Poster  6464-learning-deep-embeddings-with-histogram-l...   \n",
            "6043     Poster  6467-generalization-of-erm-in-stochastic-conve...   \n",
            "\n",
            "                                               abstract  \\\n",
            "4813  The task of reconstructing a matrix given a sa...   \n",
            "4805  In this paper we explore how machine learning ...   \n",
            "4806  Particle colliders enable us to probe the fund...   \n",
            "4807  The ever-increasing size of modern data sets c...   \n",
            "4808  We investigate architectures of discriminative...   \n",
            "...                                                 ...   \n",
            "6042  Despite the success of kernel-based nonparamet...   \n",
            "6029  Estimating patient's clinical state from multi...   \n",
            "6041  We present region-based, fully convolutional n...   \n",
            "6040  We suggest a new loss for learning deep embedd...   \n",
            "6043  In stochastic convex optimization the goal is ...   \n",
            "\n",
            "                                             paper_text  \n",
            "4813  Probabilistic low-rank matrix completion on fi...  \n",
            "4805  Learning to Discover\\nEfficient Mathematical I...  \n",
            "4806  Searching for Higgs Boson Decay Modes\\nwith De...  \n",
            "4807  Semi-supervised Learning with\\nDeep Generative...  \n",
            "4808  Two-Stream Convolutional Networks\\nfor Action ...  \n",
            "...                                                 ...  \n",
            "6042  Bayesian optimization for automated model sele...  \n",
            "6029  A Non-parametric Learning Method for Confident...  \n",
            "6041  R-FCN: Object Detection via\\nRegion-based Full...  \n",
            "6040  Learning Deep Embeddings with Histogram Loss\\n...  \n",
            "6043  Generalization of ERM in Stochastic Convex\\nOp...  \n",
            "\n",
            "[1383 rows x 7 columns], 10:         id       year                                              title  \\\n",
            "6935  7273 2017-01-01  Houdini: Fooling Deep Structured Visual and Sp...   \n",
            "6933  7271 2017-01-01  Convergence of Gradient EM on Multi-component ...   \n",
            "6937  7275 2017-01-01  When Cyclic Coordinate Descent Outperforms Ran...   \n",
            "6936  7274 2017-01-01  Efficient and Flexible Inference for Stochasti...   \n",
            "6932  7270 2017-01-01  Kernel Feature Selection via Conditional Covar...   \n",
            "...    ...        ...                                                ...   \n",
            "6707  7067 2017-01-01             Context Selection for Embedding Models   \n",
            "6708  7068 2017-01-01  Working hard to know your neighbor's margins: ...   \n",
            "6709  7069 2017-01-01  Accelerated Stochastic Greedy Coordinate Desce...   \n",
            "6405  6794 2017-01-01  Consistent Multitask Learning with Nonlinear O...   \n",
            "6665  7029 2017-01-01                      Federated Multi-Task Learning   \n",
            "\n",
            "     event_type                                           pdf_name  \\\n",
            "6935     Poster  7273-houdini-fooling-deep-structured-visual-an...   \n",
            "6933     Poster  7271-convergence-of-gradient-em-on-multi-compo...   \n",
            "6937     Poster  7275-when-cyclic-coordinate-descent-outperform...   \n",
            "6936     Poster  7274-efficient-and-flexible-inference-for-stoc...   \n",
            "6932     Poster  7270-kernel-feature-selection-via-conditional-...   \n",
            "...         ...                                                ...   \n",
            "6707     Poster    7067-context-selection-for-embedding-models.pdf   \n",
            "6708     Poster  7068-working-hard-to-know-your-neighbors-margi...   \n",
            "6709     Poster  7069-accelerated-stochastic-greedy-coordinate-...   \n",
            "6405     Poster  6794-consistent-multitask-learning-with-nonlin...   \n",
            "6665     Poster             7029-federated-multi-task-learning.pdf   \n",
            "\n",
            "                                               abstract  \\\n",
            "6935  Generating adversarial examples is a critical ...   \n",
            "6933  In this paper, we study convergence properties...   \n",
            "6937  The coordinate descent (CD) method is a classi...   \n",
            "6936  Many real world dynamical systems are describe...   \n",
            "6932  We propose a method for feature selection that...   \n",
            "...                                                 ...   \n",
            "6707  Word embeddings are an effective tool to analy...   \n",
            "6708  We introduce a loss for metric learning, which...   \n",
            "6709  In this paper we study the well-known greedy c...   \n",
            "6405  Key to multitask learning is exploiting the re...   \n",
            "6665  Federated learning poses new statistical and s...   \n",
            "\n",
            "                                             paper_text  \n",
            "6935  Houdini: Fooling Deep Structured Visual and Sp...  \n",
            "6933  Convergence of Gradient EM on Multi-component\\...  \n",
            "6937  When Cyclic Coordinate Descent Outperforms\\nRa...  \n",
            "6936  Efficient and Flexible Inference for Stochasti...  \n",
            "6932  Kernel Feature Selection via\\nConditional Cova...  \n",
            "...                                                 ...  \n",
            "6707  Context Selection for Embedding Models\\n\\nLi-P...  \n",
            "6708  Working hard to know your neighbor?s margins:\\...  \n",
            "6709  Accelerated Stochastic Greedy Coordinate Desce...  \n",
            "6405  Consistent Multitask Learning with\\nNonlinear ...  \n",
            "6665  Federated Multi-Task Learning\\n\\nVirginia Smit...  \n",
            "\n",
            "[679 rows x 7 columns]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT word2phrase to create bigrams and unigrams\n",
        "!git clone https://github.com/travisbrady/word2phrase.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6I115Y--CqF",
        "outputId": "a5a7f15c-4584-4b22-9bd1-909f35d797e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'word2phrase'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALL TIME WINDOWS SCI-BERT"
      ],
      "metadata": {
        "id": "kLi7qvOGatyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert List of Time Slice DF paper_text content to lists\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Loop through every DF and convert paper_text to list and concatenate all the papers of one time slice \n",
        "## this will be a list like  [\"All paper content string of first slice\", \"all paper content string of 2nd slice\", ...] \n",
        "\n",
        "papers_contents_list = [\" \".join(time_slice_df[\"paper_text\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n",
        "#### MEASURE THE EXECUTION TIME FOR RUNNING THE CONCATENATION CODE\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "\n",
        "# papers_contents_list\n",
        "# len(papers_contents_list[0])"
      ],
      "metadata": {
        "id": "lrwZ1HOQa9XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018f7f80-a25a-40ef-e0a7-f95f452c014a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10246014595031738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Join Paper titles for bigram and unigram extraction\n",
        "\n",
        "\n",
        "papers_titles_list = [\" \".join(time_slice_df[\"title\"].tolist()) for time_slice_df in nips_papers_partitions.values()]\n",
        "\n"
      ],
      "metadata": {
        "id": "RcUQthFrPyZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 -  Pre Processing \n",
        "\n",
        "# Remove Stopwords "
      ],
      "metadata": {
        "id": "uGQDbS_N62fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# function to rmeove digits and numbers from papers \n",
        "def regex_remove_digits(papers_contents_list):      \n",
        "    # Remove any digits for the corpus\n",
        "    all_time_window_papers_content_list = [re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", time_slice_paper) \n",
        "                                                    for time_slice_paper in papers_contents_list] \n",
        "    # Remove words with length less than 3 \n",
        "\n",
        "    # https://stackoverflow.com/questions/24332025/remove-words-of-length-less-than-4-from-string\n",
        "    all_time_window_papers_content_list = [re.sub(r'\\b\\w{1,2}\\b', '', time_slice_paper) \n",
        "                                          for time_slice_paper in all_time_window_papers_content_list]\n",
        "\n",
        "    return all_time_window_papers_content_list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4rWzW9Zl7FNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom Stopwords List for Scientific Literature \n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "path_to_stop_words = '/gdrive/My Drive/Master_dataset/stopwords_10000_most_frequent_filtered.txt'\n",
        "\n",
        "with open(path_to_stop_words, \"r\") as file1:\n",
        "    FileasList = file1.readlines()\n",
        "\n",
        "\n",
        "stopwords = [s.strip('\\n') for s in FileasList]\n",
        "print(len(stopwords))\n",
        "\n",
        "\n",
        "scientific_literature_stopwords = text.ENGLISH_STOP_WORDS.union(stopwords)\n",
        "\n",
        "len(scientific_literature_stopwords)\n"
      ],
      "metadata": {
        "id": "EYyOHKZ1QY0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8d00ed-f2e8-491c-bc04-95887fd204e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9958"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all paper content and titles for bigram and unigram generation\n",
        "all_time_window_papers_content_list = regex_remove_digits(papers_contents_list)\n",
        "all_time_window_papers_title_list = regex_remove_digits(papers_titles_list)\n"
      ],
      "metadata": {
        "id": "EM2Ek6JKQVJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Bag Of Candidate Keywords For All Time Windows"
      ],
      "metadata": {
        "id": "uaAZrFV9eAu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_time_window_papers_titles = \" \".join(all_time_window_papers_title_list)\n",
        "all_time_window_papers_titles = all_time_window_papers_titles.replace(',', '').replace(';', '').replace(\":\", \"\")"
      ],
      "metadata": {
        "id": "9vVvUZgCRXXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#About 900 stopwords\n",
        "stop_words = list(stopwords.words('english')) #About 150 stopwords\n",
        "stop_words.extend(scientific_literature_stopwords)\n",
        "\n",
        "\n",
        "\n",
        "token = nltk.word_tokenize(all_time_window_papers_titles)\n",
        "output = [lemmatizer.lemmatize(w) for w in token if not w in stop_words]\n",
        "\n",
        "unigrams = ngrams(output,1)\n",
        "bigrams = ngrams(output,2)\n",
        "\n",
        "\n",
        "\n",
        "# candidate_keywords = [ for n in ngrams]\n",
        "ngrams = Counter(bigrams).most_common()\n",
        "unigrams = Counter(unigrams).most_common()\n",
        "\n",
        "\n",
        "# unigrams = [ (n[0][0], n[1]) for n in unigrams]\n",
        "unigrams"
      ],
      "metadata": {
        "id": "FmvaKqj7CYQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8a8662-ee82-465a-be1c-0d2b74b59038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Learning',), 1447),\n",
              " (('Neural',), 565),\n",
              " (('Networks',), 548),\n",
              " (('Models',), 407),\n",
              " (('Model',), 331),\n",
              " (('Bayesian',), 287),\n",
              " (('Using',), 260),\n",
              " (('Network',), 240),\n",
              " (('The',), 225),\n",
              " (('Inference',), 221),\n",
              " (('Data',), 221),\n",
              " (('Analysis',), 215),\n",
              " (('Gaussian',), 202),\n",
              " (('Classification',), 194),\n",
              " (('Optimization',), 192),\n",
              " (('Sparse',), 186),\n",
              " (('Stochastic',), 181),\n",
              " (('Deep',), 170),\n",
              " (('Estimation',), 168),\n",
              " (('Recognition',), 163),\n",
              " (('Efficient',), 163),\n",
              " (('Clustering',), 162),\n",
              " (('Algorithms',), 160),\n",
              " (('Kernel',), 155),\n",
              " (('Reinforcement',), 151),\n",
              " (('Algorithm',), 144),\n",
              " (('Online',), 144),\n",
              " (('Adaptive',), 143),\n",
              " (('Linear',), 138),\n",
              " (('Regression',), 138),\n",
              " (('Optimal',), 136),\n",
              " (('Fast',), 136),\n",
              " (('Markov',), 133),\n",
              " (('Information',), 132),\n",
              " (('Visual',), 131),\n",
              " (('Image',), 128),\n",
              " (('Approach',), 125),\n",
              " (('Probabilistic',), 121),\n",
              " (('?',), 121),\n",
              " (('Processes',), 120),\n",
              " (('Feature',), 114),\n",
              " (('Gradient',), 113),\n",
              " (('Variational',), 113),\n",
              " (('Prediction',), 111),\n",
              " (('Modeling',), 109),\n",
              " (('Process',), 109),\n",
              " (('Methods',), 109),\n",
              " (('Robust',), 102),\n",
              " (('Dynamic',), 102),\n",
              " (('Recurrent',), 100),\n",
              " (('Hierarchical',), 97),\n",
              " (('Detection',), 97),\n",
              " (('Training',), 95),\n",
              " (('Random',), 95),\n",
              " (('Time',), 93),\n",
              " (('Structured',), 93),\n",
              " (('Control',), 92),\n",
              " (('Functions',), 92),\n",
              " (('Selection',), 91),\n",
              " (('Application',), 89),\n",
              " (('Bounds',), 87),\n",
              " (('Sampling',), 86),\n",
              " (('Representations',), 84),\n",
              " (('Local',), 83),\n",
              " (('Latent',), 82),\n",
              " (('Structure',), 81),\n",
              " (('Unsupervised',), 81),\n",
              " (('model',), 81),\n",
              " (('Machine',), 80),\n",
              " (('Search',), 80),\n",
              " (('Large',), 80),\n",
              " (('Vector',), 80),\n",
              " (('Graphical',), 80),\n",
              " (('Speech',), 79),\n",
              " (('Active',), 79),\n",
              " (('Distributed',), 78),\n",
              " (('Method',), 78),\n",
              " (('Matrix',), 78),\n",
              " (('Convergence',), 78),\n",
              " (('Dynamics',), 78),\n",
              " (('Systems',), 77),\n",
              " (('neural',), 77),\n",
              " (('Multiple',), 75),\n",
              " (('Object',), 74),\n",
              " (('Convex',), 74),\n",
              " (('Statistical',), 74),\n",
              " (('Function',), 73),\n",
              " (('Machines',), 72),\n",
              " (('Spectral',), 71),\n",
              " (('Regularization',), 69),\n",
              " (('Decision',), 68),\n",
              " (('Complexity',), 67),\n",
              " (('Support',), 67),\n",
              " (('Generalization',), 66),\n",
              " (('Approximate',), 66),\n",
              " (('Kernels',), 66),\n",
              " (('Analog',), 65),\n",
              " (('Nonlinear',), 64),\n",
              " (('Human',), 64),\n",
              " (('Natural',), 64),\n",
              " (('Continuous',), 64),\n",
              " (('Graph',), 64),\n",
              " (('Approximation',), 64),\n",
              " (('Minimization',), 64),\n",
              " (('Neurons',), 63),\n",
              " (('Propagation',), 62),\n",
              " (('Problems',), 61),\n",
              " (('Mixture',), 61),\n",
              " (('Generative',), 61),\n",
              " (('Based',), 60),\n",
              " (('VLSI',), 60),\n",
              " (('Descent',), 60),\n",
              " (('--',), 59),\n",
              " (('Programming',), 58),\n",
              " (('Hidden',), 58),\n",
              " (('Theory',), 57),\n",
              " (('Temporal',), 56),\n",
              " (('System',), 56),\n",
              " (('Features',), 56),\n",
              " (('Matching',), 55),\n",
              " (('Applications',), 54),\n",
              " (('Images',), 54),\n",
              " (('Boosting',), 54),\n",
              " (('Nonparametric',), 54),\n",
              " ((\"'\",), 53),\n",
              " (('Generalized',), 53),\n",
              " (('network',), 53),\n",
              " (('Policy',), 53),\n",
              " (('Memory',), 51),\n",
              " (('Graphs',), 51),\n",
              " (('Bandits',), 51),\n",
              " (('Maximum',), 50),\n",
              " (('-',), 49),\n",
              " (('From',), 49),\n",
              " (('Mixtures',), 49),\n",
              " (('Framework',), 48),\n",
              " (('Belief',), 48),\n",
              " (('Sequential',), 47),\n",
              " (('Parallel',), 47),\n",
              " (('Trees',), 47),\n",
              " (('Error',), 46),\n",
              " (('Coding',), 46),\n",
              " (('Convolutional',), 46),\n",
              " (('Submodular',), 46),\n",
              " (('Representation',), 45),\n",
              " (('Noise',), 45),\n",
              " (('Fields',), 45),\n",
              " (('PCA',), 45),\n",
              " (('Processing',), 44),\n",
              " (('Motion',), 44),\n",
              " (('Classifiers',), 44),\n",
              " (('(',), 44),\n",
              " ((')',), 44),\n",
              " (('Monte',), 44),\n",
              " (('Carlo',), 44),\n",
              " (('Reduction',), 43),\n",
              " (('Conditional',), 43),\n",
              " (('Discriminative',), 43),\n",
              " (('Distributions',), 42),\n",
              " (('Component',), 42),\n",
              " (('Regularized',), 42),\n",
              " (('Games',), 42),\n",
              " (('Supervised',), 41),\n",
              " (('Filtering',), 41),\n",
              " (('Segmentation',), 41),\n",
              " (('Spiking',), 41),\n",
              " (('Binary',), 41),\n",
              " (('Adaptation',), 41),\n",
              " (('Density',), 41),\n",
              " (('Connectionist',), 40),\n",
              " (('Maximization',), 40),\n",
              " (('Metric',), 40),\n",
              " (('Dynamical',), 39),\n",
              " (('New',), 39),\n",
              " (('Embedding',), 39),\n",
              " (('Brain',), 39),\n",
              " (('Space',), 39),\n",
              " (('Risk',), 39),\n",
              " (('Estimating',), 39),\n",
              " (('Value',), 39),\n",
              " (('Ranking',), 39),\n",
              " (('Margin',), 39),\n",
              " (('Scalable',), 39),\n",
              " (('Spike',), 38),\n",
              " (('Sample',), 38),\n",
              " (('High',), 37),\n",
              " (('Variable',), 37),\n",
              " (('State',), 37),\n",
              " (('Decomposition',), 37),\n",
              " (('Spatial',), 36),\n",
              " (('Performance',), 36),\n",
              " (('Probability',), 36),\n",
              " (('Adversarial',), 36),\n",
              " (('Cortex',), 35),\n",
              " (('Computation',), 35),\n",
              " (('Independent',), 35),\n",
              " (('Dirichlet',), 35),\n",
              " (('Implementation',), 34),\n",
              " (('Attention',), 34),\n",
              " (('Improved',), 34),\n",
              " (('Global',), 34),\n",
              " (('Inverse',), 34),\n",
              " (('Factorization',), 34),\n",
              " (('Tensor',), 34),\n",
              " (('Problem',), 33),\n",
              " (('Pattern',), 33),\n",
              " (('Large-Scale',), 33),\n",
              " (('Separation',), 33),\n",
              " (('Tracking',), 33),\n",
              " (('Sequence',), 33),\n",
              " (('Rates',), 33),\n",
              " (('Completion',), 33),\n",
              " (('Computational',), 32),\n",
              " (('Properties',), 32),\n",
              " (('General',), 32),\n",
              " (('Field',), 32),\n",
              " (('Architecture',), 32),\n",
              " (('Discrete',), 32),\n",
              " (('Predictive',), 32),\n",
              " (('Scale',), 32),\n",
              " (('Causal',), 32),\n",
              " (('MAP',), 32),\n",
              " (('Nets',), 31),\n",
              " (('Design',), 31),\n",
              " (('Constraints',), 31),\n",
              " (('Infinite',), 31),\n",
              " (('sparse',), 31),\n",
              " (('Associative',), 30),\n",
              " (('How',), 30),\n",
              " (('Neuronal',), 30),\n",
              " (('Exponential',), 30),\n",
              " (('Tree',), 30),\n",
              " (('Manifold',), 30),\n",
              " (('Computing',), 29),\n",
              " (('Point',), 29),\n",
              " (('Language',), 29),\n",
              " (('Exploration',), 29),\n",
              " (('Feedback',), 29),\n",
              " (('Planning',), 29),\n",
              " (('Transfer',), 29),\n",
              " (('Sets',), 29),\n",
              " (('Recovery',), 29),\n",
              " (('Joint',), 29),\n",
              " (('Regret',), 29),\n",
              " (('Boltzmann',), 28),\n",
              " (('Comparison',), 28),\n",
              " (('Codes',), 28),\n",
              " (('Identification',), 28),\n",
              " (('Basis',), 28),\n",
              " (('Finite',), 28),\n",
              " (('Complex',), 28),\n",
              " (('Auditory',), 28),\n",
              " (('Distance',), 28),\n",
              " (('algorithm',), 28),\n",
              " (('Bandit',), 28),\n",
              " (('Minimax',), 28),\n",
              " (('Entropy',), 27),\n",
              " (('Backpropagation',), 27),\n",
              " (('neuron',), 27),\n",
              " (('Structural',), 27),\n",
              " (('Loss',), 27),\n",
              " (('Variables',), 27),\n",
              " (('Semi-Supervised',), 27),\n",
              " (('Embeddings',), 27),\n",
              " (('Rank',), 27),\n",
              " (('Power',), 26),\n",
              " (('Order',), 26),\n",
              " (('Noisy',), 26),\n",
              " (('Extraction',), 26),\n",
              " (('Sparsity',), 26),\n",
              " (('Experts',), 26),\n",
              " (('Dual',), 26),\n",
              " (('Single',), 26),\n",
              " (('Principal',), 26),\n",
              " (('Series',), 26),\n",
              " (('Bayes',), 26),\n",
              " (('High-Dimensional',), 26),\n",
              " (('Topic',), 26),\n",
              " (('Constrained',), 25),\n",
              " (('Differential',), 25),\n",
              " (('Signal',), 25),\n",
              " (('Neuron',), 25),\n",
              " (('Covariance',), 25),\n",
              " (('Maps',), 25),\n",
              " (('Automatic',), 25),\n",
              " (('Predicting',), 25),\n",
              " (('Distribution',), 25),\n",
              " (('dynamic',), 25),\n",
              " (('Domain',), 25),\n",
              " (('Diffusion',), 25),\n",
              " (('Blind',), 25),\n",
              " (('Similarity',), 25),\n",
              " (('Spaces',), 25),\n",
              " (('Signals',), 24),\n",
              " (('Computer',), 24),\n",
              " (('Objects',), 24),\n",
              " (('Towards',), 24),\n",
              " (('Rules',), 24),\n",
              " (('Incremental',), 24),\n",
              " (('Dimensionality',), 24),\n",
              " (('Selective',), 24),\n",
              " (('Parameter',), 24),\n",
              " (('Discovery',), 24),\n",
              " (('Scene',), 24),\n",
              " (('Variance',), 24),\n",
              " (('Coordinate',), 24),\n",
              " (('Exact',), 24),\n",
              " (('Priors',), 24),\n",
              " (('Factor',), 24),\n",
              " (('Beyond',), 24),\n",
              " (('optimization',), 24),\n",
              " (('Activity',), 23),\n",
              " (('Motor',), 23),\n",
              " (('Net',), 23),\n",
              " (('Invariant',), 23),\n",
              " (('Functional',), 23),\n",
              " (('Retrieval',), 23),\n",
              " (('Simple',), 23),\n",
              " (('Sequences',), 23),\n",
              " (('Iterative',), 23),\n",
              " (('Pairwise',), 23),\n",
              " (('Empirical',), 23),\n",
              " (('Greedy',), 23),\n",
              " (('Semi-supervised',), 23),\n",
              " (('regression',), 23),\n",
              " (('Label',), 23),\n",
              " ((\"''\",), 22),\n",
              " (('Action',), 22),\n",
              " (('Cortical',), 22),\n",
              " (('Classifier',), 22),\n",
              " (('Understanding',), 22),\n",
              " (('Plasticity',), 22),\n",
              " (('Face',), 22),\n",
              " (('Improving',), 22),\n",
              " (('Dimension',), 22),\n",
              " (('Missing',), 22),\n",
              " (('Localization',), 22),\n",
              " (('Text',), 22),\n",
              " (('Family',), 22),\n",
              " (('Randomized',), 22),\n",
              " (('Subspace',), 22),\n",
              " (('Tasks',), 21),\n",
              " (('Phase',), 21),\n",
              " (('Mean',), 21),\n",
              " (('Recursive',), 21),\n",
              " (('Unified',), 21),\n",
              " (('Study',), 21),\n",
              " (('With',), 21),\n",
              " (('Likelihood',), 21),\n",
              " (('Prior',), 21),\n",
              " (('Rate',), 21),\n",
              " (('Response',), 21),\n",
              " (('Polynomial',), 21),\n",
              " (('Silicon',), 21),\n",
              " (('Scenes',), 21),\n",
              " (('Iteration',), 21),\n",
              " (('Partially',), 21),\n",
              " (('Multi-Task',), 21),\n",
              " (('Expectation',), 21),\n",
              " (('graph',), 21),\n",
              " (('Projection',), 20),\n",
              " (('Synaptic',), 20),\n",
              " (('Chip',), 20),\n",
              " (('Perceptual',), 20),\n",
              " (('Scaling',), 20),\n",
              " (('Vision',), 20),\n",
              " (('Combining',), 20),\n",
              " (('Effects',), 20),\n",
              " (('Group',), 20),\n",
              " (('Integration',), 20),\n",
              " (('For',), 20),\n",
              " (('Video',), 20),\n",
              " (('Consistency',), 20),\n",
              " (('Testing',), 20),\n",
              " (('Correlation',), 20),\n",
              " (('Neighbor',), 20),\n",
              " (('Bound',), 20),\n",
              " (('Particle',), 20),\n",
              " (('MCMC',), 20),\n",
              " (('Multivariate',), 20),\n",
              " (('Collaborative',), 20),\n",
              " (('Low-Rank',), 20),\n",
              " (('matrix',), 20),\n",
              " (('Its',), 19),\n",
              " (('Solving',), 19),\n",
              " (('``',), 19),\n",
              " (('Perception',), 19),\n",
              " (('Between',), 19),\n",
              " (('Artificial',), 19),\n",
              " (('Real-Time',), 19),\n",
              " (('Energy',), 19),\n",
              " (('Rule',), 19),\n",
              " (('Environments',), 19),\n",
              " (('Sensing',), 19),\n",
              " (('Shape',), 19),\n",
              " (('Parameters',), 19),\n",
              " (('Source',), 19),\n",
              " (('Weights',), 19),\n",
              " (('Knowledge',), 19),\n",
              " (('Hybrid',), 19),\n",
              " (('.',), 19),\n",
              " (('Word',), 19),\n",
              " (('Approximations',), 19),\n",
              " (('Uncertainty',), 19),\n",
              " (('Statistics',), 19),\n",
              " (('Inferring',), 19),\n",
              " (('linear',), 19),\n",
              " (('Accelerated',), 19),\n",
              " (('Dimensional',), 19),\n",
              " (('Multiclass',), 19),\n",
              " (('Matrices',), 19),\n",
              " (('Relational',), 19),\n",
              " (('visual',), 19),\n",
              " (('Social',), 19),\n",
              " (('End',), 19),\n",
              " (('Patterns',), 18),\n",
              " (('Measures',), 18),\n",
              " (('Learn',), 18),\n",
              " (('Hebbian',), 18),\n",
              " (('Dependent',), 18),\n",
              " (('Faster',), 18),\n",
              " (('Curves',), 18),\n",
              " (('Relaxation',), 18),\n",
              " (('Structures',), 18),\n",
              " (('Generation',), 18),\n",
              " (('Population',), 18),\n",
              " (('spiking',), 18),\n",
              " (('Components',), 18),\n",
              " (('Contextual',), 18),\n",
              " (('ICA',), 18),\n",
              " (('MDPs',), 18),\n",
              " (('SVM',), 18),\n",
              " (('Alignment',), 18),\n",
              " (('Lasso',), 18),\n",
              " (('Simulation',), 17),\n",
              " (('Behavior',), 17),\n",
              " (('Techniques',), 17),\n",
              " (('Mapping',), 17),\n",
              " (('Making',), 17),\n",
              " (('Size',), 17),\n",
              " (('Radial',), 17),\n",
              " (('Practical',), 17),\n",
              " (('bound',), 17),\n",
              " (('Output',), 17),\n",
              " (('Evaluation',), 17),\n",
              " (('Induction',), 17),\n",
              " (('Correlated',), 17),\n",
              " (('Unknown',), 17),\n",
              " (('Decoding',), 17),\n",
              " (('Weighted',), 17),\n",
              " (('Flow',), 17),\n",
              " (('Under',), 17),\n",
              " (('Context',), 17),\n",
              " (('Asynchronous',), 17),\n",
              " (('Universal',), 17),\n",
              " (('Allocation',), 17),\n",
              " (('Combinatorial',), 17),\n",
              " (('Streaming',), 17),\n",
              " (('Consistent',), 17),\n",
              " (('Observations',), 17),\n",
              " (('Restricted',), 17),\n",
              " (('kernel',), 17),\n",
              " (('Partial',), 17),\n",
              " (('Orientation',), 16),\n",
              " (('Set',), 16),\n",
              " (('Mechanism',), 16),\n",
              " (('Use',), 16),\n",
              " (('Perceptron',), 16),\n",
              " (('Development',), 16),\n",
              " (('Cells',), 16),\n",
              " (('Mutual',), 16),\n",
              " (('Circuits',), 16),\n",
              " (('Weight',), 16),\n",
              " (('Synthesis',), 16),\n",
              " (('Can',), 16),\n",
              " (('Cell',), 16),\n",
              " (('Interaction',), 16),\n",
              " (('Pursuit',), 16),\n",
              " (('Lower',), 16),\n",
              " (('-Line',), 16),\n",
              " (('Modelling',), 16),\n",
              " (('Estimators',), 16),\n",
              " (('Nearest',), 16),\n",
              " (('SVMs',), 16),\n",
              " (('Semantic',), 16),\n",
              " (('spike',), 16),\n",
              " (('Encoding',), 15),\n",
              " (('Geometric',), 15),\n",
              " (('Novel',), 15),\n",
              " (('Connections',), 15),\n",
              " (('Analyzing',), 15),\n",
              " (('Multilayer',), 15),\n",
              " (('Self-Organizing',), 15),\n",
              " (('Stimulus',), 15),\n",
              " (('Direct',), 15),\n",
              " (('Finding',), 15),\n",
              " (('Receptive',), 15),\n",
              " (('Exploiting',), 15),\n",
              " (('Filters',), 15),\n",
              " (('Accuracy',), 15),\n",
              " (('Dimensions',), 15),\n",
              " (('Quadratic',), 15),\n",
              " (('Gibbs',), 15),\n",
              " (('Input',), 15),\n",
              " (('Dependencies',), 15),\n",
              " (('Unlabeled',), 15),\n",
              " (('Locally',), 15),\n",
              " (('Pruning',), 15),\n",
              " (('Factorial',), 15),\n",
              " (('Alternating',), 15),\n",
              " (('Policies',), 15),\n",
              " (('Gradients',), 15),\n",
              " (('Fisher',), 15),\n",
              " (('POMDPs',), 15),\n",
              " (('Low',), 15),\n",
              " (('fMRI',), 15),\n",
              " (('Laplacian',), 15),\n",
              " (('Semidefinite',), 15),\n",
              " (('Implicit',), 15),\n",
              " (('Ensemble',), 14),\n",
              " (('Diverse',), 14),\n",
              " (('Stability',), 14),\n",
              " (('Choice',), 14),\n",
              " (('Code',), 14),\n",
              " (('Sound',), 14),\n",
              " (('Categorization',), 14),\n",
              " (('Second',), 14),\n",
              " (('Eye',), 14),\n",
              " (('Movements',), 14),\n",
              " (('Approximating',), 14),\n",
              " (('Estimates',), 14),\n",
              " (('Intrinsic',), 14),\n",
              " (('Labeling',), 14),\n",
              " (('Identifying',), 14),\n",
              " (('Bias',), 14),\n",
              " (('-line',), 14),\n",
              " (('Pose',), 14),\n",
              " (('Discriminant',), 14),\n",
              " (('Optimizing',), 14),\n",
              " (('Averaging',), 14),\n",
              " (('Poisson',), 14),\n",
              " (('Batch',), 14),\n",
              " (('One',), 14),\n",
              " (('Multiplicative',), 14),\n",
              " (('Reward',), 14),\n",
              " (('Projections',), 14),\n",
              " (('Parametric',), 14),\n",
              " (('Message',), 14),\n",
              " (('Hashing',), 14),\n",
              " (('Map',), 13),\n",
              " (('Connectivity',), 13),\n",
              " (('Solution',), 13),\n",
              " (('Experiments',), 13),\n",
              " (('Discovering',), 13),\n",
              " (('Capacity',), 13),\n",
              " (('Stable',), 13),\n",
              " (('Circuit',), 13),\n",
              " (('Real',), 13),\n",
              " (('Early',), 13),\n",
              " (('What',), 13),\n",
              " (('Theoretic',), 13),\n",
              " (('Compression',), 13),\n",
              " (('Discrimination',), 13),\n",
              " (('Effect',), 13),\n",
              " (('Robustness',), 13),\n",
              " (('Multiscale',), 13),\n",
              " (('Effective',), 13),\n",
              " (('Extracting',), 13),\n",
              " (('Transformation',), 13),\n",
              " (('Symmetric',), 13),\n",
              " (('Measure',), 13),\n",
              " (('Sources',), 13),\n",
              " (('coding',), 13),\n",
              " (('Estimator',), 13),\n",
              " (('Multidimensional',), 13),\n",
              " (('Reconstruction',), 13),\n",
              " (('Block',), 13),\n",
              " (('Metrics',), 13),\n",
              " (('Least',), 13),\n",
              " (('Observable',), 13),\n",
              " (('Aggregation',), 13),\n",
              " (('More',), 13),\n",
              " (('Posterior',), 13),\n",
              " (('Importance',), 13),\n",
              " (('Relaxations',), 13),\n",
              " (('multiple',), 13),\n",
              " (('clustering',), 13),\n",
              " (('Influence',), 13),\n",
              " (('High-dimensional',), 13),\n",
              " (('Proximal',), 13),\n",
              " (('Units',), 12),\n",
              " (('Approaches',), 12),\n",
              " (('Perceptrons',), 12),\n",
              " (('Color',), 12),\n",
              " (('Examples',), 12),\n",
              " (('Principle',), 12),\n",
              " (('Construction',), 12),\n",
              " (('Through',), 12),\n",
              " (('Fixed',), 12),\n",
              " (('Case',), 12),\n",
              " (('Movement',), 12),\n",
              " (('Flexible',), 12),\n",
              " (('Competitive',), 12),\n",
              " (('View',), 12),\n",
              " (('Grammar',), 12),\n",
              " (('Vectors',), 12),\n",
              " (('Limited',), 12),\n",
              " (('Queries',), 12),\n",
              " (('Asymptotic',), 12),\n",
              " (('Better',), 12),\n",
              " (('Integrated',), 12),\n",
              " (('Difference',), 12),\n",
              " (('Attractor',), 12),\n",
              " (('Competition',), 12),\n",
              " (('Translation',), 12),\n",
              " (('Direction',), 12),\n",
              " (('Applied',), 12),\n",
              " (('Attentional',), 12),\n",
              " (('Free',), 12),\n",
              " (('Squares',), 12),\n",
              " (('Class',), 12),\n",
              " (('Smooth',), 12),\n",
              " (('Safe',), 12),\n",
              " (('Test',), 12),\n",
              " (('Chain',), 12),\n",
              " (('Theoretical',), 12),\n",
              " (('Link',), 12),\n",
              " (('Additive',), 12),\n",
              " (('Optimistic',), 12),\n",
              " (('Reasoning',), 12),\n",
              " (('Convergent',), 12),\n",
              " (('Manifolds',), 12),\n",
              " (('Guarantees',), 12),\n",
              " (('Passing',), 12),\n",
              " (('Objectives',), 12),\n",
              " (('Interpretable',), 12),\n",
              " (('Crowdsourcing',), 12),\n",
              " (('Private',), 12),\n",
              " (('Nonconvex',), 12),\n",
              " (('Hard',), 11),\n",
              " (('Optical',), 11),\n",
              " (('Higher-Order',), 11),\n",
              " (('Synchronization',), 11),\n",
              " (('Results',), 11),\n",
              " (('Autonomous',), 11),\n",
              " (('Neuromorphic',), 11),\n",
              " (('Orthogonal',), 11),\n",
              " (('Grouping',), 11),\n",
              " (('Hierarchies',), 11),\n",
              " (('Handwritten',), 11),\n",
              " (('Mechanisms',), 11),\n",
              " (('Number',), 11),\n",
              " (('Some',), 11),\n",
              " (('Forecasting',), 11),\n",
              " (('Simultaneous',), 11),\n",
              " (('Modulation',), 11),\n",
              " (('adaptive',), 11),\n",
              " (('Automated',), 11),\n",
              " (('Task',), 11),\n",
              " (('Path',), 11),\n",
              " (('Domains',), 11),\n",
              " (('Generating',), 11),\n",
              " (('Densities',), 11),\n",
              " (('Interactions',), 11),\n",
              " (('Samples',), 11),\n",
              " (('Communication',), 11),\n",
              " (('Classes',), 11),\n",
              " (('Clusters',), 11),\n",
              " (('Correspondence',), 11),\n",
              " (('Expression',), 11),\n",
              " (('Normalization',), 11),\n",
              " (('Contour',), 11),\n",
              " (('Tight',), 11),\n",
              " (('Denoising',), 11),\n",
              " (('Nonnegative',), 11),\n",
              " (('Transductive',), 11),\n",
              " (('Multimodal',), 11),\n",
              " (('Logistic',), 11),\n",
              " (('Programs',), 11),\n",
              " (('Forests',), 11),\n",
              " (('sampling',), 11),\n",
              " (('Imitation',), 11),\n",
              " (('Large-scale',), 11),\n",
              " (('Privacy',), 11),\n",
              " (('optimal',), 11),\n",
              " (('convex',), 11),\n",
              " (('approximation',), 11),\n",
              " (('prior',), 11),\n",
              " (('Learns',), 10),\n",
              " (('Lateral',), 10),\n",
              " (('Potentials',), 10),\n",
              " (('Robot',), 10),\n",
              " (('Sensory',), 10),\n",
              " (('Annealing',), 10),\n",
              " (('Small',), 10),\n",
              " (('Acquisition',), 10),\n",
              " (('Solutions',), 10),\n",
              " (('Feedforward',), 10),\n",
              " (('Cost',), 10),\n",
              " (('Parsing',), 10),\n",
              " (('Genetic',), 10),\n",
              " (('Recognizing',), 10),\n",
              " (('Regions',), 10),\n",
              " (('Trajectory',), 10),\n",
              " (('Protein',), 10),\n",
              " (('Synapses',), 10),\n",
              " (('Learned',), 10),\n",
              " (('Deterministic',), 10),\n",
              " (('Symbolic',), 10),\n",
              " (('recurrent',), 10),\n",
              " (('versus',), 10),\n",
              " (('Switching',), 10),\n",
              " (('Quantization',), 10),\n",
              " (('Cascade',), 10),\n",
              " (('Channel',), 10),\n",
              " (('Alternative',), 10),\n",
              " (('Non-Linear',), 10),\n",
              " (('Positive',), 10),\n",
              " (('Minimum',), 10),\n",
              " (('When',), 10),\n",
              " (('Two',), 10),\n",
              " (('Saliency',), 10),\n",
              " (('Non-linear',), 10),\n",
              " (('Transform',), 10),\n",
              " (('statistical',), 10),\n",
              " (('Rapid',), 10),\n",
              " (('Arbitrary',), 10),\n",
              " (('Tractable',), 10),\n",
              " (('Facial',), 10),\n",
              " (('Accurate',), 10),\n",
              " (('Temporally',), 10),\n",
              " (('Mixed',), 10),\n",
              " (('Equations',), 10),\n",
              " (('Incomplete',), 10),\n",
              " (('Factored',), 10),\n",
              " (('Bottleneck',), 10),\n",
              " (('Reducing',), 10),\n",
              " (('Partitioning',), 10),\n",
              " (('Side',), 10),\n",
              " (('Marginal',), 10),\n",
              " (('Program',), 10),\n",
              " (('Bounded',), 10),\n",
              " (('Non-parametric',), 10),\n",
              " (('detection',), 10),\n",
              " (('Multi-task',), 10),\n",
              " (('Thresholding',), 10),\n",
              " (('Partition',), 10),\n",
              " (('Losses',), 10),\n",
              " (('Strategic',), 10),\n",
              " (('Experimental',), 9),\n",
              " (('Teaching',), 9),\n",
              " (('Storage',), 9),\n",
              " (('Spatio-Temporal',), 9),\n",
              " (('Imaging',), 9),\n",
              " (('Relevance',), 9),\n",
              " (('Shared',), 9),\n",
              " (('Extended',), 9),\n",
              " (('Sensitive',), 9),\n",
              " (('Ocular',), 9),\n",
              " (('Dominance',), 9),\n",
              " (('HMM',), 9),\n",
              " (('Forward',), 9),\n",
              " (('Threshold',), 9),\n",
              " (('Efficiency',), 9),\n",
              " (('Processor',), 9),\n",
              " (('Filter',), 9),\n",
              " (('Points',), 9),\n",
              " (('Speed',), 9),\n",
              " (('Music',), 9),\n",
              " (('Navigation',), 9),\n",
              " (('Depth',), 9),\n",
              " (('Diagnosis',), 9),\n",
              " (('Relative',), 9),\n",
              " (('distribution',), 9),\n",
              " (('Predictions',), 9),\n",
              " (('Interpretation',), 9),\n",
              " (('Overlapping',), 9),\n",
              " (('Coupling',), 9),\n",
              " (('Abstraction',), 9),\n",
              " (('Product',), 9),\n",
              " (('Related',), 9),\n",
              " (('Hand',), 9),\n",
              " (('Responses',), 9),\n",
              " (('Tuning',), 9),\n",
              " (('Very',), 9),\n",
              " (('Geometry',), 9),\n",
              " (('Improvement',), 9),\n",
              " (('-Learning',), 9),\n",
              " (('Query',), 9),\n",
              " (('Game',), 9),\n",
              " (('Quality',), 9),\n",
              " (('Anomaly',), 9),\n",
              " (('Smoothing',), 9),\n",
              " (('Labeled',), 9),\n",
              " (('constraint',), 9),\n",
              " (('Minimizing',), 9),\n",
              " (('Agnostic',), 9),\n",
              " (('&',), 9),\n",
              " (('Chains',), 9),\n",
              " (('prediction',), 9),\n",
              " (('Measuring',), 9),\n",
              " (('Hamiltonian',), 9),\n",
              " (('Penalty',), 9),\n",
              " (('Multitask',), 9),\n",
              " (('Monte-Carlo',), 9),\n",
              " (('Why',), 9),\n",
              " (('Overcomplete',), 9),\n",
              " (('Perspective',), 9),\n",
              " (('Cognitive',), 9),\n",
              " (('HMMs',), 9),\n",
              " (('Gaussians',), 9),\n",
              " (('Norm',), 9),\n",
              " (('Interactive',), 9),\n",
              " (('Hilbert',), 9),\n",
              " (('Variation',), 9),\n",
              " (('-means',), 9),\n",
              " (('Invariance',), 9),\n",
              " (('Labels',), 9),\n",
              " (('Balanced',), 9),\n",
              " (('Multi-Agent',), 9),\n",
              " (('Budget',), 9),\n",
              " (('Provable',), 9),\n",
              " (('Brain-Computer',), 9),\n",
              " (('Ising',), 9),\n",
              " (('Edge',), 9),\n",
              " (('entropy',), 9),\n",
              " (('Multi-Label',), 9),\n",
              " (('probabilistic',), 9),\n",
              " (('graphical',), 9),\n",
              " (('Unifying',), 9),\n",
              " (('Lifted',), 9),\n",
              " (('Differentially',), 9),\n",
              " (('Compressive',), 9),\n",
              " (('Question',), 9),\n",
              " (('GANs',), 9),\n",
              " (('Back-Propagation',), 8),\n",
              " (('Layered',), 8),\n",
              " (('Hippocampal',), 8),\n",
              " (('Improve',), 8),\n",
              " (('Different',), 8),\n",
              " (('Olfactory',), 8),\n",
              " (('Transitions',), 8),\n",
              " (('Architectures',), 8),\n",
              " (('Inhibition',), 8),\n",
              " (('Precision',), 8),\n",
              " (('Expert',), 8),\n",
              " (('Internal',), 8),\n",
              " (('Winner-Take-All',), 8),\n",
              " (('Resolution',), 8),\n",
              " (('Analytical',), 8),\n",
              " (('Arm',), 8),\n",
              " (('Delay',), 8),\n",
              " (('CMOS',), 8),\n",
              " (('Role',), 8),\n",
              " (('Environment',), 8),\n",
              " (('Analytic',), 8),\n",
              " (('Synchrony',), 8),\n",
              " (('Speaker',), 8),\n",
              " (('Retina',), 8),\n",
              " (('Multi-Layer',), 8),\n",
              " (('Wavelet',), 8),\n",
              " (('Transforms',), 8),\n",
              " (('Constraint',), 8),\n",
              " (('Transition',), 8),\n",
              " (('Uniform',), 8),\n",
              " (('Globally',), 8),\n",
              " (('Binding',), 8),\n",
              " (('Tangent',), 8),\n",
              " (('Selecting',), 8),\n",
              " (('Rational',), 8),\n",
              " (('Toward',), 8),\n",
              " (('Soft',), 8),\n",
              " (('Topographic',), 8),\n",
              " (('Predicts',), 8),\n",
              " (('Nonsmooth',), 8),\n",
              " (('Trajectories',), 8),\n",
              " (('Physics',), 8),\n",
              " (('Constant',), 8),\n",
              " (('Evidence',), 8),\n",
              " (('Directed',), 8),\n",
              " (('Equilibria',), 8),\n",
              " (('Correlations',), 8),\n",
              " (('Continuous-Time',), 8),\n",
              " (('Autoencoders',), 8),\n",
              " (('Slow',), 8),\n",
              " (('Emergence',), 8),\n",
              " (('Singular',), 8),\n",
              " (('Recovering',), 8),\n",
              " (('Limits',), 8),\n",
              " (('Evaluating',), 8),\n",
              " (('EEG',), 8),\n",
              " (('Average',), 8),\n",
              " (('Sensor',), 8),\n",
              " (('Calibration',), 8),\n",
              " (('Riemannian',), 8),\n",
              " (('Confidence',), 8),\n",
              " (('Non-Parametric',), 8),\n",
              " (('Concept',), 8),\n",
              " (('Multi-Class',), 8),\n",
              " (('Dyadic',), 8),\n",
              " (('Products',), 8),\n",
              " (('Multiagent',), 8),\n",
              " (('Algorithmic',), 8),\n",
              " (('approximate',), 8),\n",
              " (('Curve',), 8),\n",
              " (('PAC',), 8),\n",
              " (('PAC-Bayes',), 8),\n",
              " (('Maximizing',), 8),\n",
              " (('Doubly',), 8),\n",
              " (('Composite',), 8),\n",
              " (('Max-Margin',), 8),\n",
              " (('Tradeoffs',), 8),\n",
              " (('Integrating',), 8),\n",
              " (('Bregman',), 8),\n",
              " (('strategy',), 8),\n",
              " (('Level',), 8),\n",
              " (('plasticity',), 8),\n",
              " (('density',), 8),\n",
              " (('Compressed',), 8),\n",
              " (('stochastic',), 8),\n",
              " (('Hypothesis',), 8),\n",
              " (('Near-Optimal',), 8),\n",
              " (('nonparametric',), 8),\n",
              " (('Multi-Armed',), 8),\n",
              " (('Smoothness',), 8),\n",
              " (('Permutation',), 8),\n",
              " (('Residual',), 8),\n",
              " (('Determinantal',), 8),\n",
              " (('Cover',), 8),\n",
              " (('variational',), 8),\n",
              " (('Screening',), 8),\n",
              " (('Subset',), 8),\n",
              " (('Fairness',), 8),\n",
              " (('Self-Organization',), 7),\n",
              " (('Higher',), 7),\n",
              " (('Cycles',), 7),\n",
              " (('Cyclic',), 7),\n",
              " (('Electronic',), 7),\n",
              " (('Logic',), 7),\n",
              " (('Association',), 7),\n",
              " (('Programmable',), 7),\n",
              " (('Massive',), 7),\n",
              " (('Phoneme',), 7),\n",
              " (('Procedure',), 7),\n",
              " (('Moving',), 7),\n",
              " (('Memories',), 7),\n",
              " (('Comparing',), 7),\n",
              " (('Does',), 7),\n",
              " (('Coupled',), 7),\n",
              " (('Feed-Forward',), 7),\n",
              " (('Periodic',), 7),\n",
              " (('Heterogeneous',), 7),\n",
              " (('Owl',), 7),\n",
              " (('Biological',), 7),\n",
              " (('Surface',), 7),\n",
              " (('Formation',), 7),\n",
              " (('Relationships',), 7),\n",
              " (('Inspired',), 7),\n",
              " (('Transformations',), 7),\n",
              " (('Comparative',), 7),\n",
              " (('Constructing',), 7),\n",
              " (('World',), 7),\n",
              " (('Trained',), 7),\n",
              " (('Topology',), 7),\n",
              " (('integration',), 7),\n",
              " (('Splitting',), 7),\n",
              " (('Constructive',), 7),\n",
              " (('Reduced',), 7),\n",
              " (('Stimuli',), 7),\n",
              " (('Strategy',), 7),\n",
              " (('Event',), 7),\n",
              " (('Account',), 7),\n",
              " (('Criterion',), 7),\n",
              " (('Activities',), 7),\n",
              " (('Bootstrap',), 7),\n",
              " (('Generic',), 7),\n",
              " (('Committee',), 7),\n",
              " (('Populations',), 7),\n",
              " (('Softmax',), 7),\n",
              " (('Via',), 7),\n",
              " (('Classifying',), 7),\n",
              " (('Accelerating',), 7),\n",
              " (('Inputs',), 7),\n",
              " (('Timing',), 7),\n",
              " (('Cross',), 7),\n",
              " (('Weighting',), 7),\n",
              " (('Formulation',), 7),\n",
              " (('Area',), 7),\n",
              " (('Humans',), 7),\n",
              " (('Monitoring',), 7),\n",
              " (('Content',), 7),\n",
              " (('Interpreting',), 7),\n",
              " (('Logarithmic',), 7),\n",
              " (('Preference',), 7),\n",
              " (('Scoring',), 7),\n",
              " (('Bidirectional',), 7),\n",
              " (('Detecting',), 7),\n",
              " (('Calcium',), 7),\n",
              " (('Relations',), 7),\n",
              " (('Novelty',), 7),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams.extend(unigrams)\n",
        "# ngrams.extend([])\n",
        "\n",
        "len(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sXiXztaMO5-",
        "outputId": "e34f4fcd-856c-4d23-cdd4-7375c2842e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40045"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Sort the bag of words\n",
        "ngrams = sorted(ngrams, key=lambda item: item[1], reverse=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "tR2_pA16Kr6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords = [( \" \".join(n[0]).lower() , n[1] ) for n in ngrams]\n",
        "candidate_keywords = candidate_keywords[:500]\n",
        "\n",
        "\n",
        "\n",
        "###################################################"
      ],
      "metadata": {
        "id": "ZO9EFTixGRsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_keywords"
      ],
      "metadata": {
        "id": "Pc61_bwVLrDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93611601-6c78-4432-c49a-8417599f37ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('learning', 1447),\n",
              " ('neural', 565),\n",
              " ('networks', 548),\n",
              " ('models', 407),\n",
              " ('model', 331),\n",
              " ('bayesian', 287),\n",
              " ('using', 260),\n",
              " ('neural networks', 247),\n",
              " ('network', 240),\n",
              " ('the', 225),\n",
              " ('inference', 221),\n",
              " ('data', 221),\n",
              " ('analysis', 215),\n",
              " ('gaussian', 202),\n",
              " ('classification', 194),\n",
              " ('optimization', 192),\n",
              " ('sparse', 186),\n",
              " ('stochastic', 181),\n",
              " ('deep', 170),\n",
              " ('estimation', 168),\n",
              " ('recognition', 163),\n",
              " ('efficient', 163),\n",
              " ('clustering', 162),\n",
              " ('algorithms', 160),\n",
              " ('kernel', 155),\n",
              " ('reinforcement', 151),\n",
              " ('reinforcement learning', 148),\n",
              " ('algorithm', 144),\n",
              " ('online', 144),\n",
              " ('adaptive', 143),\n",
              " ('linear', 138),\n",
              " ('regression', 138),\n",
              " ('optimal', 136),\n",
              " ('fast', 136),\n",
              " ('neural network', 135),\n",
              " ('markov', 133),\n",
              " ('information', 132),\n",
              " ('visual', 131),\n",
              " ('image', 128),\n",
              " ('approach', 125),\n",
              " ('probabilistic', 121),\n",
              " ('?', 121),\n",
              " ('processes', 120),\n",
              " ('feature', 114),\n",
              " ('gradient', 113),\n",
              " ('variational', 113),\n",
              " ('prediction', 111),\n",
              " ('modeling', 109),\n",
              " ('process', 109),\n",
              " ('methods', 109),\n",
              " ('robust', 102),\n",
              " ('dynamic', 102),\n",
              " ('recurrent', 100),\n",
              " ('hierarchical', 97),\n",
              " ('detection', 97),\n",
              " ('training', 95),\n",
              " ('random', 95),\n",
              " ('time', 93),\n",
              " ('structured', 93),\n",
              " ('control', 92),\n",
              " ('functions', 92),\n",
              " ('selection', 91),\n",
              " ('application', 89),\n",
              " ('bounds', 87),\n",
              " ('sampling', 86),\n",
              " ('representations', 84),\n",
              " ('local', 83),\n",
              " ('latent', 82),\n",
              " ('structure', 81),\n",
              " ('unsupervised', 81),\n",
              " ('model', 81),\n",
              " ('machine', 80),\n",
              " ('search', 80),\n",
              " ('large', 80),\n",
              " ('vector', 80),\n",
              " ('graphical', 80),\n",
              " ('speech', 79),\n",
              " ('active', 79),\n",
              " ('distributed', 78),\n",
              " ('method', 78),\n",
              " ('matrix', 78),\n",
              " ('convergence', 78),\n",
              " ('dynamics', 78),\n",
              " ('systems', 77),\n",
              " ('neural', 77),\n",
              " ('multiple', 75),\n",
              " ('object', 74),\n",
              " ('convex', 74),\n",
              " ('statistical', 74),\n",
              " ('function', 73),\n",
              " ('machines', 72),\n",
              " ('spectral', 71),\n",
              " ('regularization', 69),\n",
              " ('decision', 68),\n",
              " ('gaussian process', 67),\n",
              " ('complexity', 67),\n",
              " ('support', 67),\n",
              " ('generalization', 66),\n",
              " ('approximate', 66),\n",
              " ('kernels', 66),\n",
              " ('analog', 65),\n",
              " ('nonlinear', 64),\n",
              " ('human', 64),\n",
              " ('natural', 64),\n",
              " ('continuous', 64),\n",
              " ('graph', 64),\n",
              " ('approximation', 64),\n",
              " ('minimization', 64),\n",
              " ('neurons', 63),\n",
              " ('propagation', 62),\n",
              " ('problems', 61),\n",
              " ('mixture', 61),\n",
              " ('generative', 61),\n",
              " ('based', 60),\n",
              " ('vlsi', 60),\n",
              " ('descent', 60),\n",
              " ('graphical models', 59),\n",
              " ('--', 59),\n",
              " ('programming', 58),\n",
              " ('hidden', 58),\n",
              " ('support vector', 57),\n",
              " ('theory', 57),\n",
              " ('temporal', 56),\n",
              " ('system', 56),\n",
              " ('features', 56),\n",
              " ('matching', 55),\n",
              " ('applications', 54),\n",
              " ('images', 54),\n",
              " ('boosting', 54),\n",
              " ('nonparametric', 54),\n",
              " (\"'\", 53),\n",
              " ('generalized', 53),\n",
              " ('network', 53),\n",
              " ('policy', 53),\n",
              " ('memory', 51),\n",
              " ('graphs', 51),\n",
              " ('bandits', 51),\n",
              " ('maximum', 50),\n",
              " ('gaussian processes', 49),\n",
              " ('-', 49),\n",
              " ('from', 49),\n",
              " ('mixtures', 49),\n",
              " ('framework', 48),\n",
              " ('belief', 48),\n",
              " ('sequential', 47),\n",
              " ('parallel', 47),\n",
              " ('trees', 47),\n",
              " ('active learning', 46),\n",
              " ('error', 46),\n",
              " ('coding', 46),\n",
              " ('convolutional', 46),\n",
              " ('submodular', 46),\n",
              " ('variational inference', 45),\n",
              " ('representation', 45),\n",
              " ('noise', 45),\n",
              " ('fields', 45),\n",
              " ('pca', 45),\n",
              " ('monte carlo', 44),\n",
              " ('processing', 44),\n",
              " ('motion', 44),\n",
              " ('classifiers', 44),\n",
              " ('(', 44),\n",
              " (')', 44),\n",
              " ('monte', 44),\n",
              " ('carlo', 44),\n",
              " ('online learning', 43),\n",
              " ('reduction', 43),\n",
              " ('conditional', 43),\n",
              " ('discriminative', 43),\n",
              " ('speech recognition', 42),\n",
              " ('distributions', 42),\n",
              " ('component', 42),\n",
              " ('regularized', 42),\n",
              " ('games', 42),\n",
              " ('supervised', 41),\n",
              " ('filtering', 41),\n",
              " ('segmentation', 41),\n",
              " ('spiking', 41),\n",
              " ('binary', 41),\n",
              " ('adaptation', 41),\n",
              " ('density', 41),\n",
              " ('connectionist', 40),\n",
              " ('maximization', 40),\n",
              " ('metric', 40),\n",
              " ('dynamical', 39),\n",
              " ('new', 39),\n",
              " ('embedding', 39),\n",
              " ('brain', 39),\n",
              " ('space', 39),\n",
              " ('risk', 39),\n",
              " ('estimating', 39),\n",
              " ('value', 39),\n",
              " ('ranking', 39),\n",
              " ('margin', 39),\n",
              " ('scalable', 39),\n",
              " ('spike', 38),\n",
              " ('sample', 38),\n",
              " ('recurrent neural', 37),\n",
              " ('high', 37),\n",
              " ('variable', 37),\n",
              " ('state', 37),\n",
              " ('decomposition', 37),\n",
              " ('component analysis', 36),\n",
              " ('spatial', 36),\n",
              " ('performance', 36),\n",
              " ('probability', 36),\n",
              " ('adversarial', 36),\n",
              " ('cortex', 35),\n",
              " ('computation', 35),\n",
              " ('independent', 35),\n",
              " ('dirichlet', 35),\n",
              " ('gradient descent', 34),\n",
              " ('hidden markov', 34),\n",
              " ('implementation', 34),\n",
              " ('attention', 34),\n",
              " ('improved', 34),\n",
              " ('global', 34),\n",
              " ('inverse', 34),\n",
              " ('factorization', 34),\n",
              " ('tensor', 34),\n",
              " ('problem', 33),\n",
              " ('pattern', 33),\n",
              " ('large-scale', 33),\n",
              " ('separation', 33),\n",
              " ('tracking', 33),\n",
              " ('sequence', 33),\n",
              " ('rates', 33),\n",
              " ('completion', 33),\n",
              " ('deep learning', 32),\n",
              " ('computational', 32),\n",
              " ('properties', 32),\n",
              " ('general', 32),\n",
              " ('field', 32),\n",
              " ('architecture', 32),\n",
              " ('discrete', 32),\n",
              " ('predictive', 32),\n",
              " ('scale', 32),\n",
              " ('causal', 32),\n",
              " ('map', 32),\n",
              " ('nets', 31),\n",
              " ('design', 31),\n",
              " ('constraints', 31),\n",
              " ('infinite', 31),\n",
              " ('sparse', 31),\n",
              " ('markov models', 30),\n",
              " ('vector machines', 30),\n",
              " ('associative', 30),\n",
              " ('how', 30),\n",
              " ('neuronal', 30),\n",
              " ('exponential', 30),\n",
              " ('tree', 30),\n",
              " ('manifold', 30),\n",
              " ('analog vlsi', 29),\n",
              " ('stochastic gradient', 29),\n",
              " ('computing', 29),\n",
              " ('point', 29),\n",
              " ('language', 29),\n",
              " ('exploration', 29),\n",
              " ('feedback', 29),\n",
              " ('planning', 29),\n",
              " ('transfer', 29),\n",
              " ('sets', 29),\n",
              " ('recovery', 29),\n",
              " ('joint', 29),\n",
              " ('regret', 29),\n",
              " ('networks learning', 28),\n",
              " ('markov decision', 28),\n",
              " ('feature selection', 28),\n",
              " ('boltzmann', 28),\n",
              " ('comparison', 28),\n",
              " ('codes', 28),\n",
              " ('identification', 28),\n",
              " ('basis', 28),\n",
              " ('finite', 28),\n",
              " ('complex', 28),\n",
              " ('auditory', 28),\n",
              " ('distance', 28),\n",
              " ('algorithm', 28),\n",
              " ('bandit', 28),\n",
              " ('minimax', 28),\n",
              " ('random fields', 27),\n",
              " ('machine learning', 27),\n",
              " ('entropy', 27),\n",
              " ('backpropagation', 27),\n",
              " ('neuron', 27),\n",
              " ('structural', 27),\n",
              " ('loss', 27),\n",
              " ('variables', 27),\n",
              " ('semi-supervised', 27),\n",
              " ('embeddings', 27),\n",
              " ('rank', 27),\n",
              " ('belief propagation', 26),\n",
              " ('kernel learning', 26),\n",
              " ('power', 26),\n",
              " ('order', 26),\n",
              " ('noisy', 26),\n",
              " ('extraction', 26),\n",
              " ('sparsity', 26),\n",
              " ('experts', 26),\n",
              " ('dual', 26),\n",
              " ('single', 26),\n",
              " ('principal', 26),\n",
              " ('series', 26),\n",
              " ('bayes', 26),\n",
              " ('high-dimensional', 26),\n",
              " ('topic', 26),\n",
              " ('unsupervised learning', 25),\n",
              " ('neural network', 25),\n",
              " ('model selection', 25),\n",
              " ('matrix completion', 25),\n",
              " ('constrained', 25),\n",
              " ('differential', 25),\n",
              " ('signal', 25),\n",
              " ('neuron', 25),\n",
              " ('covariance', 25),\n",
              " ('maps', 25),\n",
              " ('automatic', 25),\n",
              " ('predicting', 25),\n",
              " ('distribution', 25),\n",
              " ('dynamic', 25),\n",
              " ('domain', 25),\n",
              " ('diffusion', 25),\n",
              " ('blind', 25),\n",
              " ('similarity', 25),\n",
              " ('spaces', 25),\n",
              " ('dynamic programming', 24),\n",
              " ('function approximation', 24),\n",
              " ('decision processes', 24),\n",
              " ('signals', 24),\n",
              " ('computer', 24),\n",
              " ('objects', 24),\n",
              " ('towards', 24),\n",
              " ('rules', 24),\n",
              " ('incremental', 24),\n",
              " ('dimensionality', 24),\n",
              " ('selective', 24),\n",
              " ('parameter', 24),\n",
              " ('discovery', 24),\n",
              " ('scene', 24),\n",
              " ('variance', 24),\n",
              " ('coordinate', 24),\n",
              " ('exact', 24),\n",
              " ('priors', 24),\n",
              " ('factor', 24),\n",
              " ('beyond', 24),\n",
              " ('optimization', 24),\n",
              " ('activity', 23),\n",
              " ('motor', 23),\n",
              " ('net', 23),\n",
              " ('invariant', 23),\n",
              " ('functional', 23),\n",
              " ('retrieval', 23),\n",
              " ('simple', 23),\n",
              " ('sequences', 23),\n",
              " ('iterative', 23),\n",
              " ('pairwise', 23),\n",
              " ('empirical', 23),\n",
              " ('greedy', 23),\n",
              " ('semi-supervised', 23),\n",
              " ('regression', 23),\n",
              " ('label', 23),\n",
              " ('object recognition', 22),\n",
              " ('time series', 22),\n",
              " (\"''\", 22),\n",
              " ('action', 22),\n",
              " ('cortical', 22),\n",
              " ('classifier', 22),\n",
              " ('understanding', 22),\n",
              " ('plasticity', 22),\n",
              " ('face', 22),\n",
              " ('improving', 22),\n",
              " ('dimension', 22),\n",
              " ('missing', 22),\n",
              " ('localization', 22),\n",
              " ('text', 22),\n",
              " ('family', 22),\n",
              " ('randomized', 22),\n",
              " ('subspace', 22),\n",
              " ('mixture models', 21),\n",
              " ('latent variable', 21),\n",
              " ('deep neural', 21),\n",
              " ('tasks', 21),\n",
              " ('phase', 21),\n",
              " ('mean', 21),\n",
              " ('recursive', 21),\n",
              " ('unified', 21),\n",
              " ('study', 21),\n",
              " ('with', 21),\n",
              " ('likelihood', 21),\n",
              " ('prior', 21),\n",
              " ('rate', 21),\n",
              " ('response', 21),\n",
              " ('polynomial', 21),\n",
              " ('silicon', 21),\n",
              " ('scenes', 21),\n",
              " ('iteration', 21),\n",
              " ('partially', 21),\n",
              " ('multi-task', 21),\n",
              " ('expectation', 21),\n",
              " ('graph', 21),\n",
              " ('spiking neurons', 20),\n",
              " ('learning the', 20),\n",
              " ('bayesian inference', 20),\n",
              " ('density estimation', 20),\n",
              " ('approximate inference', 20),\n",
              " ('metric learning', 20),\n",
              " ('convex optimization', 20),\n",
              " ('projection', 20),\n",
              " ('synaptic', 20),\n",
              " ('chip', 20),\n",
              " ('perceptual', 20),\n",
              " ('scaling', 20),\n",
              " ('vision', 20),\n",
              " ('combining', 20),\n",
              " ('effects', 20),\n",
              " ('group', 20),\n",
              " ('integration', 20),\n",
              " ('for', 20),\n",
              " ('video', 20),\n",
              " ('consistency', 20),\n",
              " ('testing', 20),\n",
              " ('correlation', 20),\n",
              " ('neighbor', 20),\n",
              " ('bound', 20),\n",
              " ('particle', 20),\n",
              " ('mcmc', 20),\n",
              " ('multivariate', 20),\n",
              " ('collaborative', 20),\n",
              " ('low-rank', 20),\n",
              " ('matrix', 20),\n",
              " ('supervised learning', 19),\n",
              " ('dynamical systems', 19),\n",
              " ('convolutional neural', 19),\n",
              " ('generative models', 19),\n",
              " ('large scale', 19),\n",
              " ('matrix factorization', 19),\n",
              " ('its', 19),\n",
              " ('solving', 19),\n",
              " ('``', 19),\n",
              " ('perception', 19),\n",
              " ('between', 19),\n",
              " ('artificial', 19),\n",
              " ('real-time', 19),\n",
              " ('energy', 19),\n",
              " ('rule', 19),\n",
              " ('environments', 19),\n",
              " ('sensing', 19),\n",
              " ('shape', 19),\n",
              " ('parameters', 19),\n",
              " ('source', 19),\n",
              " ('weights', 19),\n",
              " ('knowledge', 19),\n",
              " ('hybrid', 19),\n",
              " ('.', 19),\n",
              " ('word', 19),\n",
              " ('approximations', 19),\n",
              " ('uncertainty', 19),\n",
              " ('statistics', 19),\n",
              " ('inferring', 19),\n",
              " ('linear', 19),\n",
              " ('accelerated', 19),\n",
              " ('dimensional', 19),\n",
              " ('multiclass', 19),\n",
              " ('matrices', 19),\n",
              " ('relational', 19),\n",
              " ('visual', 19),\n",
              " ('social', 19),\n",
              " ('end', 19),\n",
              " ('stochastic optimization', 18),\n",
              " ('natural images', 18),\n",
              " ('spectral clustering', 18),\n",
              " ('patterns', 18),\n",
              " ('measures', 18),\n",
              " ('learn', 18),\n",
              " ('hebbian', 18),\n",
              " ('dependent', 18),\n",
              " ('faster', 18),\n",
              " ('curves', 18),\n",
              " ('relaxation', 18),\n",
              " ('structures', 18),\n",
              " ('generation', 18),\n",
              " ('population', 18),\n",
              " ('spiking', 18),\n",
              " ('components', 18),\n",
              " ('contextual', 18),\n",
              " ('ica', 18),\n",
              " ('mdps', 18),\n",
              " ('svm', 18),\n",
              " ('alignment', 18),\n",
              " ('lasso', 18),\n",
              " ('dimensionality reduction', 17),\n",
              " ('principal component', 17),\n",
              " ('learning sparse', 17),\n",
              " ('object detection', 17),\n",
              " ('map inference', 17),\n",
              " ('simulation', 17),\n",
              " ('behavior', 17),\n",
              " ('techniques', 17),\n",
              " ('mapping', 17),\n",
              " ('making', 17)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monitoring Keywords"
      ],
      "metadata": {
        "id": "SHHmBipTORsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec2dynamics_keywords = ['neural network', 'reinforcement learning', 'active learning', 'monte carlo', 'deep learning',\n",
        "                          'machine learning', 'supervised learning', 'time series', 'artificial neural',\n",
        "                         'gaussian process', 'active learning', 'gradient descent', 'hidden markov',\n",
        "                         'nearest neighbor', 'dynamical system', 'dimensionality reduction',\n",
        "                         'unsupervised learning', 'graphical model', 'dynamic programming', 'component analysis', 'neural'\n",
        "                         ,'supervised','learning', 'model', 'reinforcement', 'markov', 'gradient', 'markov', 'neighbor','gaussian']"
      ],
      "metadata": {
        "id": "hqzzfXfjQ4RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keywords_np = np.array(candidate_keywords)\n",
        "\n",
        "candidate_keywords_ = np.array([keyword[0] for keyword in candidate_keywords])\n",
        "\n",
        "candidate_keywords_"
      ],
      "metadata": {
        "id": "Aco3xvQpSRV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4416f0-03b5-4fde-a397-b4ed99da720d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['learning', 'neural', 'networks', 'models', 'model', 'bayesian',\n",
              "       'using', 'neural networks', 'network', 'the', 'inference', 'data',\n",
              "       'analysis', 'gaussian', 'classification', 'optimization', 'sparse',\n",
              "       'stochastic', 'deep', 'estimation', 'recognition', 'efficient',\n",
              "       'clustering', 'algorithms', 'kernel', 'reinforcement',\n",
              "       'reinforcement learning', 'algorithm', 'online', 'adaptive',\n",
              "       'linear', 'regression', 'optimal', 'fast', 'neural network',\n",
              "       'markov', 'information', 'visual', 'image', 'approach',\n",
              "       'probabilistic', '?', 'processes', 'feature', 'gradient',\n",
              "       'variational', 'prediction', 'modeling', 'process', 'methods',\n",
              "       'robust', 'dynamic', 'recurrent', 'hierarchical', 'detection',\n",
              "       'training', 'random', 'time', 'structured', 'control', 'functions',\n",
              "       'selection', 'application', 'bounds', 'sampling',\n",
              "       'representations', 'local', 'latent', 'structure', 'unsupervised',\n",
              "       'model', 'machine', 'search', 'large', 'vector', 'graphical',\n",
              "       'speech', 'active', 'distributed', 'method', 'matrix',\n",
              "       'convergence', 'dynamics', 'systems', 'neural', 'multiple',\n",
              "       'object', 'convex', 'statistical', 'function', 'machines',\n",
              "       'spectral', 'regularization', 'decision', 'gaussian process',\n",
              "       'complexity', 'support', 'generalization', 'approximate',\n",
              "       'kernels', 'analog', 'nonlinear', 'human', 'natural', 'continuous',\n",
              "       'graph', 'approximation', 'minimization', 'neurons', 'propagation',\n",
              "       'problems', 'mixture', 'generative', 'based', 'vlsi', 'descent',\n",
              "       'graphical models', '--', 'programming', 'hidden',\n",
              "       'support vector', 'theory', 'temporal', 'system', 'features',\n",
              "       'matching', 'applications', 'images', 'boosting', 'nonparametric',\n",
              "       \"'\", 'generalized', 'network', 'policy', 'memory', 'graphs',\n",
              "       'bandits', 'maximum', 'gaussian processes', '-', 'from',\n",
              "       'mixtures', 'framework', 'belief', 'sequential', 'parallel',\n",
              "       'trees', 'active learning', 'error', 'coding', 'convolutional',\n",
              "       'submodular', 'variational inference', 'representation', 'noise',\n",
              "       'fields', 'pca', 'monte carlo', 'processing', 'motion',\n",
              "       'classifiers', '(', ')', 'monte', 'carlo', 'online learning',\n",
              "       'reduction', 'conditional', 'discriminative', 'speech recognition',\n",
              "       'distributions', 'component', 'regularized', 'games', 'supervised',\n",
              "       'filtering', 'segmentation', 'spiking', 'binary', 'adaptation',\n",
              "       'density', 'connectionist', 'maximization', 'metric', 'dynamical',\n",
              "       'new', 'embedding', 'brain', 'space', 'risk', 'estimating',\n",
              "       'value', 'ranking', 'margin', 'scalable', 'spike', 'sample',\n",
              "       'recurrent neural', 'high', 'variable', 'state', 'decomposition',\n",
              "       'component analysis', 'spatial', 'performance', 'probability',\n",
              "       'adversarial', 'cortex', 'computation', 'independent', 'dirichlet',\n",
              "       'gradient descent', 'hidden markov', 'implementation', 'attention',\n",
              "       'improved', 'global', 'inverse', 'factorization', 'tensor',\n",
              "       'problem', 'pattern', 'large-scale', 'separation', 'tracking',\n",
              "       'sequence', 'rates', 'completion', 'deep learning',\n",
              "       'computational', 'properties', 'general', 'field', 'architecture',\n",
              "       'discrete', 'predictive', 'scale', 'causal', 'map', 'nets',\n",
              "       'design', 'constraints', 'infinite', 'sparse', 'markov models',\n",
              "       'vector machines', 'associative', 'how', 'neuronal', 'exponential',\n",
              "       'tree', 'manifold', 'analog vlsi', 'stochastic gradient',\n",
              "       'computing', 'point', 'language', 'exploration', 'feedback',\n",
              "       'planning', 'transfer', 'sets', 'recovery', 'joint', 'regret',\n",
              "       'networks learning', 'markov decision', 'feature selection',\n",
              "       'boltzmann', 'comparison', 'codes', 'identification', 'basis',\n",
              "       'finite', 'complex', 'auditory', 'distance', 'algorithm', 'bandit',\n",
              "       'minimax', 'random fields', 'machine learning', 'entropy',\n",
              "       'backpropagation', 'neuron', 'structural', 'loss', 'variables',\n",
              "       'semi-supervised', 'embeddings', 'rank', 'belief propagation',\n",
              "       'kernel learning', 'power', 'order', 'noisy', 'extraction',\n",
              "       'sparsity', 'experts', 'dual', 'single', 'principal', 'series',\n",
              "       'bayes', 'high-dimensional', 'topic', 'unsupervised learning',\n",
              "       'neural network', 'model selection', 'matrix completion',\n",
              "       'constrained', 'differential', 'signal', 'neuron', 'covariance',\n",
              "       'maps', 'automatic', 'predicting', 'distribution', 'dynamic',\n",
              "       'domain', 'diffusion', 'blind', 'similarity', 'spaces',\n",
              "       'dynamic programming', 'function approximation',\n",
              "       'decision processes', 'signals', 'computer', 'objects', 'towards',\n",
              "       'rules', 'incremental', 'dimensionality', 'selective', 'parameter',\n",
              "       'discovery', 'scene', 'variance', 'coordinate', 'exact', 'priors',\n",
              "       'factor', 'beyond', 'optimization', 'activity', 'motor', 'net',\n",
              "       'invariant', 'functional', 'retrieval', 'simple', 'sequences',\n",
              "       'iterative', 'pairwise', 'empirical', 'greedy', 'semi-supervised',\n",
              "       'regression', 'label', 'object recognition', 'time series', \"''\",\n",
              "       'action', 'cortical', 'classifier', 'understanding', 'plasticity',\n",
              "       'face', 'improving', 'dimension', 'missing', 'localization',\n",
              "       'text', 'family', 'randomized', 'subspace', 'mixture models',\n",
              "       'latent variable', 'deep neural', 'tasks', 'phase', 'mean',\n",
              "       'recursive', 'unified', 'study', 'with', 'likelihood', 'prior',\n",
              "       'rate', 'response', 'polynomial', 'silicon', 'scenes', 'iteration',\n",
              "       'partially', 'multi-task', 'expectation', 'graph',\n",
              "       'spiking neurons', 'learning the', 'bayesian inference',\n",
              "       'density estimation', 'approximate inference', 'metric learning',\n",
              "       'convex optimization', 'projection', 'synaptic', 'chip',\n",
              "       'perceptual', 'scaling', 'vision', 'combining', 'effects', 'group',\n",
              "       'integration', 'for', 'video', 'consistency', 'testing',\n",
              "       'correlation', 'neighbor', 'bound', 'particle', 'mcmc',\n",
              "       'multivariate', 'collaborative', 'low-rank', 'matrix',\n",
              "       'supervised learning', 'dynamical systems', 'convolutional neural',\n",
              "       'generative models', 'large scale', 'matrix factorization', 'its',\n",
              "       'solving', '``', 'perception', 'between', 'artificial',\n",
              "       'real-time', 'energy', 'rule', 'environments', 'sensing', 'shape',\n",
              "       'parameters', 'source', 'weights', 'knowledge', 'hybrid', '.',\n",
              "       'word', 'approximations', 'uncertainty', 'statistics', 'inferring',\n",
              "       'linear', 'accelerated', 'dimensional', 'multiclass', 'matrices',\n",
              "       'relational', 'visual', 'social', 'end', 'stochastic optimization',\n",
              "       'natural images', 'spectral clustering', 'patterns', 'measures',\n",
              "       'learn', 'hebbian', 'dependent', 'faster', 'curves', 'relaxation',\n",
              "       'structures', 'generation', 'population', 'spiking', 'components',\n",
              "       'contextual', 'ica', 'mdps', 'svm', 'alignment', 'lasso',\n",
              "       'dimensionality reduction', 'principal component',\n",
              "       'learning sparse', 'object detection', 'map inference',\n",
              "       'simulation', 'behavior', 'techniques', 'mapping', 'making'],\n",
              "      dtype='<U24')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(vec2dynamics_keywords) - set(candidate_keywords_))"
      ],
      "metadata": {
        "id": "8ZG38qs5TmkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bf0224-082b-4473-92c7-f7525cc3b09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['graphical model',\n",
              " 'dynamical system',\n",
              " 'artificial neural',\n",
              " 'nearest neighbor']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monitering_keywords = list(set(vec2dynamics_keywords).intersection(set(candidate_keywords_)))\n",
        "monitering_keywords = monitering_keywords[:20]"
      ],
      "metadata": {
        "id": "Kn3otZ9NSfwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# candidate_keywords = candidate_keywords_\n",
        "\n",
        "len(monitering_keywords)"
      ],
      "metadata": {
        "id": "45O_nIsPU6S0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902a5ffe-5845-4a84-96de-6d4228cb5ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.1 - Get Vocabulary list"
      ],
      "metadata": {
        "id": "ShQ2rcd-qIIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers_contents_list = [\" \".join(time_slice_df[\"paper_text\"].tolist()).lower() for time_slice_df in nips_papers_partitions.values()]\n"
      ],
      "metadata": {
        "id": "G-7eZaE4rCqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# function to rmeove digits and numbers from papers \n",
        "def v_preprocess(papers_contents_list):      \n",
        "    # Remove any digits for the corpus\n",
        "    all_time_window_papers_content_list = list( (re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", time_slice_paper) \n",
        "                                                    for time_slice_paper in papers_contents_list) )\n",
        "    # Remove words with length less than 3 \n",
        "\n",
        "    # https://stackoverflow.com/questions/24332025/remove-words-of-length-less-than-4-from-string\n",
        "    all_time_window_papers_content_list = list( (re.sub(r'\\b\\w{1,2}\\b', '', time_slice_paper) \n",
        "                                          for time_slice_paper in all_time_window_papers_content_list) )\n",
        "\n",
        "\n",
        "    # remove words with number in it \n",
        "    # https://stackoverflow.com/questions/18082130/python-regex-to-remove-all-words-which-contains-number\n",
        "\n",
        "    all_time_window_papers_content_list = list( (re.sub(r'\\w*\\d\\w*', '', time_slice_paper) \n",
        "                                          for time_slice_paper in all_time_window_papers_content_list) )\n",
        "    return all_time_window_papers_content_list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2PYJpbYGC7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers_contents_list[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW1W_AjKyyKt",
        "outputId": "96e6f466-16f6-403e-ed41-d6e758dd18fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46835872"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers_contents_list = v_preprocess(papers_contents_list)"
      ],
      "metadata": {
        "id": "ANT5wGX2J8ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers_contents_list[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HvYq_aGzBMB",
        "outputId": "7ad87bed-71a5-405d-b063-c06ef7aa163f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41875126"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For optimization purpose\n",
        "import nltk\n",
        "def vocabulary(C):\n",
        "\n",
        "    v = list(set( (lemmatizer.lemmatize(w) for w in nltk.word_tokenize(C) if w not in stop_words) ))\n",
        "    return v"
      ],
      "metadata": {
        "id": "XD_rDH7fqTDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "\n",
        "# start = time.time()\n",
        "\n",
        "# v10 = vocabulary(papers_contents_list[9])\n",
        "\n",
        "# end = time.time()\n",
        "# print(end - start)"
      ],
      "metadata": {
        "id": "MjP6OTkRF1fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = vocabulary(papers_contents_list[0][:100000])"
      ],
      "metadata": {
        "id": "a1QP8xwICPyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v2 = vocabulary(papers_contents_list[1][:100000]) \n",
        "v3 = vocabulary(papers_contents_list[2][:100000]) \n",
        "v4 = vocabulary(papers_contents_list[3][:100000]) \n",
        "v5 = vocabulary(papers_contents_list[4][:100000]) \n",
        "v6 = vocabulary(papers_contents_list[5][:100000]) \n"
      ],
      "metadata": {
        "id": "tHhoqJmPrvWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_map = {\n",
        "\n",
        "    \"v1\":v1,\n",
        "    \"v2\":v2,\n",
        "    \"v3\":v3,\n",
        "    \"v4\":v4,\n",
        "    \"v5\":v5,\n",
        "    \"v6\":v6\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_2.pickle', 'wb+') as f:\n",
        "     pickle.dump(v_map, f)"
      ],
      "metadata": {
        "id": "cZ7EzCFH0ucK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v7 = vocabulary(papers_contents_list[6][:100000]) \n",
        "v8 = vocabulary(papers_contents_list[7][:100000]) \n",
        "\n",
        "\n",
        "v_map2 = {\n",
        "\n",
        "    \"v7\":v7,\n",
        "    \"v8\":v8,\n",
        "}\n",
        "\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_2.pickle', 'ab+') as f:\n",
        "     pickle.dump(v_map2, f)"
      ],
      "metadata": {
        "id": "7gYXIHWgHowx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v9 = vocabulary(papers_contents_list[8][:100000]) \n",
        "v10 = vocabulary( papers_contents_list[9][:100000]) \n",
        "\n",
        "\n",
        "v_map3 = {\n",
        "    \n",
        "    \"v9\":v9,\n",
        "    \"v10\":v10\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_2.pickle', 'ab+') as f:\n",
        "     pickle.dump(v_map3, f)"
      ],
      "metadata": {
        "id": "q2f7GYuA_DsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_2.pickle', 'rb+') as f:\n",
        "     v_map_1 = pickle.load(f)\n",
        "     v_map_2 = pickle.load(f)\n",
        "     v_map_3 = pickle.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "NrcE0FnWh7zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_map = {\n",
        "    **v_map_1,\n",
        "    **v_map_2,\n",
        "    **v_map_3\n",
        "}\n",
        "\n",
        "\n",
        "v1 = v_map[\"v1\"]\n",
        "v2 = v_map[\"v2\"]\n",
        "v3 = v_map[\"v3\"]\n",
        "v4 = v_map[\"v4\"]\n",
        "v5 = v_map[\"v5\"]\n",
        "v6 = v_map[\"v6\"]\n",
        "v7 = v_map[\"v7\"]\n",
        "v8 = v_map[\"v8\"]\n",
        "v9 = v_map[\"v9\"]\n",
        "v10 = v_map[\"v10\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9xfDY2nlIDJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of \\n V1={len(v1)} \\n V2={len(v2)} \\n V3={len(v3)} \\n V4={len(v4)} \\n V5={len(v5)} \\n V6={len(v6)} \\n V7={len(v7)} \\n V8={len(v8)} \\n V9={len(v9)} V10={len(v10)}\")"
      ],
      "metadata": {
        "id": "GkohRp9xsGj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa382986-ee1c-4ae2-a3a0-8d74c911a2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of \n",
            " V1=1276 \n",
            " V2=1200 \n",
            " V3=1441 \n",
            " V4=1456 \n",
            " V5=1244 \n",
            " V6=1103 \n",
            " V7=1216 \n",
            " V8=1205 \n",
            " V9=1179 V10=1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - BERT EMBEDDING GENERATE"
      ],
      "metadata": {
        "id": "kTigylDrZ2xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_ngram_candidate_keywords_time_slices_sorted_ = [ngram[0] for ngram in candidate_keywords]\n",
        "# t = \"\\n\".join(title_ngram_candidate_keywords_time_slices_sorted_)\n",
        "t = \"\\n\".join(monitering_keywords)\n",
        "\n",
        "t"
      ],
      "metadata": {
        "id": "4fcx51Krc-lh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1a74ffb3-57cd-4efc-d7e6-7b4f3f3c4d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'markov\\ndeep learning\\nsupervised\\ngradient descent\\nsupervised learning\\nneural network\\ndimensionality reduction\\ncomponent analysis\\ntime series\\nneural\\nneighbor\\nmonte carlo\\nreinforcement learning\\nhidden markov\\nmodel\\nreinforcement\\ngradient\\nlearning\\nmachine learning\\ngaussian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install Unidecode"
      ],
      "metadata": {
        "id": "j6BqKd5ZheKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756f79e8-a732-48c0-ae78-0589ebc2e4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     || 123 kB 29.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.58-py3-none-any.whl (132 kB)\n",
            "\u001b[K     || 132 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.58\n",
            "  Downloading botocore-1.27.58-py3-none-any.whl (9.1 MB)\n",
            "\u001b[K     || 9.1 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     || 79 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     || 140 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.58->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.58->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     || 127 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.58 botocore-1.27.58 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     || 235 kB 24.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertConfig\n",
        "from collections import OrderedDict\n",
        "import unidecode\n",
        "import numpy as np\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline"
      ],
      "metadata": {
        "id": "x6P0dfVehoGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "import torch\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "mTl8ffpftcpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "113f7913-a0ec-4beb-af5d-c4d661aac617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Use the pre-trained Base BERT model \n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.cuda()\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "FKo54yLjzQut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa94c04-8e22-46e5-b473-cbc08da5379c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 231508/231508 [00:00<00:00, 252581.82B/s]\n",
            "100%|| 407873900/407873900 [00:34<00:00, 11698618.93B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class Data():\n",
        "\n",
        "    def __getitem__(self, content=None):\n",
        "         if content!=None:\n",
        "             self.doc = \"\".join(content)\n",
        "         return self.doc\n",
        "     \n",
        "    def _preprocess(self,targets,corpus):\n",
        "        self.index=[]\n",
        "        self.t_index=OrderedDict()\n",
        "        for target in targets:\n",
        "            \n",
        "            for _,item in enumerate(corpus):\n",
        "                # if target in item:\n",
        "                  if item.lower().find(target) != -1:\n",
        "                # if bool(re.search(target, item)):\n",
        "\n",
        "                  # Check if sentence has multiple occurances of the target term\n",
        "                      count_target=item.count(target)\n",
        "                  #   Avoiding the sentences with multiple occurrences of the target term for the time being###\n",
        "                      if count_target==1:\n",
        "                        if target not in self.t_index.keys():\n",
        "                            self.t_index[target]=[_]\n",
        "                        else:\n",
        "                            self.t_index[target].append(_)\n",
        "                        self.index.append(_)\n",
        "        return self.index,self.t_index"
      ],
      "metadata": {
        "id": "7FhI9iflZ-2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "LOAD & EXTRACT DATA\n",
        "'''\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "p1 = nips_papers_partitions[0][\"paper_text\"].tolist()\n",
        "p2 = nips_papers_partitions[1][\"paper_text\"].tolist()\n",
        "p3 = nips_papers_partitions[2][\"paper_text\"].tolist()\n",
        "p4 = nips_papers_partitions[3][\"paper_text\"].tolist()\n",
        "p5 = nips_papers_partitions[4][\"paper_text\"].tolist()\n",
        "p6 = nips_papers_partitions[5][\"paper_text\"].tolist()\n",
        "p7 = nips_papers_partitions[6][\"paper_text\"].tolist()\n",
        "p8 = nips_papers_partitions[7][\"paper_text\"].tolist()\n",
        "p9 = nips_papers_partitions[8][\"paper_text\"].tolist()\n",
        "p10 = nips_papers_partitions[9][\"paper_text\"].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "t = t\n",
        "datasets = Data() \n",
        "\n",
        "# doc1 =  [\"Sentence1\", \"Sentence2\".....]\n",
        "doc1=datasets.__getitem__(p1).split('\\n')   \n",
        "doc2=datasets.__getitem__(p2).split('\\n')\n",
        "doc3=datasets.__getitem__(p3).split('\\n')\n",
        "doc4=datasets.__getitem__(p4).split('\\n')\n",
        "doc5=datasets.__getitem__(p5).split('\\n')\n",
        "doc6=datasets.__getitem__(p6).split('\\n')\n",
        "doc7=datasets.__getitem__(p7).split('\\n')\n",
        "doc8=datasets.__getitem__(p8).split('\\n')\n",
        "doc9=datasets.__getitem__(p9).split('\\n')\n",
        "doc10=datasets.__getitem__(p10).split('\\n')\n",
        "\n",
        "\n",
        "t1=datasets.__getitem__(t).split('\\n')\n",
        "target_act=[x for x in t1 if len(x)>1]\n",
        "t1=[x.lower() for x in t1 if len(x)>1]\n",
        "\n",
        "index1=datasets._preprocess(t1,doc1)\n",
        "index2=datasets._preprocess(t1,doc2)\n",
        "index3=datasets._preprocess(t1,doc3)\n",
        "index4=datasets._preprocess(t1,doc4)\n",
        "index5=datasets._preprocess(t1,doc5)\n",
        "index6=datasets._preprocess(t1,doc6)\n",
        "index7=datasets._preprocess(t1,doc7)\n",
        "index8=datasets._preprocess(t1,doc8)\n",
        "index9=datasets._preprocess(t1,doc9)\n",
        "index10=datasets._preprocess(t1,doc10)\n",
        "\n",
        "\n",
        "index_t1=index1[1]\n",
        "index_t2=index2[1]\n",
        "index_t3=index3[1]\n",
        "index_t4=index4[1]\n",
        "index_t5=index5[1]\n",
        "index_t6=index6[1]\n",
        "index_t7=index7[1]\n",
        "index_t8=index8[1]\n",
        "index_t9=index9[1]\n",
        "index_t10=index10[1]\n",
        "\n",
        "print('The target words are:',t1)\n",
        "target_words=t1\n",
        "\n",
        "print('The index_t1 are ', index_t1)\n",
        "print('The index_t2 are ', index_t2)\n",
        "\n",
        "\n",
        "#conversions\n",
        "target_uni=[unidecode.unidecode(m) for m in t1]\n",
        "target_toks=[]\n",
        "# print(target_uni)\n",
        "for k in t1:\n",
        "  target_toks.append(tokenizer.tokenize(k))\n",
        "print('converted target toks',target_toks)"
      ],
      "metadata": {
        "id": "WBbu-VZwaN3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26018469-0160-4a41-9f42-588f197f5825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target words are: ['markov', 'deep learning', 'supervised', 'gradient descent', 'supervised learning', 'neural network', 'dimensionality reduction', 'component analysis', 'time series', 'neural', 'neighbor', 'monte carlo', 'reinforcement learning', 'hidden markov', 'model', 'reinforcement', 'gradient', 'learning', 'machine learning', 'gaussian']\n",
            "The index_t1 are  OrderedDict([('markov', [2697, 2814, 3009, 110171]), ('supervised', [628, 1672, 19713, 19714, 19734, 19736, 19796, 19814, 19819, 20208, 20218, 20220, 20353, 20629, 26312, 26333, 28033, 28055, 28056, 28058, 28533, 28627, 28633, 28643, 28654, 29969, 31446, 31919, 32017, 32018, 32038, 32129, 32138, 32146, 32147, 32702, 38083, 38254, 51732, 51734, 51768, 54331, 54422, 55325, 58202, 58644, 59027, 59042, 59043, 59076, 59605, 60074, 60078, 60543, 60545, 60546, 60553, 61176, 61183, 61260, 61293, 61346, 61360, 61361, 61366, 61373, 61411, 61421, 61457, 61479, 61502, 61504, 64783, 64785, 65291, 65294, 70013, 70014, 71120, 71146, 71580, 77067, 84022, 90480, 90607, 91774, 92177, 99540, 101851, 104005, 109819, 109843, 110003, 110016, 110090, 112044, 112057, 112059, 112090, 112128, 112327, 112389, 112422, 112443, 112444, 112496, 112503, 113650, 114031, 114965, 117178, 117450, 119251, 119730, 120343, 120792, 120904, 120906, 120918, 120925, 120993, 121176, 121365, 121368, 123137, 123299, 123396, 123397, 128954, 129834, 130471, 130719, 135885, 135997, 137912, 139586, 139608, 139615, 139646, 139659, 139888, 141110, 141553, 141877, 142352, 142357, 142444, 142500, 143457, 143492]), ('gradient descent', [703, 704, 788, 3675, 3799, 3903, 3986, 4133, 4179, 10703, 10741, 11803, 12018, 13158, 15391, 16733, 16943, 16994, 17013, 17019, 17025, 17084, 17250, 21878, 21927, 22212, 22252, 22257, 23162, 23219, 23285, 23330, 23334, 23339, 32497, 35169, 37875, 37880, 37981, 42088, 46692, 46756, 49237, 49238, 49270, 49273, 54331, 54332, 54377, 58752, 58754, 59077, 59169, 59608, 66268, 67641, 67686, 67818, 67944, 68021, 68595, 71212, 71614, 71658, 73838, 73980, 79384, 79867, 79889, 79917, 83150, 90932, 90960, 91254, 91282, 96002, 97429, 97453, 97754, 102883, 112081, 112083, 114207, 114278, 114365, 117660, 117879, 118058, 122251, 122692, 123485, 123820, 123924, 129778, 134373, 137962, 139284, 139306, 140541, 142595, 142624, 142635, 143143, 143214, 143319, 143787]), ('supervised learning', [628, 19713, 19814, 19819, 20208, 20218, 20220, 20353, 20629, 26312, 26333, 28033, 28058, 28533, 28627, 28633, 28643, 28654, 32147, 51732, 51734, 51768, 54422, 58202, 59027, 59042, 59043, 59076, 59605, 60545, 60546, 60553, 61502, 61504, 64783, 64785, 65294, 70013, 71120, 71146, 77067, 84022, 91774, 99540, 101851, 104005, 109819, 109843, 112057, 112503, 113650, 114031, 114965, 117450, 119251, 119730, 120343, 120918, 120925, 123137, 123299, 123397, 128954, 130471, 130719, 132141, 137912, 139659, 141110, 142357, 142366, 142444, 142500, 143457, 143492]), ('neural network', [10, 55, 59, 67, 93, 178, 527, 609, 611, 622, 644, 645, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1934, 1950, 1952, 1957, 1972, 2583, 2651, 2653, 2654, 2700, 2706, 2796, 2814, 2817, 2824, 2933, 3086, 3128, 3607, 3665, 3672, 3705, 3855, 3876, 4854, 4855, 4868, 4870, 4891, 5136, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 6241, 6323, 6357, 6667, 6701, 6721, 6792, 6801, 6802, 6851, 7262, 7267, 7273, 7275, 7290, 7454, 7456, 7641, 7647, 7825, 8280, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9383, 9534, 9749, 9969, 9974, 9975, 9999, 10001, 10002, 10005, 10013, 10016, 10018, 10045, 10072, 11879, 12245, 12834, 12908, 13276, 13351, 14032, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15892, 15895, 15950, 15957, 15979, 16062, 16257, 16270, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17529, 18681, 18733, 19659, 19662, 20650, 20674, 21159, 21240, 22283, 22323, 22347, 22354, 22356, 22365, 22387, 22779, 22796, 23038, 23159, 23168, 23175, 26348, 26844, 26864, 26914, 27188, 27244, 28050, 28667, 28793, 28902, 29003, 29038, 29058, 29060, 29285, 29367, 29833, 30442, 30445, 30483, 30484, 30486, 30496, 30546, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30854, 30915, 30936, 30938, 30943, 30963, 32144, 32166, 32606, 32657, 32661, 32681, 33225, 33233, 33247, 33251, 33258, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33462, 33468, 33472, 33980, 33991, 34022, 34023, 34034, 34244, 34253, 34258, 34268, 34301, 34417, 34891, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35896, 36322, 36325, 36331, 36337, 36382, 36395, 36413, 36416, 36493, 36548, 36747, 36750, 36784, 36802, 36892, 36897, 36899, 36910, 36913, 36919, 36929, 36938, 37053, 37121, 37157, 37320, 37369, 37385, 37420, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 38128, 38897, 38898, 38904, 38908, 38912, 38919, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43706, 43761, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45657, 46258, 46317, 47396, 48398, 48405, 48408, 48538, 48592, 48594, 48640, 48647, 48706, 48770, 48876, 48879, 48891, 48900, 48901, 48987, 49002, 49005, 49016, 49021, 49025, 49061, 49063, 49076, 49094, 49294, 49542, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50611, 50637, 51186, 51201, 51214, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55952, 56521, 56720, 56724, 56840, 56857, 56865, 56884, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57781, 57801, 58223, 58275, 58465, 58481, 59008, 59042, 59053, 59055, 59639, 59651, 59856, 59926, 60715, 61176, 61183, 61192, 61504, 61529, 61537, 61551, 61688, 61821, 61849, 61915, 62891, 62906, 64670, 65360, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69142, 69149, 69446, 69483, 69673, 69960, 69962, 69980, 70832, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72473, 72476, 72483, 72486, 72487, 72550, 72588, 73156, 73167, 73170, 73171, 73175, 73279, 73369, 74215, 74797, 74832, 75041, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 76329, 76332, 76351, 76397, 76413, 76528, 76617, 76719, 77195, 77207, 77218, 77228, 77593, 77599, 77610, 77611, 77625, 78264, 78279, 78522, 78545, 79379, 79409, 79510, 79825, 81267, 81758, 82044, 82566, 82594, 82599, 83219, 83259, 84022, 84039, 84059, 84406, 84462, 84463, 86146, 86159, 86192, 86418, 86534, 86568, 86588, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87086, 87462, 87473, 87918, 87932, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 90486, 90598, 90622, 90638, 90718, 90725, 92322, 92327, 92357, 92359, 92361, 92366, 92372, 92373, 92376, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92676, 92819, 92824, 92873, 92967, 93655, 93699, 93701, 93708, 93714, 93717, 93728, 93731, 94080, 94100, 94142, 94151, 94154, 94158, 94170, 94221, 94235, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95672, 95681, 95746, 95854, 95967, 96006, 96014, 96024, 96093, 96213, 96661, 96685, 97183, 97187, 97199, 97225, 97908, 97974, 97987, 97996, 98367, 99036, 99090, 99123, 99125, 99258, 99266, 100805, 101124, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103492, 103493, 103590, 103684, 103728, 103734, 103742, 106635, 106645, 108061, 108072, 108079, 108103, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108727, 108927, 108937, 108956, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 111656, 111659, 111660, 112074, 112438, 112455, 113161, 113753, 115874, 115878, 117952, 118424, 119251, 119722, 120918, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 122247, 122254, 122264, 122267, 122279, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123416, 123454, 123914, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125375, 125385, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125828, 125829, 125831, 126020, 126025, 126027, 126087, 126100, 126126, 127242, 127457, 128631, 129031, 129598, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130445, 130471, 130480, 130490, 130493, 130627, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134433, 134473, 135026, 135029, 135072, 135239, 135243, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136727, 136739, 136760, 136762, 136772, 136786, 136820, 137044, 137055, 137058, 137063, 137068, 137095, 138161, 138378, 138424, 138744, 138759, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139448, 139994, 140011, 140012, 140016, 140385, 140425, 140430, 140475, 140476, 140484, 140493, 140495, 140499, 140540, 140954, 140956, 141004, 141011, 141072, 141098, 141295, 142457, 142465, 143092, 143149, 143183, 143265, 143303, 143313, 143398, 143410, 143411, 143492, 143924, 143950, 144992, 145013, 145324, 145362, 145733, 146825]), ('dimensionality reduction', [56790, 89935, 112412, 112413, 128327, 128330, 143459, 143485, 143493]), ('component analysis', [41496, 48534, 90930, 90955, 91252, 91277, 143476]), ('time series', [10006, 10022, 10036, 10037, 10213, 10231, 10233, 10238, 10250, 10310, 10605, 16413, 16456, 54240, 58392, 58412, 58442, 58445, 58448, 58451, 58457, 58473, 71920, 101222, 101231, 102649, 112133, 138067, 138769, 138887, 138889, 138893, 138906]), ('neural', [10, 55, 59, 67, 93, 178, 526, 527, 602, 609, 611, 614, 618, 622, 644, 645, 649, 656, 1192, 1665, 1689, 1755, 1767, 1773, 1780, 1789, 1796, 1838, 1849, 1867, 1869, 1872, 1888, 1921, 1923, 1926, 1928, 1934, 1950, 1952, 1957, 1972, 2003, 2044, 2050, 2052, 2055, 2059, 2061, 2065, 2067, 2070, 2086, 2121, 2123, 2125, 2128, 2134, 2366, 2381, 2583, 2586, 2653, 2654, 2662, 2668, 2669, 2688, 2700, 2706, 2796, 2814, 2817, 2824, 2833, 2933, 2990, 3009, 3086, 3106, 3113, 3128, 3268, 3607, 3672, 3705, 3855, 3876, 4245, 4256, 4351, 4854, 4855, 4868, 4870, 4889, 4891, 4918, 4924, 4976, 5090, 5136, 5160, 5164, 5181, 5328, 5340, 5398, 5413, 5428, 5441, 6241, 6255, 6275, 6323, 6357, 6358, 6667, 6701, 6721, 6792, 6801, 6802, 6821, 6851, 7252, 7262, 7263, 7267, 7273, 7275, 7290, 7451, 7454, 7456, 7641, 7647, 7809, 7825, 8024, 8280, 8298, 8649, 8662, 8664, 8669, 8671, 8672, 8680, 8685, 8789, 8794, 8891, 9259, 9350, 9372, 9374, 9376, 9383, 9534, 9749, 9917, 9918, 9966, 9969, 9974, 9975, 9999, 10000, 10001, 10002, 10003, 10005, 10007, 10009, 10016, 10018, 10045, 10048, 10050, 10051, 10052, 10055, 10057, 10072, 10077, 10087, 10179, 10259, 10261, 10288, 10299, 10308, 10314, 10321, 10554, 10586, 10589, 10595, 10596, 10610, 10615, 10617, 10636, 10660, 10669, 10717, 11879, 12245, 12303, 12500, 12834, 12908, 13276, 13351, 14032, 14036, 14092, 14446, 14697, 14699, 14712, 14720, 14735, 14740, 14816, 15012, 15068, 15313, 15340, 15364, 15372, 15376, 15388, 15390, 15403, 15404, 15449, 15456, 15463, 15516, 15892, 15895, 15950, 15957, 15979, 16062, 16166, 16257, 16270, 16359, 16374, 16433, 16465, 16491, 17271, 17273, 17274, 17302, 17308, 17326, 17391, 17420, 17423, 17454, 17497, 17516, 17529, 17531, 18086, 18129, 18263, 18673, 18681, 18686, 18706, 18733, 19659, 19662, 19693, 19736, 19795, 19817, 20358, 20624, 20650, 20674, 20707, 20709, 21122, 21139, 21159, 21240, 21903, 22283, 22295, 22323, 22326, 22332, 22338, 22347, 22354, 22356, 22365, 22387, 22434, 22448, 22472, 22764, 22779, 22796, 22812, 22814, 22815, 22818, 23038, 23159, 23168, 23175, 25506, 26348, 26844, 26864, 26897, 26899, 26914, 27102, 27188, 27212, 27244, 28050, 28633, 28667, 28747, 28793, 28902, 29003, 29038, 29058, 29060, 29067, 29285, 29287, 29367, 29833, 30099, 30442, 30445, 30483, 30484, 30486, 30491, 30496, 30502, 30546, 30556, 30558, 30561, 30572, 30574, 30576, 30824, 30827, 30833, 30839, 30843, 30854, 30915, 30929, 30936, 30938, 30943, 30952, 30963, 31441, 31448, 31459, 31772, 32144, 32151, 32155, 32166, 32606, 32657, 32661, 32662, 32681, 32700, 33225, 33233, 33247, 33248, 33251, 33258, 33260, 33277, 33293, 33329, 33360, 33362, 33416, 33431, 33457, 33462, 33468, 33470, 33472, 33980, 33991, 34021, 34022, 34023, 34034, 34128, 34131, 34244, 34253, 34258, 34268, 34301, 34313, 34417, 34891, 34922, 34948, 34952, 34959, 34964, 34965, 34971, 35069, 35125, 35531, 35532, 35548, 35704, 35858, 35877, 35882, 35887, 35896, 36059, 36310, 36322, 36325, 36331, 36337, 36344, 36352, 36374, 36376, 36382, 36395, 36399, 36404, 36410, 36413, 36416, 36457, 36460, 36467, 36487, 36489, 36493, 36501, 36502, 36507, 36510, 36511, 36548, 36551, 36570, 36572, 36613, 36737, 36747, 36748, 36750, 36784, 36802, 36809, 36812, 36892, 36897, 36899, 36903, 36910, 36913, 36919, 36929, 36938, 36976, 37053, 37119, 37121, 37157, 37175, 37320, 37336, 37369, 37385, 37420, 37448, 37453, 37468, 37495, 37496, 37504, 37509, 37511, 37874, 38081, 38096, 38103, 38124, 38125, 38128, 38131, 38343, 38450, 38481, 38501, 38508, 38509, 38510, 38897, 38898, 38904, 38908, 38912, 38919, 39088, 39318, 39555, 39566, 39568, 39570, 39995, 40535, 40538, 40554, 40557, 40579, 40705, 40819, 41088, 41216, 41458, 41957, 41958, 41961, 41970, 41977, 41981, 42027, 42149, 42170, 42173, 42176, 42179, 42188, 42224, 42247, 42256, 42303, 42310, 42323, 42327, 42441, 42442, 42445, 42446, 42453, 42475, 42480, 42504, 42577, 42588, 42624, 42651, 42724, 42905, 42935, 43629, 43640, 43667, 43706, 43761, 43810, 43811, 44434, 44435, 44440, 44446, 44467, 45068, 45425, 45432, 45435, 45442, 45640, 45645, 45657, 45760, 46258, 46317, 47396, 47403, 47886, 48398, 48399, 48403, 48405, 48407, 48408, 48424, 48428, 48483, 48485, 48487, 48496, 48504, 48508, 48531, 48538, 48540, 48542, 48592, 48594, 48601, 48640, 48647, 48706, 48709, 48744, 48749, 48770, 48774, 48876, 48879, 48885, 48900, 48901, 48980, 48987, 49002, 49005, 49016, 49017, 49021, 49025, 49033, 49061, 49063, 49065, 49076, 49078, 49080, 49094, 49123, 49294, 49584, 49769, 49772, 49774, 49798, 49840, 49875, 50496, 50576, 50601, 50611, 50637, 51024, 51053, 51186, 51201, 51214, 51824, 52209, 52211, 52213, 52217, 52218, 52221, 52257, 52289, 52364, 52370, 52391, 52414, 53161, 53374, 54407, 55306, 55348, 55387, 55918, 55948, 55952, 56521, 56548, 56720, 56724, 56804, 56811, 56812, 56840, 56857, 56865, 56884, 56928, 56998, 57005, 57051, 57052, 57057, 57068, 57069, 57072, 57073, 57079, 57089, 57261, 57299, 57589, 57626, 57629, 57632, 57633, 57781, 57788, 57801, 58223, 58275, 58465, 58481, 59008, 59028, 59053, 59055, 59639, 59651, 59751, 59768, 59856, 59926, 60103, 60133, 60242, 60331, 60419, 60715, 60747, 60789, 61176, 61183, 61192, 61493, 61496, 61504, 61529, 61537, 61550, 61551, 61613, 61688, 61821, 61849, 61915, 62891, 62892, 62906, 62948, 64008, 64327, 64613, 64619, 64620, 64670, 65356, 65360, 65397, 65435, 65441, 65460, 65652, 65697, 65744, 65756, 65764, 65768, 65770, 66023, 66024, 66030, 66031, 66391, 66400, 66452, 66838, 66854, 66859, 66863, 66868, 67340, 67647, 67653, 67661, 68518, 69141, 69142, 69149, 69446, 69457, 69483, 69673, 69960, 69962, 69980, 70516, 70832, 70924, 71071, 71074, 71138, 71142, 71154, 71556, 71576, 71937, 71940, 71999, 72362, 72438, 72443, 72473, 72474, 72483, 72486, 72487, 72502, 72504, 72550, 72555, 72567, 72588, 73156, 73161, 73163, 73165, 73167, 73170, 73171, 73176, 73279, 73321, 73334, 73369, 73397, 73437, 73532, 73546, 73696, 73804, 73948, 74215, 74270, 74284, 74780, 74793, 74797, 74798, 74832, 75041, 75152, 75180, 75188, 75827, 75833, 75834, 75863, 75870, 75873, 75874, 75887, 75889, 75918, 75958, 75997, 76064, 76304, 76329, 76332, 76351, 76397, 76413, 76528, 76533, 76544, 76546, 76549, 76552, 76559, 76561, 76563, 76586, 76607, 76610, 76615, 76617, 76618, 76656, 76658, 76676, 76679, 76681, 76717, 76721, 76726, 77195, 77207, 77211, 77218, 77228, 77229, 77323, 77593, 77599, 77610, 77611, 77625, 77776, 77777, 77782, 78230, 78249, 78264, 78279, 78522, 79379, 79409, 79510, 79812, 79825, 80243, 80245, 80684, 80707, 81190, 81192, 81256, 81267, 81268, 81343, 81626, 81659, 81758, 82044, 82566, 82594, 82599, 83219, 83227, 83260, 83657, 83702, 83704, 84022, 84039, 84059, 84406, 84462, 84463, 84510, 84513, 84911, 84982, 85295, 85297, 85301, 85351, 85354, 85462, 86138, 86146, 86148, 86159, 86161, 86192, 86418, 86530, 86534, 86568, 86588, 86606, 86619, 86627, 86631, 86635, 86642, 86734, 86800, 87042, 87076, 87086, 87108, 87116, 87462, 87473, 87918, 87932, 88136, 88163, 88349, 88956, 88961, 89195, 89203, 89219, 89266, 89269, 89270, 89294, 89813, 89828, 89922, 90486, 90598, 90622, 90638, 90718, 90725, 91418, 91760, 91764, 92320, 92322, 92324, 92327, 92328, 92357, 92359, 92361, 92366, 92372, 92373, 92379, 92380, 92454, 92504, 92569, 92578, 92665, 92674, 92676, 92677, 92700, 92702, 92757, 92773, 92819, 92823, 92824, 92842, 92863, 92865, 92873, 92881, 92884, 92922, 92923, 92928, 92930, 92935, 92939, 92948, 92952, 92967, 92968, 92969, 93655, 93699, 93708, 93709, 93714, 93715, 93717, 93728, 93731, 94077, 94080, 94095, 94100, 94142, 94145, 94151, 94154, 94158, 94170, 94221, 94238, 94240, 94256, 94260, 94305, 94336, 94575, 94577, 94579, 95245, 95531, 95632, 95668, 95672, 95681, 95715, 95726, 95729, 95746, 95749, 95854, 95855, 95967, 96006, 96014, 96024, 96027, 96093, 96094, 96097, 96150, 96213, 96237, 96361, 96661, 96677, 96678, 96685, 96815, 96824, 96839, 97123, 97183, 97187, 97199, 97225, 97908, 97974, 97976, 97987, 97988, 97994, 97996, 98010, 98076, 98105, 98119, 98203, 98367, 98390, 98938, 99036, 99090, 99123, 99125, 99258, 99266, 99528, 99614, 99688, 100178, 100184, 100191, 100194, 100210, 100734, 100738, 100805, 100913, 100940, 101040, 101078, 101124, 101134, 101142, 101144, 101174, 101187, 101218, 101223, 101248, 101874, 101884, 101890, 101893, 101961, 102158, 102583, 102605, 102606, 102621, 102639, 102888, 103041, 103076, 103114, 103254, 103327, 103353, 103395, 103445, 103471, 103480, 103481, 103482, 103485, 103491, 103492, 103493, 103585, 103590, 103684, 103721, 103728, 103734, 103742, 106149, 106159, 106174, 106178, 106179, 106191, 106591, 106632, 106635, 106645, 106658, 106659, 106760, 106780, 106988, 107082, 107086, 107253, 108061, 108072, 108079, 108103, 108111, 108416, 108440, 108459, 108461, 108472, 108491, 108500, 108503, 108510, 108516, 108521, 108727, 108927, 108937, 108956, 109048, 109104, 109268, 109432, 109826, 109834, 109837, 109966, 109994, 109998, 110131, 110133, 110639, 111092, 111130, 111132, 111134, 111136, 111137, 111139, 111165, 111273, 111653, 111656, 111659, 111660, 112074, 112438, 112455, 112468, 113159, 113161, 113166, 113753, 114161, 114862, 114944, 115260, 115269, 115874, 115878, 116187, 117558, 117952, 118424, 118881, 119251, 119263, 119722, 120365, 120417, 120466, 120918, 120958, 120971, 120975, 120977, 120978, 121389, 121392, 121393, 121402, 121403, 121424, 121430, 121438, 121441, 121442, 121443, 121447, 121458, 121468, 121474, 121501, 121502, 121507, 121509, 121584, 121585, 121596, 121597, 121602, 121609, 121610, 121640, 121642, 121651, 121674, 121675, 121679, 121680, 121689, 121692, 121698, 121699, 121700, 121703, 121706, 121707, 121708, 121709, 121710, 121712, 121713, 121724, 121726, 121751, 121780, 121805, 122247, 122254, 122264, 122267, 122279, 122289, 122310, 122598, 122815, 122820, 122829, 123360, 123382, 123389, 123391, 123393, 123403, 123410, 123416, 123454, 123914, 124026, 124229, 124238, 124268, 124752, 124792, 124793, 124802, 124814, 124845, 125242, 125243, 125254, 125275, 125288, 125333, 125336, 125375, 125377, 125385, 125395, 125455, 125513, 125568, 125611, 125736, 125737, 125754, 125755, 125757, 125764, 125776, 125786, 125793, 125828, 125829, 125831, 125988, 126020, 126025, 126027, 126087, 126100, 126126, 126639, 126642, 126744, 126817, 126833, 126838, 126970, 126975, 127038, 127058, 127076, 127077, 127082, 127085, 127086, 127139, 127152, 127153, 127242, 127342, 127343, 127369, 127381, 127382, 127407, 127429, 127432, 127457, 127507, 128000, 128631, 128978, 129011, 129031, 129036, 129559, 129569, 129591, 129598, 129604, 129978, 129995, 129999, 130054, 130066, 130088, 130107, 130186, 130190, 130192, 130210, 130211, 130217, 130258, 130282, 130405, 130424, 130435, 130440, 130443, 130445, 130471, 130480, 130490, 130491, 130493, 130611, 130627, 130642, 130749, 130822, 131000, 131234, 131442, 131455, 131458, 131469, 131472, 131476, 131481, 131537, 131655, 131932, 132120, 132129, 132147, 132153, 132156, 132235, 132410, 133089, 133105, 133140, 133159, 133163, 133187, 133223, 133242, 133250, 133427, 133472, 133497, 133499, 133540, 134005, 134021, 134116, 134249, 134431, 134433, 134438, 134453, 134467, 134473, 135026, 135029, 135051, 135072, 135239, 135243, 135303, 135306, 135572, 135647, 135686, 135787, 135788, 135885, 135997, 136036, 136095, 136100, 136108, 136118, 136119, 136123, 136124, 136130, 136138, 136169, 136174, 136175, 136177, 136281, 136623, 136639, 136642, 136661, 136666, 136673, 136727, 136739, 136760, 136762, 136772, 136786, 136812, 136820, 136828, 137044, 137055, 137058, 137063, 137068, 138161, 138376, 138377, 138378, 138410, 138411, 138424, 138462, 138470, 138507, 138547, 138554, 138592, 138595, 138684, 138713, 138744, 138756, 138759, 138764, 138800, 138858, 138905, 138916, 139207, 139222, 139306, 139307, 139448, 139895, 139994, 140011, 140012, 140013, 140016, 140019, 140385, 140420, 140425, 140430, 140475, 140476, 140484, 140487, 140493, 140495, 140499, 140540, 140954, 140956, 140988, 141004, 141011, 141072, 141098, 141295, 141315, 141321, 141416, 141427, 142070, 142256, 142457, 142463, 142465, 143092, 143138, 143140, 143141, 143148, 143149, 143150, 143172, 143183, 143223, 143232, 143243, 143262, 143268, 143269, 143271, 143285, 143288, 143303, 143313, 143357, 143360, 143398, 143405, 143410, 143411, 143457, 143492, 143924, 143950, 144187, 144992, 145013, 145313, 145324, 145362, 145733, 146382, 146658, 146825, 146874, 147030, 147321]), ('neighbor', [732, 1203, 1303, 1564, 1566, 1568, 1610, 1613, 1621, 2693, 2709, 2717, 2815, 3228, 4418, 4420, 4522, 5415, 5622, 5808, 5857, 5859, 5944, 6200, 6202, 6211, 6215, 7585, 11657, 11660, 11662, 11663, 11668, 11671, 15373, 15688, 17288, 17289, 26855, 27275, 27285, 27288, 27441, 27444, 27455, 27490, 27729, 30534, 30536, 30542, 30548, 30602, 30603, 30608, 30624, 30692, 30733, 30740, 30746, 30753, 30756, 30768, 30769, 30771, 30772, 30796, 30799, 30801, 31441, 31448, 31458, 31935, 31938, 32016, 32127, 32136, 32138, 32139, 32223, 32408, 32493, 32553, 33417, 33422, 33429, 33956, 36980, 37116, 37442, 38256, 38274, 38275, 38277, 38370, 38503, 38532, 39029, 39125, 39392, 41003, 41056, 41599, 41651, 41652, 41653, 41654, 41716, 41728, 41796, 41797, 41799, 41804, 41806, 41809, 41811, 41813, 41816, 41825, 41867, 41876, 41885, 41886, 51861, 51920, 53132, 53279, 60575, 64521, 64559, 66262, 66551, 69612, 69903, 71187, 71189, 71230, 71236, 71245, 71290, 71294, 71301, 71311, 71312, 71313, 71321, 71323, 71611, 72473, 72493, 72505, 72583, 72587, 73082, 73166, 73167, 73941, 73942, 74841, 74843, 74880, 74885, 75024, 75169, 75207, 75211, 75220, 75221, 79659, 82608, 82903, 83596, 84536, 85456, 87154, 87155, 87941, 89333, 90610, 91419, 91508, 91517, 94018, 94434, 95166, 95168, 95682, 100182, 100397, 100546, 100739, 101043, 101207, 102607, 102608, 102609, 102639, 102642, 102643, 102645, 102647, 102648, 102651, 102653, 102654, 102663, 102685, 102757, 102771, 102877, 103318, 103326, 103872, 103873, 104015, 104041, 104758, 104773, 104809, 104968, 105253, 107018, 109061, 109311, 109312, 109314, 109489, 111137, 116263, 116325, 119578, 120587, 120732, 123145, 124130, 124146, 127256, 127262, 127270, 127303, 127512, 128337, 128360, 128365, 128368, 128374, 128386, 129011, 129017, 129038, 129188, 129201, 129222, 129318, 129373, 129483, 129550, 133219, 133221, 134473, 135678, 135712, 136932, 137141, 137144, 137205, 137373, 142444, 142502, 142568, 142773, 142774, 142778, 143043]), ('monte carlo', [76705]), ('reinforcement learning', [19716, 19802, 20214, 20240, 20343, 20345, 20605, 20655, 51729, 51737, 60828, 60830, 109822, 109838, 109844, 109968, 109972, 109974, 109976, 110133, 119714, 119732, 119742, 120170, 120344, 120345, 120372]), ('model', [529, 535, 583, 594, 600, 608, 614, 617, 627, 631, 639, 644, 650, 690, 691, 815, 833, 834, 846, 847, 854, 857, 873, 902, 986, 987, 1075, 1087, 1088, 1116, 1187, 1205, 1207, 1232, 1233, 1234, 1258, 1260, 1265, 1267, 1275, 1286, 1287, 1288, 1449, 1450, 1455, 1456, 1457, 1458, 1459, 1466, 1467, 1480, 1481, 1482, 1492, 1498, 1504, 1507, 1511, 1512, 1513, 1515, 1516, 1521, 1524, 1558, 1571, 1575, 1578, 1579, 1581, 1590, 1616, 1634, 1637, 1642, 1650, 1651, 1665, 1677, 1684, 1755, 1756, 1759, 1762, 1765, 1780, 1828, 1870, 1888, 1921, 1931, 2428, 2430, 2652, 2653, 2655, 2659, 2660, 2662, 2669, 2678, 2680, 2687, 2695, 2700, 2702, 2792, 2806, 2814, 2820, 2848, 2933, 2957, 2965, 2990, 2995, 3009, 3086, 3107, 3128, 3131, 3133, 3137, 3205, 3252, 3342, 3387, 3390, 3407, 3434, 3607, 4480, 4505, 4506, 4509, 4520, 4579, 4601, 4606, 4610, 4622, 4639, 4870, 4924, 5041, 5046, 5066, 5164, 5345, 5441, 5442, 5560, 5632, 5633, 5635, 5641, 6821, 6829, 7863, 8133, 8144, 8521, 8649, 8663, 8666, 8886, 8987, 8998, 9013, 9259, 9340, 9384, 9385, 9388, 9392, 10703, 10704, 10707, 10710, 10711, 10716, 10717, 10740, 10741, 10915, 11237, 11238, 11243, 11278, 11307, 11335, 11358, 11636, 11651, 11653, 11717, 11737, 11739, 11829, 11834, 11842, 11843, 11852, 11859, 12298, 13347, 13351, 13387, 13397, 13398, 13434, 13490, 13501, 13788, 13789, 14066, 14084, 14094, 14145, 14713, 14714, 14716, 14720, 14723, 14724, 14725, 14726, 14738, 14740, 14744, 14746, 14747, 14758, 14765, 14772, 14801, 14816, 14817, 14821, 14834, 14884, 14887, 14911, 14912, 14914, 14919, 15034, 15066, 15145, 15148, 15153, 15169, 15180, 15181, 15201, 15213, 15214, 15215, 15313, 15398, 15446, 15450, 15884, 16024, 16272, 16460, 17302, 17308, 17314, 17340, 17423, 17425, 17448, 17497, 17511, 17515, 17516, 17558, 17866, 17869, 17877, 17893, 17949, 17961, 18067, 18068, 18069, 18108, 18110, 18113, 18118, 18124, 18132, 18135, 18136, 18174, 18399, 18574, 18681, 18683, 18686, 18690, 18699, 18722, 18728, 18733, 18761, 18773, 18784, 18842, 18851, 18889, 18893, 18894, 19434, 19657, 19659, 19671, 19693, 19731, 19732, 19739, 19823, 19824, 20197, 20214, 20216, 20244, 20350, 20706, 21166, 21211, 21213, 21215, 21224, 21234, 21239, 21241, 21255, 21263, 21266, 21268, 21269, 21274, 21276, 21277, 21285, 21294, 21299, 21399, 21400, 21435, 21476, 21552, 21691, 21744, 21745, 21749, 21824, 21825, 23159, 23735, 23967, 23977, 23978, 24001, 24002, 24006, 24094, 24096, 24098, 24107, 24110, 24131, 24171, 24194, 24201, 24203, 24213, 24216, 24217, 24277, 24278, 24279, 24284, 24371, 24372, 24445, 24448, 24449, 24451, 24454, 24461, 24465, 24466, 24508, 24570, 24592, 24600, 24603, 24604, 24605, 24611, 24615, 24618, 24653, 24654, 24661, 24662, 24665, 24787, 24789, 24794, 24795, 24984, 25174, 25177, 25557, 25560, 25561, 25564, 25596, 25600, 25602, 25604, 25606, 25612, 25644, 25650, 25651, 25656, 25660, 25661, 25668, 25671, 25676, 25680, 25683, 25687, 25691, 25693, 25707, 25721, 25731, 25736, 25740, 25742, 25829, 25836, 25900, 25902, 25913, 25917, 25920, 26012, 26013, 26019, 26022, 26025, 26033, 26039, 26040, 26041, 26042, 26049, 26050, 26053, 26059, 26064, 26067, 26074, 26080, 26082, 26088, 26091, 26096, 26098, 26102, 26104, 26107, 26203, 26548, 26554, 26849, 26853, 26864, 26873, 26889, 26904, 26916, 26921, 26928, 26949, 27104, 27248, 27262, 27272, 27319, 27527, 27539, 27634, 27636, 27651, 27662, 27719, 28654, 29983, 30008, 30041, 30090, 30125, 30127, 30140, 30143, 30266, 30267, 30269, 30276, 30285, 30310, 30429, 30442, 30464, 30467, 30470, 30491, 30524, 30526, 30530, 30545, 30546, 30549, 30551, 30556, 30561, 30562, 30563, 30572, 31829, 31921, 32422, 32423, 32588, 32611, 33236, 33252, 33280, 33481, 33584, 33586, 33587, 34129, 34132, 34301, 34439, 34525, 34647, 34652, 34675, 34692, 34702, 34869, 34880, 34917, 34922, 34955, 34964, 34965, 34971, 35150, 35478, 35529, 35531, 35532, 35533, 35534, 35537, 35539, 35545, 35550, 35705, 35706, 35809, 35815, 35944, 35990, 36281, 36310, 36578, 36596, 36736, 36892, 36910, 36911, 36934, 37590, 38495, 38579, 38586, 38589, 38597, 38618, 38622, 38625, 38634, 38637, 38785, 38898, 38908, 38918, 39072, 39089, 39214, 39215, 39216, 39260, 39318, 39449, 39459, 39472, 39473, 39474, 39482, 39580, 39943, 39977, 40007, 40028, 40130, 40540, 40541, 40565, 40725, 40791, 40792, 40818, 40819, 40822, 40980, 40986, 41006, 41337, 41354, 41394, 41396, 41407, 41457, 41469, 41475, 41499, 41577, 41581, 41584, 41586, 41588, 41595, 41691, 41711, 41737, 41821, 41854, 41876, 41908, 41958, 41972, 41987, 42367, 42501, 42535, 42563, 42735, 43082, 43087, 43385, 43388, 43389, 43390, 43634, 43635, 43639, 43666, 43669, 43674, 43678, 43679, 43706, 43708, 43709, 43726, 43728, 43740, 43745, 43747, 43749, 43758, 43759, 43761, 43770, 43778, 43966, 44424, 44434, 44437, 44447, 44467, 44473, 44476, 44478, 44492, 44497, 44684, 44731, 45068, 45069, 45077, 45080, 45081, 45083, 45084, 45086, 45393, 45435, 45442, 45504, 45513, 45528, 45573, 45657, 45696, 45701, 45702, 45704, 45743, 45745, 45758, 45767, 45770, 45774, 45779, 45781, 45921, 45930, 45954, 45970, 46252, 46266, 46289, 46348, 47155, 47423, 47437, 47469, 47664, 47674, 49061, 49065, 49080, 49845, 49846, 49852, 49853, 49855, 49857, 49858, 49859, 49865, 49866, 49876, 49998, 49999, 50041, 50042, 50062, 50066, 50069, 50076, 50114, 50150, 50276, 50316, 50318, 50320, 50322, 50326, 50490, 50491, 50497, 50501, 50554, 50602, 50606, 50610, 50618, 50633, 50636, 50647, 51025, 51053, 51061, 51134, 51137, 51202, 51408, 51632, 51683, 51689, 51719, 51760, 51786, 51788, 51789, 51790, 51824, 52063, 52091, 52093, 52097, 52104, 52116, 52118, 52131, 52170, 52522, 52523, 52524, 52528, 52531, 52535, 52537, 52579, 52580, 52602, 52631, 52904, 52907, 53056, 53057, 53133, 53347, 53721, 53732, 53735, 53739, 53753, 53754, 53806, 53849, 53854, 53856, 53895, 53910, 53913, 53914, 53936, 53986, 53994, 54126, 54128, 54149, 54199, 54202, 54205, 54211, 54215, 54280, 54331, 54537, 55348, 55902, 55927, 55949, 55952, 55953, 55980, 55981, 56535, 57004, 57014, 57033, 57051, 57072, 57089, 57681, 57714, 58170, 58210, 58211, 58229, 58231, 58234, 58259, 58262, 58275, 58303, 58318, 58321, 58322, 58328, 58337, 58341, 58347, 58363, 58394, 58454, 58461, 58466, 58471, 58473, 58482, 58965, 59049, 59051, 59054, 59075, 59408, 59514, 59527, 59586, 59589, 59603, 59607, 60083, 60136, 60243, 61532, 61540, 61546, 61580, 61605, 61606, 61613, 61619, 61622, 61623, 61678, 61795, 61811, 61812, 61824, 61879, 61881, 61882, 61885, 62435, 62469, 62474, 62479, 62486, 62487, 62489, 62492, 62494, 62499, 62501, 62506, 62525, 62530, 62704, 62785, 62792, 62881, 62882, 62884, 62900, 62906, 62907, 62951, 63046, 63048, 63053, 63063, 63074, 63080, 63090, 63107, 63109, 63117, 63123, 63126, 63141, 63812, 63817, 63821, 63828, 63868, 63923, 63947, 63973, 64177, 64184, 64231, 64255, 64258, 64270, 64272, 64291, 64303, 64422, 64435, 64655, 64656, 64880, 65290, 65300, 65304, 65307, 65313, 65315, 65317, 65319, 65328, 65331, 65382, 65383, 65506, 65689, 66024, 66189, 66396, 66407, 66420, 66535, 66831, 67036, 67647, 69171, 69172, 69197, 69203, 69210, 69212, 69239, 69306, 69361, 69384, 69386, 69464, 69515, 69552, 69954, 70514, 70530, 70533, 70567, 70597, 70615, 70617, 70925, 70929, 70958, 71072, 71082, 71098, 71121, 71139, 71143, 71155, 71158, 71289, 71304, 71678, 71900, 72019, 72482, 72485, 72493, 72502, 72508, 72513, 72514, 72525, 72544, 72588, 73143, 73155, 73308, 73309, 73312, 73338, 73340, 73374, 73375, 73388, 73407, 73424, 73425, 73429, 73433, 73439, 73441, 73442, 73444, 73446, 73458, 73459, 73460, 73461, 73462, 73465, 73541, 73551, 73559, 73565, 73566, 73569, 73570, 73626, 73631, 73652, 73686, 73692, 73693, 73696, 73699, 73700, 73701, 73705, 73954, 74217, 74457, 75885, 75911, 75916, 75958, 75991, 75997, 76324, 76326, 76329, 76364, 76550, 76665, 76689, 76854, 76866, 76868, 76893, 76929, 76936, 76944, 77067, 77141, 77152, 77166, 77173, 77175, 77195, 77219, 77250, 77499, 77505, 77507, 77510, 77608, 77610, 77617, 77648, 78230, 78231, 78232, 78245, 78247, 78253, 78265, 78273, 78290, 78349, 78350, 78364, 78368, 78474, 78484, 78496, 78562, 78565, 78567, 78607, 78611, 78622, 79020, 79031, 79062, 79075, 79126, 79675, 79833, 80680, 80682, 80704, 80705, 80761, 81758, 81789, 82043, 82623, 82658, 82666, 82671, 83232, 83253, 83259, 83261, 83279, 83280, 83281, 83346, 83348, 83358, 83360, 83361, 83362, 83373, 83385, 83426, 83442, 83452, 83459, 83466, 83476, 83503, 83507, 83594, 83604, 83632, 83655, 83657, 83658, 83659, 83661, 84039, 84992, 85055, 85075, 85076, 85077, 85099, 85103, 85153, 85158, 85163, 85238, 85247, 85253, 85259, 85264, 85281, 85285, 85286, 85297, 85298, 85300, 85311, 85341, 85355, 85415, 85456, 85458, 85462, 85817, 85888, 86044, 86138, 86140, 86169, 86171, 86172, 86174, 86178, 86179, 86181, 86190, 86195, 86196, 86333, 86373, 86412, 86433, 86437, 86440, 86508, 86525, 86526, 86527, 86532, 86533, 86537, 86539, 86557, 86815, 87077, 87090, 87091, 87093, 87095, 87103, 87106, 87107, 87119, 87129, 87133, 87137, 87153, 87175, 87176, 87183, 87184, 87185, 87216, 87240, 87252, 87264, 87266, 87269, 87270, 87271, 87274, 87287, 87309, 87329, 87331, 87333, 87339, 87342, 87453, 87462, 87464, 87489, 87513, 87539, 87563, 87891, 87918, 87932, 88086, 88137, 88163, 88333, 88371, 88378, 88716, 88876, 88877, 88880, 88881, 88882, 88894, 88895, 88911, 89302, 89438, 89496, 89499, 89501, 89502, 89506, 89515, 89517, 89532, 89533, 89534, 89536, 89542, 89543, 89544, 89548, 89549, 89552, 89557, 89617, 89633, 89643, 89653, 89713, 89762, 89776, 89787, 89793, 89794, 89812, 89813, 89815, 89817, 89823, 89833, 89848, 89897, 89903, 90534, 90545, 90552, 90553, 90554, 90561, 90622, 90623, 90628, 90638, 90639, 90642, 90649, 90661, 90662, 90675, 90716, 90723, 91388, 91389, 91396, 91429, 91431, 91432, 91437, 91442, 91461, 91469, 91472, 91547, 91729, 91735, 91740, 91764, 91771, 91775, 91795, 91801, 91803, 91806, 91809, 91812, 91829, 91832, 91841, 91843, 91850, 91855, 91860, 91873, 91875, 91878, 91950, 91981, 92050, 92051, 92172, 92220, 92251, 92257, 92266, 92741, 93669, 93672, 93705, 93710, 93982, 94094, 94096, 94619, 94632, 94640, 94984, 95105, 95113, 95182, 95183, 95668, 95675, 95678, 95680, 95715, 95718, 95719, 95722, 95724, 95725, 95730, 95747, 95852, 96027, 96093, 96107, 96115, 96212, 96215, 96216, 96222, 96228, 96234, 96236, 96245, 96287, 96314, 96345, 96365, 96368, 96375, 96378, 96401, 96437, 96462, 96471, 96497, 96501, 96529, 96542, 96654, 96657, 96660, 96666, 96679, 96681, 96682, 96738, 96739, 96747, 96794, 96813, 96814, 96830, 96836, 96845, 96921, 97086, 97124, 97141, 97146, 98416, 99129, 99132, 99137, 99536, 99556, 99573, 99688, 99809, 100107, 100805, 100806, 100807, 100835, 100852, 100858, 100894, 101040, 101119, 101540, 101566, 101837, 102160, 102165, 102166, 102171, 102173, 102178, 102181, 102227, 102503, 102529, 102532, 102538, 102582, 102605, 102608, 102609, 102622, 102624, 102626, 102627, 102632, 102633, 102634, 102635, 102644, 102645, 102647, 102648, 102657, 102706, 102709, 102712, 102716, 102717, 102732, 102735, 102757, 102773, 102774, 102866, 102868, 102869, 102878, 102881, 102885, 103084, 103395, 104504, 104513, 104544, 104713, 104790, 104798, 104806, 104809, 104810, 104813, 104845, 104847, 104895, 104897, 104905, 104924, 104927, 104932, 104945, 104973, 104977, 104986, 105037, 105039, 105128, 105130, 105176, 105252, 105253, 105254, 105256, 105262, 105270, 105344, 105397, 105420, 105424, 105428, 105432, 105442, 105443, 105447, 105577, 105578, 105579, 105593, 105594, 106056, 106057, 106117, 106619, 106634, 106643, 106650, 106667, 106673, 106754, 106874, 106921, 106978, 106992, 107005, 107065, 107066, 107071, 107078, 107086, 107099, 107102, 107108, 107112, 107114, 107115, 107120, 107122, 107130, 107147, 107150, 107167, 107175, 107177, 107186, 107187, 107241, 107242, 107250, 107268, 107278, 107316, 107325, 107326, 107352, 107353, 107886, 107889, 107907, 108065, 108083, 108086, 108101, 108102, 108104, 108110, 108115, 108189, 108226, 108330, 108331, 108345, 108356, 108379, 108382, 108383, 108428, 108430, 108442, 108444, 108447, 108469, 108500, 108504, 108509, 108515, 108532, 108534, 108542, 108726, 108946, 108954, 109122, 109123, 109124, 109184, 109250, 109258, 109260, 109264, 109353, 109549, 109762, 109820, 109870, 109931, 109973, 109975, 109976, 109997, 110126, 110127, 110164, 110169, 110242, 110669, 110676, 110930, 110936, 111005, 111009, 111011, 111021, 111051, 111055, 111065, 111068, 111087, 111098, 111198, 111219, 111221, 111269, 111273, 111414, 111647, 111665, 112046, 112049, 112050, 112081, 112165, 112167, 112177, 112207, 112208, 112232, 112234, 112235, 112246, 112249, 112254, 112257, 112277, 112279, 112328, 112391, 112403, 112414, 112496, 113062, 113118, 113163, 113166, 113613, 114085, 114086, 114105, 114404, 115048, 115174, 115190, 115198, 115289, 115298, 115300, 115303, 115317, 115320, 115322, 115323, 115335, 115338, 115343, 115344, 115345, 115347, 115350, 115352, 115371, 115374, 115409, 115439, 115441, 115454, 115599, 115650, 115656, 115657, 115660, 115674, 115675, 115676, 115829, 115950, 116131, 116658, 116670, 116672, 116808, 117139, 117140, 117164, 117173, 117178, 117213, 117216, 117221, 117224, 117226, 117230, 117262, 117264, 117269, 117284, 117378, 117379, 117380, 117382, 117393, 117444, 117448, 117449, 117541, 117668, 117685, 117782, 117809, 117814, 117816, 117823, 117831, 117839, 117888, 117891, 117895, 117897, 117898, 117902, 117915, 117994, 118182, 118872, 118874, 118883, 118890, 118915, 118919, 118923, 118966, 119627, 119629, 119630, 119634, 119636, 120365, 120391, 120424, 120449, 120451, 120476, 120482, 120484, 120574, 120575, 120588, 120650, 120788, 120803, 120868, 120875, 120889, 120899, 121404, 121419, 121422, 121424, 121426, 121431, 121578, 121720, 121751, 121805, 121807, 122096, 122180, 122192, 122247, 122310, 122709, 122713, 122851, 122865, 122868, 122873, 122875, 122877, 122878, 122881, 122888, 122895, 122896, 122897, 122909, 122910, 122919, 122920, 122979, 123120, 123124, 123125, 123137, 123164, 123165, 123179, 123182, 123183, 123184, 123187, 123194, 123195, 123196, 123197, 123217, 123218, 123220, 123224, 123231, 123238, 123240, 123249, 123295, 123296, 123452, 123995, 124008, 124037, 124098, 124099, 124100, 124101, 124105, 124119, 124122, 124128, 124130, 124146, 124152, 124154, 124163, 124165, 124187, 124197, 124212, 124214, 124216, 124218, 124224, 124229, 124230, 124232, 124325, 124663, 124674, 124676, 125288, 126100, 126126, 127256, 127297, 127306, 127999, 128309, 128326, 128624, 128628, 128678, 128679, 128740, 128813, 128834, 128883, 128886, 128887, 128910, 128912, 128943, 128953, 128955, 128956, 128961, 128969, 129604, 130443, 130495, 130500, 130542, 130609, 130755, 131447, 131536, 131563, 131618, 131640, 132197, 132205, 132219, 132224, 132233, 132241, 132260, 132267, 132274, 132276, 132288, 132295, 132367, 132607, 132622, 132624, 132729, 132743, 132800, 132834, 132835, 132837, 132845, 132846, 132852, 133021, 133038, 133040, 133043, 133051, 133052, 133055, 133057, 133067, 133073, 133074, 133076, 133085, 133086, 133088, 133140, 133151, 133242, 133427, 133502, 133670, 133684, 133693, 133984, 134014, 134103, 134104, 134240, 134372, 134498, 134505, 134513, 134534, 134541, 134544, 134550, 134589, 134769, 134779, 134783, 134859, 134965, 134967, 134986, 135015, 135049, 135238, 135239, 135323, 135647, 135648, 135657, 135675, 135693, 135706, 135729, 135895, 136054, 136187, 136189, 136206, 136644, 136646, 136676, 136746, 136765, 136766, 136769, 136774, 136775, 136975, 137067, 137098, 137099, 137130, 137132, 137139, 137453, 137455, 137462, 137483, 137496, 137825, 137949, 137982, 137984, 137995, 138022, 138026, 138028, 138044, 138047, 138048, 138106, 138108, 138113, 138134, 138135, 138136, 138139, 138140, 138147, 138148, 138162, 138166, 138425, 139222, 139699, 139900, 139905, 139917, 139927, 139954, 139957, 141297, 141310, 141564, 141565, 141603, 141605, 141606, 141647, 141649, 141668, 141756, 141758, 141853, 141861, 141868, 141878, 141880, 141882, 141974, 141975, 141977, 142060, 142115, 142117, 142133, 142145, 142411, 142420, 142441, 142465, 142473, 142478, 142499, 142530, 143092, 143149, 143150, 143151, 143153, 143155, 143180, 143184, 143489, 143975, 143976, 144020, 144026, 144028, 144030, 144058, 144061, 144063, 144071, 144072, 144089, 144092, 144142, 144144, 144155, 144158, 144165, 144187, 144188, 144338, 144343, 144355, 144357, 144364, 144539, 145398, 145828, 145829, 145976, 146280, 146313, 146315, 146317, 146326, 146371, 146378, 146379, 146381, 146392, 146453, 146513, 146518, 146522, 146532, 146535, 146543, 146544, 146549, 146550, 146552, 146555, 146556, 146568, 146571, 146862, 146864, 146867, 146873, 146876, 146886, 146890, 147034, 147145, 147154, 147235, 147238, 147255, 147256, 147259, 147264, 147270, 147275, 147283, 147287, 147289, 147291, 147321]), ('reinforcement', [3372, 3373, 3376, 3380, 3383, 19716, 19735, 19802, 20214, 20217, 20221, 20226, 20233, 20240, 20245, 20248, 20253, 20254, 20258, 20261, 20343, 20345, 20605, 20655, 21216, 21217, 21259, 21260, 21262, 21269, 21271, 21273, 21279, 21310, 21314, 21359, 21360, 21362, 21363, 21394, 21396, 21397, 21398, 21399, 21400, 21402, 21403, 21405, 21428, 21456, 21496, 21511, 21518, 21526, 21531, 21533, 21534, 21569, 21570, 21586, 21588, 21593, 21614, 21621, 21622, 21623, 21627, 21628, 21649, 21650, 21651, 21653, 21730, 21748, 21756, 21778, 21824, 26319, 26321, 26328, 26653, 26654, 26658, 26719, 51729, 51737, 51770, 58634, 58635, 58768, 58769, 58779, 58801, 58802, 58812, 58859, 58869, 58970, 58982, 58994, 60811, 60815, 60823, 60828, 60830, 60832, 60840, 60843, 60846, 60856, 70014, 92389, 92411, 92482, 92483, 97075, 109822, 109838, 109843, 109844, 109968, 109972, 109974, 109976, 110133, 110165, 111655, 117539, 117541, 117815, 117936, 119705, 119714, 119715, 119719, 119722, 119732, 119733, 119742, 119750, 119765, 119802, 119819, 119825, 119853, 120170, 120344, 120345, 120357, 120365, 120372, 120374]), ('gradient', [703, 704, 788, 855, 875, 877, 1082, 1083, 3675, 3788, 3799, 3903, 3909, 3981, 3986, 4133, 4179, 4180, 4182, 4313, 4405, 8527, 8536, 8564, 10178, 10205, 10703, 10720, 10722, 10723, 10741, 10782, 10846, 10859, 10880, 10881, 10882, 10890, 11088, 11803, 12018, 12030, 13158, 14439, 15391, 16733, 16774, 16868, 16943, 16994, 17013, 17019, 17025, 17084, 17250, 19792, 19797, 20221, 21878, 21881, 21927, 22055, 22089, 22094, 22126, 22212, 22252, 22257, 23162, 23219, 23223, 23267, 23285, 23304, 23330, 23334, 23339, 26472, 28629, 28746, 28829, 28832, 30011, 30035, 30052, 30053, 30056, 30267, 30430, 32208, 32212, 32213, 32227, 32265, 32268, 32406, 32497, 32522, 32535, 32549, 32577, 35169, 37714, 37725, 37770, 37820, 37821, 37823, 37827, 37832, 37834, 37835, 37844, 37873, 37875, 37880, 37981, 38000, 38053, 41003, 41005, 41055, 41239, 41323, 41329, 41359, 41888, 42088, 45573, 46692, 46756, 49237, 49270, 49273, 49292, 51022, 52209, 52211, 52212, 52220, 52222, 52282, 52283, 52289, 52391, 52397, 53166, 54179, 54185, 54331, 54332, 54377, 54422, 54432, 54601, 58752, 58754, 59077, 59169, 59314, 59608, 60856, 60907, 60918, 60965, 61008, 61009, 61014, 61017, 61020, 61026, 61027, 61053, 61054, 61056, 61122, 61127, 61137, 61140, 61146, 61147, 61561, 61999, 64181, 64690, 66268, 66293, 66333, 66901, 67252, 67255, 67257, 67258, 67263, 67341, 67373, 67641, 67686, 67818, 67944, 68021, 68595, 69497, 69498, 69536, 71212, 71614, 71657, 71658, 73838, 74083, 74501, 79384, 79867, 79889, 79917, 80203, 80209, 83150, 85910, 85912, 85920, 87972, 90891, 90932, 90960, 90976, 91024, 91213, 91254, 91282, 91298, 91346, 93286, 95167, 95983, 96002, 97264, 97281, 97294, 97297, 97302, 97317, 97318, 97320, 97387, 97390, 97402, 97416, 97429, 97440, 97453, 97754, 100279, 101445, 101707, 101944, 102733, 102883, 103159, 103160, 103161, 104223, 104228, 104511, 104539, 104844, 104919, 104926, 105220, 108420, 109537, 110011, 110013, 110014, 112081, 112083, 113171, 113235, 113236, 113297, 114207, 114278, 114365, 116521, 117541, 117660, 117879, 118058, 119387, 122250, 122252, 122265, 122270, 122272, 122273, 122278, 122413, 122459, 122550, 122577, 122641, 122654, 122680, 122692, 122705, 122716, 122734, 122735, 122785, 122980, 123485, 123820, 123916, 123924, 126090, 126177, 126346, 126385, 126387, 126390, 126391, 128363, 129131, 129140, 129778, 129944, 130473, 130485, 130604, 131081, 131117, 131215, 131235, 132344, 132739, 132835, 134373, 135924, 136025, 136903, 136937, 136939, 137744, 137962, 138482, 139306, 139309, 140541, 140551, 140557, 140708, 140927, 140944, 140947, 142595, 142624, 142635, 143143, 143214, 143319, 143787, 143796, 143829, 145016, 145207, 145404, 145520, 146519]), ('learning', [16, 19, 20, 21, 24, 30, 32, 35, 39, 40, 69, 93, 266, 276, 434, 436, 547, 628, 629, 638, 749, 1179, 1191, 2046, 2132, 2146, 2147, 2159, 2373, 2382, 2445, 2448, 2450, 2567, 2576, 2578, 2585, 3370, 3660, 3673, 3677, 3715, 3785, 3799, 3800, 3852, 3854, 3888, 3890, 3927, 4057, 4064, 4167, 4174, 4857, 4875, 5015, 5020, 5049, 5055, 5056, 5058, 5060, 5061, 5063, 5065, 5073, 5074, 5366, 5394, 6281, 6319, 6697, 6698, 6707, 6713, 6714, 6715, 6797, 6804, 6810, 6811, 6818, 6821, 6832, 6838, 6840, 6858, 7606, 7653, 8654, 8681, 9055, 9119, 10072, 10573, 10587, 10703, 10903, 10936, 10943, 11089, 11234, 11644, 11651, 11803, 11909, 12021, 12030, 12252, 13074, 13154, 14096, 14104, 14106, 14119, 14126, 14129, 14290, 14688, 14695, 15033, 15118, 15398, 15402, 15890, 15950, 15971, 16016, 16055, 16211, 16240, 16244, 16250, 16264, 17165, 17277, 17299, 17423, 17425, 17426, 17446, 17448, 18897, 19692, 19709, 19713, 19714, 19716, 19717, 19720, 19733, 19735, 19737, 19776, 19790, 19792, 19799, 19802, 19803, 19805, 19806, 19814, 19819, 19822, 19826, 19894, 19895, 19989, 20169, 20175, 20196, 20208, 20209, 20214, 20218, 20220, 20222, 20240, 20242, 20262, 20267, 20269, 20343, 20345, 20346, 20351, 20353, 20359, 20363, 20450, 20594, 20596, 20597, 20599, 20605, 20619, 20622, 20626, 20629, 20644, 20655, 21228, 21230, 21256, 21277, 21293, 21401, 21515, 21692, 21749, 21755, 21795, 21827, 21828, 21870, 21871, 21873, 21881, 21930, 21973, 22008, 22026, 22090, 22103, 22121, 22129, 22134, 22153, 22155, 22162, 22177, 22196, 22208, 22211, 22222, 22230, 22248, 22253, 22260, 22359, 23147, 23149, 23152, 23154, 23156, 23158, 23163, 23165, 23168, 23217, 23220, 23234, 23284, 23307, 23329, 23331, 23341, 23358, 23376, 23380, 23386, 23388, 23389, 23391, 23393, 23395, 23397, 23398, 23403, 23404, 23409, 23412, 23419, 23552, 23553, 23554, 23559, 23563, 23565, 23567, 23570, 23629, 23630, 23641, 23646, 23650, 23653, 23717, 23731, 23732, 23740, 23815, 23816, 23817, 23824, 23825, 23923, 23926, 23942, 23945, 24448, 24457, 25544, 25545, 25661, 25693, 25703, 25711, 25909, 26016, 26028, 26047, 26082, 26102, 26312, 26315, 26317, 26318, 26319, 26324, 26326, 26328, 26333, 26342, 26343, 26362, 26377, 26402, 26404, 26419, 26425, 26434, 26443, 26446, 26465, 26473, 26508, 26514, 26525, 26575, 26580, 26607, 26609, 26685, 26689, 26751, 26752, 26756, 26757, 26758, 26760, 26761, 26763, 26764, 26771, 26792, 26796, 26858, 28033, 28036, 28041, 28048, 28049, 28055, 28057, 28058, 28066, 28067, 28069, 28079, 28266, 28278, 28280, 28308, 28314, 28533, 28546, 28559, 28560, 28561, 28563, 28570, 28594, 28596, 28597, 28605, 28627, 28633, 28634, 28643, 28654, 28663, 28792, 28893, 29727, 29980, 30129, 30308, 32701, 32703, 32706, 32724, 32730, 32788, 32810, 34540, 34543, 34679, 34695, 34897, 34911, 34923, 34925, 34928, 34952, 34969, 34970, 35071, 35108, 35122, 35145, 35150, 35153, 35177, 35225, 35548, 35553, 35702, 35862, 35911, 36402, 36572, 36575, 36581, 36585, 36587, 36596, 36617, 36624, 36626, 37448, 37510, 37554, 37872, 38106, 38129, 38193, 38238, 38254, 38305, 38427, 38439, 38458, 38904, 38908, 38914, 39489, 39645, 39651, 39938, 39939, 39940, 39942, 41973, 41982, 41986, 42083, 42087, 42146, 42147, 42213, 42249, 42298, 42447, 42453, 42461, 42462, 42468, 42475, 42484, 42487, 42543, 42549, 42552, 43686, 43698, 43719, 43726, 43739, 43779, 43840, 43849, 43850, 43898, 43909, 43910, 43915, 43919, 43949, 43966, 43967, 44407, 44425, 44426, 44442, 44456, 44467, 44468, 44474, 44494, 44498, 44515, 44519, 44533, 44608, 44623, 44633, 44663, 44680, 44681, 44685, 44704, 44730, 44733, 44737, 44739, 44743, 44744, 44753, 44755, 44760, 44812, 44985, 45003, 45005, 45015, 45021, 45026, 45028, 45078, 45121, 45287, 45292, 45331, 45372, 45376, 45393, 45714, 45744, 45749, 45753, 45755, 45773, 45781, 45788, 45789, 45847, 45865, 45873, 45877, 45943, 46043, 46050, 46229, 46238, 46253, 46263, 46271, 46274, 46290, 46362, 46811, 46888, 47007, 47156, 47264, 47265, 47405, 49076, 49848, 49860, 49919, 50075, 50111, 50466, 50467, 50469, 51728, 51729, 51730, 51731, 51732, 51734, 51755, 51756, 51758, 51764, 51765, 51766, 51767, 51768, 51769, 51783, 51785, 51817, 51818, 51836, 51864, 51865, 51885, 51900, 51901, 51904, 51910, 51926, 51956, 51957, 51961, 51962, 51984, 52110, 52111, 52126, 52134, 52171, 52172, 52176, 52190, 53703, 53795, 54318, 54377, 54378, 54422, 54460, 54482, 54535, 54696, 55024, 55072, 55091, 55098, 55142, 55235, 55307, 55329, 55426, 56966, 57051, 57072, 57080, 57088, 57089, 57094, 57095, 57099, 57198, 57202, 57299, 57346, 57348, 57349, 57350, 57353, 57356, 57449, 57502, 57503, 57506, 57507, 57508, 57767, 57771, 58141, 58200, 58202, 58477, 58645, 58655, 58658, 58783, 58815, 58903, 58915, 59004, 59011, 59031, 59032, 59042, 59043, 59047, 59057, 59074, 59075, 59076, 59094, 59098, 59100, 59183, 59302, 59308, 59316, 59407, 59409, 59533, 59542, 59605, 59608, 59609, 59641, 59676, 59679, 59683, 59691, 59693, 59694, 60027, 60030, 60075, 60078, 60082, 60083, 60090, 60092, 60103, 60233, 60243, 60301, 60310, 60323, 60324, 60328, 60412, 60415, 60545, 60546, 60553, 60578, 60648, 60655, 60656, 60657, 60672, 60674, 60685, 60689, 60690, 60703, 60716, 60721, 60724, 60739, 60760, 60761, 60774, 60778, 60781, 60795, 60823, 60828, 60830, 61019, 61046, 61048, 61049, 61150, 61157, 61159, 61256, 61492, 61502, 61504, 61537, 61540, 61550, 61552, 61558, 61560, 61687, 61745, 61919, 61942, 61944, 62006, 62007, 62009, 62010, 62018, 62037, 62039, 62053, 62073, 62084, 62095, 62149, 62151, 62158, 62252, 62365, 62367, 62376, 62391, 62401, 63142, 64668, 64783, 64785, 65292, 65294, 65439, 65443, 65469, 65490, 65513, 65518, 65519, 65521, 65523, 65529, 65697, 65753, 65975, 65993, 66806, 66901, 66939, 67114, 67116, 67231, 67342, 67371, 67383, 67384, 67985, 67986, 68003, 68010, 68012, 68026, 68319, 68442, 68451, 68457, 68486, 68515, 68530, 68547, 68600, 68646, 68659, 68734, 68736, 68741, 68767, 68841, 68844, 68866, 68868, 68873, 68874, 68879, 68963, 68964, 68965, 69025, 69027, 69040, 69041, 69042, 69052, 69053, 69060, 69107, 69118, 69119, 69130, 69132, 69144, 69444, 69454, 69516, 69626, 69632, 69867, 69871, 69886, 69985, 69993, 70012, 70015, 70455, 70459, 70460, 70482, 71120, 71142, 71143, 71146, 71174, 71433, 71437, 71614, 71681, 71869, 71880, 71883, 71928, 71930, 71932, 71968, 72002, 72006, 72010, 72019, 72028, 72040, 72219, 72245, 72250, 72253, 72362, 72364, 72370, 72415, 72419, 72421, 72422, 72423, 72473, 72492, 73171, 73176, 73279, 74796, 75035, 75090, 75092, 75094, 75158, 75206, 75210, 75211, 75238, 75504, 75864, 75866, 75869, 76343, 76888, 76912, 76915, 76936, 77064, 77096, 77597, 77598, 77729, 77752, 77758, 77761, 77867, 77946, 77947, 77948, 78016, 78020, 78155, 78169, 78230, 78243, 78244, 78250, 78251, 78252, 78279, 78282, 78313, 78335, 80084, 80087, 80088, 80094, 80110, 80157, 80205, 80207, 80209, 80215, 80216, 80217, 80218, 80233, 80280, 80281, 80284, 80508, 80542, 80543, 80548, 80619, 80621, 80624, 80648, 80655, 80708, 80757, 81173, 81655, 81656, 82099, 82130, 82141, 82373, 82473, 82488, 82497, 82529, 82555, 82565, 82609, 83154, 83159, 83161, 83164, 83212, 84022, 84028, 84030, 84039, 84059, 84198, 84519, 84543, 84707, 84912, 84933, 85346, 85348, 85438, 85441, 85750, 85751, 85754, 85780, 85781, 86620, 86633, 86672, 86673, 86675, 86679, 86681, 86684, 86691, 86697, 86702, 86711, 86714, 86716, 86718, 86719, 86720, 86723, 86799, 86802, 86803, 87018, 87920, 87926, 87949, 87963, 88252, 88254, 88302, 88330, 88373, 88375, 88404, 88899, 89044, 89296, 89496, 89503, 89508, 89509, 89515, 89530, 89532, 89536, 89537, 89539, 89546, 89557, 89564, 89567, 89569, 89611, 89614, 89618, 89628, 89632, 89650, 89709, 89710, 89786, 89793, 89797, 89813, 89815, 89817, 89822, 89828, 89834, 89891, 90540, 90608, 90695, 90738, 90747, 90933, 90937, 90950, 91012, 91019, 91025, 91060, 91069, 91255, 91259, 91272, 91334, 91341, 91347, 91774, 92322, 92323, 92337, 92340, 92361, 92368, 92369, 92376, 92377, 92405, 92631, 92638, 93621, 93629, 94277, 94416, 94627, 94637, 94640, 94641, 95104, 95112, 95114, 95141, 95164, 95170, 95179, 95193, 95195, 95208, 95329, 95333, 95334, 95532, 95684, 95875, 95969, 95990, 96004, 96036, 96100, 96105, 96109, 96145, 96151, 96160, 96205, 96211, 96213, 96239, 96246, 96363, 96380, 96646, 96675, 96678, 96687, 96711, 96730, 96734, 96736, 97184, 97187, 97189, 97193, 97200, 97225, 97250, 97258, 97259, 97299, 97319, 97373, 97380, 97415, 97430, 97433, 97453, 97472, 97626, 97629, 97755, 97778, 97791, 97908, 97919, 97920, 98267, 98367, 98392, 98400, 98448, 98456, 98698, 99052, 99077, 99083, 99091, 99092, 99112, 99164, 99207, 99211, 99219, 99262, 99269, 99540, 100178, 100194, 100446, 100791, 100793, 100796, 100807, 100810, 100820, 100821, 100827, 100830, 100835, 100856, 100888, 100895, 100928, 100931, 100936, 100947, 100948, 100982, 100986, 100987, 101019, 101028, 101033, 101040, 101044, 101055, 101065, 101074, 101085, 101086, 101087, 101099, 101104, 101142, 101144, 101520, 101559, 101636, 101725, 101764, 101767, 101792, 101826, 101828, 101838, 101851, 101874, 101876, 101878, 101884, 101892, 101903, 101913, 101914, 101922, 101941, 101942, 101972, 101974, 101980, 101983, 102037, 102061, 102064, 102572, 102582, 102606, 102613, 102620, 102745, 102749, 102754, 102865, 102868, 102875, 103158, 103397, 103489, 103806, 103813, 103844, 104005, 104077, 104102, 104108, 104111, 105337, 105338, 105390, 105393, 105394, 106055, 106062, 106082, 106108, 106625, 106784, 107010, 107108, 108283, 108455, 108458, 108461, 108502, 109430, 109819, 109822, 109823, 109834, 109836, 109838, 109843, 109846, 109847, 109854, 109860, 109870, 109972, 109974, 109976, 110003, 110016, 110031, 110071, 110090, 110131, 110133, 110144, 110156, 110163, 110198, 110204, 112057, 112084, 112090, 112140, 112418, 112478, 112498, 112500, 112503, 112520, 112523, 112525, 112526, 112534, 112537, 112542, 112547, 112548, 112549, 112556, 112568, 112570, 112579, 112603, 112609, 112610, 112612, 112645, 112809, 112827, 112835, 112844, 112854, 112900, 112927, 113034, 113039, 113063, 113079, 113093, 113098, 113108, 113234, 113278, 113368, 113534, 113599, 113605, 113613, 113650, 113662, 113714, 113743, 113752, 113755, 113863, 113865, 114031, 114126, 114161, 114162, 114167, 114174, 114190, 114201, 114241, 114243, 114271, 114278, 114367, 114368, 114415, 114452, 114455, 114464, 114465, 114469, 114501, 114503, 114543, 114547, 114566, 114568, 114570, 114575, 114802, 114803, 114809, 114823, 114834, 114862, 114892, 114939, 114950, 114962, 114965, 115044, 115088, 115145, 115146, 115189, 115209, 115219, 115298, 115319, 115323, 115454, 115898, 115935, 115995, 115996, 115997, 116016, 116094, 116112, 116115, 116187, 117107, 117108, 117109, 117120, 117212, 117218, 117227, 117254, 117261, 117272, 117278, 117338, 117357, 117364, 117366, 117387, 117409, 117433, 117438, 117449, 117450, 117465, 117487, 117507, 117534, 117550, 117558, 117564, 117577, 117783, 117793, 117808, 117831, 117868, 117904, 117914, 117923, 117939, 118447, 118459, 118461, 118462, 118470, 118473, 118532, 118541, 118542, 118564, 118584, 118593, 118596, 118601, 118623, 118637, 118687, 118688, 118703, 118711, 118792, 118811, 118814, 118876, 119190, 119251, 119264, 119269, 119301, 119332, 119334, 119335, 119497, 119583, 119590, 119598, 119615, 119620, 119623, 119628, 119629, 119706, 119714, 119715, 119729, 119730, 119731, 119732, 119734, 119742, 119771, 119834, 120170, 120343, 120344, 120346, 120348, 120349, 120358, 120362, 120369, 120372, 120374, 120395, 120424, 120431, 120432, 120439, 120469, 120573, 120729, 120770, 120889, 120918, 120922, 120925, 121098, 121151, 121443, 121768, 122095, 122267, 122268, 122285, 122413, 122666, 122668, 122708, 122711, 122731, 122785, 122786, 122787, 122788, 122828, 122830, 122851, 122855, 122862, 122877, 122880, 122881, 122882, 122895, 122980, 123004, 123110, 123112, 123124, 123137, 123197, 123210, 123220, 123223, 123238, 123248, 123249, 123250, 123252, 123352, 123354, 123356, 123358, 123360, 123386, 123397, 123478, 123483, 123485, 123493, 123506, 123643, 123649, 123651, 123658, 123671, 123687, 123815, 123820, 123913, 123916, 123953, 123963, 123987, 124387, 124665, 124672, 124677, 125830, 125835, 125837, 127496, 127499, 127503, 127507, 127510, 127524, 127528, 127574, 127604, 127615, 127825, 127849, 127884, 127894, 127904, 127925, 127945, 127997, 128312, 128330, 128468, 128657, 128677, 128687, 128688, 128691, 128954, 128978, 129012, 129039, 129577, 129593, 129604, 129622, 129624, 129625, 129634, 129637, 129640, 129645, 129655, 129686, 129687, 129690, 129691, 129699, 129700, 129834, 129943, 129963, 129964, 129984, 129985, 129987, 129994, 129996, 130039, 130041, 130043, 130062, 130074, 130084, 130103, 130131, 130219, 130296, 130297, 130406, 130408, 130443, 130447, 130471, 130473, 130482, 130484, 130542, 130543, 130660, 130719, 130749, 131020, 131092, 131098, 131197, 131205, 131209, 131216, 131222, 131234, 131251, 131444, 131445, 131446, 131449, 131457, 131458, 131471, 131486, 131539, 131603, 131626, 131628, 131632, 131635, 131640, 131927, 131928, 131932, 131933, 132099, 132141, 132259, 132302, 132303, 132377, 133495, 133499, 133507, 133523, 133526, 133541, 133542, 133697, 133786, 133870, 133948, 133949, 133994, 134014, 134033, 134061, 134062, 134103, 134104, 134108, 134116, 134240, 134252, 134371, 134373, 134374, 134375, 134441, 134446, 134513, 134988, 135053, 135061, 135606, 135607, 136733, 136739, 136834, 136866, 136902, 137020, 137062, 137522, 137813, 137912, 138139, 138146, 138404, 139659, 140373, 140496, 140528, 140540, 140542, 140543, 140551, 140554, 140559, 140621, 140648, 140649, 140692, 140718, 140816, 140848, 140854, 140913, 140927, 140944, 140945, 140947, 140959, 140962, 140963, 141078, 141764, 141878, 142074, 142081, 142352, 142357, 142366, 142444, 142498, 142500, 142501, 142508, 142568, 142595, 142623, 142626, 142629, 142631, 142643, 142651, 142654, 142657, 142690, 142703, 142770, 143094, 143143, 143150, 143161, 143162, 143164, 143171, 143201, 143218, 143223, 143233, 143270, 143319, 143384, 143385, 143386, 143415, 143457, 143492, 143500, 143606, 143952, 144545, 144620, 144889, 144895, 144898, 145315, 145324, 145331, 145372, 145816, 145822, 145956, 145975, 146031, 146335, 146370, 146378, 146382, 146400, 146502, 146530, 146532, 146617, 146619, 146712, 146815, 146824]), ('machine learning', [19826, 23149, 23237, 28594, 47156, 51755, 92320, 92323, 92337, 92363, 92405, 110156, 129634, 134371]), ('gaussian', [10904, 10915, 10916, 10925, 12481, 24138, 49990, 51837, 57684, 57696, 57714, 61015, 64828, 64875, 65213, 74328, 74480, 76653, 83596, 91507, 91586, 91588, 100881, 100885, 100907, 105637, 106092, 106214, 106291, 110234, 110236, 110238, 112046, 112146, 112166, 112178, 112182, 112196, 112202, 112203, 112204, 112206, 112207, 112209, 112225, 112231, 112257, 112285, 112321, 112370, 112373, 112408, 112424, 112455, 117565, 117601, 117633, 117676, 117680, 117682, 117763, 117766, 117767, 117779, 117782, 117785, 117808, 117816, 117819, 133053, 133843, 134052, 135743, 137127, 146190])])\n",
            "The index_t2 are  OrderedDict([('markov', [60350, 68801, 87298, 165025, 165028, 169014, 206019]), ('supervised', [405, 449, 1003, 3753, 3824, 6428, 14305, 18175, 19287, 24070, 26645, 27143, 27901, 27902, 28116, 28120, 28125, 28129, 28145, 28189, 28234, 28256, 28296, 28329, 28364, 28375, 28450, 28578, 28580, 28639, 28670, 32254, 32892, 34027, 34057, 37098, 37101, 37118, 37147, 37149, 37152, 38214, 38226, 38646, 38655, 42197, 45082, 45089, 45577, 45741, 45753, 47661, 53583, 53694, 56410, 63222, 63300, 64014, 64312, 64376, 64407, 64988, 69037, 69090, 70405, 70406, 70504, 70531, 70540, 70542, 70551, 70722, 71381, 77575, 77618, 77650, 77724, 77817, 77918, 77962, 77966, 77973, 77975, 78377, 84339, 84376, 84388, 84534, 84739, 84772, 85265, 85355, 85367, 85399, 85759, 87407, 87974, 87990, 88245, 88265, 90834, 90984, 91015, 91093, 91180, 91729, 92857, 92859, 93047, 93121, 98408, 99900, 101838, 101839, 102171, 102224, 102226, 102229, 102268, 102271, 102278, 102279, 102288, 102290, 102292, 102294, 102301, 102333, 102338, 102429, 102436, 102437, 102444, 102460, 102471, 102483, 102572, 102650, 102655, 102657, 102659, 102660, 102672, 102676, 107842, 107845, 107888, 107907, 108033, 108213, 110698, 111774, 111806, 111826, 112123, 112249, 113366, 115033, 115045, 115054, 115060, 115071, 115092, 115097, 115150, 115157, 115219, 115352, 115366, 120969, 123927, 125458, 125490, 125497, 125500, 125558, 125772, 125776, 129453, 134315, 135443, 137392, 137444, 137519, 141762, 141787, 142179, 146130, 146181, 146184, 146552, 146611, 146626, 146639, 147072, 156025, 156072, 156145, 156239, 156242, 156254, 156259, 170484, 174260, 175886, 176257, 176262, 180299, 180671, 182009, 184976, 184997, 184998, 185087, 189621, 189630, 190848, 190849, 190860, 191157, 192121, 192205, 192883, 192884, 192978, 193135, 194086, 194096, 194109, 194666, 194667, 194690, 194722, 194753, 194844, 194896, 194898, 195149, 195204, 195418, 195829, 198289, 203603, 203634, 203714, 203846, 203900, 203935, 204049, 206676, 206677, 206750, 206751, 206754, 206782, 206785, 207327, 207328, 207371, 207572, 208870, 209092]), ('gradient descent', [3546, 3676, 3793, 3818, 7150, 7157, 7226, 7236, 7342, 8182, 8186, 8258, 10412, 17187, 19740, 20488, 21346, 22187, 23749, 25814, 26445, 26595, 26605, 26607, 26617, 26620, 26622, 26653, 26770, 26791, 26798, 26823, 28256, 32364, 32395, 33176, 33182, 33680, 34109, 34168, 34283, 38264, 38586, 38609, 39252, 39310, 39324, 39680, 42300, 42353, 42505, 44658, 45782, 48753, 52496, 52524, 52772, 53114, 54691, 54692, 54727, 54733, 54746, 54752, 54759, 54809, 55032, 55046, 60844, 60878, 60928, 61105, 61213, 63869, 65024, 65548, 65550, 65563, 69102, 73843, 73846, 74919, 74991, 75024, 75265, 75299, 76729, 76731, 76744, 78037, 78066, 78075, 78091, 78139, 80169, 80324, 80583, 81373, 82618, 83523, 83535, 86752, 87024, 87087, 87965, 90877, 92858, 96978, 99019, 99091, 102482, 102565, 111979, 111982, 112002, 113916, 113923, 113937, 113939, 113950, 114103, 119159, 120298, 123485, 124470, 126953, 129363, 129372, 129390, 129391, 129420, 129663, 131701, 131770, 131783, 131784, 131787, 131808, 131830, 132391, 132444, 132473, 132510, 132517, 132839, 140805, 144339, 148145, 156464, 156468, 156844, 158241, 158696, 164035, 164123, 164129, 164231, 165247, 167863, 168830, 171109, 171746, 176828, 177006, 177210, 177417, 177432, 177569, 177865, 177872, 182027, 182109, 182113, 182139, 182160, 182162, 182164, 182199, 182220, 182250, 182251, 182374, 182407, 182414, 182433, 182455, 182457, 182458, 186564, 186621, 187625, 187653, 188404, 188413, 188435, 189119, 190868, 191305, 193574, 194633, 195127, 197700, 197711, 197737, 197851, 197955, 198096, 201509, 201541, 201542, 201578, 201587, 201666, 201768, 201927, 201935, 201943, 201959, 204507, 204519, 204888, 207323, 207573, 207592, 207630, 207666, 208579, 208869, 208943, 209972, 210414]), ('supervised learning', [405, 449, 1003, 3765, 6428, 14305, 24070, 28296, 28639, 28670, 34027, 34057, 37118, 38646, 38655, 42197, 45577, 45741, 45753, 53583, 53694, 56410, 63222, 63300, 64407, 69037, 69090, 70387, 70399, 70405, 70504, 70551, 78377, 84339, 84376, 84388, 84534, 84739, 84772, 85265, 85355, 85399, 87407, 88245, 90834, 91015, 91093, 98408, 101839, 102171, 102224, 102229, 102268, 102278, 102288, 102290, 102292, 102294, 102301, 102324, 102338, 102436, 102444, 102471, 102483, 102572, 102650, 102655, 102657, 102659, 102660, 102672, 102676, 107842, 107888, 107907, 110693, 112123, 112249, 115092, 120969, 125776, 129453, 134315, 137444, 137519, 141762, 146130, 146184, 146552, 146611, 174260, 182009, 189630, 190848, 190849, 190860, 191157, 192205, 194086, 194096, 194666, 194844, 194898, 195204, 195418, 195829, 198289, 203634, 206667, 206677, 206751, 206754, 206785, 207328, 207353, 207371, 207572, 208870, 209092]), ('neural network', [10, 30, 45, 59, 78, 115, 191, 290, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2870, 3429, 3433, 3456, 3824, 4189, 4200, 4217, 4361, 4369, 4444, 6398, 6413, 6457, 7563, 7577, 7590, 7836, 8231, 8245, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9368, 9388, 9434, 9444, 9495, 9511, 9567, 9570, 9967, 10287, 11498, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12801, 12825, 13163, 13832, 13858, 15539, 15579, 15854, 15888, 16016, 16318, 16345, 16352, 16395, 16581, 16584, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17254, 17324, 17414, 17447, 17525, 18031, 18060, 18489, 18554, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20653, 20718, 20983, 21026, 21035, 21457, 21552, 21560, 21604, 21834, 22153, 22161, 22164, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24025, 25091, 25124, 26169, 26179, 27051, 27065, 27067, 27119, 27297, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28313, 28634, 28773, 29016, 29039, 29442, 29488, 29543, 29551, 29556, 29991, 30005, 30028, 30345, 30378, 30382, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30891, 30895, 30981, 31020, 31024, 31028, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 34034, 34040, 34602, 34633, 34634, 34653, 34676, 35319, 35320, 35341, 37098, 37112, 37188, 37469, 37485, 37523, 37790, 37803, 37824, 37825, 37838, 37840, 37841, 38138, 38144, 38149, 38150, 38162, 38167, 38655, 39238, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43744, 43775, 43795, 44125, 44547, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45722, 45753, 47250, 47411, 47661, 48067, 48172, 48183, 48186, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49046, 49056, 49078, 49091, 49559, 50392, 50395, 50399, 50415, 50432, 50539, 50691, 50694, 50696, 50706, 50767, 50775, 50777, 50848, 50931, 51206, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53149, 53173, 53182, 53361, 53680, 53741, 53743, 53753, 53798, 53849, 54067, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54362, 54606, 54610, 54649, 54661, 54664, 55075, 55101, 55102, 55103, 55108, 55122, 55964, 56080, 57356, 57364, 57380, 57391, 57438, 57768, 57792, 58127, 58129, 58131, 58136, 58144, 58148, 58149, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58577, 58581, 58589, 58633, 58852, 59088, 59090, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63091, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63283, 63315, 63373, 63392, 63416, 63423, 63442, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64866, 64876, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 67789, 67803, 67867, 68319, 68793, 68809, 69930, 70021, 70200, 70255, 70386, 70398, 70405, 70707, 70994, 71891, 72405, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73248, 73301, 73303, 73305, 73332, 73335, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 75069, 75853, 75905, 75929, 77962, 77966, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80450, 80466, 80488, 81117, 81123, 81132, 81859, 81870, 82303, 82309, 82747, 82749, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87704, 87774, 87950, 88015, 88066, 88254, 88277, 88278, 88283, 88325, 88355, 88376, 89187, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89662, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91170, 91358, 91748, 91777, 91781, 92363, 92395, 92397, 92421, 96250, 96275, 96278, 96284, 96295, 96497, 96528, 96541, 96758, 96759, 96834, 96842, 96848, 96852, 96904, 96913, 96926, 97120, 97129, 97224, 97235, 97236, 97239, 97241, 97307, 97310, 97415, 97416, 97440, 97493, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98850, 98866, 98878, 98883, 99302, 99330, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101084, 101085, 101091, 101166, 101641, 101657, 101839, 102171, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103529, 103616, 103862, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 106017, 106327, 106328, 106337, 106340, 106455, 106489, 106546, 106797, 106834, 106840, 106899, 107588, 107592, 107595, 107596, 107629, 107632, 107669, 107671, 107720, 107723, 107744, 107749, 107769, 108237, 109776, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111720, 112221, 112250, 112264, 112278, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117857, 119375, 119379, 119473, 119500, 119503, 119505, 119927, 119981, 119983, 120002, 120416, 120967, 120980, 121014, 121135, 121664, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124739, 124741, 124909, 124913, 125008, 125009, 125011, 125435, 125467, 125775, 125844, 125847, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126831, 126834, 126838, 126851, 126866, 127283, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128188, 128378, 128395, 128420, 128436, 128852, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131936, 131953, 132020, 132297, 132872, 132888, 132903, 132954, 133394, 133480, 133878, 133896, 134543, 135398, 135411, 135599, 135624, 135646, 135658, 135669, 136149, 136300, 136314, 136400, 136644, 136711, 137026, 137076, 137108, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140613, 140614, 140669, 141667, 141683, 142241, 142653, 142681, 142800, 143425, 143426, 143436, 143442, 144951, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 146129, 146130, 146155, 146244, 146439, 146492, 146553, 146573, 146582, 146595, 146597, 146599, 147072, 147816, 147899, 150129, 150809, 150812, 150847, 150869, 151108, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152703, 152707, 152746, 152946, 153078, 153083, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156258, 156354, 156491, 156497, 156506, 156912, 157511, 157512, 157514, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159286, 159850, 160065, 160069, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161724, 161726, 161731, 161733, 161737, 161745, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161993, 162276, 162306, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165043, 166217, 166256, 166283, 166669, 167039, 167067, 167089, 167106, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167622, 167628, 167744, 167749, 167750, 168033, 168040, 168094, 168108, 168109, 168122, 168125, 168140, 168325, 168380, 168384, 168397, 168411, 168416, 168419, 168423, 172384, 172415, 173746, 176754, 176774, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178427, 178437, 178441, 178452, 178457, 179092, 179558, 179559, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180675, 180681, 180711, 181215, 181245, 181279, 181942, 182196, 182583, 182763, 182870, 183064, 183184, 183329, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185638, 185706, 185750, 185787, 186223, 187223, 187620, 187671, 188243, 188435, 189130, 189151, 189376, 189436, 189499, 189562, 189578, 189581, 189594, 190015, 190036, 190694, 190726, 190730, 190741, 191205, 191219, 191699, 191713, 191729, 192147, 192193, 192230, 192236, 192243, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193209, 193240, 193259, 193568, 193665, 193685, 193728, 194048, 194180, 194199, 194711, 195160, 195168, 195171, 195419, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 197244, 197273, 197277, 197282, 197285, 197286, 197294, 197350, 197404, 197618, 197629, 197921, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199343, 199362, 199418, 200441, 200456, 200861, 200871, 200873, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202827, 203011, 204044, 204049, 204523, 204978, 205021, 205555, 205558, 205982, 205995, 206611, 206666, 206966, 207056, 207233, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('dimensionality reduction', [32254, 32258, 32268, 32426, 32427, 32457, 64330, 77638, 77639, 77669, 77670, 77925, 192144, 200113]), ('component analysis', [33520, 33529, 63391, 86967, 86969, 87054, 87104, 111782, 112216, 177358, 178535, 202443, 202456]), ('time series', [25065, 25541, 25889, 26112, 26126, 26157, 26596, 26829, 26830, 26832, 44255, 44285, 57439, 57443, 57444, 57447, 61323, 64966, 65289, 65409, 75104, 75822, 87407, 123309, 123322, 123324, 123328, 123331, 123341, 123432, 123465, 123644, 123849, 123864, 124389, 124601, 124655, 125900, 125907, 125923, 127285, 136151, 136327, 136333, 136676, 136720, 136915, 136918, 136946, 136948, 137065, 141592, 145603, 145629, 145777, 145817, 145832, 157024, 165072, 165203, 165345, 167766, 168035, 178396, 190820, 190961, 191055, 191163, 191296, 191308, 191309, 191575, 194102, 200274]), ('neural', [10, 30, 45, 59, 78, 115, 191, 290, 377, 1001, 1017, 1373, 1384, 1399, 1445, 2402, 2405, 2817, 2830, 2832, 2870, 3123, 3311, 3320, 3429, 3433, 3439, 3456, 3702, 3824, 3828, 3925, 4189, 4200, 4217, 4361, 4369, 4444, 4481, 6398, 6413, 6457, 7108, 7563, 7577, 7590, 7836, 8231, 8234, 8245, 8633, 8664, 8675, 8708, 8740, 9042, 9120, 9327, 9337, 9365, 9368, 9388, 9434, 9444, 9495, 9511, 9557, 9567, 9570, 9620, 9765, 9797, 9967, 9986, 9992, 10287, 10807, 10843, 11219, 11223, 11240, 11249, 11498, 11509, 11545, 11657, 11661, 11943, 11949, 11950, 11954, 12279, 12291, 12341, 12356, 12716, 12736, 12743, 12801, 12825, 13134, 13163, 13832, 13858, 14774, 14780, 14815, 14855, 15539, 15579, 15854, 15870, 15882, 15888, 16011, 16016, 16318, 16345, 16352, 16369, 16391, 16395, 16396, 16398, 16406, 16413, 16424, 16547, 16581, 16584, 16633, 16654, 16808, 16843, 16878, 16886, 16887, 16894, 16913, 16922, 17079, 17175, 17179, 17202, 17254, 17324, 17393, 17414, 17447, 17525, 17575, 17705, 17708, 17714, 17788, 18031, 18045, 18053, 18060, 18489, 18518, 18554, 18609, 18818, 18874, 19990, 19992, 20401, 20415, 20422, 20426, 20428, 20447, 20454, 20467, 20469, 20561, 20564, 20625, 20628, 20630, 20653, 20718, 20983, 21001, 21026, 21035, 21457, 21546, 21552, 21560, 21572, 21578, 21579, 21589, 21604, 21624, 21834, 21858, 21874, 22090, 22153, 22161, 22164, 22191, 22354, 22777, 22783, 22798, 23716, 23720, 23737, 23747, 23766, 23887, 23899, 23922, 24010, 24025, 24055, 24060, 25091, 25117, 25124, 25173, 26169, 26179, 27048, 27051, 27065, 27067, 27079, 27119, 27297, 27426, 27440, 27465, 27850, 27867, 27868, 27878, 27898, 28267, 28279, 28313, 28634, 28773, 29016, 29039, 29090, 29442, 29488, 29543, 29551, 29556, 29557, 29991, 30005, 30028, 30345, 30355, 30356, 30357, 30360, 30378, 30382, 30387, 30794, 30806, 30810, 30814, 30826, 30827, 30889, 30890, 30891, 30895, 30911, 30912, 30934, 30981, 31020, 31024, 31028, 31089, 31139, 31192, 31228, 31261, 31263, 32254, 32437, 32541, 32546, 32579, 32903, 34034, 34040, 34563, 34602, 34624, 34633, 34634, 34653, 34676, 34906, 35319, 35320, 35341, 36171, 36187, 36204, 36216, 36231, 36238, 36290, 36321, 36384, 36385, 36388, 36397, 36399, 36431, 36474, 36762, 37098, 37112, 37188, 37469, 37475, 37485, 37513, 37523, 37790, 37792, 37803, 37824, 37825, 37828, 37838, 37840, 37841, 38063, 38138, 38144, 38149, 38150, 38162, 38214, 38222, 38226, 38465, 38503, 38504, 38640, 38645, 38655, 38668, 39238, 39769, 40353, 40355, 40363, 40368, 40479, 40480, 40962, 40990, 41003, 41064, 41419, 41421, 41477, 41514, 42193, 42219, 42728, 42744, 42817, 42823, 42871, 43307, 43308, 43325, 43328, 43346, 43367, 43744, 43751, 43775, 43795, 44125, 44146, 44161, 44215, 44230, 44255, 44259, 44265, 44300, 44364, 44380, 44501, 44531, 44547, 44553, 44575, 44584, 44585, 44611, 44645, 44657, 44684, 44711, 44714, 44810, 44813, 44819, 44826, 44831, 44843, 44952, 44995, 45709, 45711, 45722, 45753, 46531, 47250, 47411, 47661, 47718, 48067, 48172, 48183, 48186, 48189, 48191, 48194, 48198, 48279, 48283, 48403, 48410, 48472, 48509, 48521, 48528, 48533, 48554, 48642, 48650, 48668, 48669, 48675, 48801, 48803, 48804, 48818, 49012, 49015, 49046, 49055, 49056, 49062, 49078, 49091, 49093, 49294, 49559, 49633, 50392, 50395, 50399, 50415, 50432, 50483, 50539, 50543, 50691, 50694, 50696, 50706, 50762, 50765, 50767, 50775, 50777, 50848, 50931, 51206, 51263, 51663, 51713, 51747, 51863, 51868, 51895, 51947, 51949, 51952, 52026, 52506, 52511, 53111, 53131, 53149, 53150, 53173, 53182, 53361, 53680, 53716, 53741, 53743, 53753, 53755, 53798, 53849, 53865, 54013, 54063, 54067, 54073, 54090, 54096, 54120, 54248, 54249, 54252, 54259, 54263, 54264, 54362, 54606, 54610, 54649, 54656, 54661, 54664, 55059, 55075, 55095, 55101, 55102, 55103, 55108, 55114, 55122, 55153, 55396, 55413, 55452, 55457, 55964, 56080, 56344, 57356, 57357, 57364, 57380, 57391, 57438, 57768, 57792, 57797, 58124, 58127, 58129, 58131, 58136, 58137, 58140, 58141, 58144, 58145, 58146, 58148, 58149, 58165, 58170, 58223, 58255, 58337, 58344, 58390, 58403, 58410, 58413, 58415, 58443, 58559, 58560, 58577, 58581, 58589, 58633, 58634, 58645, 58647, 58652, 58657, 58728, 58729, 58748, 58749, 58816, 58852, 58860, 58939, 58940, 58948, 58986, 59048, 59049, 59083, 59088, 59090, 59091, 59126, 60351, 60364, 60383, 60406, 60857, 60859, 61286, 61629, 61634, 61669, 61694, 61817, 62232, 63078, 63083, 63087, 63091, 63114, 63133, 63147, 63159, 63162, 63167, 63168, 63170, 63183, 63186, 63283, 63315, 63373, 63386, 63392, 63416, 63423, 63442, 63444, 63447, 63449, 63451, 64350, 64433, 64442, 64445, 64446, 64461, 64489, 64491, 64504, 64530, 64842, 64866, 64876, 64898, 64905, 64907, 64909, 64923, 64935, 64941, 64957, 65304, 65427, 65455, 65478, 67431, 67437, 67459, 67585, 67606, 67608, 67610, 67674, 67675, 67676, 67678, 67679, 67737, 67738, 67739, 67745, 67748, 67789, 67803, 67867, 68319, 68793, 68807, 68809, 69930, 70021, 70022, 70111, 70157, 70172, 70200, 70209, 70225, 70324, 70339, 70386, 70398, 70405, 70518, 70707, 70994, 71379, 71444, 71891, 71910, 72294, 72399, 72405, 72407, 72421, 72481, 72568, 72855, 73087, 73088, 73092, 73093, 73100, 73102, 73146, 73152, 73157, 73165, 73238, 73248, 73301, 73303, 73305, 73332, 73335, 73337, 73379, 73397, 73500, 73501, 73503, 73505, 73509, 73511, 73646, 73650, 73653, 73663, 73668, 73671, 73674, 73675, 73677, 73691, 73692, 73696, 73697, 73699, 73709, 73718, 73723, 74129, 74561, 75069, 75105, 75838, 75853, 75905, 75929, 75930, 76175, 76290, 76588, 76590, 76593, 76636, 76659, 77561, 77568, 77962, 77966, 78372, 78377, 79184, 79185, 79195, 79274, 79277, 79278, 79280, 79295, 79395, 79538, 79657, 80175, 80186, 80275, 80432, 80450, 80454, 80466, 80487, 80488, 80490, 80495, 80500, 80664, 80769, 81115, 81117, 81121, 81123, 81132, 81859, 81870, 81945, 81947, 82303, 82309, 82324, 82351, 82413, 82745, 82747, 82749, 82751, 82758, 83185, 84715, 85367, 85380, 85429, 86029, 86554, 86960, 86988, 87333, 87336, 87356, 87704, 87774, 87950, 87965, 87995, 88015, 88059, 88066, 88200, 88254, 88277, 88278, 88283, 88325, 88354, 88355, 88376, 89187, 89198, 89201, 89565, 89588, 89594, 89603, 89608, 89613, 89651, 89662, 89684, 89706, 89883, 89888, 89891, 90355, 90419, 91035, 91036, 91046, 91067, 91070, 91148, 91159, 91170, 91358, 91748, 91775, 91777, 91781, 92340, 92349, 92363, 92395, 92397, 92421, 92429, 92758, 92768, 96250, 96275, 96278, 96284, 96285, 96293, 96295, 96328, 96337, 96497, 96528, 96541, 96758, 96759, 96774, 96834, 96836, 96840, 96842, 96848, 96852, 96904, 96913, 96926, 97119, 97120, 97129, 97132, 97224, 97233, 97235, 97236, 97238, 97239, 97241, 97244, 97257, 97303, 97306, 97307, 97310, 97317, 97322, 97415, 97416, 97440, 97493, 97617, 97627, 97634, 97637, 97640, 98069, 98408, 98455, 98488, 98498, 98501, 98580, 98850, 98866, 98870, 98878, 98883, 98884, 99302, 99330, 99360, 99594, 99602, 99891, 99900, 99933, 99943, 99987, 100361, 100380, 100388, 100408, 101044, 101046, 101047, 101052, 101062, 101074, 101075, 101084, 101085, 101091, 101098, 101166, 101638, 101641, 101652, 101657, 101839, 102156, 102171, 102687, 102694, 102722, 103128, 103138, 103149, 103171, 103183, 103291, 103294, 103310, 103330, 103501, 103529, 103616, 103862, 103953, 104404, 105547, 105552, 105553, 105836, 105837, 105838, 105848, 105956, 105961, 105993, 106017, 106219, 106295, 106311, 106327, 106328, 106337, 106340, 106455, 106489, 106490, 106546, 106777, 106794, 106834, 106840, 106899, 107585, 107588, 107592, 107593, 107595, 107596, 107618, 107629, 107632, 107669, 107671, 107672, 107689, 107690, 107720, 107723, 107744, 107749, 107750, 107767, 107769, 107773, 108237, 109776, 110174, 110206, 110236, 110319, 110621, 111130, 111164, 111173, 111175, 111177, 111178, 111200, 111201, 111504, 111505, 111508, 111509, 111720, 112221, 112250, 112264, 112278, 112296, 112790, 113934, 115026, 115056, 115522, 115596, 115606, 115648, 115954, 116101, 116126, 116137, 116155, 116190, 116220, 116751, 116752, 117260, 117278, 117301, 117565, 117566, 117587, 117599, 117783, 117856, 117857, 117873, 117877, 118122, 118130, 118135, 118150, 118158, 118854, 118890, 118922, 119348, 119375, 119379, 119394, 119471, 119473, 119476, 119500, 119503, 119505, 119835, 119927, 119981, 119983, 120002, 120007, 120017, 120019, 120028, 120038, 120182, 120219, 120225, 120234, 120237, 120248, 120305, 120416, 120437, 120442, 120935, 120967, 120971, 120972, 120980, 121014, 121135, 121136, 121148, 121664, 122424, 122646, 122690, 122703, 122728, 123277, 123312, 123325, 123327, 123331, 123340, 123440, 123572, 123578, 123657, 124249, 124252, 124275, 124699, 124705, 124730, 124739, 124741, 124909, 124913, 124922, 125008, 125009, 125011, 125072, 125074, 125435, 125467, 125775, 125844, 125847, 126029, 126030, 126052, 126054, 126061, 126071, 126078, 126356, 126387, 126394, 126402, 126426, 126427, 126428, 126439, 126543, 126557, 126650, 126661, 126682, 126685, 126695, 126697, 126734, 126747, 126761, 126790, 126791, 126819, 126831, 126834, 126838, 126851, 126866, 126915, 127021, 127283, 127313, 127330, 127420, 127430, 127432, 127436, 127476, 127488, 128180, 128181, 128182, 128187, 128188, 128206, 128378, 128395, 128420, 128436, 128852, 129418, 130274, 130336, 130436, 130726, 131362, 131378, 131381, 131930, 131936, 131953, 132020, 132297, 132338, 132340, 132352, 132361, 132872, 132888, 132903, 132954, 133394, 133480, 133488, 133489, 133878, 133896, 134470, 134480, 134543, 134692, 135227, 135243, 135398, 135411, 135416, 135599, 135624, 135646, 135658, 135669, 136149, 136297, 136300, 136314, 136400, 136644, 136674, 136685, 136687, 136711, 136727, 136785, 137025, 137026, 137076, 137078, 137081, 137101, 137108, 137125, 137127, 137133, 137145, 137165, 137187, 137569, 137638, 138108, 139556, 139562, 139733, 139736, 139777, 139869, 139871, 140047, 140090, 140507, 140576, 140606, 140613, 140614, 140669, 141121, 141667, 141683, 142241, 142653, 142778, 142800, 142882, 142903, 142976, 142978, 142992, 143270, 143425, 143426, 143436, 143442, 143466, 143492, 143536, 143864, 144951, 144970, 144975, 145067, 145365, 145368, 145370, 145379, 145388, 145407, 145568, 145575, 145580, 145658, 145662, 146095, 146129, 146130, 146149, 146155, 146157, 146159, 146176, 146244, 146439, 146492, 146549, 146553, 146554, 146573, 146580, 146582, 146595, 146597, 146599, 147072, 147810, 147816, 147845, 147850, 147893, 147899, 147906, 148199, 148241, 148758, 149319, 150129, 150809, 150812, 150847, 150869, 151108, 151153, 152225, 152226, 152230, 152249, 152254, 152256, 152279, 152456, 152627, 152665, 152675, 152703, 152707, 152746, 152946, 153078, 153083, 153217, 153220, 153245, 153275, 153294, 153404, 153426, 153695, 153698, 155907, 156239, 156248, 156254, 156258, 156304, 156310, 156354, 156491, 156497, 156506, 156508, 156912, 156999, 157003, 157255, 157351, 157360, 157395, 157404, 157428, 157432, 157511, 157512, 157514, 157536, 157537, 157791, 158085, 158652, 158664, 158681, 158684, 159010, 159215, 159229, 159243, 159286, 159850, 159886, 159898, 160065, 160069, 160248, 161036, 161122, 161490, 161493, 161631, 161651, 161652, 161658, 161660, 161662, 161719, 161724, 161726, 161729, 161731, 161733, 161735, 161737, 161745, 161774, 161784, 161796, 161807, 161817, 161823, 161869, 161943, 161967, 161993, 162276, 162306, 162319, 162327, 162891, 162908, 162924, 163677, 163687, 164123, 164152, 164371, 164796, 164890, 165025, 165040, 165043, 165076, 165707, 166217, 166227, 166256, 166283, 166381, 166385, 166435, 166461, 166645, 166669, 167039, 167067, 167089, 167105, 167106, 167112, 167118, 167264, 167265, 167267, 167335, 167338, 167382, 167490, 167554, 167573, 167592, 167608, 167610, 167622, 167628, 167650, 167744, 167749, 167750, 167772, 168033, 168036, 168040, 168094, 168108, 168109, 168122, 168125, 168137, 168140, 168149, 168325, 168329, 168380, 168384, 168397, 168402, 168411, 168416, 168419, 168423, 171083, 171086, 171091, 171131, 171148, 171176, 171295, 171428, 171455, 172365, 172384, 172415, 173500, 173551, 173571, 173746, 174745, 174800, 174802, 174850, 174863, 174918, 175164, 175258, 176721, 176725, 176754, 176774, 177355, 177424, 177849, 177883, 178024, 178173, 178220, 178248, 178258, 178273, 178281, 178316, 178427, 178437, 178441, 178452, 179092, 179553, 179558, 179559, 179565, 179577, 179583, 179621, 179652, 179658, 179659, 179668, 179674, 179683, 179865, 179883, 179991, 180024, 180040, 180041, 180174, 180175, 180177, 180181, 180225, 180229, 180295, 180668, 180675, 180681, 180684, 180711, 181215, 181216, 181245, 181277, 181279, 181942, 182196, 182583, 182763, 182870, 183006, 183008, 183011, 183012, 183014, 183036, 183040, 183041, 183064, 183065, 183067, 183072, 183168, 183184, 183188, 183507, 183520, 183580, 183614, 183623, 183827, 183866, 184481, 184797, 184799, 184802, 184805, 185042, 185168, 185170, 185302, 185303, 185304, 185306, 185322, 185324, 185325, 185383, 185393, 185468, 185616, 185633, 185634, 185638, 185706, 185750, 185755, 185787, 186223, 186507, 186897, 186921, 186964, 187065, 187193, 187223, 187312, 187620, 187671, 188243, 188435, 189130, 189132, 189151, 189376, 189436, 189499, 189562, 189572, 189578, 189581, 189584, 189594, 190015, 190036, 190694, 190722, 190726, 190730, 190741, 191205, 191219, 191278, 191699, 191713, 191729, 191868, 192147, 192157, 192163, 192193, 192230, 192236, 192243, 192245, 192263, 192270, 192762, 192768, 192874, 192877, 193199, 193201, 193202, 193206, 193209, 193240, 193247, 193259, 193568, 193574, 193665, 193684, 193685, 193688, 193694, 193702, 193728, 193750, 193854, 193881, 193991, 194048, 194050, 194180, 194199, 194711, 195160, 195168, 195171, 195304, 195419, 195456, 195528, 195542, 195552, 195823, 195829, 195948, 195953, 196024, 196047, 196085, 196222, 196575, 196730, 196741, 196743, 196744, 196751, 196753, 196755, 197244, 197256, 197258, 197273, 197277, 197285, 197286, 197294, 197350, 197360, 197404, 197618, 197629, 197712, 197921, 198288, 198684, 198752, 198765, 199310, 199316, 199320, 199330, 199334, 199340, 199343, 199362, 199374, 199375, 199376, 199418, 200441, 200456, 200861, 200871, 200873, 200961, 201113, 201536, 201539, 201687, 201937, 202042, 202224, 202368, 202459, 202492, 202526, 202621, 202624, 202692, 202698, 202706, 202809, 202827, 202835, 203011, 204044, 204049, 204523, 204953, 204963, 204966, 204978, 205021, 205555, 205558, 205577, 205588, 205708, 205727, 205958, 205982, 205993, 205995, 205998, 206003, 206009, 206017, 206611, 206666, 206879, 206966, 207056, 207211, 207233, 207257, 207296, 207334, 207827, 208446, 208492, 208502, 208522, 209021, 209049, 209055, 209108, 209517, 209595]), ('neighbor', [1744, 1755, 1764, 1776, 1782, 6104, 6106, 6148, 6155, 8505, 10281, 10444, 10493, 10573, 10576, 10588, 10625, 10694, 10755, 10838, 10840, 10866, 10992, 13011, 13164, 13165, 13181, 13915, 15041, 15087, 17621, 17622, 17631, 17718, 17779, 17794, 17799, 17904, 20227, 24091, 26606, 26628, 29507, 29528, 29553, 29557, 29636, 29660, 29664, 29677, 29687, 29690, 29694, 29715, 29723, 29725, 29949, 29982, 29987, 30004, 30010, 30011, 31073, 31130, 31134, 31135, 31147, 31162, 31354, 31359, 31361, 32656, 36533, 37572, 37601, 37869, 37875, 38061, 38146, 38674, 38715, 38772, 38794, 38805, 38865, 41123, 41494, 41495, 41506, 41512, 41516, 41557, 41691, 41771, 41783, 41820, 44780, 50023, 50089, 50320, 50545, 50996, 52012, 52330, 52437, 52820, 54339, 55188, 56477, 56479, 56509, 57971, 58012, 61681, 61802, 61804, 61849, 61856, 61929, 61978, 62218, 62219, 63285, 63763, 63773, 64987, 66827, 66906, 66915, 67051, 67271, 67373, 68204, 68299, 69993, 70000, 70026, 70060, 70103, 70119, 70120, 70132, 70137, 70139, 70186, 70187, 70208, 76589, 82618, 83068, 85665, 85671, 86575, 86864, 86891, 86902, 87688, 88867, 89077, 90835, 90914, 90915, 90944, 90967, 90969, 91004, 98163, 102378, 102395, 102429, 102466, 106904, 106942, 106945, 108356, 112115, 114219, 114501, 114713, 115011, 115024, 119009, 120635, 120726, 120732, 120733, 120776, 120809, 120811, 120821, 127526, 127538, 127570, 127649, 127664, 127666, 128276, 128308, 128333, 128337, 128894, 128910, 128925, 128933, 128960, 128969, 128972, 128975, 128985, 128986, 129006, 129007, 129008, 129009, 129031, 129045, 129091, 129234, 129245, 129247, 129248, 129250, 129252, 129263, 129265, 129268, 129308, 129315, 132181, 132184, 132189, 134339, 137066, 142241, 142291, 142329, 142363, 142642, 142648, 142651, 149280, 149323, 149825, 149961, 149962, 149996, 150018, 150028, 150763, 153098, 155939, 156814, 160796, 160991, 160999, 161074, 161089, 161419, 161476, 161491, 161493, 161507, 161531, 161585, 161593, 161595, 162392, 164064, 165450, 166979, 169353, 171500, 171504, 171600, 171661, 171680, 171697, 171700, 171726, 171729, 178515, 180291, 180301, 180302, 180317, 180318, 180356, 180359, 180360, 180368, 180378, 180386, 180391, 180463, 180665, 182777, 182782, 185619, 190851, 190853, 191112, 191137, 191159, 191336, 191340, 191716, 191813, 191959, 191973, 191979, 191980, 191982, 191993, 192023, 194812, 200502, 204236, 204595, 204999, 206373, 206376, 207436, 208941, 209978]), ('monte carlo', [207829]), ('reinforcement learning', [3494, 3749, 3765, 3824, 23254, 23259, 23383, 23476, 23509, 23513, 23516, 31790, 31807, 31816, 31837, 31843, 31962, 32203, 32217, 32226, 54732, 78331, 78384, 87974, 87994, 88103, 107815, 121190, 121201, 121203, 121208, 121234, 121239, 121584, 121640, 141883, 142175, 162363, 162373, 166996, 168148, 169045, 169051, 169064, 169065, 169073, 169087, 169090, 169571, 169577, 169591, 169613, 170189, 170202, 170476, 170551, 170561, 174241, 174247, 174263, 174272, 174276, 174277, 174283, 174285, 174510, 174511, 174662, 174732, 174770, 182099, 185314, 185747, 189674, 189677, 194138, 194193, 194627]), ('hidden markov', [165025, 165028]), ('model', [23, 67, 376, 426, 665, 740, 748, 754, 808, 846, 1040, 1383, 1399, 1402, 2094, 2461, 3497, 3510, 3520, 3524, 3526, 3528, 3536, 3538, 3546, 3547, 3550, 3552, 3554, 3555, 3558, 3560, 3583, 3584, 3586, 3590, 3593, 3598, 3600, 3612, 3703, 3708, 3716, 3721, 3726, 3736, 3756, 3766, 3773, 3816, 3878, 3879, 3917, 3919, 3948, 3966, 3973, 4090, 4130, 4266, 5729, 5730, 5737, 5916, 5920, 5982, 6088, 6090, 6102, 6118, 6539, 6548, 6556, 6568, 6778, 6980, 8236, 8249, 8260, 8396, 8632, 9454, 9465, 9510, 9989, 10287, 10686, 10687, 10758, 11051, 11542, 11543, 11554, 11555, 11556, 11557, 11562, 11567, 11568, 11569, 11578, 11579, 11595, 11597, 11610, 11611, 11613, 11630, 11631, 11649, 11651, 11652, 11653, 11658, 11659, 11663, 11664, 11670, 11671, 11685, 11687, 11689, 11692, 11694, 11695, 11697, 11707, 11712, 11723, 11732, 11743, 11761, 11763, 11777, 11803, 11815, 11828, 11909, 11912, 11923, 11928, 11929, 11936, 11938, 11946, 11960, 11968, 11976, 12006, 12010, 12031, 12043, 12051, 12061, 12072, 12265, 12291, 12301, 12311, 12363, 12440, 12712, 12981, 13102, 13186, 13839, 13967, 14029, 14030, 14034, 14039, 14191, 14192, 14195, 14568, 14774, 14780, 14784, 14785, 14786, 14787, 14808, 14811, 14815, 14839, 14855, 15127, 15362, 15364, 15365, 15581, 15610, 15653, 15656, 15877, 16038, 16045, 16086, 16087, 16138, 16221, 16280, 16284, 16299, 16301, 16311, 16316, 16861, 17254, 17313, 17315, 17326, 17328, 17377, 17383, 17384, 17385, 17393, 17405, 17412, 17415, 17419, 17425, 17430, 17432, 17438, 17447, 17448, 17449, 17458, 17460, 17461, 17475, 17476, 17477, 17486, 17498, 17499, 17500, 17501, 17569, 17600, 17601, 17606, 17623, 17705, 17709, 17711, 17712, 17720, 17752, 17802, 17905, 17945, 17948, 17952, 17982, 17983, 18636, 18874, 19023, 19210, 19231, 19233, 19239, 19257, 19259, 19262, 19263, 19270, 19278, 19461, 19504, 19512, 19521, 19522, 19523, 19526, 19567, 19587, 19592, 19598, 19603, 19607, 19646, 19704, 19719, 19740, 19746, 19764, 19799, 19800, 19803, 19804, 19806, 19807, 19809, 19815, 19819, 19823, 19891, 19912, 19913, 19916, 19917, 19921, 19923, 19925, 19939, 19941, 19990, 19999, 20721, 21001, 21237, 21545, 21576, 21671, 22162, 22282, 22369, 22794, 23225, 23228, 23229, 23238, 23251, 23259, 23274, 23275, 23278, 23303, 23346, 23348, 23379, 23381, 23444, 23469, 23480, 23512, 23514, 23547, 23563, 23660, 23661, 24000, 24001, 24480, 24510, 24512, 24540, 24777, 24792, 25094, 25101, 25128, 25175, 25192, 25193, 25250, 25251, 25306, 25329, 25342, 25343, 25365, 25381, 25383, 25384, 25414, 25415, 25421, 25437, 25443, 25446, 25459, 25460, 25461, 25467, 25468, 25470, 25472, 25473, 25478, 25566, 25581, 25594, 25619, 25620, 25895, 25896, 26142, 26179, 27084, 27506, 27512, 27519, 27520, 27521, 27531, 27534, 27535, 27540, 27541, 27576, 27591, 27611, 27617, 27634, 27637, 27770, 27775, 27850, 27856, 27866, 27878, 27903, 27932, 27940, 27942, 27997, 27999, 28027, 28075, 28268, 28274, 28320, 28328, 28621, 28710, 28718, 28740, 29083, 29084, 29087, 29090, 29129, 29133, 29375, 29488, 30030, 30052, 30345, 30355, 30356, 30357, 30360, 30911, 31016, 31022, 31062, 31088, 31419, 31431, 31709, 31744, 31751, 31803, 32903, 32947, 32950, 32999, 33004, 33015, 33020, 33022, 33023, 33026, 33027, 33063, 33163, 33176, 33181, 33268, 33269, 33435, 33443, 33445, 33461, 33463, 33469, 33470, 33480, 33484, 33501, 33526, 33536, 33552, 33562, 33601, 33608, 33812, 33922, 33978, 34002, 34009, 34011, 34015, 34017, 34027, 34045, 34056, 34136, 34602, 34603, 34608, 34632, 34634, 34653, 34663, 34664, 34666, 34676, 34908, 35319, 35328, 35403, 35644, 35647, 35659, 35668, 35670, 35674, 35676, 35726, 35774, 35781, 35782, 35825, 35902, 35904, 35913, 35914, 35916, 35964, 35967, 36159, 36171, 36182, 36511, 36512, 36514, 36517, 36526, 36550, 36562, 36590, 36696, 36714, 37042, 37045, 37056, 37057, 37349, 37430, 37432, 37444, 37456, 37458, 37654, 37657, 37658, 37659, 37666, 37668, 37674, 37687, 37690, 37719, 37725, 37726, 37755, 38275, 38301, 38368, 38525, 38639, 38680, 38681, 38841, 38861, 38949, 38952, 39238, 39271, 39333, 40353, 40355, 40357, 40360, 40363, 40368, 40370, 40385, 40386, 40389, 40402, 40476, 40480, 40482, 40502, 40507, 40512, 40559, 40560, 40572, 40582, 40583, 40793, 40899, 40901, 40907, 41477, 41478, 41482, 41513, 41516, 41518, 41519, 41531, 41589, 42238, 42347, 42359, 42709, 42805, 42846, 43367, 43373, 43868, 44146, 44161, 44165, 44172, 44201, 44279, 44372, 44383, 44451, 44543, 44552, 44603, 44752, 45021, 45349, 45470, 45553, 45645, 45663, 45681, 45835, 46191, 46195, 46214, 46267, 46273, 46274, 46309, 46311, 46331, 46341, 46343, 46350, 46409, 46412, 46413, 46414, 46418, 46419, 46422, 46425, 46517, 46522, 46526, 46530, 46533, 46544, 47675, 47676, 47679, 47695, 47703, 47705, 47707, 47708, 47721, 47727, 47752, 47853, 47862, 47866, 47941, 48025, 48032, 48035, 48045, 48049, 48135, 48192, 48393, 48472, 48479, 48480, 48484, 48517, 48530, 48558, 48802, 48803, 48819, 48829, 49016, 49019, 49022, 49069, 49071, 49094, 49381, 49393, 49416, 49483, 49489, 50010, 50012, 50022, 50038, 50316, 50324, 50361, 50762, 50771, 50773, 50847, 50850, 50854, 50858, 50860, 50906, 50990, 51084, 51086, 51088, 51177, 51236, 51262, 51324, 51330, 51332, 51354, 51356, 51364, 51369, 51373, 51374, 51458, 51527, 51737, 52064, 52065, 52068, 52071, 52230, 53387, 53391, 53393, 53446, 53452, 53465, 53466, 53477, 53478, 53500, 53515, 53516, 53521, 53522, 53568, 53569, 53573, 53581, 53585, 53658, 53659, 53663, 53687, 54691, 54693, 54710, 54712, 54713, 54714, 54726, 54732, 54744, 54749, 54783, 54787, 54802, 54807, 54815, 54826, 54839, 54899, 54900, 54902, 54920, 54921, 54923, 54932, 54956, 54978, 55000, 55021, 55022, 55024, 55048, 55050, 55438, 55440, 55441, 55458, 55476, 55479, 55482, 55491, 55495, 55541, 55559, 55561, 55566, 55572, 55964, 55965, 55970, 55997, 56032, 56054, 56067, 56084, 56092, 56266, 56282, 56284, 56332, 56353, 56376, 56809, 57318, 57328, 57356, 57357, 57361, 57369, 57375, 57377, 57378, 57381, 57391, 57399, 57438, 57450, 57454, 57484, 57486, 57490, 57498, 57500, 57506, 57516, 57519, 57546, 57550, 57568, 57601, 57607, 57628, 57659, 57660, 57661, 57664, 57666, 57667, 57674, 57681, 57683, 57702, 57708, 57715, 57724, 57727, 57730, 57731, 57732, 57734, 57736, 57737, 57774, 57776, 57777, 57779, 57781, 57782, 57783, 57793, 57801, 57804, 57810, 57823, 57830, 57833, 57834, 57971, 58013, 58082, 58088, 58633, 58635, 58636, 58637, 58638, 58661, 58674, 58725, 58728, 58730, 58731, 58732, 58738, 58847, 58848, 58915, 58924, 58937, 58940, 58942, 58961, 58965, 58983, 58991, 59037, 59045, 59046, 59073, 59074, 59081, 59083, 59129, 59432, 59710, 59711, 59778, 59818, 59903, 59920, 60404, 60406, 60410, 60413, 60465, 60467, 60509, 60610, 60647, 60657, 60659, 60660, 60661, 60764, 60777, 60785, 60786, 61622, 61657, 61694, 61817, 62232, 62474, 62484, 62486, 62500, 62502, 62564, 62580, 62581, 62584, 62586, 62638, 62640, 62647, 62653, 62672, 62674, 62678, 62728, 62823, 62874, 62878, 62904, 63121, 63122, 63134, 63148, 63157, 63401, 63405, 63407, 63415, 63424, 63435, 63792, 63985, 64021, 64022, 64089, 64206, 64229, 64233, 64343, 64350, 64368, 64375, 64383, 64385, 65478, 66047, 66819, 66828, 66837, 66843, 66851, 66856, 66860, 66927, 67176, 67180, 67266, 67365, 67381, 67405, 67439, 67570, 67571, 67575, 68019, 68024, 68294, 68804, 68873, 69387, 69470, 69848, 69858, 69962, 70037, 70329, 70510, 70519, 71177, 71340, 71342, 71344, 71362, 71364, 71380, 71381, 71384, 71385, 71386, 71387, 71418, 71421, 71422, 71423, 71438, 71599, 71607, 71728, 71729, 71879, 71912, 71914, 72033, 72338, 72352, 72354, 72356, 72358, 72361, 72365, 72385, 72402, 73343, 73654, 73722, 73757, 73760, 73780, 73781, 73787, 73789, 73790, 73798, 73842, 73855, 73914, 73919, 73957, 73980, 74068, 74076, 74077, 74130, 74229, 74230, 74242, 74246, 74250, 74256, 74438, 74439, 74441, 74586, 74598, 74609, 74612, 74614, 74621, 74721, 74732, 74913, 74964, 74994, 75834, 76659, 77238, 77252, 77398, 77572, 77602, 77626, 77628, 77633, 77637, 77639, 77642, 77646, 77712, 77719, 77757, 77760, 77775, 77784, 77790, 77800, 77918, 77920, 77924, 77975, 77983, 78036, 78063, 78065, 78074, 78075, 78080, 78089, 78090, 78099, 78101, 78103, 78104, 78106, 78110, 78126, 78128, 78228, 78231, 78234, 78235, 78266, 78272, 78296, 78304, 78398, 78400, 78401, 78402, 78409, 78412, 78424, 78428, 78443, 78454, 78458, 78459, 78461, 78476, 78478, 78480, 78489, 78490, 78491, 78496, 78497, 78501, 78502, 78503, 78516, 78535, 78536, 78540, 78580, 78581, 78582, 78583, 78590, 78592, 78600, 78811, 78861, 78862, 78865, 78866, 78998, 79056, 79140, 79141, 79142, 79143, 79146, 79272, 79607, 79662, 79715, 79718, 79723, 79882, 79884, 79886, 79987, 79993, 80070, 80113, 80133, 80136, 80163, 80168, 80169, 80183, 80196, 80215, 80273, 80304, 80325, 80374, 80387, 80389, 80390, 80402, 80404, 80413, 80416, 80420, 80423, 80506, 80665, 81095, 81098, 81100, 81120, 81121, 81271, 81275, 81655, 81656, 81727, 81728, 81730, 81734, 82282, 82290, 82291, 82303, 82785, 82801, 82815, 82862, 82864, 82874, 82882, 83060, 83067, 83071, 83122, 83125, 83126, 83127, 83130, 83135, 83137, 83141, 83142, 83143, 83144, 83147, 83155, 83156, 83158, 83163, 83230, 83271, 83294, 83295, 83301, 83311, 83354, 83365, 83413, 83425, 83427, 83431, 83437, 83520, 83875, 84271, 84286, 84293, 84295, 84304, 84307, 84308, 84311, 84321, 84354, 84355, 84377, 84380, 84382, 84383, 84396, 84397, 84402, 84403, 84410, 84411, 84420, 84421, 84448, 84478, 84513, 84518, 84526, 84541, 84568, 84573, 84574, 84576, 84577, 84584, 84591, 84597, 84707, 84708, 84714, 84742, 84745, 84772, 84773, 84775, 84778, 84779, 84780, 84782, 84795, 85221, 85224, 85226, 85227, 85229, 85232, 85233, 85234, 85235, 85236, 85238, 85241, 85242, 85258, 85260, 85261, 85262, 85344, 85345, 85346, 85404, 85405, 85406, 85413, 85434, 85506, 85508, 85509, 85510, 85537, 85541, 86069, 86084, 86117, 86135, 86137, 86139, 86140, 86147, 86228, 86396, 86422, 86518, 86536, 86541, 86542, 86544, 86545, 86556, 86561, 86562, 86563, 86571, 86576, 86578, 86579, 86580, 86584, 86588, 86590, 86597, 86599, 86601, 86603, 86604, 86611, 86634, 86635, 86637, 86650, 86653, 86654, 86668, 86679, 86691, 86693, 86698, 86700, 86720, 86721, 86722, 86723, 86727, 86750, 86756, 86773, 86775, 86776, 86777, 86798, 86813, 86816, 86832, 86834, 86836, 86866, 86870, 86873, 86884, 86889, 86892, 86906, 86910, 86912, 86914, 86915, 86916, 86917, 86922, 86925, 86962, 86965, 86966, 86990, 86994, 86996, 87022, 87239, 87248, 87254, 87255, 87256, 87259, 87267, 87277, 87278, 87282, 87297, 87298, 87383, 87417, 87519, 87534, 87570, 87672, 87673, 87681, 87686, 87687, 87690, 87692, 87704, 87706, 87720, 87776, 87782, 87788, 87849, 87870, 87887, 87903, 87933, 87938, 88265, 88322, 88758, 88783, 88797, 88810, 89234, 89235, 89236, 89237, 89239, 89245, 89256, 89339, 89340, 89385, 89387, 89437, 89588, 89595, 89633, 89634, 89638, 89652, 89668, 89679, 89680, 89684, 89848, 89855, 89857, 89862, 89886, 89928, 90169, 90291, 90306, 90310, 90316, 90323, 90324, 90327, 90360, 90382, 90411, 90412, 90419, 90420, 90424, 90434, 90435, 90444, 90625, 90631, 90635, 90647, 90673, 90676, 90677, 90679, 90694, 90695, 90700, 90707, 90712, 90724, 90762, 90764, 90807, 90881, 90886, 91719, 91751, 91775, 91777, 91781, 91784, 91830, 91864, 91937, 92015, 92061, 92193, 92279, 92324, 92345, 92799, 92955, 92956, 92960, 92982, 92984, 92991, 93006, 96267, 96269, 96279, 96280, 96528, 96840, 96915, 97089, 97256, 98040, 98069, 98070, 98075, 98129, 98227, 98229, 98237, 98387, 98392, 98393, 98396, 98532, 98697, 98824, 98881, 98929, 99347, 99348, 99352, 99523, 99534, 99589, 99593, 99596, 99603, 99616, 99620, 99801, 99843, 99848, 99864, 99866, 99870, 99939, 99990, 100125, 100127, 100128, 100154, 100155, 100157, 100161, 100344, 100345, 100358, 100377, 100432, 100449, 100467, 100570, 100904, 101650, 101707, 101739, 101771, 102727, 102780, 102783, 102788, 102947, 102949, 102951, 103052, 103058, 103124, 103139, 103159, 103161, 103167, 103168, 103169, 103239, 103244, 103257, 103270, 103278, 103293, 103296, 103301, 103324, 103333, 103338, 103359, 103373, 103398, 103470, 103507, 103521, 103862, 103942, 103952, 104116, 104117, 104138, 104371, 104387, 104405, 104446, 104477, 104674, 105822, 105955, 105957, 105960, 105968, 105970, 105985, 105987, 105993, 105994, 105996, 106005, 106007, 106029, 106038, 106039, 106043, 106102, 106216, 106273, 106289, 106290, 106293, 106295, 106297, 106299, 106302, 106326, 106337, 106338, 106339, 106341, 106343, 106348, 106421, 106422, 106423, 106440, 106465, 106471, 106884, 107118, 107153, 107179, 107252, 107291, 107322, 107325, 107330, 107332, 107336, 107356, 107357, 107359, 107384, 107386, 107388, 107389, 107432, 107434, 107435, 107436, 107483, 107484, 107493, 107495, 107499, 107502, 107506, 107509, 107534, 107536, 107589, 107593, 107597, 107658, 107669, 107671, 107673, 107680, 107694, 107734, 107742, 107744, 107750, 107767, 107773, 107780, 108258, 108292, 108399, 108404, 108408, 108432, 108495, 108530, 109769, 110141, 110173, 110219, 110367, 110368, 110374, 110584, 110646, 111192, 112242, 112270, 112280, 112298, 112300, 112345, 112762, 112841, 113321, 113362, 113377, 113388, 113591, 113870, 113871, 115006, 115114, 115129, 115154, 115373, 115375, 115376, 115388, 115395, 115428, 115458, 115461, 115471, 115484, 115522, 115581, 115594, 115596, 115605, 115636, 115639, 115648, 115649, 115716, 115724, 115756, 115846, 115849, 115850, 115860, 115870, 115883, 115884, 115885, 115973, 115979, 116074, 116082, 116852, 116853, 116865, 116878, 116879, 116886, 116887, 116889, 116900, 116901, 116903, 116909, 116920, 117120, 117165, 117166, 117172, 117174, 117178, 117187, 117202, 117203, 117205, 117207, 117209, 117213, 117230, 117240, 117243, 117248, 117253, 117256, 117260, 117279, 117302, 117573, 117587, 117599, 117783, 117791, 117854, 118906, 118915, 118935, 119231, 119262, 119314, 119316, 119348, 119376, 119380, 119382, 119471, 119475, 119496, 119497, 119500, 119505, 119614, 119617, 119624, 119626, 119632, 119712, 119713, 119714, 119839, 119922, 119923, 119925, 119929, 119930, 119935, 119959, 119962, 119982, 119999, 120007, 120015, 120020, 120182, 120230, 120255, 120380, 120416, 120434, 120438, 120446, 120595, 120598, 120599, 120603, 120612, 120622, 120643, 120661, 120673, 120680, 120730, 120740, 120845, 120850, 120855, 120895, 120926, 120930, 120932, 121214, 121217, 121635, 121664, 122414, 122416, 122420, 122421, 122422, 122434, 122436, 122442, 122447, 122466, 122512, 122518, 122526, 122622, 122634, 122639, 122641, 122643, 122646, 122650, 122662, 122666, 122669, 122673, 122690, 122691, 122694, 122704, 122728, 122734, 122737, 122758, 122785, 122974, 122980, 122984, 122988, 123112, 123126, 123264, 123310, 123313, 123323, 123324, 123327, 123331, 123338, 123340, 123341, 123342, 123350, 123351, 123353, 123354, 123379, 123439, 123441, 123446, 123465, 123498, 123503, 123524, 123544, 123548, 123549, 123550, 123569, 123572, 123573, 123578, 123579, 123582, 123583, 123594, 123595, 123597, 123598, 123599, 123601, 123602, 123608, 123611, 123613, 123641, 123646, 123653, 123656, 123668, 123849, 123924, 124281, 124347, 124426, 124427, 124540, 124573, 124581, 124583, 124585, 124588, 124634, 124659, 124668, 124675, 124677, 124695, 124732, 124739, 124740, 124743, 124806, 124808, 124811, 124813, 124815, 124835, 124923, 124981, 124987, 124999, 125006, 125079, 125159, 125210, 125389, 125423, 125437, 125478, 125481, 125888, 125890, 125903, 125905, 125924, 125932, 125936, 125939, 126007, 126049, 126050, 126054, 126057, 126059, 126060, 126062, 126064, 126071, 126075, 126119, 126126, 126132, 126134, 126198, 126201, 126202, 126203, 126211, 126212, 126228, 126230, 126297, 126299, 126301, 126304, 126305, 126307, 126314, 126315, 126316, 126317, 126329, 126331, 126332, 126335, 126338, 126339, 126340, 126344, 126641, 126642, 126819, 126822, 126825, 126867, 127769, 128420, 128436, 128576, 128593, 128596, 128598, 128748, 128849, 128854, 128866, 130746, 131842, 131929, 131931, 131932, 131942, 131950, 131952, 131961, 131962, 131963, 131966, 131968, 131970, 131972, 131973, 132000, 132002, 132005, 132006, 132008, 132011, 132013, 132014, 132016, 132019, 132021, 132023, 132030, 132031, 132034, 132039, 132040, 132041, 132043, 132044, 132045, 132048, 132054, 132057, 132065, 132142, 132144, 132145, 132146, 132149, 132154, 132158, 132160, 132178, 132191, 132201, 132261, 132262, 132264, 132265, 132266, 132268, 132269, 132275, 132284, 133488, 133896, 133932, 133934, 133943, 134163, 134297, 134318, 134348, 134461, 134499, 134500, 134542, 134544, 134640, 134660, 134916, 135143, 135144, 135155, 135166, 135227, 135398, 135400, 135417, 135440, 135576, 135577, 135609, 136150, 136151, 136153, 136179, 136196, 136198, 136203, 136206, 136209, 136210, 136211, 136212, 136213, 136225, 136227, 136228, 136237, 136239, 136252, 136282, 136288, 136292, 136294, 136295, 136308, 136312, 136317, 136336, 136337, 136345, 136356, 136383, 136386, 136391, 136401, 136402, 136403, 136504, 136553, 136555, 136572, 136573, 136575, 136591, 136595, 136605, 136610, 136612, 136613, 136614, 136644, 136674, 136683, 136684, 136687, 136712, 136714, 136785, 136914, 136948, 137025, 137063, 137077, 137101, 137160, 137162, 137164, 137176, 137179, 137180, 137182, 137183, 137296, 137308, 137312, 137698, 137760, 138069, 138153, 138154, 138450, 138768, 138801, 138802, 138829, 138832, 138858, 138861, 138865, 138880, 138881, 138883, 138893, 138896, 138902, 138914, 138918, 138921, 138934, 138940, 139026, 139170, 139174, 139176, 139178, 139183, 139436, 139437, 139438, 139462, 139473, 139484, 139501, 139503, 139505, 139507, 139525, 139532, 139538, 139542, 139553, 139556, 139557, 139559, 139560, 139561, 139566, 139569, 139573, 139574, 139575, 139576, 139624, 139661, 139687, 139689, 139692, 139709, 139711, 139721, 139736, 139756, 139757, 139782, 139872, 139925, 139937, 139938, 139949, 139969, 139972, 139995, 139997, 139998, 140011, 140077, 140085, 140109, 140401, 140612, 140748, 141090, 141102, 141104, 141114, 141115, 141140, 141141, 141143, 141239, 141416, 141762, 141764, 141766, 141793, 141800, 141830, 141833, 141854, 141857, 141875, 141880, 141896, 141903, 141905, 141938, 142012, 142017, 142018, 142023, 142027, 142033, 142037, 142117, 142128, 142131, 142133, 142134, 142139, 142141, 142152, 142156, 142159, 142165, 142167, 142172, 142173, 142701, 142775, 142803, 142810, 142896, 142898, 142999, 143243, 143408, 143410, 143412, 143436, 143462, 143500, 143530, 143533, 143534, 143535, 143538, 143544, 143626, 143817, 143819, 143854, 143864, 143881, 143882, 143883, 143909, 143910, 143912, 143933, 143939, 144009, 144010, 144038, 144049, 144101, 144109, 144245, 144248, 144258, 145045, 145061, 145065, 145073, 145355, 145361, 145362, 145367, 145369, 145393, 145394, 145398, 145415, 145508, 145567, 146096, 146158, 146556, 146659, 146660, 146676, 146793, 146827, 146967, 147836, 147849, 147908, 147923, 147938, 147972, 147986, 147988, 147991, 147993, 147995, 148032, 148044, 148091, 148093, 148117, 148182, 148184, 148196, 148197, 148198, 148200, 148242, 148267, 148270, 148275, 148283, 148296, 148299, 148303, 148304, 148308, 148311, 148314, 148315, 148316, 148323, 148326, 148329, 148342, 148346, 148348, 148350, 148353, 148354, 148360, 148367, 148368, 148369, 148374, 148375, 148376, 148377, 148378, 148388, 148389, 148412, 148414, 148416, 148425, 148427, 148429, 148433, 148442, 148446, 148449, 148451, 148455, 148472, 148481, 148495, 148496, 148500, 148513, 148514, 148515, 148522, 148524, 148648, 148650, 148654, 148655, 148656, 148659, 148662, 148666, 148668, 148669, 148698, 148699, 148707, 148715, 149571, 149573, 149970, 150223, 150406, 150408, 150873, 150889, 150909, 150924, 150927, 150929, 150940, 151109, 151115, 151119, 151121, 151122, 151190, 151345, 151348, 151349, 151354, 151357, 151362, 151369, 151371, 151377, 151469, 151476, 151493, 151498, 151504, 151555, 151628, 151635, 151649, 151653, 151701, 151722, 151729, 151733, 151773, 151789, 151812, 151831, 151834, 151863, 151864, 151875, 151876, 151884, 151900, 152024, 152034, 152041, 152057, 152062, 152071, 152085, 152157, 152177, 152178, 152180, 152225, 152237, 152240, 152248, 152253, 152257, 152271, 152273, 152277, 152279, 152290, 152297, 152305, 152318, 152323, 152329, 152335, 152389, 152397, 152435, 152456, 152457, 152531, 152542, 152549, 152624, 152626, 152627, 152628, 152663, 152675, 152680, 152684, 152708, 152730, 152733, 152737, 152751, 152753, 152755, 152769, 152770, 152782, 152784, 152787, 152792, 152835, 152836, 152930, 152936, 153038, 153074, 153076, 153093, 153094, 153200, 153214, 153223, 153225, 153232, 153275, 153342, 153343, 153353, 153356, 153357, 153390, 153395, 153403, 153404, 153418, 153427, 153429, 153462, 153463, 153543, 153562, 153636, 153644, 153675, 153676, 153677, 153679, 153683, 153688, 153696, 153699, 153702, 155449, 155514, 155523, 155561, 155567, 155615, 155619, 155626, 155657, 155680, 155735, 155803, 155804, 155806, 155826, 155973, 156156, 156187, 156260, 156288, 156306, 156310, 156996, 156999, 157350, 157351, 157366, 157502, 157509, 157510, 157595, 157607, 157785, 157814, 159012, 159017, 159046, 159208, 159214, 159234, 159280, 159286, 159317, 159544, 159850, 159854, 159856, 159858, 160482, 160496, 160498, 160509, 160545, 160547, 160555, 160570, 160581, 160595, 160610, 160746, 160747, 160775, 160814, 160815, 160823, 160947, 160989, 160998, 161003, 161004, 161011, 161015, 161030, 161053, 161631, 161652, 161662, 161665, 161678, 161679, 161686, 161688, 161720, 161721, 161943, 161953, 161983, 161996, 162014, 162017, 162018, 162019, 162020, 162034, 162035, 162037, 162130, 162183, 162270, 162276, 162278, 162279, 162281, 162286, 162306, 162311, 162319, 162396, 162891, 162895, 162898, 162908, 162924, 162925, 162937, 162941, 162945, 162950, 162951, 162952, 162956, 162958, 162962, 162971, 163059, 163106, 163151, 163261, 163710, 163718, 163749, 163756, 163758, 163766, 163767, 163769, 163770, 163772, 163817, 163818, 163821, 163822, 163828, 163829, 163834, 163835, 163837, 163839, 163846, 163902, 163916, 163950, 163974, 164011, 164042, 164052, 164054, 164055, 164059, 164079, 164085, 164095, 164104, 164125, 164128, 164138, 164141, 164155, 164158, 164817, 164823, 164884, 164885, 164994, 164996, 165002, 165009, 165011, 165025, 165028, 165032, 165104, 165498, 165499, 165527, 165529, 165530, 165654, 165657, 165661, 165665, 165697, 165704, 165723, 165724, 166030, 166056, 166057, 166061, 166066, 166069, 166198, 166217, 166219, 166225, 166469, 166539, 166549, 166644, 166698, 167019, 167066, 167067, 167069, 167077, 167084, 167089, 167102, 167104, 167106, 167108, 167109, 167112, 167113, 167117, 167122, 167124, 167133, 167138, 167140, 167257, 167259, 167261, 167275, 167291, 167341, 167344, 167351, 167355, 167382, 167386, 167393, 167398, 167400, 167401, 167418, 167419, 167420, 167422, 167424, 167425, 167427, 167428, 167429, 167430, 167434, 167436, 167437, 167440, 167441, 167466, 167467, 167483, 167494, 167496, 167499, 167502, 167503, 167504, 167517, 167518, 167520, 167523, 167528, 167530, 167531, 167533, 167548, 167549, 167553, 167555, 167557, 167558, 167559, 167560, 167561, 167563, 167564, 167591, 167609, 167670, 167793, 167803, 167831, 167935, 168067, 168068, 168112, 168403, 168597, 168600, 168609, 168610, 168614, 168621, 168624, 168630, 168631, 168637, 168638, 168642, 168644, 168649, 168650, 168653, 168655, 168661, 168670, 168676, 168677, 168678, 168679, 168681, 168682, 168684, 168700, 168715, 168754, 168764, 168769, 168923, 168924, 168935, 168938, 168950, 168954, 168955, 168956, 168959, 168966, 168971, 168973, 168996, 168999, 169003, 169004, 169006, 169030, 169297, 169298, 169575, 169609, 169646, 169687, 169766, 169781, 169787, 169791, 169792, 169815, 169816, 169851, 169853, 169854, 169856, 169867, 169874, 169896, 170026, 170027, 170044, 170068, 170069, 170070, 170074, 170096, 170099, 170150, 170244, 170505, 170561, 170596, 170612, 170614, 170886, 171059, 171496, 171498, 172196, 172209, 172211, 172221, 172268, 172283, 172316, 172398, 172400, 172403, 172404, 172406, 172414, 172416, 172431, 172439, 172441, 172443, 172480, 172517, 172518, 172519, 172520, 172541, 172544, 172545, 172546, 172557, 172559, 172609, 172612, 172615, 172632, 172703, 172767, 172842, 172954, 172955, 172976, 172984, 172991, 172994, 173011, 173014, 173016, 173052, 173133, 173135, 173136, 173142, 173145, 173147, 173152, 173228, 173238, 173239, 173250, 173266, 173403, 173486, 173496, 173498, 173501, 173513, 173515, 173518, 173519, 173523, 174277, 174278, 174281, 174302, 174761, 174802, 174854, 174942, 174944, 174948, 174952, 175036, 175123, 175156, 175157, 175234, 175236, 175258, 175871, 175884, 176244, 176248, 176271, 176325, 176365, 176371, 176599, 176721, 178184, 178293, 178438, 178479, 179021, 179025, 179036, 179198, 179621, 179658, 179674, 179683, 180174, 180177, 180181, 180225, 180227, 180246, 180252, 180259, 180261, 180271, 180276, 180277, 180279, 180281, 180283, 180328, 180330, 180345, 180358, 180360, 180404, 180411, 180464, 180469, 180482, 180494, 180508, 180513, 180579, 180583, 180588, 180593, 180603, 180609, 180611, 180638, 180643, 180645, 180682, 181997, 182054, 182084, 182099, 182122, 182175, 183579, 183582, 183586, 183608, 183611, 183614, 183616, 183621, 183622, 183623, 183626, 183661, 183664, 183666, 183669, 183670, 183672, 183676, 183681, 183686, 183687, 183716, 183721, 183722, 183723, 183725, 183749, 183751, 183763, 183768, 183770, 183777, 183779, 183783, 183786, 183795, 183800, 183812, 183877, 183883, 183893, 183903, 183984, 183994, 184055, 184076, 184152, 184163, 184181, 184266, 184267, 184433, 184590, 184779, 184833, 184834, 184838, 184839, 184842, 184844, 184845, 184846, 184848, 184849, 184942, 184944, 184947, 184953, 184954, 184955, 184957, 184958, 184959, 184960, 184961, 184962, 184963, 184965, 184966, 184974, 184975, 184988, 184989, 184990, 184993, 185099, 185100, 185101, 185107, 185108, 185110, 185111, 185113, 185168, 185307, 185351, 185352, 185354, 185359, 185366, 185393, 185410, 185416, 185478, 185566, 185615, 185619, 185625, 185636, 185700, 185709, 185746, 185787, 185884, 186613, 187265, 187296, 187298, 187368, 187565, 187620, 187621, 187623, 187633, 187637, 187639, 187672, 187674, 187675, 187677, 187717, 187719, 187723, 187775, 187796, 188241, 188250, 188251, 188254, 188256, 188266, 188268, 188271, 188272, 188366, 189133, 189400, 189413, 189434, 189659, 189660, 189935, 189966, 190003, 191192, 191204, 191286, 191301, 191328, 191458, 191587, 191694, 192163, 192181, 192209, 192211, 192236, 192257, 192292, 192366, 192707, 192708, 192721, 192729, 192731, 192734, 192743, 192748, 192768, 192800, 192804, 192810, 192813, 193209, 193574, 193664, 193666, 193675, 193684, 193709, 193747, 193836, 193851, 193866, 193867, 193871, 193881, 193884, 193891, 193894, 193897, 193898, 193912, 193916, 193919, 193927, 193929, 193930, 193932, 193978, 193979, 193986, 194036, 194040, 194622, 194676, 194720, 194742, 194901, 195095, 195096, 195098, 195130, 195164, 195201, 195206, 195225, 195227, 195299, 195466, 195490, 195495, 195552, 195753, 195758, 195760, 196273, 196575, 196657, 196660, 196707, 196708, 196712, 196725, 196726, 196729, 196730, 196731, 196732, 196784, 196786, 196878, 196879, 196880, 196889, 197258, 197294, 197319, 197320, 197331, 197341, 197361, 197404, 197471, 198281, 198392, 198666, 198667, 198690, 198753, 198754, 198766, 198769, 198771, 198873, 198890, 199054, 199056, 199104, 199218, 199275, 199362, 199366, 199376, 199377, 199418, 199429, 199501, 199510, 199526, 199528, 199529, 199535, 199566, 199622, 199840, 199926, 199929, 201113, 201538, 202492, 202502, 202513, 202516, 202625, 202641, 202685, 202697, 202706, 202707, 202753, 202760, 202792, 202813, 202821, 202842, 203070, 203088, 203093, 203116, 203123, 203212, 203213, 203215, 203218, 203246, 203358, 203370, 203395, 204323, 204344, 204719, 204720, 204738, 204740, 204745, 204746, 204749, 204755, 204764, 204772, 204773, 204776, 204792, 204815, 204873, 204877, 204879, 204885, 204887, 204890, 204899, 204900, 204935, 204959, 204990, 204991, 205002, 205021, 205233, 205234, 205558, 205611, 205628, 205633, 205694, 205698, 205704, 205726, 205924, 205960, 205962, 205964, 205967, 205971, 205979, 205983, 205992, 206036, 206040, 206077, 206079, 206092, 206101, 206156, 206160, 206162, 206163, 206190, 206208, 206216, 206224, 206227, 206244, 206323, 206336, 206364, 206437, 206441, 206453, 206486, 206498, 206503, 206507, 206508, 206509, 206524, 206558, 206936, 206950, 206955, 206963, 206965, 207024, 207056, 207057, 207116, 207208, 207211, 207215, 207216, 207225, 207228, 207241, 207243, 207246, 207258, 207825, 208062, 208303, 208319, 208324, 208456, 208666, 208862, 208870, 209052, 209136, 209557, 209724, 209785, 209953, 209955, 210126, 210157, 210219, 210227, 210403, 210405, 210570, 210571, 210690, 210693]), ('reinforcement', [3494, 3506, 3508, 3512, 3523, 3702, 3749, 3764, 3765, 3822, 3824, 3835, 14321, 14323, 14328, 14334, 14344, 14443, 14444, 14490, 14503, 23223, 23254, 23259, 23383, 23476, 23509, 23512, 23513, 23516, 23643, 23660, 24058, 24168, 24170, 24181, 24220, 24237, 31714, 31727, 31769, 31779, 31790, 31807, 31808, 31811, 31816, 31823, 31837, 31843, 31865, 31867, 31872, 31882, 31925, 31937, 31940, 31942, 31944, 31955, 31962, 32203, 32217, 32226, 54692, 54693, 54704, 54706, 54732, 54733, 54744, 54747, 54763, 54765, 54767, 54768, 54804, 54805, 54857, 54877, 54878, 54975, 55021, 55032, 55043, 56777, 56926, 56939, 56940, 57116, 57290, 78318, 78331, 78364, 78384, 78386, 87974, 87994, 88103, 88120, 88276, 88323, 103668, 103669, 107815, 119224, 121172, 121188, 121190, 121200, 121201, 121203, 121208, 121234, 121239, 121322, 121584, 121635, 121640, 121643, 141883, 142175, 152004, 155530, 157278, 157305, 162363, 162373, 166996, 168148, 169045, 169051, 169064, 169065, 169073, 169087, 169090, 169571, 169577, 169591, 169613, 170189, 170194, 170202, 170248, 170251, 170289, 170476, 170510, 170511, 170530, 170551, 170561, 174241, 174247, 174263, 174272, 174276, 174277, 174278, 174283, 174285, 174510, 174511, 174662, 174732, 174770, 182099, 184957, 185314, 185747, 189612, 189614, 189655, 189656, 189660, 189674, 189677, 189679, 189686, 189693, 189728, 189761, 189765, 189766, 189772, 189778, 189781, 189785, 189786, 189787, 189826, 189827, 189829, 189843, 189844, 189859, 189865, 189880, 189882, 189918, 189920, 189922, 189939, 189943, 189969, 194076, 194103, 194134, 194138, 194146, 194148, 194152, 194158, 194177, 194193, 194247, 194594, 194627, 194650]), ('gradient', [3522, 3523, 3544, 3546, 3585, 3676, 3793, 3818, 4445, 4477, 4672, 4675, 4682, 4689, 4781, 4785, 5639, 5666, 6098, 7138, 7150, 7157, 7211, 7226, 7236, 7338, 7342, 8182, 8186, 8258, 10412, 14086, 17187, 18062, 18071, 18279, 18454, 18696, 19599, 19659, 19690, 19691, 19740, 20488, 21346, 21358, 21543, 21577, 21591, 21592, 21740, 21825, 22076, 22092, 22187, 23749, 24791, 25617, 25814, 26445, 26595, 26605, 26607, 26617, 26620, 26622, 26653, 26770, 26791, 26798, 26823, 27114, 27144, 27994, 28256, 28514, 30835, 32364, 32395, 32992, 32993, 33016, 33075, 33080, 33108, 33128, 33176, 33182, 33276, 33501, 33680, 34109, 34158, 34159, 34160, 34168, 34283, 34306, 36713, 38007, 38264, 38586, 38609, 39252, 39310, 39320, 39324, 39373, 39403, 39680, 41782, 42300, 42353, 42382, 42502, 42505, 42603, 44041, 44093, 44658, 44686, 44700, 45442, 45654, 45782, 48753, 48792, 50021, 52496, 52524, 52632, 52772, 53114, 54691, 54692, 54727, 54733, 54746, 54752, 54759, 54807, 54808, 54809, 54815, 54817, 54831, 54877, 54904, 55020, 55021, 55024, 55032, 55046, 55074, 56283, 56732, 56745, 56752, 56771, 57898, 58058, 58655, 59043, 60844, 60878, 60928, 60931, 61014, 61075, 61105, 61213, 62389, 62392, 63869, 63881, 65024, 65545, 65548, 65550, 65563, 66859, 67840, 67853, 69102, 69980, 69988, 70164, 72505, 73843, 73846, 73951, 73982, 74313, 74723, 74919, 74991, 75024, 75237, 75265, 75299, 76726, 76729, 76731, 76744, 78037, 78066, 78075, 78089, 78090, 78091, 78128, 78139, 79329, 79356, 79670, 79672, 79730, 79791, 79792, 80169, 80324, 80583, 80614, 81215, 81255, 81258, 81260, 81368, 81370, 81373, 81851, 81868, 82097, 82100, 82618, 83177, 83523, 83535, 84136, 84358, 84360, 84361, 84399, 84581, 84586, 84629, 84664, 84718, 84775, 84784, 84789, 84792, 84794, 84849, 85224, 85226, 85230, 85231, 85236, 85987, 86752, 87024, 87087, 87190, 87256, 87965, 88325, 88327, 89342, 89354, 90877, 90878, 91869, 91872, 92277, 92301, 92316, 92586, 92758, 92858, 92978, 92998, 93126, 96832, 96978, 97021, 97246, 99019, 99091, 102151, 102482, 102490, 102492, 102561, 102562, 102565, 102687, 102735, 102737, 102795, 102856, 102857, 103676, 103678, 103745, 107425, 107426, 107839, 107841, 107885, 111883, 111896, 111979, 111982, 112002, 113916, 113923, 113937, 113939, 113950, 114010, 114103, 114251, 114276, 115108, 115249, 117084, 117086, 117104, 117107, 117117, 117118, 117122, 117139, 119159, 120253, 120286, 120298, 120959, 121017, 121149, 121242, 121254, 121290, 123485, 124324, 124326, 124470, 124577, 126008, 126953, 129363, 129372, 129390, 129391, 129399, 129420, 129548, 129559, 129637, 129663, 129792, 131701, 131770, 131783, 131785, 131787, 131808, 131830, 132343, 132364, 132384, 132390, 132391, 132392, 132395, 132444, 132470, 132473, 132478, 132494, 132495, 132503, 132504, 132505, 132506, 132510, 132516, 132521, 132523, 132524, 132549, 132574, 132576, 132590, 132682, 132696, 132717, 132727, 132742, 132754, 132755, 132758, 132759, 132800, 132801, 132816, 132817, 132820, 132821, 132839, 132840, 132842, 132844, 132863, 133988, 137150, 137328, 137414, 137415, 137558, 139586, 140805, 141831, 141856, 141885, 141887, 141903, 141941, 141951, 141956, 141958, 142021, 142025, 144339, 144946, 144970, 145383, 146546, 146590, 148145, 149886, 149945, 149947, 150169, 150667, 150736, 155529, 156123, 156464, 156468, 156623, 156844, 158241, 158285, 158696, 158697, 158775, 158786, 158817, 158902, 158997, 161590, 164035, 164123, 164127, 164129, 164138, 164142, 164166, 164180, 164225, 164230, 164231, 164332, 164333, 164339, 164341, 164344, 164360, 164642, 164643, 164646, 165247, 166867, 167863, 168830, 170150, 171109, 171421, 171746, 176828, 177006, 177210, 177417, 177432, 177569, 177748, 177757, 177865, 177872, 182027, 182040, 182042, 182109, 182113, 182139, 182147, 182160, 182162, 182164, 182177, 182199, 182202, 182214, 182220, 182221, 182223, 182250, 182251, 182311, 182313, 182315, 182342, 182374, 182407, 182414, 182433, 182453, 182455, 182457, 182458, 182904, 186237, 186564, 186621, 187625, 187653, 188404, 188406, 188417, 188427, 188435, 188438, 188561, 188576, 188609, 188687, 188695, 188780, 189119, 189120, 190868, 190912, 191304, 191317, 191571, 193574, 194087, 194091, 194107, 194633, 194817, 194818, 194840, 195127, 195134, 195925, 197700, 197711, 197737, 197743, 197749, 197778, 197786, 197851, 197914, 197919, 197920, 197954, 197955, 198004, 198095, 198096, 200386, 200472, 201503, 201509, 201520, 201523, 201539, 201541, 201542, 201562, 201587, 201592, 201666, 201691, 201762, 201769, 201773, 201852, 201927, 201939, 201940, 201943, 201959, 203626, 203696, 203759, 203912, 203986, 204081, 204106, 204507, 204508, 204519, 204521, 204522, 204888, 205894, 207323, 207573, 207592, 207630, 207631, 207666, 208579, 208869, 208943, 209969, 209972, 210414, 210704]), ('learning', [405, 416, 446, 449, 848, 1003, 1018, 1030, 1221, 1224, 1254, 1259, 1348, 1350, 1351, 1432, 1433, 1435, 1437, 1451, 1713, 1733, 1845, 1860, 1881, 2131, 3495, 3507, 3533, 3568, 3611, 3612, 3749, 3773, 3814, 3824, 3828, 3836, 3838, 5643, 5683, 5692, 5694, 5703, 5720, 5727, 5755, 5758, 5765, 5777, 5877, 6041, 6042, 6046, 6416, 6428, 6429, 6434, 6436, 6446, 6453, 6501, 6506, 6517, 6984, 6995, 7003, 7122, 7138, 7148, 7177, 7248, 7257, 7285, 7302, 7304, 7318, 7332, 7340, 7577, 7582, 7822, 7838, 7862, 7868, 8022, 8180, 8181, 8195, 8196, 8197, 8201, 8237, 8245, 8351, 8478, 8576, 8587, 8637, 8646, 9232, 9257, 9465, 11118, 11174, 11926, 12291, 13039, 13902, 13914, 13917, 13966, 13968, 14195, 14197, 14198, 14246, 14275, 14277, 14305, 14326, 14337, 14343, 14344, 14354, 14361, 14373, 14420, 14421, 14443, 14455, 14462, 14467, 14482, 14489, 14505, 14517, 14527, 14565, 15567, 15576, 15582, 15588, 15671, 15745, 15853, 16879, 16908, 16910, 16929, 16986, 16991, 16995, 16999, 17045, 17051, 17052, 17059, 17081, 17176, 17177, 17178, 17180, 17185, 17191, 17200, 17202, 17254, 17324, 18032, 18033, 18039, 18044, 18058, 18061, 18069, 18071, 18072, 18073, 18078, 18079, 18091, 18094, 18096, 18099, 18108, 18112, 18176, 18263, 18272, 18279, 18285, 18369, 18371, 18372, 18375, 18377, 18391, 18392, 18395, 18397, 18402, 18403, 18407, 18408, 18409, 18411, 18413, 18414, 18415, 18416, 18417, 18419, 18420, 18424, 18429, 18432, 18453, 18457, 18460, 18463, 18464, 18465, 18481, 18488, 18905, 19166, 19171, 19188, 19193, 19229, 19239, 19269, 19345, 19570, 19587, 19588, 19590, 19592, 19599, 19604, 19607, 19742, 19743, 19744, 19745, 19747, 19771, 19776, 19780, 19789, 19808, 19815, 19816, 19819, 19820, 19823, 19825, 19827, 19830, 19832, 19887, 19904, 19912, 19914, 19915, 19917, 19921, 19923, 19925, 19930, 19939, 19941, 19946, 19949, 20030, 20100, 20163, 20179, 20337, 20622, 20988, 21001, 21031, 21288, 21291, 21318, 21321, 21343, 21485, 21489, 21490, 21529, 21531, 21543, 21546, 21554, 21572, 21575, 21576, 21595, 21635, 21693, 22090, 22097, 22487, 22783, 23223, 23251, 23254, 23255, 23259, 23279, 23280, 23351, 23361, 23372, 23444, 23469, 23475, 23476, 23483, 23507, 23509, 23512, 23513, 23516, 23536, 23645, 23654, 23660, 23661, 23663, 24040, 24061, 24070, 24107, 24298, 24390, 24392, 24397, 24432, 24436, 25071, 25072, 25604, 25617, 26094, 26098, 26605, 26606, 26660, 26771, 26856, 26859, 26872, 27046, 27155, 27515, 27532, 27585, 27625, 27858, 28296, 28458, 28501, 28608, 28620, 28622, 28639, 28661, 28666, 28670, 28715, 28758, 28767, 28772, 28898, 28944, 28956, 28957, 28958, 28959, 29016, 29628, 29993, 29997, 30396, 30397, 30400, 30402, 30412, 30786, 30826, 30834, 30838, 30844, 30986, 31024, 31026, 31125, 31186, 31188, 31246, 31417, 31418, 31483, 31556, 31558, 31562, 31575, 31579, 31727, 31739, 31744, 31748, 31770, 31774, 31778, 31781, 31784, 31790, 31805, 31807, 31809, 31811, 31816, 31837, 31838, 31843, 31857, 31858, 31859, 31873, 31875, 31881, 31901, 31902, 31911, 31916, 31918, 31925, 31962, 31964, 32196, 32197, 32205, 32206, 32210, 32219, 32221, 32226, 32257, 32374, 32570, 32572, 32573, 32588, 32733, 32815, 32823, 32850, 32892, 32896, 32912, 32942, 32950, 32971, 33054, 33056, 33063, 33069, 33082, 33164, 33180, 33265, 33276, 33277, 33439, 33445, 33447, 33452, 33469, 33471, 33484, 33487, 33489, 33539, 33542, 33550, 33566, 33845, 33896, 34000, 34004, 34012, 34027, 34034, 34040, 34043, 34057, 34076, 34080, 34104, 34106, 34107, 34117, 34161, 34182, 34187, 34212, 34326, 34327, 34466, 34521, 34550, 34553, 35341, 35648, 35810, 35816, 35817, 35825, 35841, 35914, 35919, 35966, 35967, 35972, 36160, 36161, 36164, 36171, 36472, 37118, 37127, 37129, 37136, 37140, 37179, 37182, 37184, 37278, 37309, 37311, 37322, 37331, 37440, 37470, 37495, 37515, 37516, 37519, 37521, 37631, 37638, 37654, 37715, 37716, 37754, 37768, 37791, 37808, 38214, 38217, 38225, 38227, 38230, 38264, 38275, 38276, 38284, 38291, 38293, 38401, 38514, 38525, 38530, 38643, 38646, 38651, 38653, 38655, 39238, 39242, 39250, 39258, 39292, 39323, 39494, 39505, 39511, 39574, 39658, 39673, 39686, 39733, 39746, 39750, 39762, 39769, 40354, 40356, 40362, 40363, 40376, 40381, 40383, 40404, 40483, 40501, 40502, 40503, 40559, 40560, 40636, 40653, 40729, 40733, 40907, 40953, 40984, 40998, 41005, 41095, 41114, 41124, 41178, 41182, 41184, 41187, 41202, 41212, 41420, 41425, 41426, 41428, 41547, 42197, 42248, 42252, 42292, 42353, 42357, 42359, 42680, 42892, 42894, 42904, 43349, 43403, 43412, 43435, 43489, 43642, 43673, 43703, 43839, 43867, 43868, 43917, 43936, 43944, 43952, 43954, 43981, 43994, 44003, 44013, 44032, 44075, 44080, 44082, 44094, 44096, 44118, 44710, 44952, 45404, 45414, 45551, 45577, 45741, 45742, 45743, 45746, 45747, 45748, 45749, 45753, 45754, 45756, 45761, 45764, 45767, 45768, 45769, 45770, 45847, 45852, 45864, 45873, 45944, 45951, 45952, 46028, 46031, 46039, 46042, 46059, 46124, 46131, 46132, 46592, 46737, 46783, 47248, 47421, 47469, 47591, 47622, 47662, 48018, 48065, 48713, 48751, 49021, 49075, 49150, 49158, 49174, 49182, 49205, 49419, 49557, 49558, 49560, 49564, 50635, 51659, 52826, 52833, 53090, 53095, 53111, 53115, 53173, 53175, 53185, 53385, 53400, 53454, 53583, 53657, 53682, 53684, 53692, 53694, 53701, 53760, 53764, 53765, 54099, 54244, 54249, 54260, 54264, 54337, 54339, 54495, 54645, 54649, 54656, 54732, 55000, 55061, 55066, 55075, 55089, 55130, 55156, 55265, 55269, 55290, 56266, 56271, 56344, 56404, 56410, 56421, 56457, 56470, 56473, 56522, 56523, 56552, 56577, 56582, 56634, 56635, 56648, 56650, 56660, 56712, 56718, 56739, 56768, 56770, 56772, 56781, 56783, 56785, 56786, 56942, 56961, 57114, 57115, 57119, 57282, 57289, 57295, 57319, 57323, 57341, 58176, 58235, 58569, 58577, 58637, 58731, 58937, 58939, 58941, 58942, 58943, 58948, 58951, 58953, 58973, 59047, 59073, 59074, 59131, 59153, 59189, 59230, 59233, 59306, 59425, 59433, 59706, 59772, 59776, 59870, 60007, 60013, 60129, 60131, 60260, 60322, 60324, 60325, 60329, 60339, 60845, 60859, 60929, 60975, 60988, 61075, 61105, 61257, 62392, 62395, 63222, 63300, 63401, 63504, 63509, 63520, 63526, 63983, 63990, 63992, 64005, 64013, 64014, 64117, 64120, 64142, 64143, 64403, 64407, 64953, 64955, 64957, 64958, 64960, 64962, 64969, 64970, 64973, 64981, 65251, 65279, 65304, 65408, 65409, 65425, 66875, 67792, 67804, 67840, 67875, 67876, 67897, 67926, 68000, 68024, 68025, 68129, 68140, 68149, 68205, 68206, 68274, 68292, 68294, 68312, 68328, 68826, 68837, 68838, 68839, 68850, 68852, 68855, 68873, 68874, 68886, 68893, 68895, 68947, 69001, 69002, 69026, 69037, 69090, 69091, 69092, 69095, 69102, 69119, 69176, 69299, 69300, 69312, 69323, 69324, 69338, 69341, 69351, 69355, 69379, 69387, 69388, 69412, 69470, 69851, 69854, 69894, 70387, 70399, 70405, 70504, 70514, 70551, 70706, 70925, 70928, 70949, 70992, 71202, 71204, 71205, 71210, 71265, 71336, 71352, 71359, 71360, 71362, 71378, 71385, 71386, 71438, 71448, 71487, 71524, 71532, 71542, 71598, 73058, 73765, 73785, 73932, 73984, 74004, 74053, 74072, 74351, 74352, 74368, 74445, 74586, 74587, 74588, 74590, 74592, 74598, 74606, 74713, 74897, 74911, 74934, 74961, 75005, 75008, 75012, 75070, 75072, 75076, 75265, 75270, 75271, 75323, 75417, 75437, 75439, 75440, 75457, 75460, 75463, 75466, 75467, 75470, 75768, 75782, 75796, 75799, 75800, 75830, 75834, 75965, 75976, 76589, 76593, 77232, 77522, 77951, 78010, 78026, 78040, 78044, 78046, 78051, 78056, 78057, 78105, 78109, 78110, 78118, 78153, 78189, 78293, 78295, 78306, 78326, 78331, 78362, 78365, 78372, 78381, 78384, 78387, 79325, 79331, 79344, 79449, 79454, 80407, 80428, 80454, 80457, 80488, 80490, 80498, 80523, 80536, 80578, 80610, 80663, 80684, 80688, 80778, 80784, 80796, 80803, 80869, 81033, 81099, 81116, 81131, 81869, 82108, 82109, 82379, 82417, 82499, 82515, 82596, 82684, 82705, 82712, 82742, 82757, 83535, 83760, 83795, 83798, 83838, 83843, 83851, 83878, 83882, 83884, 83931, 83942, 83974, 83975, 84024, 84287, 84304, 84322, 84339, 84357, 84358, 84361, 84364, 84376, 84378, 84379, 84388, 84399, 84401, 84534, 84586, 84588, 84590, 84651, 84703, 84734, 84739, 84772, 84775, 84779, 85236, 85265, 85344, 85350, 85355, 85372, 85399, 85413, 85423, 85521, 85674, 85751, 85955, 85993, 86012, 86020, 86582, 86729, 86752, 86762, 86832, 86833, 86886, 86889, 86915, 86937, 87257, 87333, 87373, 87406, 87407, 87433, 87966, 87974, 87990, 88081, 88098, 88103, 88106, 88121, 88174, 88245, 88254, 88265, 88304, 88311, 88323, 88331, 88332, 88355, 88378, 89348, 90430, 90666, 90759, 90770, 90791, 90800, 90807, 90834, 90891, 91001, 91015, 91093, 91097, 91154, 91166, 91172, 91180, 91204, 91205, 91236, 91238, 91240, 91296, 91302, 91332, 91357, 91360, 91363, 91431, 91433, 91452, 91459, 91464, 91477, 91479, 91491, 91494, 91557, 91559, 91621, 91623, 91639, 91723, 91730, 91745, 91761, 91763, 91773, 91776, 92316, 92798, 92800, 92819, 92865, 92892, 92957, 93140, 93203, 96542, 96561, 96600, 96831, 96832, 96843, 96846, 96848, 96851, 96871, 96996, 97018, 97035, 97039, 97050, 97092, 97101, 97246, 97247, 97803, 98284, 98408, 98868, 98870, 98883, 98886, 99061, 99075, 99306, 99312, 99313, 99331, 99827, 99839, 99840, 99852, 99891, 99907, 99933, 99939, 99945, 99947, 99964, 99978, 99980, 99981, 99982, 99990, 99997, 100079, 100108, 100154, 100161, 100210, 100214, 100223, 100224, 100228, 100229, 100344, 100355, 100357, 100361, 100362, 100367, 100376, 100379, 100385, 100391, 100397, 100406, 100408, 100432, 100434, 100437, 100444, 100446, 100447, 100454, 100470, 100476, 100903, 100921, 101023, 101027, 101045, 101048, 101053, 101075, 101104, 101166, 101335, 101405, 101619, 101631, 101634, 101652, 101680, 101690, 101714, 101716, 101838, 101850, 101925, 102014, 102015, 102144, 102148, 102171, 102223, 102224, 102227, 102229, 102230, 102265, 102268, 102278, 102279, 102288, 102290, 102292, 102294, 102301, 102308, 102324, 102338, 102380, 102430, 102436, 102438, 102471, 102483, 102489, 102559, 102572, 102650, 102655, 102656, 102657, 102659, 102660, 102672, 102676, 102684, 102689, 102701, 102705, 103676, 104449, 104453, 104501, 104505, 104507, 104636, 104638, 104660, 104661, 104663, 104674, 104773, 104978, 104980, 104989, 104991, 104992, 104995, 104998, 105000, 105020, 105310, 105333, 105832, 106092, 106349, 106566, 106869, 107670, 107723, 107767, 107798, 107815, 107842, 107850, 107859, 107867, 107876, 107885, 107888, 107904, 107907, 107912, 107926, 107936, 107938, 107942, 107943, 107946, 107952, 107964, 108033, 108046, 108140, 108210, 108215, 108230, 108235, 108239, 108745, 108957, 109029, 109052, 109055, 109772, 109804, 110667, 110669, 110674, 110676, 110685, 110686, 110688, 110693, 110696, 110742, 111023, 111106, 111108, 111109, 111110, 111143, 111771, 111782, 111792, 111827, 111831, 111837, 111842, 111854, 111974, 112025, 112099, 112123, 112140, 112232, 112240, 112249, 112261, 112264, 112284, 113324, 113332, 113838, 113867, 113876, 114240, 114324, 114446, 114457, 114459, 114476, 114630, 114966, 114972, 115014, 115021, 115092, 115457, 116093, 116456, 116459, 116753, 117145, 117857, 117864, 117966, 118125, 118127, 118150, 118902, 119143, 119160, 119305, 119395, 119474, 119504, 119617, 120232, 120286, 120454, 120599, 120612, 120621, 120672, 120676, 120680, 120754, 120809, 120811, 120813, 120814, 120819, 120833, 120897, 120898, 120930, 120934, 120935, 120968, 120969, 121183, 121186, 121190, 121201, 121203, 121207, 121208, 121234, 121239, 121251, 121253, 121266, 121345, 121349, 121356, 121538, 121542, 121569, 121570, 121584, 121626, 121640, 121643, 121654, 121655, 121656, 121657, 121658, 121660, 121664, 121667, 121673, 121676, 121678, 121681, 121696, 121698, 121699, 121735, 121740, 121750, 121800, 121802, 121806, 121997, 122083, 122093, 122185, 122187, 122191, 122258, 122260, 122264, 122269, 122270, 122276, 122361, 122700, 122703, 123276, 123928, 123935, 124123, 124316, 124411, 124484, 124677, 125458, 125481, 125493, 125594, 125776, 125778, 126345, 126394, 126416, 126425, 126614, 126664, 126681, 126696, 126808, 126812, 126851, 126857, 126873, 126953, 126979, 126994, 127050, 127266, 127272, 127358, 127365, 127368, 127369, 127417, 127420, 127435, 127892, 127902, 127904, 127923, 127928, 127930, 127935, 127944, 128011, 128136, 128153, 128186, 128230, 128231, 128236, 128378, 128921, 128932, 128958, 128965, 128974, 128975, 128984, 129368, 129378, 129380, 129420, 129428, 129451, 129453, 129549, 129554, 129635, 129637, 129651, 129774, 129785, 129805, 129807, 129817, 129839, 129963, 129966, 130419, 130795, 130890, 130891, 131065, 131132, 131356, 131359, 131400, 131418, 131829, 131835, 131931, 131940, 131942, 131954, 131961, 131970, 131984, 132002, 132005, 132007, 132012, 132015, 132019, 132022, 132262, 132294, 132301, 132336, 132351, 132472, 132872, 132885, 132887, 132902, 132930, 132953, 132956, 133427, 133436, 134315, 134326, 135289, 135444, 135472, 135473, 135605, 135668, 136088, 136717, 136787, 136790, 136931, 136932, 136992, 137132, 137150, 137158, 137307, 137328, 137425, 137444, 137519, 137527, 137569, 137653, 137665, 137794, 139558, 139717, 139928, 140046, 140047, 140052, 140077, 140079, 140085, 140090, 140091, 140100, 140102, 140103, 140105, 140106, 140110, 140145, 140197, 140198, 140237, 140244, 140349, 140360, 140534, 140535, 140560, 140562, 140564, 140570, 140571, 140596, 140658, 140777, 140803, 140850, 140966, 141006, 141045, 141762, 141772, 141788, 141791, 141881, 141883, 141887, 141961, 142018, 142034, 142117, 142123, 142154, 142174, 142175, 142207, 142635, 142674, 143388, 143414, 143433, 144338, 144339, 144612, 144778, 144781, 144879, 144888, 144890, 145612, 145623, 145754, 145770, 145833, 145851, 146067, 146130, 146179, 146182, 146184, 146257, 146263, 146552, 146557, 146575, 146594, 146611, 146626, 146629, 146640, 147076, 148265, 148282, 148302, 148357, 148445, 148512, 148653, 148707, 149539, 150172, 150355, 150642, 150646, 150667, 150703, 150735, 150739, 150795, 150804, 150811, 151122, 151636, 152537, 152671, 155530, 155826, 155835, 156147, 156353, 156468, 156492, 156711, 156848, 156952, 156979, 157027, 157501, 157502, 157515, 157537, 157549, 157578, 157616, 157618, 157814, 158119, 158254, 158304, 158326, 158415, 158610, 158652, 158664, 158680, 158696, 158723, 158725, 158728, 158730, 158734, 158788, 158815, 158826, 159204, 159211, 159213, 159967, 160074, 160115, 160170, 160472, 160474, 161591, 161599, 162197, 162360, 162363, 162373, 162522, 162590, 162604, 162733, 162737, 163035, 163676, 164123, 164138, 164154, 164155, 164156, 164158, 164230, 164339, 164343, 164345, 164353, 164357, 164360, 164361, 164372, 164389, 164392, 164474, 164480, 164482, 164485, 164588, 164592, 164594, 164595, 164597, 164607, 164642, 164650, 164659, 164711, 164720, 164722, 164725, 165071, 165092, 165094, 165176, 165178, 165182, 165193, 165214, 165230, 165235, 165282, 165283, 165295, 165296, 165298, 165311, 165332, 165345, 165352, 165498, 165499, 165502, 165528, 165529, 165531, 165663, 165701, 165703, 165714, 165720, 165725, 165829, 165830, 165831, 165834, 165847, 165853, 165973, 165977, 165987, 165995, 165998, 166003, 166006, 166016, 166029, 166031, 166032, 166033, 166034, 166035, 166055, 166057, 166065, 166067, 166170, 166171, 166173, 166175, 166197, 166201, 166202, 166203, 166218, 166225, 166227, 166228, 166229, 166230, 166584, 166669, 166674, 166965, 166973, 166974, 166984, 166996, 167006, 167011, 167019, 167022, 167061, 167067, 167077, 167079, 167084, 167096, 167253, 167351, 167391, 167427, 167441, 167490, 167495, 167519, 167548, 167598, 167819, 167821, 167824, 167825, 167827, 167828, 167830, 167997, 168093, 168128, 168167, 168748, 168749, 168831, 169045, 169051, 169058, 169064, 169065, 169073, 169077, 169087, 169090, 169097, 169193, 169197, 169234, 169316, 169545, 169564, 169571, 169577, 169591, 169613, 169619, 169640, 169642, 169649, 169667, 169668, 169769, 169770, 169774, 169783, 169789, 169790, 169791, 169801, 169809, 169832, 169840, 169860, 169866, 169870, 169874, 169898, 170023, 170036, 170038, 170042, 170044, 170050, 170054, 170082, 170091, 170100, 170102, 170112, 170117, 170162, 170202, 170204, 170235, 170251, 170266, 170425, 170428, 170429, 170466, 170469, 170476, 170551, 170556, 170559, 170562, 170888, 171021, 172988, 173547, 173557, 173560, 173568, 173569, 173571, 173572, 173574, 173632, 174054, 174119, 174198, 174199, 174202, 174241, 174242, 174247, 174257, 174260, 174263, 174273, 174276, 174277, 174279, 174281, 174283, 174315, 174316, 174462, 174510, 174511, 174550, 174647, 174651, 174659, 174662, 174727, 174732, 174745, 174753, 175905, 176755, 176773, 176801, 177036, 177099, 177107, 177377, 177380, 177383, 177384, 177400, 177919, 177941, 177942, 177967, 177968, 177969, 177979, 177980, 177982, 178011, 178028, 178029, 178031, 178060, 178083, 178101, 178120, 178130, 178133, 178134, 178166, 178183, 178185, 178199, 178211, 178457, 178458, 178811, 179580, 179622, 179623, 179657, 179663, 179668, 179673, 179686, 179690, 179704, 179865, 179926, 180020, 180021, 180303, 181996, 181998, 182003, 182009, 182017, 182021, 182041, 182099, 182101, 182113, 182119, 182121, 182122, 182140, 182145, 182178, 182198, 182203, 182224, 182228, 182239, 182243, 182314, 182316, 182375, 182409, 182410, 182411, 182414, 182433, 182451, 182454, 182456, 182531, 182567, 182756, 183508, 183509, 183884, 183944, 184167, 184259, 184402, 184405, 184407, 184410, 184422, 184429, 184433, 184454, 184490, 184491, 184494, 184502, 184503, 184513, 184514, 184531, 184590, 184631, 184638, 184640, 184657, 184658, 184713, 184777, 184781, 184784, 184786, 184857, 184948, 184956, 184981, 185057, 185078, 185085, 185093, 185104, 185167, 185303, 185304, 185307, 185308, 185313, 185314, 185317, 185322, 185325, 185335, 185345, 185346, 185354, 185357, 185360, 185366, 185367, 185369, 185397, 185481, 185506, 185516, 185517, 185519, 185524, 185564, 185574, 185627, 185628, 185629, 185635, 185700, 185701, 185706, 185709, 185714, 185739, 185744, 185746, 185747, 185755, 185762, 185787, 185788, 185862, 185884, 185885, 185906, 185974, 186078, 186141, 186209, 186219, 186229, 186318, 186461, 186507, 186517, 186519, 186523, 186783, 186834, 186867, 186879, 186881, 186908, 186943, 187081, 187082, 187083, 187201, 187355, 188374, 189127, 189256, 189594, 189621, 189630, 189639, 189644, 189654, 189674, 189677, 189679, 189686, 189694, 189706, 189724, 189767, 189768, 189777, 189782, 189785, 189788, 189842, 189862, 189868, 189872, 189878, 189892, 189926, 189928, 189939, 189942, 189956, 189960, 189966, 189967, 189999, 190016, 190034, 190047, 190050, 190080, 190082, 190519, 190590, 190597, 190604, 190695, 190696, 190715, 190718, 190719, 190762, 190763, 190764, 190779, 190803, 190804, 190811, 190820, 190833, 190845, 190847, 190848, 190849, 190853, 190860, 190894, 190901, 190905, 190957, 190960, 190963, 191157, 191169, 191178, 191180, 191188, 191190, 191203, 191208, 191217, 191220, 191272, 191281, 191571, 191688, 191691, 191696, 192205, 192233, 192256, 192462, 192477, 192482, 192693, 192745, 192757, 192761, 192763, 192765, 192770, 192885, 192982, 193004, 193100, 193132, 193136, 193137, 193165, 193261, 193585, 194076, 194086, 194088, 194089, 194096, 194103, 194113, 194126, 194138, 194152, 194157, 194193, 194399, 194400, 194483, 194586, 194594, 194595, 194610, 194613, 194618, 194627, 194651, 194669, 194670, 194682, 194723, 194745, 194761, 194815, 194825, 194832, 194844, 194851, 195086, 195088, 195122, 195127, 195149, 195152, 195204, 195418, 195544, 195805, 195809, 195826, 195827, 195829, 195839, 195841, 195953, 196231, 197275, 197705, 197711, 197712, 197749, 197769, 197771, 197805, 197836, 197842, 197850, 197861, 197863, 197865, 197869, 197883, 197902, 197956, 197979, 198078, 198081, 198087, 198091, 198094, 198102, 198195, 198197, 198265, 198266, 198281, 198288, 198289, 198754, 198755, 198758, 198759, 198767, 198769, 198770, 198851, 198879, 198915, 198969, 199027, 199104, 199105, 199106, 199109, 199127, 199195, 199202, 199203, 199204, 199205, 199206, 199305, 199307, 199308, 199323, 199342, 199565, 199570, 199584, 199842, 199843, 199844, 199923, 200104, 200436, 200469, 200489, 200774, 200854, 201508, 201540, 201704, 201937, 201984, 202408, 202489, 202504, 202528, 202603, 202643, 203065, 203102, 203165, 203169, 203176, 203187, 203392, 203621, 203634, 203677, 203695, 203766, 203814, 203890, 203898, 203912, 204073, 204076, 204081, 204087, 204097, 204105, 204110, 204111, 204321, 204335, 204507, 204677, 204684, 204687, 204692, 204701, 204704, 204786, 205701, 205708, 205727, 205728, 205777, 205780, 205860, 205878, 205880, 205958, 205969, 205981, 205985, 206013, 206613, 206655, 206657, 206667, 206674, 206676, 206677, 206749, 206751, 206754, 206757, 206770, 206785, 206881, 206899, 206904, 207257, 207318, 207323, 207324, 207328, 207346, 207350, 207353, 207361, 207370, 207371, 207373, 207375, 207439, 207478, 207497, 207556, 207563, 207572, 207591, 207640, 207644, 207677, 207742, 207807, 207817, 207831, 207835, 207844, 208480, 208870, 208930, 209045, 209085, 209092, 209098, 209108, 209110, 209112, 209116, 209119, 209132, 209135, 209136, 209148, 209170, 209171, 209179, 209210, 209221, 209382, 209388, 209477, 209482, 209517, 209520, 209536, 209538, 209544, 209549, 209560]), ('machine learning', [7213, 15567, 54649, 60859, 83838, 83851, 84651, 99312, 101053, 101405, 104453, 105333, 108046, 108230, 117857, 131953, 132885, 140090, 150646, 156353, 156848, 204701]), ('gaussian', [14029, 14030, 14036, 14037, 16879, 16922, 16926, 16943, 16987, 16993, 17046, 17176, 18637, 18645, 21130, 21184, 21193, 21344, 21372, 21433, 21435, 33460, 35830, 35861, 35887, 35888, 42347, 42349, 45425, 45430, 45431, 45527, 45554, 45844, 65018, 73838, 74442, 78211, 83991, 84195, 84723, 84724, 84726, 84728, 85612, 85630, 86978, 87086, 87239, 87249, 87254, 87267, 87294, 87297, 87460, 87536, 92033, 92035, 102219, 104030, 121235, 121268, 121273, 121274, 121303, 121335, 121336, 121338, 121731, 124278, 124333, 124348, 124369, 124371, 124375, 124384, 124386, 124400, 124401, 124419, 124463, 124465, 124467, 124468, 124578, 128243, 129541, 137008, 139609, 139696, 139697, 139704, 139709, 150890, 150982, 151370, 160250, 163878, 164351, 164352, 166445, 171093, 171160, 173925, 177557, 179224, 192883, 192889, 192982, 194092, 194093, 194205, 202633, 204441, 204472, 204476, 204477, 204790, 204795, 204797, 209971, 209973, 209981])])\n",
            "converted target toks [['marko', '##v'], ['deep', 'learning'], ['supervised'], ['gradient', 'descent'], ['supervised', 'learning'], ['neural', 'network'], ['dimensional', '##ity', 'reduction'], ['component', 'analysis'], ['time', 'series'], ['neural'], ['neighbor'], ['monte', 'carlo'], ['reinforcement', 'learning'], ['hidden', 'marko', '##v'], ['model'], ['reinforcement'], ['gradient'], ['learning'], ['machine', 'learning'], ['ga', '##uss', '##ian']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(t1)\n",
        "print(len(index_t1))\n",
        "print(len(index_t2))\n",
        "# target_toks\n",
        "\n",
        "len(list(index_t1.values())[1])\n"
      ],
      "metadata": {
        "id": "dkhf0E9Zoo1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659449f0-96ef-414a-8b4b-a80eba732009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _pre_bert(doc,index,t):\n",
        "  \n",
        "  # index =  index_t1 -> { target_w1: index, target_w2: index2, target_w1 : index5 } -  index = Sentence index in which target word appears\n",
        "  s=[\"Not Found\"]  \n",
        "  \n",
        "  if t in index.keys():\n",
        "      s=[doc[ind] for ind in index[t]]\n",
        "\n",
        "  print('len of sentences',len(s))\n",
        "  l=len(s)\n",
        "  marked_text = [\"[CLS] \" + text + \" [SEP]\" for text in s]\n",
        "  tokenized_text = [tokenizer.tokenize(m) for m in marked_text]\n",
        "  \n",
        "  tokenized_text=[x[:512] if len(x)>512 else x for x in tokenized_text]\n",
        "  indexed_tokens = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n",
        "  segments_ids = [[1] * len(x) for x in tokenized_text]\n",
        "  return s,marked_text,tokenized_text,indexed_tokens,segments_ids,l\n",
        "\n",
        "\n",
        "def _bert_features(tokens_tensor, segments_tensors,tokenized_text):\n",
        "  # print(len(tokens_tensor[0]))\n",
        "  with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
        "  # print (\"Number of layers:\", len(encoded_layers))\n",
        "  layer_i = 0\n",
        "\n",
        "  # # print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "  batch_i = 0\n",
        "\n",
        "  # print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "  token_i = 0\n",
        "\n",
        "  # print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
        "  # Convert the hidden state embeddings into single token vectors\n",
        "\n",
        "  # Holds the list of 12 layer embeddings for each token\n",
        "  # Will have the shape: [# tokens, # layers, # features]\n",
        "  token_embeddings = [] \n",
        "\n",
        "  # For each token in the sentence...\n",
        "  # tokenized_text=[x for x in tokenized_text if x not in ['_', 'n', '##n','v', '##b']]\n",
        "  for token_i in range(len(tokenized_text)):\n",
        "    \n",
        "    # Holds 12 layers of hidden states for each token \n",
        "    hidden_layers = [] \n",
        "    \n",
        "    # For each of the 12 layers...\n",
        "    for layer_i in range(len(encoded_layers)):\n",
        "      \n",
        "      # Lookup the vector for `token_i` in `layer_i`\n",
        "      vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "      \n",
        "      hidden_layers.append(vec)\n",
        "      \n",
        "    token_embeddings.append(hidden_layers)\n",
        "\n",
        "  # Sanity check the dimensions:\n",
        "  # print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
        "  # print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
        "  return token_embeddings\n",
        "# s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "def _get_embeddings(pre,tg):\n",
        "  m_embed_full=[]\n",
        "  # print('len(pre[0])',len(pre[0]))\n",
        "  # print(tg)\n",
        "  for _,item in enumerate(pre[0]):\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    # print(item)\n",
        "    token_list=pre[2][_]\n",
        "    \n",
        "    tokens_tensor = torch.tensor([pre[3][_]])\n",
        "    segments_tensors = torch.tensor([pre[4][_]])\n",
        "    # Predict hidden states features for each layer\n",
        "    token_embeddings=_bert_features(tokens_tensor, segments_tensors,pre[2][_])\n",
        "    concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
        "\n",
        "    summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]\n",
        "    \n",
        "    #consider the tokenized target\n",
        "  \n",
        "    indxs=[]\n",
        "    # print(token_list)\n",
        "    for tok in tg:\n",
        "      '''\n",
        "      remove -1,-2,-3\n",
        "      '''\n",
        "      if tok in token_list:\n",
        "        if tok not in ['_', 'n', '##n','v', '##b']:\n",
        "          indxs.append(token_list.index(tok))\n",
        "\n",
        "    # print('indxs',indxs)\n",
        "    if len(indxs)==1:\n",
        "      #bert_embed=concatenated_last_4_layers [indxs[0]]\n",
        "      bert_embed=summed_last_4_layers [indxs[0]]\n",
        "\n",
        "      m_embed_full.append(bert_embed)\n",
        "    elif len(indxs)>1:\n",
        "      b_emb=[]\n",
        "      for ind in indxs:\n",
        "        #b_emb.append(concatenated_last_4_layers[ind])\n",
        "        b_emb.append(summed_last_4_layers[ind])\n",
        "        \n",
        "      bert_embed= torch.sum(torch.stack(b_emb), 0)\n",
        "      m_embed_full.append(bert_embed)\n",
        "    # indx=token_list.index(tg.lower())\n",
        "    # indx = [i for (i, elem) in enumerate(pre[2][_]) if t in elem]\n",
        "    # print('indx',indx)\n",
        "    # print(pre[1][_],indx)\n",
        "\n",
        "    # if len(indx)>0:\n",
        "    # bert_embed=concatenated_last_4_layers[indx[0]]\n",
        "    \n",
        "    # cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
        "    \n",
        "    \n",
        "  return  m_embed_full, summed_last_4_layers\n",
        "# For a particular target word,do clustering and find if there is a sense change\n"
      ],
      "metadata": {
        "id": "ec5y4w-gqamr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding for all time windows\n",
        "\n",
        "sents_all=[]\n",
        "\n",
        "# Holds all bert embeddings \n",
        "# [] -> [[embedding1], [embedding2],...]\n",
        "X=[]\n",
        "\n",
        "def embeddings_extract(target_words,target_toks,doc1,index_t1):\n",
        "  t=target_words\n",
        "  X_C1=[]\n",
        "  lens1=[]\n",
        "  for k,t in enumerate(target_words) :\n",
        "    berts=[]\n",
        "    sents=[]\n",
        "    print('The target word is',t)    \n",
        "    \n",
        "    #get the sentences from corpus c1 and c2 for the specific target word 't'\n",
        "    \n",
        "    # This will generate tokenized sentences, tokens for the specific word. Or sentences containing specific word\n",
        "    pre1=_pre_bert(doc1,index_t1,t)\n",
        "\n",
        "    # lens1.append(pre1[-1])\n",
        "    # lens2.append(pre2[-1])\n",
        "    # print(pre1)\n",
        "    \n",
        "    sents.extend(pre1[0])\n",
        "    #aggregate all the embeddings\n",
        "    # s,marked_text,tokenized_text,indexed_tokens,segments_ids\n",
        "\n",
        "    '''\n",
        "    Get the embeddings of the targets from corpus 1 and 2\n",
        "    '''\n",
        "    _ , b1=_get_embeddings(pre1,target_toks[k])\n",
        "    print('len of t1',len(b1))\n",
        "    \n",
        "    '''\n",
        "    store the lenghts of no. of sentences extracted for each target word for each corpus\n",
        "    '''\n",
        "    lens1.append(len(b1))\n",
        "    \n",
        "    berts.extend(b1)\n",
        "    print('len of each target word extractions is',len(berts))\n",
        "    X.append(berts)\n",
        "\n",
        "    # ______________ Placeholder to flatten the tensors into 1-D tensor for the \n",
        "    #           respective sentence tensors of specific keyword _______________ (b1)\n",
        "\n",
        "    X_C1.append(b1)# the embeddings for C1\n",
        "    sents_all.append(sents)\n",
        "  return X,X_C1,lens1,sents_all\n",
        "\n"
      ],
      "metadata": {
        "id": "encxlY89yzVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### BERT FOR Vocabulary\n",
        "\n",
        "def bert_text_preparation(text, tokenizer):\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1]*len(indexed_tokens)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    return tokenized_text, tokens_tensor, segments_tensors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_v_embeddings(v):\n",
        "    target_word_embeddings = []\n",
        "    for text in v:\n",
        "        tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
        "        list_token_embeddings = _bert_features(tokens_tensor, segments_tensors, tokenized_text)\n",
        "        summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in list_token_embeddings] # [number_of_tokens, 768]\n",
        "        bert_embed= torch.sum(torch.stack(summed_last_4_layers), 0)\n",
        "        # # Find the position 'bank' in list of tokens\n",
        "        # word_index = tokenized_text.index('bank')\n",
        "        # # Get the embedding for bank\n",
        "        # word_embedding = list_token_embeddings[word_index]\n",
        "\n",
        "        # target_word_embeddings.append(word_embedding)\n",
        "        target_word_embeddings.append(bert_embed)\n",
        "        \n",
        "    return  target_word_embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "DH9y10UtlPBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "v1_emb = extract_v_embeddings(v1)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time {end - start} \\n')\n",
        "len(v1_emb)\n"
      ],
      "metadata": {
        "id": "4Q15aYNK5JKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1_emb = extract_v_embeddings(v1)\n",
        "v2_emb = extract_v_embeddings(v2)\n",
        "v3_emb = extract_v_embeddings(v3)\n",
        "v4_emb = extract_v_embeddings(v4)\n",
        "v5_emb = extract_v_embeddings(v5)\n",
        "\n"
      ],
      "metadata": {
        "id": "F_SBEU4PSRzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_map1 = {\n",
        "\n",
        "    \"v1_emb\":v1_emb,\n",
        "    \"v2_emb\":v2_emb,\n",
        "    \"v3_emb\":v3_emb,\n",
        "    \"v4_emb\":v4_emb,\n",
        "    \"v5_emb\":v5_emb\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_emb2.pickle', 'wb+') as f:\n",
        "     pickle.dump(v_map1, f)"
      ],
      "metadata": {
        "id": "msoaI5QESfnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v6_emb = extract_v_embeddings(v6)\n",
        "v7_emb = extract_v_embeddings(v7)\n",
        "v8_emb = extract_v_embeddings(v8)\n",
        "\n",
        "v_map2 = {\n",
        "\n",
        "    \"v6_emb\":v6_emb,\n",
        "    \"v7_emb\":v7_emb,\n",
        "    \"v8_emb\":v8_emb\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_emb2.pickle', 'ab+') as f:\n",
        "     pickle.dump(v_map2, f)"
      ],
      "metadata": {
        "id": "_EoOdJJRS2r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v9_emb = extract_v_embeddings(v9)\n",
        "v10_emb = extract_v_embeddings(v10)\n",
        "\n",
        "\n",
        "v_map3 = {\n",
        "\n",
        "    \"v9_emb\":v9_emb,\n",
        "    \"v10_emb\":v10_emb\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/vocabulary_emb2.pickle', 'ab+') as f:\n",
        "     pickle.dump(v_map3, f)"
      ],
      "metadata": {
        "id": "CgIyBjOGTDbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "# embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "\n",
        "# lens=[len_c1]\n",
        "# # lens.append(len_c2)\n",
        "# print('saved')\n",
        "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "LLgkz2ZztHOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")"
      ],
      "metadata": {
        "id": "sWzlJE8F5UGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT Embeddings\n",
        "\n",
        "embed_full,embed_C1,len_c1,sents=embeddings_extract(target_words,target_toks,doc1,index_t1)\n",
        "embed_full,embed_C2,len_c2,sents=embeddings_extract(target_words,target_toks,doc2,index_t2)\n",
        "embed_full,embed_C3,len_c3,sents=embeddings_extract(target_words,target_toks,doc3,index_t3)\n",
        "embed_full,embed_C4,len_c4,sents=embeddings_extract(target_words,target_toks,doc4,index_t4)\n",
        "embed_full,embed_C5,len_c5,sents=embeddings_extract(target_words,target_toks,doc5,index_t5)\n"
      ],
      "metadata": {
        "id": "KPcYgXrINfhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b625928-5a1c-46ed-d52d-33634b804cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target word is markov\n",
            "len of sentences 4\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 150\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is gradient descent\n",
            "len of sentences 106\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is supervised learning\n",
            "len of sentences 75\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is neural network\n",
            "len of sentences 969\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 9\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is component analysis\n",
            "len of sentences 7\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is time series\n",
            "len of sentences 33\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neural\n",
            "len of sentences 1711\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is neighbor\n",
            "len of sentences 273\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is monte carlo\n",
            "len of sentences 1\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is reinforcement learning\n",
            "len of sentences 27\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is hidden markov\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is model\n",
            "len of sentences 2308\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is reinforcement\n",
            "len of sentences 152\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is gradient\n",
            "len of sentences 369\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is learning\n",
            "len of sentences 1948\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is machine learning\n",
            "len of sentences 14\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is gaussian\n",
            "len of sentences 75\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is markov\n",
            "len of sentences 7\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 262\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is gradient descent\n",
            "len of sentences 231\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is supervised learning\n",
            "len of sentences 120\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is neural network\n",
            "len of sentences 1292\n",
            "len of t1 59\n",
            "len of each target word extractions is 59\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 14\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is component analysis\n",
            "len of sentences 13\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is time series\n",
            "len of sentences 74\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is neural\n",
            "len of sentences 1946\n",
            "len of t1 59\n",
            "len of each target word extractions is 59\n",
            "The target word is neighbor\n",
            "len of sentences 324\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is monte carlo\n",
            "len of sentences 1\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is reinforcement learning\n",
            "len of sentences 78\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is hidden markov\n",
            "len of sentences 2\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is model\n",
            "len of sentences 3797\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is reinforcement\n",
            "len of sentences 220\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is gradient\n",
            "len of sentences 634\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is learning\n",
            "len of sentences 2809\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is machine learning\n",
            "len of sentences 22\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is gaussian\n",
            "len of sentences 123\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is markov\n",
            "len of sentences 17\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 354\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is gradient descent\n",
            "len of sentences 203\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is supervised learning\n",
            "len of sentences 148\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is neural network\n",
            "len of sentences 1474\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 14\n",
            "len of t1 71\n",
            "len of each target word extractions is 71\n",
            "The target word is component analysis\n",
            "len of sentences 43\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is time series\n",
            "len of sentences 121\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is neural\n",
            "len of sentences 2273\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is neighbor\n",
            "len of sentences 453\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is monte carlo\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is reinforcement learning\n",
            "len of sentences 162\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is hidden markov\n",
            "len of sentences 6\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is model\n",
            "len of sentences 4506\n",
            "len of t1 65\n",
            "len of each target word extractions is 65\n",
            "The target word is reinforcement\n",
            "len of sentences 255\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is gradient\n",
            "len of sentences 636\n",
            "len of t1 64\n",
            "len of each target word extractions is 64\n",
            "The target word is learning\n",
            "len of sentences 3594\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is machine learning\n",
            "len of sentences 41\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is gaussian\n",
            "len of sentences 70\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is markov\n",
            "len of sentences 17\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 276\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is gradient descent\n",
            "len of sentences 128\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is supervised learning\n",
            "len of sentences 113\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neural network\n",
            "len of sentences 1002\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 43\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is component analysis\n",
            "len of sentences 111\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is time series\n",
            "len of sentences 130\n",
            "len of t1 10\n",
            "len of each target word extractions is 10\n",
            "The target word is neural\n",
            "len of sentences 1568\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is neighbor\n",
            "len of sentences 376\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is monte carlo\n",
            "len of sentences 1\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is reinforcement learning\n",
            "len of sentences 247\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is hidden markov\n",
            "len of sentences 6\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is model\n",
            "len of sentences 5817\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is reinforcement\n",
            "len of sentences 327\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is gradient\n",
            "len of sentences 618\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is learning\n",
            "len of sentences 3268\n",
            "len of t1 52\n",
            "len of each target word extractions is 52\n",
            "The target word is machine learning\n",
            "len of sentences 57\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is gaussian\n",
            "len of sentences 69\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is markov\n",
            "len of sentences 25\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 370\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is gradient descent\n",
            "len of sentences 125\n",
            "len of t1 11\n",
            "len of each target word extractions is 11\n",
            "The target word is supervised learning\n",
            "len of sentences 169\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is neural network\n",
            "len of sentences 598\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 29\n",
            "len of t1 8\n",
            "len of each target word extractions is 8\n",
            "The target word is component analysis\n",
            "len of sentences 132\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is time series\n",
            "len of sentences 84\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is neural\n",
            "len of sentences 1083\n",
            "len of t1 54\n",
            "len of each target word extractions is 54\n",
            "The target word is neighbor\n",
            "len of sentences 466\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is monte carlo\n",
            "len of sentences 14\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is reinforcement learning\n",
            "len of sentences 208\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is hidden markov\n",
            "len of sentences 8\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is model\n",
            "len of sentences 6874\n",
            "len of t1 47\n",
            "len of each target word extractions is 47\n",
            "The target word is reinforcement\n",
            "len of sentences 274\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is gradient\n",
            "len of sentences 646\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is learning\n",
            "len of sentences 3360\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is machine learning\n",
            "len of sentences 96\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is gaussian\n",
            "len of sentences 79\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_map3 = {\n",
        "\n",
        "    \"embed_C1\":embed_C1,\n",
        "    \"embed_C2\":embed_C2,\n",
        "    \"embed_C3\":embed_C3,\n",
        "    \"embed_C4\":embed_C4,\n",
        "    \"embed_C5\":embed_C5\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_4.pickle', 'wb+') as f:\n",
        "     pickle.dump(saved_map3, f)"
      ],
      "metadata": {
        "id": "90ABnsNnpfoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")"
      ],
      "metadata": {
        "id": "zxrA_kgTja8f",
        "outputId": "9577221d-463c-4c87-f948-86df4ec26b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_full,embed_C6,len_c6,sents=embeddings_extract(target_words,target_toks,doc6,index_t6)\n",
        "embed_full,embed_C7,len_c7,sents=embeddings_extract(target_words,target_toks,doc7,index_t7)\n",
        "embed_full,embed_C8,len_c8,sents=embeddings_extract(target_words,target_toks,doc8,index_t8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "saved_map4 =  {\n",
        "    \"embed_C6\":embed_C6,\n",
        "    \"embed_C7\":embed_C7,\n",
        "    \"embed_C8\":embed_C8\n",
        "    }\n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_4.pickle', 'ab+') as f:\n",
        "     pickle.dump(saved_map4, f)"
      ],
      "metadata": {
        "id": "IYYRTC_nOc4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ada236-e381-4300-a3c9-ba1127587313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target word is markov\n",
            "len of sentences 54\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is deep learning\n",
            "len of sentences 1\n",
            "len of t1 4\n",
            "len of each target word extractions is 4\n",
            "The target word is supervised\n",
            "len of sentences 737\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is gradient descent\n",
            "len of sentences 115\n",
            "len of t1 26\n",
            "len of each target word extractions is 26\n",
            "The target word is supervised learning\n",
            "len of sentences 323\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is neural network\n",
            "len of sentences 335\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 201\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is component analysis\n",
            "len of sentences 132\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is time series\n",
            "len of sentences 100\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is neural\n",
            "len of sentences 934\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is neighbor\n",
            "len of sentences 780\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is monte carlo\n",
            "len of sentences 10\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is reinforcement learning\n",
            "len of sentences 177\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is hidden markov\n",
            "len of sentences 12\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is model\n",
            "len of sentences 9509\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is reinforcement\n",
            "len of sentences 289\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is gradient\n",
            "len of sentences 697\n",
            "len of t1 13\n",
            "len of each target word extractions is 13\n",
            "The target word is learning\n",
            "len of sentences 4368\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is machine learning\n",
            "len of sentences 254\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is gaussian\n",
            "len of sentences 131\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is markov\n",
            "len of sentences 47\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is deep learning\n",
            "len of sentences 3\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is supervised\n",
            "len of sentences 1069\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is gradient descent\n",
            "len of sentences 193\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is supervised learning\n",
            "len of sentences 475\n",
            "len of t1 41\n",
            "len of each target word extractions is 41\n",
            "The target word is neural network\n",
            "len of sentences 220\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 175\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is component analysis\n",
            "len of sentences 118\n",
            "len of t1 43\n",
            "len of each target word extractions is 43\n",
            "The target word is time series\n",
            "len of sentences 147\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neural\n",
            "len of sentences 865\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is neighbor\n",
            "len of sentences 892\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is monte carlo\n",
            "len of sentences 3\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is reinforcement learning\n",
            "len of sentences 201\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is hidden markov\n",
            "len of sentences 15\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is model\n",
            "len of sentences 12092\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is reinforcement\n",
            "len of sentences 259\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is gradient\n",
            "len of sentences 1382\n",
            "len of t1 14\n",
            "len of each target word extractions is 14\n",
            "The target word is learning\n",
            "len of sentences 5232\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is machine learning\n",
            "len of sentences 306\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is gaussian\n",
            "len of sentences 105\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is markov\n",
            "len of sentences 103\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is deep learning\n",
            "len of sentences 31\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is supervised\n",
            "len of sentences 1672\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is gradient descent\n",
            "len of sentences 338\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is supervised learning\n",
            "len of sentences 554\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is neural network\n",
            "len of sentences 323\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 290\n",
            "len of t1 53\n",
            "len of each target word extractions is 53\n",
            "The target word is component analysis\n",
            "len of sentences 182\n",
            "len of t1 35\n",
            "len of each target word extractions is 35\n",
            "The target word is time series\n",
            "len of sentences 263\n",
            "len of t1 30\n",
            "len of each target word extractions is 30\n",
            "The target word is neural\n",
            "len of sentences 1265\n",
            "len of t1 46\n",
            "len of each target word extractions is 46\n",
            "The target word is neighbor\n",
            "len of sentences 1132\n",
            "len of t1 45\n",
            "len of each target word extractions is 45\n",
            "The target word is monte carlo\n",
            "len of sentences 19\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is reinforcement learning\n",
            "len of sentences 371\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is hidden markov\n",
            "len of sentences 26\n",
            "len of t1 42\n",
            "len of each target word extractions is 42\n",
            "The target word is model\n",
            "len of sentences 17683\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is reinforcement\n",
            "len of sentences 426\n",
            "len of t1 18\n",
            "len of each target word extractions is 18\n",
            "The target word is gradient\n",
            "len of sentences 2165\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is learning\n",
            "len of sentences 8871\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is machine learning\n",
            "len of sentences 584\n",
            "len of t1 57\n",
            "len of each target word extractions is 57\n",
            "The target word is gaussian\n",
            "len of sentences 157\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_full,embed_C9,len_c9,sents=embeddings_extract(target_words,target_toks,doc9,index_t9)\n",
        "embed_full,embed_C10,len_c10,sents=embeddings_extract(target_words,target_toks,doc10,index_t10)\n",
        "\n",
        "\n",
        "\n",
        "saved_map5 = {\n",
        "    \"embed_C9\":embed_C9,\n",
        "    \"embed_C10\":embed_C10,\n",
        "    \"sents\":sents,\n",
        "    \"embed_full\":embed_full\n",
        "}\n",
        "    \n",
        "\n",
        "import pickle\n",
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_4.pickle', 'ab+') as f:\n",
        "     pickle.dump(saved_map5, f)"
      ],
      "metadata": {
        "id": "vV-hWLnYOjFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8882fd7c-2ee5-4914-b983-a866737cec32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target word is markov\n",
            "len of sentences 136\n",
            "len of t1 15\n",
            "len of each target word extractions is 15\n",
            "The target word is deep learning\n",
            "len of sentences 95\n",
            "len of t1 17\n",
            "len of each target word extractions is 17\n",
            "The target word is supervised\n",
            "len of sentences 1583\n",
            "len of t1 39\n",
            "len of each target word extractions is 39\n",
            "The target word is gradient descent\n",
            "len of sentences 553\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is supervised learning\n",
            "len of sentences 565\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is neural network\n",
            "len of sentences 710\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 221\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is component analysis\n",
            "len of sentences 288\n",
            "len of t1 34\n",
            "len of each target word extractions is 34\n",
            "The target word is time series\n",
            "len of sentences 379\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n",
            "The target word is neural\n",
            "len of sentences 2004\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is neighbor\n",
            "len of sentences 1539\n",
            "len of t1 16\n",
            "len of each target word extractions is 16\n",
            "The target word is monte carlo\n",
            "len of sentences 35\n",
            "len of t1 25\n",
            "len of each target word extractions is 25\n",
            "The target word is reinforcement learning\n",
            "len of sentences 535\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is hidden markov\n",
            "len of sentences 30\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is model\n",
            "len of sentences 21800\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is reinforcement\n",
            "len of sentences 618\n",
            "len of t1 40\n",
            "len of each target word extractions is 40\n",
            "The target word is gradient\n",
            "len of sentences 3461\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is learning\n",
            "len of sentences 11441\n",
            "len of t1 29\n",
            "len of each target word extractions is 29\n",
            "The target word is machine learning\n",
            "len of sentences 807\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is gaussian\n",
            "len of sentences 272\n",
            "len of t1 37\n",
            "len of each target word extractions is 37\n",
            "The target word is markov\n",
            "len of sentences 197\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is deep learning\n",
            "len of sentences 507\n",
            "len of t1 36\n",
            "len of each target word extractions is 36\n",
            "The target word is supervised\n",
            "len of sentences 2443\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is gradient descent\n",
            "len of sentences 1108\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is supervised learning\n",
            "len of sentences 888\n",
            "len of t1 22\n",
            "len of each target word extractions is 22\n",
            "The target word is neural network\n",
            "len of sentences 3042\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is dimensionality reduction\n",
            "len of sentences 204\n",
            "len of t1 23\n",
            "len of each target word extractions is 23\n",
            "The target word is component analysis\n",
            "len of sentences 259\n",
            "len of t1 31\n",
            "len of each target word extractions is 31\n",
            "The target word is time series\n",
            "len of sentences 444\n",
            "len of t1 19\n",
            "len of each target word extractions is 19\n",
            "The target word is neural\n",
            "len of sentences 5179\n",
            "len of t1 32\n",
            "len of each target word extractions is 32\n",
            "The target word is neighbor\n",
            "len of sentences 1918\n",
            "len of t1 28\n",
            "len of each target word extractions is 28\n",
            "The target word is monte carlo\n",
            "len of sentences 71\n",
            "len of t1 20\n",
            "len of each target word extractions is 20\n",
            "The target word is reinforcement learning\n",
            "len of sentences 615\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is hidden markov\n",
            "len of sentences 45\n",
            "len of t1 24\n",
            "len of each target word extractions is 24\n",
            "The target word is model\n",
            "len of sentences 28578\n",
            "len of t1 58\n",
            "len of each target word extractions is 58\n",
            "The target word is reinforcement\n",
            "len of sentences 705\n",
            "len of t1 21\n",
            "len of each target word extractions is 21\n",
            "The target word is gradient\n",
            "len of sentences 6608\n",
            "len of t1 27\n",
            "len of each target word extractions is 27\n",
            "The target word is learning\n",
            "len of sentences 15608\n",
            "len of t1 38\n",
            "len of each target word extractions is 38\n",
            "The target word is machine learning\n",
            "len of sentences 1459\n",
            "len of t1 12\n",
            "len of each target word extractions is 12\n",
            "The target word is gaussian\n",
            "len of sentences 412\n",
            "len of t1 33\n",
            "len of each target word extractions is 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply K-NN with Cosine Similarity "
      ],
      "metadata": {
        "id": "0Pd6JvLB5k9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "UmdHFHk3ytYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/gdrive/My Drive/Master_dataset/bert_embeddings_4.pickle', 'rb+') as f:\n",
        "  saved_map3 = pickle.load(f)\n",
        "  saved_map4 = pickle.load(f)\n",
        "  saved_map5 = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "2FS2lzDHwl5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_map = {\n",
        "    **saved_map3,\n",
        "    **saved_map4,\n",
        "    **saved_map5\n",
        "}"
      ],
      "metadata": {
        "id": "9jflIY7k5CD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(saved_map[\"embed_C7\"][0][0])"
      ],
      "metadata": {
        "id": "tER4rF1JhoJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22d686c-bd2c-45d1-c0e4-9a514dfdb872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_C1 = saved_map[\"embed_C1\"]\n",
        "embed_C2 = saved_map[\"embed_C2\"]\n",
        "embed_C3 = saved_map[\"embed_C3\"]\n",
        "embed_C4 = saved_map[\"embed_C4\"]\n",
        "embed_C5 = saved_map[\"embed_C5\"]\n",
        "embed_C6 = saved_map[\"embed_C6\"]\n",
        "embed_C7 = saved_map[\"embed_C7\"]\n",
        "embed_C8 = saved_map[\"embed_C8\"]\n",
        "embed_C9 = saved_map[\"embed_C9\"]\n",
        "embed_C10 = saved_map[\"embed_C10\"]"
      ],
      "metadata": {
        "id": "CPaPK6goyQUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-NN to calculate the Nearest neighbor of keywords\n",
        "\n",
        "def convert_tensors_tolist(mapping):\n",
        "  for i, word_sentences in enumerate(mapping):\n",
        "        # Use below line whe converting tensors to numpy array\n",
        "        X1=np.array([np.array(x.to('cpu')) for x in word_sentences])\n",
        "\n",
        "        # X1=np.array([np.array(x) for x in word_sentences])\n",
        "        X1=X1.sum(axis=0).tolist()\n",
        "        mapping[i] = X1\n",
        "  return mapping\n",
        "\n",
        "\n",
        "\n",
        "def convert_v_tolist(v):\n",
        "\n",
        "  for i, word in enumerate(v):\n",
        "        # Use below line whe converting tensors to numpy array\n",
        "        w = np.array(word.to('cpu')).tolist()\n",
        "        v[i] = w\n",
        "\n",
        "  return v"
      ],
      "metadata": {
        "id": "5bVz7KBItoEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### FLATTEN tensors of sentences of respective words to 1-D\n",
        "\n",
        "embed_C1_ = convert_tensors_tolist(embed_C1)\n",
        "embed_C2_ = convert_tensors_tolist(embed_C2)\n",
        "embed_C3_ = convert_tensors_tolist(embed_C3)\n",
        "embed_C4_ = convert_tensors_tolist(embed_C4)\n",
        "embed_C5_ = convert_tensors_tolist(embed_C5)\n",
        "embed_C6_ = convert_tensors_tolist(embed_C6)\n",
        "embed_C7_ = convert_tensors_tolist(embed_C7)\n",
        "embed_C8_ = convert_tensors_tolist(embed_C8)\n",
        "embed_C9_ = convert_tensors_tolist(embed_C9)\n",
        "embed_C10_ = convert_tensors_tolist(embed_C10)\n",
        "\n"
      ],
      "metadata": {
        "id": "PEb6gAo3BTJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1_emb_ = convert_v_tolist(v1_emb)\n",
        "v2_emb_ = convert_v_tolist(v2_emb)\n",
        "v3_emb_ = convert_v_tolist(v3_emb)\n",
        "v4_emb_ = convert_v_tolist(v4_emb)\n",
        "v5_emb_ = convert_v_tolist(v5_emb)\n",
        "v6_emb_ = convert_v_tolist(v6_emb)\n",
        "v7_emb_ = convert_v_tolist(v7_emb)\n",
        "v8_emb_ = convert_v_tolist(v8_emb)\n",
        "v9_emb_ = convert_v_tolist(v9_emb)\n",
        "v10_emb_ = convert_v_tolist(v10_emb)\n"
      ],
      "metadata": {
        "id": "5bVQiFa0Toqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed_C2_[0])"
      ],
      "metadata": {
        "id": "pQZIuXhYIl-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108d5c08-a7b7-44fb-f8e9-0a80f9370788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def _nn_(V, X):\n",
        "  model = NearestNeighbors(n_neighbors=10,\n",
        "                          metric='cosine',\n",
        "                          algorithm='brute',\n",
        "                          n_jobs=-1)\n",
        "\n",
        "  n_n = model.fit(V)  \n",
        "  distance, indeces = model.kneighbors(X)\n",
        "\n",
        "\n",
        "  return indeces\n"
      ],
      "metadata": {
        "id": "lwAm7M0MHUvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indeces_1 = nn_(embed_C1_)\n",
        "\n",
        "indeces1 = _nn_(v1_emb_ , embed_C1_)\n",
        "indeces2 = _nn_(v2_emb_ , embed_C2_)\n",
        "indeces3 = _nn_(v3_emb_ , embed_C3_)\n",
        "indeces4 = _nn_(v4_emb_ , embed_C4_)\n",
        "indeces5 = _nn_(v5_emb_ , embed_C5_)\n",
        "indeces6 = _nn_(v6_emb_ , embed_C6_)\n",
        "indeces7 = _nn_(v7_emb_ , embed_C7_)\n",
        "indeces8 = _nn_(v8_emb_ , embed_C8_)\n",
        "indeces9 = _nn_(v9_emb_ , embed_C9_)\n",
        "indeces10 = _nn_(v10_emb_ , embed_C10_)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rGjvILCoRe6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(v1_emb_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2UctKzBrbs",
        "outputId": "dee13ef4-7e80-47ba-b9a8-c4b72400a5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1276"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeces1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx3IX9ZMITu7",
        "outputId": "eaf1afe3-95fe-45e8-9a7f-d64bf5db7057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 409,  741,   53, 1081, 1221,  800,  494,  822,  689,  225])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GET NEAREST NEIGHBORS"
      ],
      "metadata": {
        "id": "mKlotxZxOXG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_nearest_keywords_(indeces, v,keywords_np=monitering_keywords):\n",
        "  tup_nearest_neighbor = []\n",
        "  v = np.array(v)\n",
        "  for index, candidate_keyword in enumerate(keywords_np):\n",
        "      # Take the current index of the keyword and get the list of 10 nearest index from KNN algorithm\n",
        "      nearest_neighbors_indeces_of_current_keyword = indeces[index]\n",
        "\n",
        "      # Filter the keyword list using the list of indeces obtained in previous step\n",
        "      nearest_keywords = v[nearest_neighbors_indeces_of_current_keyword]\n",
        "\n",
        "      # Create tuple with first element as the keyword for current iteration and 2nd element as list of its nearest neighbors\n",
        "      tup_nearest_neighbor.append({candidate_keyword : set(nearest_keywords)})\n",
        "\n",
        "\n",
        "  return tup_nearest_neighbor"
      ],
      "metadata": {
        "id": "WdBcyanMKGVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_1 = get_nearest_keywords_(indeces1, v1)\n",
        "nn_2 = get_nearest_keywords_(indeces2, v2)\n",
        "nn_3 = get_nearest_keywords_(indeces3, v3)\n",
        "nn_4 = get_nearest_keywords_(indeces4, v4)\n",
        "nn_5 = get_nearest_keywords_(indeces5, v5)\n",
        "nn_6 = get_nearest_keywords_(indeces6, v6)\n",
        "nn_7 = get_nearest_keywords_(indeces7, v7)\n",
        "nn_8 = get_nearest_keywords_(indeces8, v8)\n",
        "nn_9 = get_nearest_keywords_(indeces9, v9)\n",
        "nn_10 = get_nearest_keywords_(indeces10, v10)\n"
      ],
      "metadata": {
        "id": "68S9WFs4Kgmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2"
      ],
      "metadata": {
        "id": "RzJLQ3lYLKz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_target_nn(nn, monitering_keywords = monitering_keywords):\n",
        "    return [n for n in nn for key in list(n.keys()) if key in monitering_keywords]\n",
        "    "
      ],
      "metadata": {
        "id": "BnWxBHdAg6xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2_ = get_target_nn(nn_2)\n",
        "nn_3_ = get_target_nn(nn_3)\n",
        "nn_4_ = get_target_nn(nn_4)\n",
        "nn_5_ = get_target_nn(nn_5)\n",
        "nn_6_ = get_target_nn(nn_6)\n",
        "nn_7_ = get_target_nn(nn_7)\n",
        "nn_8_ = get_target_nn(nn_8)\n",
        "nn_9_ = get_target_nn(nn_9)\n",
        "nn_10_ = get_target_nn(nn_10)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QBae2ny_XDFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2_[9][\"Machine Learning\"].intersection(nn_3_[9][\"Machine Learning\"])"
      ],
      "metadata": {
        "id": "rNv_LeWZYx_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nn_10_[0][\"Reinforcement Learning\"])"
      ],
      "metadata": {
        "id": "86ZMV8dhYoPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_10_"
      ],
      "metadata": {
        "id": "Ac9KJ-sEC-0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870d2b31-27ba-4b02-fe00-717fc5c1d35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'markov': {'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'high-dimensional',\n",
              "   'hyperparameter-optimized',\n",
              "   'hyperparameters',\n",
              "   'log-likelihood',\n",
              "   'low-dimensional',\n",
              "   'multi-variate',\n",
              "   'parameterss.',\n",
              "   'trace-norm'}},\n",
              " {'deep learning': {'bonawitz',\n",
              "   'datasets.',\n",
              "   'ecom',\n",
              "   'embeddings',\n",
              "   'jean.lafond',\n",
              "   'lafond',\n",
              "   'olga.klopp',\n",
              "   'parameterss.',\n",
              "   'rouby',\n",
              "   'soft-thresholding'}},\n",
              " {'supervised': {'conversely',\n",
              "   'eigen-analysis',\n",
              "   'hyper-parameter',\n",
              "   'hyperparameters',\n",
              "   'inferential',\n",
              "   'matrix-vector',\n",
              "   'parameterss.',\n",
              "   'real-valued',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'gradient descent': {'combinatorial',\n",
              "   'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'log-likelihood',\n",
              "   'multi-variate',\n",
              "   'non-linearity',\n",
              "   'parameterss.',\n",
              "   'real-valued',\n",
              "   'stochastic',\n",
              "   'trace-norm'}},\n",
              " {'supervised learning': {'conversely',\n",
              "   'eigen-analysis',\n",
              "   'hyper-parameter',\n",
              "   'hyperparameters',\n",
              "   'inferential',\n",
              "   'matrix-vector',\n",
              "   'parameterss.',\n",
              "   'real-valued',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'neural network': {'cross-entropy',\n",
              "   'datasets.',\n",
              "   'discriminativetraining',\n",
              "   'eigen-analysis',\n",
              "   'embeddings',\n",
              "   'generativetraining',\n",
              "   'neural-network',\n",
              "   'parameterss.',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'dimensionality reduction': {'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'hyper-parameter',\n",
              "   'hyperparameter-optimized',\n",
              "   'hyperparameters',\n",
              "   'inferential',\n",
              "   'multi-variate',\n",
              "   'non-linearity',\n",
              "   'parameterss.',\n",
              "   'trace-norm'}},\n",
              " {'component analysis': {'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'high-dimensional',\n",
              "   'hyperparameter-optimized',\n",
              "   'low-dimensional',\n",
              "   'multi-variate',\n",
              "   'parameterss.',\n",
              "   'stochastic',\n",
              "   'three-dimensional',\n",
              "   'trace-norm'}},\n",
              " {'time series': {'constant.',\n",
              "   'data.',\n",
              "   'datasets.',\n",
              "   'equational',\n",
              "   'exponential',\n",
              "   'iteration',\n",
              "   'nuclear-norm',\n",
              "   'parameterss.',\n",
              "   'problems.',\n",
              "   'variational'}},\n",
              " {'neural': {'cross-entropy',\n",
              "   'datasets.',\n",
              "   'discriminativetraining',\n",
              "   'eigen-analysis',\n",
              "   'embeddings',\n",
              "   'generativetraining',\n",
              "   'neural-network',\n",
              "   'parameterss.',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'neighbor': {'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'high-dimensional',\n",
              "   'hyperparameter',\n",
              "   'hyperparameters',\n",
              "   'low-dimensional',\n",
              "   'multi-variate',\n",
              "   'parameterss.',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'monte carlo': {'approaches.',\n",
              "   'combinatorially',\n",
              "   'computationally',\n",
              "   'cross-entropy',\n",
              "   'datasets.',\n",
              "   'eigen-analysis',\n",
              "   'hyperparameter-optimized',\n",
              "   'hyperparameters',\n",
              "   'neural-network',\n",
              "   'parameterss.'}},\n",
              " {'reinforcement learning': {'datasets.',\n",
              "   'hyper-parameter',\n",
              "   'hyperparameter-optimized',\n",
              "   'integer-based',\n",
              "   'iterative',\n",
              "   'multitask',\n",
              "   'parameterize',\n",
              "   'parameterss.',\n",
              "   'scalar',\n",
              "   'toolkit'}},\n",
              " {'hidden markov': {'cross-entropy',\n",
              "   'datasets.',\n",
              "   'eigen-analysis',\n",
              "   'embeddings',\n",
              "   'graph-based',\n",
              "   'hyperparameter-optimized',\n",
              "   'hyperparameters',\n",
              "   'multi-variate',\n",
              "   'parameterss.',\n",
              "   'trace-norm'}},\n",
              " {'model': {'+tsvm',\n",
              "   'datasets.',\n",
              "   'hyperparameter-optimized',\n",
              "   'hyperparameters',\n",
              "   'minj=',\n",
              "   'parameterss.',\n",
              "   'rectified-linear',\n",
              "   'super-exponentially',\n",
              "   'trace-norm',\n",
              "   'zero-mean'}},\n",
              " {'reinforcement': {'datasets.',\n",
              "   'hyper-parameter',\n",
              "   'hyperparameter-optimized',\n",
              "   'integer-based',\n",
              "   'iterative',\n",
              "   'multitask',\n",
              "   'parameterize',\n",
              "   'parameterss.',\n",
              "   'scalar',\n",
              "   'toolkit'}},\n",
              " {'gradient': {'combinatorial',\n",
              "   'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'log-likelihood',\n",
              "   'multi-variate',\n",
              "   'non-linearity',\n",
              "   'parameterss.',\n",
              "   'real-valued',\n",
              "   'stochastic',\n",
              "   'trace-norm'}},\n",
              " {'learning': {'baldi',\n",
              "   'combinatorially',\n",
              "   'eigen-analysis',\n",
              "   'hyperparameter-optimized',\n",
              "   'koltchinskii',\n",
              "   'montanari',\n",
              "   'multi-variate',\n",
              "   'parameterss.',\n",
              "   'trace-norm',\n",
              "   'word-vectors'}},\n",
              " {'machine learning': {'combinatorially',\n",
              "   'combinatorics',\n",
              "   'computationally',\n",
              "   'datasets.',\n",
              "   'hyperparameter-optimized',\n",
              "   'integration',\n",
              "   'matrices.',\n",
              "   'optimization',\n",
              "   'parameterss.',\n",
              "   'theorem-proving'}},\n",
              " {'gaussian': {'cross-entropy',\n",
              "   'eigen-analysis',\n",
              "   'high-dimensional',\n",
              "   'klopp',\n",
              "   'krehl',\n",
              "   'multi-variate',\n",
              "   'olga.klopp',\n",
              "   'parameterss.',\n",
              "   'trace-norm',\n",
              "   'uller'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_slice_nn = [nn_2_, nn_3_, nn_4_ , nn_5_ , nn_6_, nn_7_ , nn_8_ , nn_9_ , nn_10_]"
      ],
      "metadata": {
        "id": "Igv6VTt1qIWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def log_stability(A, B, keyword):\n",
        "  a = len(A.intersection(B))\n",
        "  b = len(A - B)\n",
        "  # print(f\"{keyword} : Intersection {a} - Subtract {b} :\")\n",
        "  if a == 0:\n",
        "    return round( math.log10(1 / 10 ), 3)\n",
        "  elif b == 0:\n",
        "    return  -1 * round( math.log10( 10  ) , 3)\n",
        "  else:\n",
        "    return round ( math.log10( a  /  b  ) , 3)\n",
        "\n",
        "\n",
        "def calc_stability(nn, keyword):\n",
        "    i = 0\n",
        "    stability = []\n",
        "    for _,n in enumerate(nn):\n",
        "       i = _ + 1\n",
        "\n",
        "       if i < len(nn):\n",
        "          stability.append( log_stability(nn[_], nn[i] , keyword) )\n",
        "\n",
        "    return stability\n",
        "\n",
        "def extract_keyword_nns(target_nn_10tw, keyword):\n",
        "    keyword_neighbors_all_windows = []\n",
        "    for _ , target_nn in enumerate(target_nn_10tw):\n",
        "\n",
        "      keyword_neighbors_all_windows.extend([target[keyword] for index, target in enumerate(target_nn) if list(target.keys())[0] == keyword ])\n",
        "    \n",
        "    s = calc_stability(keyword_neighbors_all_windows, keyword)\n",
        "    \n",
        "    return s\n",
        "\n",
        "def extract_stability(target_nn_10tw):\n",
        "    s_n = []\n",
        "    for _ , keyword in enumerate(monitering_keywords):\n",
        "       s_n.append( { keyword: extract_keyword_nns(target_nn_10tw, keyword) } )\n",
        "\n",
        "    return s_n"
      ],
      "metadata": {
        "id": "yqLHw5F5XbA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_stab = extract_stability(all_slice_nn)\n",
        "keyword_stab"
      ],
      "metadata": {
        "id": "e5EfLzPzzbFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c61e219-efba-4b4a-f42c-85d8d086ebf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'markov': [-1.0, -1.0, -1.0, -1.0, -0.954, -0.602, -0.602, -0.954]},\n",
              " {'deep learning': [-0.368, -0.368, -0.368, -0.602, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'supervised': [-1.0, -1.0, -1.0, -0.954, -1.0, -0.954, -1.0, -1.0]},\n",
              " {'gradient descent': [-1.0, -0.954, -1.0, -1.0, -0.954, -1.0, -1.0, -0.954]},\n",
              " {'supervised learning': [-1.0, -1.0, -1.0, -1.0, -1.0, -0.954, -1.0, -0.954]},\n",
              " {'neural network': [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'dimensionality reduction': [-0.954,\n",
              "   -0.954,\n",
              "   -0.954,\n",
              "   -1.0,\n",
              "   -1.0,\n",
              "   -0.602,\n",
              "   -0.368,\n",
              "   -1.0]},\n",
              " {'component analysis': [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'time series': [-1.0, -1.0, -1.0, -1.0, -0.954, -0.602, -1.0, -0.954]},\n",
              " {'neural': [-1.0, -1.0, -1.0, -1.0, -0.368, -1.0, -0.954, -1.0]},\n",
              " {'neighbor': [-1.0, -1.0, -1.0, -0.602, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'monte carlo': [-1.0, -1.0, -0.954, -1.0, -1.0, -1.0, -0.954, -0.954]},\n",
              " {'reinforcement learning': [-1.0,\n",
              "   -0.954,\n",
              "   -1.0,\n",
              "   -0.954,\n",
              "   -1.0,\n",
              "   -1.0,\n",
              "   -1.0,\n",
              "   -1.0]},\n",
              " {'hidden markov': [-0.954, -0.954, -1.0, -1.0, -1.0, -0.602, -0.602, -0.954]},\n",
              " {'model': [-0.954, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'reinforcement': [-1.0, -1.0, -1.0, -0.954, -1.0, -1.0, -1.0, -1.0]},\n",
              " {'gradient': [-1.0, -0.954, -0.954, -0.368, -0.602, -1.0, -1.0, -1.0]},\n",
              " {'learning': [-1.0, -1.0, -1.0, -1.0, -1.0, -0.954, -1.0, -1.0]},\n",
              " {'machine learning': [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.954]},\n",
              " {'gaussian': [-0.954, -1.0, -1.0, -0.602, -0.602, -1.0, -1.0, -1.0]}]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_stability(nn_8_[0][\"Reinforcement Learning\"], nn_7_[0][\"Reinforcement Learning\"])\n"
      ],
      "metadata": {
        "id": "ROcoZZiyzZaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = [n for n in nn_2_] \n",
        "\n",
        "\n",
        "\n",
        "list(nn_2_[0].keys())[0]"
      ],
      "metadata": {
        "id": "O0LyJM3F04gM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}